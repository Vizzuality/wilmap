nid,i_region,i_country,aux,transnational,title,topic,body,focus_area,post_date,uid,author,type
5261,,United States,0,0,DMCA Safeharbor Faces $1 Billion Test,Copyright,"<p>It's finally happened. <a href=""http://money.cnn.com/2007/03/13/news/companies/youtube_viacom_reaction/index.htm?cnn=yes"">Viacom has sued Google</a> for $1 billion in damages for copyright infringement over videos posted on YouTube. This case will be a great test for exactly how powerful the DMCA Safeharbor protections actually are. </p>
<!--break--><p>Section 512(c) of the DMCA seems to free GooTube from liability for ""infringement of copyright by reason of the storage at the direction of a user of material that resides on a system or network controlled or operated by [YouTube]"" if it sets up a notice and takedown system. Such a system places the burden on the content owners to inform YouTube of copyright violations, which YouTube must then take down. <a href=""http://www.forbes.com/markets/2007/02/02/viacom-youtube-google-markets-equity-cx_lh_0202markets20.html"">Viacom recently demanded</a> that YouTube remove 100,000 allegedly infringing videos, and I would assume YouTube has complied with the takedown requirements (though many of those videos were <a href=""http://www.eff.org/deeplinks/archives/005109.php"">clearly not</a> Viacom owned content).</p>
<p>So it if YouTube is complying with the notice and takedown procedures, the 512 safeharbor should protect it right? Not necessarily.</p>
<p>There are two other requirements that YouTube must comply with to get protection under the safeharbor. </p>
<p>First, it must not have (1) actual knowledge of the infringement, (2) awareness of ""facts or circumstances from which infringing activity is apparent,"" or (3) if it does have either of these, it must remove the infringing materials. I haven't seen the complaint, but from the articles I've read, it sounds like Viacom is arguing that YouTube knows or should know that infringement is occurring on the site. But how much knowledge is required here? Is it enough for YouTube to know that this is generally happening, or does it need to know that a specific video is infringing? If the safeharbors are to be at all useful in protecting service providers, the latter must be the case. Otherwise, YouTube would have to proactively police all the content on its system, which is a heavy burden (and one the safeharbors seemed designed to remove). Viacom wants YouTube to actively seek out infringing materials using filtering software, but if Section 512 does anything at all, it shifts the burden from the service provider to the content owners. Viacom is in the better position to police the materials, since Viacom presumably knows what content it owns rights to, whereas YouTube can't know (without the content owner's help) whether a given clip is copyrighted or not.</p>
<p>Second, the safeharbor requires that YouTube ""not receive a financial benefit directly attributable to the infringing activity"" if YouTube ""has the right and ability to control such activity."" But how ""direct"" is direct? Does the fact that videos bring people to the site, thus increasing the audience for banner ads, count as ""direct"", even if the ads are not on the video pages themselves? Read broadly, this could mean any service provider engaged in a for profit venture cannot qualify for the 512 safeharbor. But again, that would relegate the safeharbor to protecting a tiny portion of service providers. ""Directly attributable"" must require a closer nexus between the infringing activity and the financial benefit. YouTube has avoided such a direct benefit by keeping banner ads off the video pages. </p>
<p>Whether the court interprets these requirements broadly or narrowly will determine whether the DMCA Safeharbors are to have any relevance in the future of technological innovation. If Viacom prevails, the Safeharbor will essentially be gutted, leaving service providers in a murky realm of liability the Safeharbor was designed to free them from in the first place. It seems to me that GooTube is on solid legal ground, but we'll see if the courts agree.</p>
",Copyright and Fair Use,2007-03-13 11:20,301,Henry Lien,News
5282,,United States,0,0,"Viacom v. YouTube:  Uncertainty, Investment And Innovation",Copyright,"<p>A lot has been said about Viacom's billion dollar lawsuit against YouTube and Google. In his <a href=""http://www.nytimes.com/2007/03/18/opinion/18lessig.html?_r=1&oref=slogin"">editorial</a> in last Sunday's New York Times, Larry Lessig pointed out the chaos the Supreme Court has invited through its new-found fondness for the common law of copyright. </p>
<p>One victim of this chaos may be investment and innovation. If companies cannot rely predictably on clear statutory protections like those the DMCA provides for online service providers who create open platforms for people to share content, then many innovators and investors may simply steer clear of this business in favor of one that offers more security and predictability. </p>
<!--break--><p>
I am not particularly concerned about the impact of this case on Viacom's pocketbook or Google's. But I am very concerned about what this battle of behemoths will mean for technology we have not even thought of yet. If technology with a multitude of lawful and fantastically beneficial uses suffers a billion dollar penalty because some use it to violate copyright laws, then it is technology, innovation -- and ultimately all of us -- that will suffer most.</p>
","Privacy, Copyright and Fair Use",2007-03-19 21:42,281,Anthony Falzone,News
5397,,United States,0,0,Universal Music's Second Strike,Copyright,"<p>Last year, Universal Music threatened Javier Prato with legal action for using ""I Will Survive"" in a humorous video posted on YouTube. It retreated after the Fair Use Project explained Prato's video was protected by Fair Use.</p>
<p>Now, Universal has targeted video blogger Michelle Malkin, who has been harshly critical of one of Universal's recording artists, the rapper Akon. Malkin posted a video blog on YouTube detailing (and showing) what appears to be footage of Akon assaulting a fifteen year old girl during a concert, and asking why his actions have not been addressed by Akon's label (Universal), his other sponsors, and certain politicians. In her video, Malkin includes footage from the concert at which this alleged assault happened, and other examples of what she asserts to be Akon's misognystic performances, in order to make her case. </p>
<p>So how did Universal respond? It apparently issued a DMCA takedown notice to YouTube on the ground Malkin's blog infringed its copyrights. The video was taken down from YouTube, but you can still see it <a href=""http://hotair.cachefly.net/video/vent/vent-00227-2007-05-03.m4v"">here</a>, on Malkin's blog. Read Malkin's discussion of the issue <a href=""http://michellemalkin.com/archives/007446.htm"">here</a>.</p>
<p>If Universal did issue this takedown notice, it needs to retract it and apologize at once. Copyright is not a tool to silence or remove speech you don't like.</p>
<!--break-->",Copyright and Fair Use,2007-05-07 21:05,281,Anthony Falzone,News
5402,,United States,0,0,Take Down Stay Down,Copyright,"<p>After a successful trial <a href=""http://www.myspace.com/"">MySpace</a> has <a href=""http://home.businesswire.com/portal/site/google/index.jsp?ndmViewId=news_view&newsId=20070511005160&newsLang=en"">announced</a> its novel “Take Down Stay Down” campaign. The idea is that upon reception of notice about unauthorized upload of copyrighted material, MySpace will not only remove the allegedly infringing file, but also take digital fingerprint of the accused content. It will then stored the information - which is essentially like shorthand numbers uniquely representing the file – in a database, making sure that the content will not be reposted on MySpace services. </p>
<!--break--><p> It is going to work like this: </p>
<blockquote><p>When a content owner informs MySpace that a user has improperly posted its content onto MySpace Videos, not only is the video promptly removed by MySpace, but MySpace also creates a digital fingerprint of the video content and adds it to its copyright filter, which is based on industry-leading Audible Magic technology. If any user tries to upload the same content that has been removed, the filter will recognize the digital fingerprint and block the content from being uploaded. This way, when copyright owners remove content from MySpace, they will have greater comfort that it will stay down and not be reposted.</p></blockquote>
<p>A few observations. First, under this arrangement copyright holders remain responsible for identifying the content themselves. MySpace will not do the initial filtering without individual notices. This might fall a bit shorter of fulfilling the content industry’s sweetest dream, but then again, a major breakthrough. </p>
<p>Second, is appease that MySpace will promptly take down the suspect files, without further inspection, upon reception of proper notice in line with the <a href=""http://www.myspace.com/Modules/Common/Pages/TermsConditions.aspx"">company policy</a> that mirrors the DMCA procedure. Proper notice alone, based on the statement of the notifying party, is all that is needed to trigger the process: A digital fingerprint will be taken and the file will be doomed to obsolescence on the popular social networking site (and later perhaps also on other sites belonging to News Corp.) </p>
<p>This much is pretty straightforward. It might get murky when a MySpace user files a counter notification, stating, in the language of the DMCA, “a good faith belief that the material was removed or disabled as a result of mistake or misidentification.” By the way, the language of Section 512(g)(3)(C) does not contemplate other reasons that could underlie a counter notification. One may assume that a take-down notice targeting noninfringing activity should be classified as “mistake” or “misidentification” - though in reality it is often neither. A recent example of abusing the procedure in an attempt to silence criticism is the one of <a href=""http://www.techdirt.com/articles/20070402/123201.shtml"">Uri Geller</a>.</p>
<p>Sure enough, MySpace does not have a general legal obligation to host any content, whether infringing or not. Nor is the company obligated under the DMCA to repost the removed content after it has been shown that the user did not infringe. Generally, if the service provider does not implement a certain procedure that ensures the repost of removed material - stipulated in Section 512(g)(2) - it cannot enjoy a general immunity from third-party liability as a result of the removal. Thus, MySpace and other service providers are free to indiscriminately and irreversibly execute take-down notifications at the price of giving up their third-party immunity, shielding, e.g., from legal claims invoked by angry subscribers that complain about the company manipulating “their spaces”. </p>
<p>Alternatively, providers may comply with Section 512(g)(2) and repost the content if the notifying party does not filed an action seeking a court order within two weeks after the counter notification was received. This is a kind of “double immunity” track, securing the service provider from copyright claims on one front, and from third parties’ claims on the other front. </p>
<p>At bottom, service provider are not obligated to follow the double immunity track, but if they do, the content initially removed will not necessarily “stay down” - as the catchy slogan suggests. Either way, a digital fingerprint will be taken and added to an ever-growing database of condemned files. It is not clear whether MySpace would choose to pursue the double immunity track. It is further unclear what it plans to do with the fingerprint once a take-down notice proved baseless. </p>
<p>If users are unhappy with the new policy they can always switch to an alternative platform, but for those who have already invested much time and energy in building up their spaces the switching costs are painfully high. The problem can become more general if fingerprinting and stay-down policies turn into a trend. For instance, <a href=""http://www.dailymotion.com/"">Dailymotion</a>, reportedly the world's largest independent video sharing site, <a href=""http://biz.yahoo.com/bw/070510/20070510006255.html?.v=1"">announced</a> last week it will implement the same fingerprinting technology. And of course, the billion dollars’ question - what is You-Tube up to? </p>
<p>Fingerprinting and other copyright filtering technologies will remain a hot topic in the near future as more market leaders are expected to be drawn into this copyright swamp. The mechanism adopted by MySpace gives rise to difficult legal questions. The blocking of subsequent attempts to upload the content is automatic and circumstances-insensitive. It does not require any further statement or declaration (under penalty of perjury or otherwise) by content owners. Yet posting the same work by one user in an infringing manner does not mean that posting the same work (or a portion thereof) by another would necessarily infringe as well. The latter could be protected under the fair use doctrine, for example, if the second attempt to post the file actually incorporates a smaller portion of the work as part of a derivative work aiming at criticizing the content owner. Another question is whether sabotaging the function of the filtering system will constitute a violation of the anticircumvention provisions. Would hacking into the database of fingerprints and manipulating the data violate section 1201? Does manipulation of the file to represent an altered value that nevertheless passes the filter constitute circumvention? What about section 1202? </p>
<p>It is important to clearly state the legitimate objections to the use of such DRMs before they become industry standard. People misuse the DMCA take-down procedure all the time and as it happens, only the most notorious and frivolous attempts <a href=""http://www.eff.org/legal/cases/sapient_v_geller/"">receive publicity and face effective opposition</a>. Usually, the content is taken down upon notice, whether infringing or not, without anyone caring about it. The “stay down” system will ensure that the content is further suppressed, again, without human decision-making and indication of infringement. The effect of private censorship made possible under the take-down policy is likely to intensify. The nightmare scenario is that fingerprinting are used by multiple large providers who exchange fingerprinting information while blocking also content that was taken down by other providers. </p>
<p>Users can always threat to boycott providers who implement blind take-down policies, or even try to sue them for unjustified removal of content based on a misuse of the take-down notice (what cause of action?) Whether this may convince ISPs to abandon the “take down stay down” policy or not, this slogan conjured in my mind the first amendment doctrine of prior restraints. This doctrine is typically relevant when the government’s suppression of speech takes place before speech had the chance to happen. The classic example is licensing laws, for example, a governmental licensing requirement imposed on newspapers publishers. This doctrine is rarely mentioned in the context of copyright. I assume that one reason is that state-supported infringement penalties and remedies are usually imposed after the speech has occurred, not beforehand. </p>
<p>The Supreme Court once held that “the special vice of prior restraint is that communication will be suppressed, either directly or by inducing excessive caution in the speaker, before an adequate determination that it is unprotected by the First Amendment.” Pittsburgh Press, 413 U.S. 376, 390 (1973). (This statement was made in the context of upholding a municipal ordinance which prohibited newspaper from carrying sex designated advertising columns for nonexempt job opportunities as not violating the newspaper publisher's First Amendment rights.)</p>
<p>Intuitively, the “stay down” feature can indeed suppress communication before it happens and before anyone has the chance to evaluate the justifications for suppression, either because the speech is obscene (as in the case quoted above) or because it infringes on copyrights. Of course, the two issues are not cut from the same cloth and one can doubt whether the first amendment is at all relevant in the first place. Service providers are not the government, and the government does not obligate anyone to use ""stay down"" DRMs. Still, the smell of censorship remains in the air, not less objectionable even when championed by private companies and in the name of copyright. </p>
",Copyright and Fair Use,2007-05-14 3:43,279,Zohar Efroni,News
5449,,Belgium,0,0,DRM by mandate? Belgium court imposes a filtering duty on ISP,Copyright,"<p>In a press release from today the <a href=""http://www.ifpi.org/"">IFPI</a> hails a Belgium court decision, which reportedly imposes a duty on an Internet Service Provider to use filtering technology for stopping illegal file sharing activities running through its network. From the press release: </p>
<blockquote><p>A court in Belgium has confirmed that an Internet Service Provider must take responsibility for stopping illegal file-sharing on its network. The ruling is the first of its kind in Europe … it sets an important precedent in the fight against piracy internationally … The judge said that ISPs have the technical means at their disposal to either block or filter copyright-infringing material on P2P networks and gave the ISP Scarlet (formerly Tiscali) six months to implement such measures.</p>
<p>The judgement pointed in particular to the filtering technology developed by Audible Magic. It also referred to six other possible solutions to block the traffic of unlicensed music, which are highlighted in an experts’ report commissioned by the court. This is the first case in Europe that has examined in detail the technologies that are available to block or filter copyright-infringing traffic on file-sharing networks.</p>
<p>IFPI Chairman and CEO John Kennedy said: “This is an extremely significant ruling which bears out exactly what we have been saying for the last two years - that the internet’s gatekeepers, the ISPs, have a responsibility to help control copyright-infringing traffic on their networks. The court has confirmed that the ISPs have both a legal responsibility and the technical means to tackle piracy. This is a decision that we hope will set the mould for government policy and for courts in other countries in Europe and around the world.”</p></blockquote>
<p>Two observations. I did not have the chance to read the decision yet, but assuming that the details are accurate, the defendant is an ISP for general internet connection services. In previous posts (<a href=""http://cyberlaw.stanford.edu/node/5358"">here</a> and also <a href=""http://cyberlaw.stanford.edu/node/5208"">here</a>) I have discussed the growing trend among companies like MySpace and YouTube to adopt fingerprinting technology in order to get copyright holders off their back and ensure that users do not exploit their services for illegal exchange of copyrighted material. The difference here is that filtering is not voluntary and that the court order is directed against a <em>general</em> ISP, not a service that allows users to upload files to the internet. When an ISP turns on a filtering system such as the one engineered by <a href=""http://www.audiblemagic.com/index.asp"">Audible Magic</a>, the user cannot simply switch to another service (say, a competing social networking website that does not police traffic) – without replacing provider of internet connection service. A user might have many legitimate reasons to object filtering that is applied, say, to a video sharing site, all the more when filtering affects the entire information exchange with the Internet. Now, if the duty to deploy filtering technology were a <em>legal duty </em> (as the Belgium court would have it), this duty should then apply to <em>all</em> ISPs in the jurisdiction. Switching out becomes impossible. In case that the duty to police internet traffic attaches directly to ISPs, filtering technology will become unavoidable, like a built-in fishing net hovering over cyberspace (at least from the perspective of users in jurisdictions that adopt such an approach.) </p>
<p>Second, it should be remembered that the assumption of technical and practical obstacles greatly influenced the safe harbor regime that currently maps the duties and responsibilities on ISPs wishing to avoid infringement liability. The assumption that monitoring the entire network traffic were infeasible stood at the basis of the pre-legislation bargains that eventually secured ISPs immunity under a statutory scheme. If it is true that ISPs now “have the technical means at their disposal to either block or filter copyright infringing-traffic” – should it follow that the rationale behind safe harbor provisions is vanishing? </p>
<p>The notion of large-scale DRMs-by-mandate has never passed legislation, neither in the U.S. nor in Europe. Recital 48 of the famous E.U. Copyright Directive of 2001 also contains its “no mandate” language (“legal protection [i.e., anticircumvention laws] implies no obligation to design devices, products, components or services to correspond to technological measures, so long as such device, product, component or service does not otherwise fall under the prohibition of Article 6.”) One may argue that filtering technology is more like “broadcast flag” and less like technological protection measures, but that does not render technological mandate less objectionable. The Belgium court seems to have entered a rather explosive minefield.</p>
",Copyright and Fair Use,2007-07-05 14:18,279,Zohar Efroni,News
5604,,Germany,0,0,German Copyright Law Amended,Copyright,"<p>Today was the official publication of a new amendment to the German Copyright Act. The amendment will enter into force in January 1st, 2008. After four long years of discussions, debates and negotiations, the final text is now <a href=""http://www.bgblportal.de/BGBL/bgbl1f/bgbl107s2513.pdf"">available</a>. A few highlights: </p>
<!--break--><ul><li>The rule, which annulled the transfer of rights concerning exploitation in not-yet-known methods, is repealed. It is replaced by an arrangement that allows authors to transfer such rights. They retain however a withdrawal window of three months from notice, during which the transfer can be revoked. Alternatively, the author can demand “special royalties” if the transferee actually relys on a contractual provision allowing exploitation in new methods that were not known at the time of the original transfer.</li>
<li>New exceptions in favor of libraries, archives and similar institutions are supposed to immune them from violating the “making-available” right for providing electronic reading stations within the institution premises for study and research. There’s a catch: The new exceptions will not survive an agreement stating otherwise…</li>
<li>Germany was a pioneer nation in introducing the first levy system already in the 60s. The system imposes levies on makers and traders in media and devices that can be used for private, noncommercial copying. Unlike in the US, such copying in Germany is permissible in some situations under a special statutory exception. The amendment dramatically alters the mechanism determining the tariffs paid to rightholders. No more statutory rates dictated by the state. The law now stipulates a framework for negotiations between collection societies and levy payers.</li>
<li>Despite much debate and public outcry, the <em>download</em> of works from suspicious sources that use presumably illegally-produced copies (a code name for P2P networks) remains explicitly outside the scope of the private copying exception. In other words, it is a <em>prima facie</em> violation of the reproduction right. Criminal penalties for this horrendous conduct remain possible, after the proposal to introduce a <em>de minimis</em> provision had died before the bill arrived the finish line.</li>
</ul><p></p>
",Copyright and Fair Use,2007-10-31 14:21,279,Zohar Efroni,News
5616,,Israel,0,0,New Copyright Statute for Israel,Copyright,"<p>Some time ago I posted an <a href=""http://cyberlaw.stanford.edu/node/5081"">update</a> about the planned copyright reform in Israel. The Israeli copyright law now passed legislation and the text of the new statute is available for download <a href=""http://www.knesset.gov.il/privatelaw/data/17/3/196_3_1.rtf"">here</a>. You don’t get the chance to write your copyright law from scratch very often, maybe once or twice in a century. This law indeed replaces an anachronistic statute from 1911 and it is remarkable in several respects.</p>
<!--break--><p>
It is a fairly skinny copyright act (16 pages in the format I have). In addition to the usual economic rights it also protects the moral rights of attribution and integrity. It contains the only Copyright Act-style fair use provision outside of the United States I’m aware of. This fair use provision has an interesting addition: Alongside the familiar four-factor test designed for courts, the law authorizes the minister to articulate the conditions under which uses shall be considered fair. The law further contains an E.U.-style making-available right and, among other exceptions, a liberal and elaborated exception concerning the reproduction of computer programs.</p>
<p>All in all, I think it is a very sensible piece of legislation. Some complain it ignores the Internet and the problems of the information society. Maybe. In fact, there is <em>absolutely nothing</em> in this law about legal protection to technological protection measures and copyright management systems. If anything, it is a proof that there are other ways to do copyright legislation for the new Millennium, with an old fashioned flavor, so to speak. </p>
",Copyright and Fair Use,2007-11-21 1:53,279,Zohar Efroni,News
5617,,France,0,0,Sarkozy’s digital agenda,Copyright,"<p>Zdnet <a href=""http://news.zdnet.com/2100-9588_22-6219944.html"">reports</a> on a <a href=""http://www.elysee.fr/documents/index.php?lang=fr&mode=view&cat_id=7&press_id=708"">new initiative in France</a> to tighten copyright protection over the Internet and prevent illegal downloading. The French president himself gave announcements that makes one think he’s on payroll of the music and film industry (""we run the risk of witnessing a genuine destruction of culture..."")</p>
<!--break--><p>
The most dangerous and unprecedented aspect of this initiative is the union between the content industry and ISPs under governmental patronage and the forming of an extra-judicial body that would issue warning letter to users (""electronic warning messages""), have authority to punish them by blocking their Internet access, and encourage filtering and DRM deployment at the ISP level. I hope someone stops them on time. </p>
",Copyright and Fair Use,2007-11-24 4:02,279,Zohar Efroni,News
5670,,Israel,0,0,Israel’s Fair Use,Copyright,"<p>Some time ago I did a <a href=""http://cyberlaw.stanford.edu/node/5616"">post</a> on the new copyright legislation in Israel. There are many interesting things about this law, and now, at the curtsey of Prof. Niva Elkin-Koren from Haifa University, there is an unofficial English translation of the new statute <a href=""http://law.haifa.ac.il/events/event_sites/newip/englishcopyright.doc"">available</a>.</p>
<!--break--><p>
Section 19 is of particular interest. It replicates section 107 of the U.S. Copyright Act with two important improvements. First, the first fair use factor does not include the sentence “…including whether such use is of a commercial nature or is for nonprofit educational purposes.” This formulation created difficulties for U.S. courts in giving decisive weight to pure normative considerations, notwithstanding commercial or noncommercial use aspects. Many fair uses are <em>not</em> nonprofit and are <em>not</em> for educational purposes, but they are still fair uses. Courts now should be able to bring powerful normative-qualitative considerations into their fair use analysis without feeling guilty, which is great. </p>
<p>Second, the Israeli provision in 19(c) authorizes the minister to clarify the conditions under which certain uses are deemed lawful. This is a feature that Section 107 USCA does not have, and one may add, unfortunately. I could not find many words in the Bill about this important subsection (c) – but its purpose seems clear enough. It seeks to reduce uncertainties surrounding the application of fair use, and reduce their effect on risk-averse actors who can only guess, <em>ex ante</em>, whether the court would later excuse their use or not if an infringement action came their way. Subsection (c) permits the minister to introduce some more certainty into fair use law, by creating irrefutable presumptions (so I read it) that no liability attaches under certain stipulated conditions. </p>
<p>A third point that is not explicit in the text is the issue of transformativeness. I do not think that in Israeli law the question of transformativeness has acquired so much weight as it has in US law. In any event, the Israeli first fair use factor is beautifully concise: The court should consider “[t]he purpose and character of the use.” This is much more open than a strict transformativeness examination. It is possible that the caselaw will develop a similar requirement in the future, but at the moment, courts are not strictly bound by it. </p>
<p>All in all, I think it’s a balanced and sensible provision (William Patry appears to think so <a href=""http://williampatry.blogspot.com/2008/01/israelis-new-copyright-law.html"">too</a>). Thanks for the link, Niva!</p>
",Copyright and Fair Use,2008-01-30 2:05,279,Zohar Efroni,News
5688,,Canada,0,0,Old-Style Canadian Formalities and Copyright Reform,Copyright,"<p>Next month Stanford CIS is hosting a conference about <a href=""http://cyberlaw.stanford.edu/node/5685"">Legal Futures</a>. Judging by the list of participants, the upcoming even should be nothing less than electrifying. This post is unrelated to the conference. In fact, it is not about legal “futures” at all. Rather, it is about legal “pasts.”</p>
<p>Some CIS-ers have received recently a curious mail from me concerning a Canadian 1921 copyright legislation. This legislation was actually the first copyright statute made-in-Canada (before that the 1911 British statute was followed; for a historical background see <a href=""http://www.culturaleconomics.atfreeweb.com/Post%20Doc%20Articles/06%2009%20SIPP%20CCA%201921-2006.htm"">this online paper</a>). To my surprise, I found out that there is no googleable copy of this legislation available online. Hard copies appeared difficult to find outside of North America, so I had to launch a more active search. In the end I got it (thank you <a href=""http://cyberlaw.stanford.edu/profile/brandy-karl"">Brandy Karl</a> and Amanda Smith!) and found what I was looking for. The issue is copyright formalities and the unique arrangement set forth in section 13 of the old Canadian law.</p>
<p>A bit of history first. Formalities are official requirements that rightholders must fulfill in order to enjoy the full breadth of their copyrights in a given jurisdiction. Formalities were prevalent in many countries (U.S. included) from a very early stage and continued to reign for more than two centuries. Typical formalities are requirements of registration, deposit of copies, copyright notice, record of transfer, payment of fees, procedures of renewal, and so on. The consequences of noncompliance with formalities diverse. They can range from losing some strategic advantages in infringement litigation to a complete and irreversible forfeiture of exclusive rights. </p>
<p>It is well known that the <a href=""http://www.wipo.int/treaties/en/ip/berne/trtdocs_wo001.html"">Berne Convention for the Protection of Literary and Artistic Works</a> prohibits member states to impose domestic formalities that impede the enjoyment and exercise of copyrights by foreign authors in the adjudicating state. It is less known that the original Berne Act from 1886 (including the Paris Act text from 1896) permitted domestic formalities. To the extent that formalities existed in the country of origin and the country of adjudication, the latter was obligated to recognize compliance in the country of origin (this was regulated in old Article II(2) of Berne.)</p>
<p>The situation changed after the 1908 Berlin Revision, during which the familiar prohibition on formalities was introduced. The convening representatives desired to hinder any interpretation of Article II that would lead to the loss of copyrights by unionist authors due to error, ignorance or impossibility. At the dawn of the Twentieth Century, the assessment that domestic formalities were an undesired burden on the international regime enjoyed a broad consensus. The language of current Article 5(2) leaves little doubts about its meaning. The conclusiveness of the formalities prohibition is evident. </p>
<p>Back to the Canadian statute. I first found a reference to the unique arrangement in a German treatise on the Berne Convention from 1935 authored by an intellectual property jurist called Willy Hoffmann. Hoffmann belonged to a small, esoteric circle of pre-WWII continental-European jurists (mostly Germans), who believed that the public actually had stakes in intellectual property legislation, and that both domestic and international law should meaningfully respect the interest of the public. In fact, Hoffmann’s book is less a treatise on the Berne Convention than an elaborate, rigorous critique on the orthodox interpretation and application of some Berne fundamentals such as the substantive minima, national treatments and independence of protection. Hoffmann, together with another German jurist by the name of Alfred Baum, promoted the heroic, strange and controversial argument that the Berne Convention stipulated not only a minimum, but also a <em>maximum</em> bar to copyright protection in the adjudicating country with respect to foreign works! Hoffmann was a vehement opponent to an absolute formalities prohibition, which was probably the reason why he found the Canadian provision intriguing. </p>
<p>The 1921 Canadian statute required compliance with a long list of formalities, including registration, deposit and payment of fees. Since Canada was already a member of the Berne union, those formalities did not apply to foreign unionist rightholders. The 1921 statute had an additional unique arrangement, a quasi-formality requirement stipulated in old section 13. That provision allowed a statutory license, granted upon application to the Minister, to print and publish a published book still under copyright if two alternative conditions were met: (1) the rightholder failed to print the book in Canada, or (2) the rightholder failed to supply enough copies to satisfy the demand for the book in Canada. In short, this was a kind of a “publication-plus” requirement having the main purpose to ensure that exclusive copyrights did not result in a shortage of access to the work. </p>
<p>Rightholders that did not comply with this “publication-plus” requirement ran the risk of seeing competing publishers apply for a compulsory license under section 13. Applicants were required to deposit no less than ten percent of the retail selling price of one thousand copies. According to the procedure, the Minister should immediately notify the rightholder about the filing of such application, and if the rightholder still failed to comply with the “publication-plus” requirement, the minister, at his/her discretion, could grand the applicant a license to print and publish the book for a maximum period of five years. The licensee was obligated to pay royalties to the rightholder at a rate determined by the minister. </p>
<p>Section 13 is not a classic formality provision, since the a work subject to the statutory license was still under copyright for any other purpose. However, noncompliance with the “publication-plus” requirement effectively replaced the right to exclude with a mere liability rule, that is, a mere claim to receive royalties from the licensee’s sales. This went one step too far, and Hoffmann reported that the Berne International Bureau declared the provision a violation of international obligations as applied to foreign authors. Consequently, Canada was compelled to amend the law, and in 1923 it did so by explicitly excluding foreign works from that statutory license under section 13.</p>
<p>What does this have to do with contemporary copyright issues? Formalities have been considered taboo for decades. Several recent calls challenged that. Pro formalities commentators view them an important instrument to correct the harmful effect of overprotection. Lessig mentions formalities as a possible correction mechanism in <a href=""http://www.free-culture.cc/index.html"">Free Culture</a>. <a href=""http://cyberlaw.stanford.edu/profile/christopher-sprigman"">Chris Sprigman</a> penned a thorough study on formalities published in the Stanford Law Review in 2004. I join the voices advocating for the re-introduction of formalities, thought within a broad context. </p>
<p>The argument for formalities is strong. It revolves mostly around efficiency considerations and reduction of <a href=""http://cyberlaw.stanford.edu/node/5587"">information costs</a>. The economic rationale is quite simple. In an “opt in” copyright system, nonmarket works will not comply, and hence, will not be under exclusive rights. If such works are used commercially, rightholders will have enforceable claims to receive modest compensation according to a statutory scheme. Since statutory compensation is modest, rightholders who expect large income from exploitation revenues will comply immediately. Rightholders themselves will determine the regime controlling use according to their own assessments and inclinations. As a result of compliance, the public is on notice that someone is serious about enforcing exclusive rights in those works. By checking the registration database, risk-averse users will have a cheap and easy way to clarify the status of a work. They are allowed to assume that unregistered works that bear no copyright notice are subject to statutory licensing. </p>
<p>In the age of global networks, complying with formalities should not be much more complicated than sending an email plus attachment or filling a basic online form. Domestic requirements would have to be internationally standardized to some degree. Standardization should be tailored around the most basic, simple and information cost relevant formalities: Registration, notice, and possibly a requirement to deposit an electronic copy of the work. </p>
<p>Commercial, professional and corporate rightholders should not have a reason to complain. Complying with formalities would constitute an additional, minor, tax-deductible expense in their production costs. The issue with formalities is, and has always been, the small, atomistic, poor and uninformed creative individuals, who might lose their rights as a consequence of ignorance or mistake. The problem exacerbated in the international setting, if rightholders were obligated to comply with divergent domestic rules. These concerns should be put into proportion. The phenomenal success of creative commons shows that when creative individuals have an active interest in their copyrights, and when given proper tools, such creators can take care of their affairs. One should expect a far broader involvement and individual engagement if the preservation of exclusive rights were at stake, rather than the voluntary wish to grant a permissive CC license.</p>
<p>The interesting aspect of section 13 is that it combines the advantages of formalities and the advantages of a liability rule in a way that nicely prevents unjust results while enhancing efficiency and broad access. To be sure, reintroducing formalities cannot be <em>the</em> solution all the problems. However, it can definitely be a part of the solution. </p>
<p>A solution is called for because copyright law is problematic. Much of the trouble emanates from accidental effects of legislative expansion tendencies, a result of ad-hoc responses to the threats of the “darknet.” In its current state, copyright law is not a product of intelligent design. The basic entitlements model is so cluttered with numerous patches and gap-filling provisions that accidents are almost inevitable. The reform must begin with the basics. It should redefine the exclusive rights to correspond the conditions of digital technology and networks. Old-style Canadian formalities will then be constructive as means to inhibit overprotection and enhance economic efficiency of information markets. </p>
<p>The fact that the Canadian legislature crafted such an elegant solution to prevent socially undesirable impacts of copyright protection suggests that legal futures can find their fortune in legal pasts. The fact that a law drafted nearly a century ago combines two of the most important contemporary approaches to copyright reform – a return to formalities and a shift to liability rules - is telling. If one digs deep enough, one has good chances to find out that many great ideas have a pedigree. </p>
",Copyright and Fair Use,2008-02-13 12:57,279,Zohar Efroni,News
5770,,United States,0,0,Section 230 Immunity and the Roommates.com Case,Other,"<p>I write in <a></a>href=""<a href=""http://www.cioinsight.com/c/a/Opinion/Avoiding-Web-Rocks-and-Shoals/"">http://www.cioinsight.com/c/a/Opinion/Avoiding-Web-Rocks-and-Shoals/</a>"">this month’s CIO Insight about the 9th Circuit’s en banc decision in the Roommates.com case. This important decision tested the limits of immunity for information service providers (in this case, the operator of a website that allows users to post roommate-matching ads) under Section 230 of the 1996 Communications Act. </p>
<!--break--><p> At issue was whether Roommates.com could be sued under fair housing laws for asking users about their age, sex, sexual orientation, whether they have children and their preferences for these characteristics in a roommate. Eric Goldman has an excellent post on the case at his website: <a href=""http://blog.ericgoldman.org/archives/2008/04/roommatescom_de_1.htm"">http://blog.ericgoldman.org/archives/2008/04/roommatescom_de_1.htm</a></p>
<p>Writing for the majority, Chief Judge Kozinski held that the service was not entitled to immunity (the merits are yet to be decided) because the site was a “developer” of the potentially-illegal content. In short, Kozinski distinguished free-form text boxes (immunity intact) from drop down menus that offered only limited choices. The drop down menus, the court held, are not immune, because they cross the line between hosting and assisting in the development of the content, and Section 230 applies only to the former.</p>
<p>I’m troubled, as many people are, by the decision and some of its dicta. In particular, Footnote 15 signals increasing judicial resistance to the Section 230 safe harbor. It also falls into the trap of judges assuming they know more about the information economy than they do:</p>
<p>“The dissent stresses the importance of the Internet to modern life and commerce, Dissent at 3476, and we, of course, agree: The Internet is no longer a fragile new means of communication that could easily be smothered in the cradle by overzealous enforcement of laws and regulations applicable to brick-and-mortar businesses. Rather, it has become a dominant—perhaps the preeminent—means through which commerce is conducted. And its vast reach into the lives of millions is exactly why we must be careful not to exceed the scope of the immunity provided by Congres and thus give online businesses an unfair advantage over their realworld counterparts, which must comply with laws of general applicability.”</p>
<p>Kozinski cites nothing to support these comments. But what does it even mean to say that the Internet has become “a dominant…means [can there be more than one dominant mean?] through which commerce is conducted”? Despite double-digit growth for over ten years, e-commerce still only accounts for well under 10% of retail activity. And I can’t even find a measurement for services revenue, which Roommates.com represents. Which is to say, as far as I can determine, “the Internet” is still a fragile new means of communication.</p>
",Architecture and Public Policy,2008-05-31 10:54,295,Larry Downes,News
5836,,United States,0,0,YouTube Shows Us How To Be A Good Intermediary,Copyright+Freedom of Expression,"<p>Many have worried about the role of intermediaries who provide platforms for sharing information and expression on the internet, and their sometimes profound power to make content disappear. But here is an example of one intermediary -- a big and very important one -- that did the right thing.</p>
<p>Students for a Free Tibet posted a <a href=""hthttp://www.youtube.com/watch?v=j60x3C43Qao"">video</a> on YouTube showing their protest at the Chinese consulate in New York, which included various images relating to the Beijing Olympics, all to speak against China's human rights record -- a fair use to be sure.</p>
<p>The International Olympic Committee filed a DMCA takedown notice and the video was removed. Upon learning more about the content of the removed video, YouTube contacted the IOC and asked them if they really planned to pursue a claim about this [really very preposterous position] and if not, to withdraw the takedown notice. To the IOC's credit, they retracted the notice and the video was reposted within hours.</p>
<p>So here is an intermediary who took an interest in free speech and fair use, even when it didn't necessarily have to. Yes, that followed widespread outrage among bloggers and others. Yes, the situation would have been much tougher if the IOC had maintained its irresponsible position. But we should all be pleased to see YouTube going out of its way to do <i>more</i> than it's required to do under the law to protect free expression.</p>
<!--break-->
","Copyright and Fair Use, Intermediary Liability",2008-08-13 21:41,281,Anthony Falzone,News
5885,,United States,0,0,Albany Business Review Tries To Use Bogus Copyright Claim To Silence NY Assembly Candidate,Copyright,"<p>Not all campaign controversies fill the national stage. But this one should get national attention for being so abusive.</p>
<p>Mark Blanchfield is challenging George Amedore for his New York state assembly seat. Last week, Blanchfield released political ads that include excerpts of an interview Amedore apparently gave to the Albany Business Review in connection with an award he received from the Business Review last May. In that interview, Amedore says he doesn't ""look at [his] Assembly position as [his] job.""</p>
<p>Blanchfield's radio and <a href=""http://cyberlaw.stanford.edu/biguploads/Blanchfield_LO.mov"">TV ad</a> lambast Amedore for this comment. In response, the Business Review turned its lawyers loose on Blanchfield, who received a <a href=""http://cyberlaw.stanford.edu/system/files/Blanchfiled+C%2526D+Letter.pdf"">letter</a> accusing him of copyright infringement and threatening legal action if he does not pull his ads off the air.</p>
<p>This is an abuse of copyright law that should trouble everyone, and cannot be allowed to persist or spread. Copyright is not a tool to censor criticism, and cannot be allowed to become a device to suppress statements that public officials wish they had not made. </p>
<p>What Blanchfield did here is a textbook example of fair use -- and an important one at that. Blanchfield is using a small portion of the video to criticize the views expressed in it by Amedore and to expose to the voters Amedore's attitude about the job he's been elected to do; moreover, Blanchfiled's use of this material will have no conceivable impact on whatever market there might be for the video the Business Review made (assuming there is a market for it in the first place). </p>
<!--break--><p>The law protects what Blanchfield did here, and it should. The Business Review's suggestion of infringement is silly and dangerous. At the very least, Amedore should stand up for Blanchfield and the right to free and open debate. But above all else, no media outlet should cave to the Business Review's tactics and pull this ad. </p>
<p>Our political system cannot function without free and open debate. Copyright law cannot be allowed to become an excuse to suppress that debate.</p>
","Privacy, Copyright and Fair Use",2008-10-13 8:30,281,Anthony Falzone,News
5886,,Germany,0,0,German Court Finds Google’s Image Search Infringing,Copyright,"<p>The German blogsphere is buzzing about the new opinion handed down by a court in Hamburg, finding Google’s image search infringing. The court agreed with the copyright holder of comics images, and held that the unauthorized display of the images as thumbnails on the search result pages violated his rights. </p>
<!--break--><p>
The first thing that came to my mind was <a href=""http://www.ca9.uscourts.gov/ca9/newopinions.nsf/90756C6E9CC4CF10882573A600513540/$file/0655405.pdf?openelement"">Perfect 10 v. Google</a>, which rejected similar allegations under fair use, finding that Google’s use of the images was “highly transformative.” But the star guest in this party cannot be fair use, because such a defense does not exist in German law. Google vows to fight through the instances, so it is definitely not the end of the story. I haven't gotten the chance to read the decision yet, but as soon as I do and have something to add, there will be a follow-up. </p>
",Copyright and Fair Use,2008-10-14 7:29,279,Zohar Efroni,News
5890,,United States,0,0,Content-Sharing Website Veoh.com Entitled to Safe Harbor Under DMCA,Copyright,"<p>Author: José Mauro Decoussau Machado</p>
<p>Io produces, markets, and distributes adult entertainment products. In its lawsuit against Veoh, it maintained that a variety of its copyrighted videos had been uploaded and viewed on veoh.com without prior authorization. Io did not inform Veoh of the presence of the allegedly infringing files in its systems prior to bringing an action. Coincidently, Veoh had already independently decided to no longer permit adult content on its website, such that no disputed material was accessible on veoh.com by the time the suit was actually filed. </p>
<p>Veoh demonstrated to the court that it had a variety of safeguards to avoid copyright violations. First, Veoh has a Copyright Policy that requires users that upload content to declare that the published material does not constitute infringement of third parties intellectual property rights. Second, Veoh has a designated Copyright Agent that receives notification of alleged violations, can terminate the user’s account, and can disable all content that the user uploaded and block the user’s e-mail address so that a new account cannot be opened with that same address. Veoh employees also perform “spot checks” to determine whether uploaded videos are in compliance with Veoh’s policies and to ensure accuracy in the description and categorization of the content. If such checks reveal a blatant infringement, Veoh normally disables access to the material.</p>
<p>The court found that Veoh presented evidence that it fulfills the threshold requirements to qualify for safe harbor under the DMCA, as it is a service provider which has adopted, implemented, and informed users of its policy on copyright infringement. In this regard, Io failed to present evidence that a repeat infringer could have established new accounts under false pretenses, or that Veoh intentionally allowed such conduct. </p>
<p>The court further found that Veoh fulfilled the requirements set forth in Section 512(c) of DMCA to be qualified for safe harbor. Specifically: (1) Veoh does not itself actively participate or supervise the uploading of files, which are uploaded through an automated process which is initiated at the users discretion; (2) before the filing of the lawsuit, Io did not provide Veoh with any information about the alleged copyright infringement; (3) none of the video files uploaded contained any kind of copyright notice provided by Io, such that the infringement could be not considered obvious; (4) even if Veoh had sufficient knowledge of the alleged infringement, it has a policy of removing the disputed content from its website in the same day a notification is received; (5) and, unlike Napster, Veoh’s right and ability to control its system does not equate to the right and ability to control infringing activity, i.e., the files in question did not bear titles resembling plaintiff’s works and Io did not provide Veoh with its titles to search. </p>
<p>In view of the above, court found that Veoh was entitled to safe harbor and dismissed the case.</p>
",Copyright and Fair Use,2008-10-15 16:03,1,admin,News
5891,,United States,0,0,"Section 230 of the CDA, May – or May Not – Immunize Online Marketplace Providers from Ticket-scalping Liability",Copyright,"<p>Author: Allison Pedrazzi Helfrich</p>
<p><a href=""http://www.ncbusinesslitigationreport.com/StubHub%20Order%20MTD.rtf"">Hill v. Stubhub</a></p>
<p>Jeffrey Hill and Lisa Hill brought suit against Stubhub, an online marketplace for reselling tickets, after purchasing four tickets to a Hannah Montana concert for $149 each. The face value printed on the tickets turned out to be only $56—a 152% markup. According to North Carolina’s anti-ticket scalping statute, the resale of a ticket “shall not be … greater than the combined face value of the ticket, tax, and the authorized service fee,” which should not exceed $3 per ticket. Unable to tell who exactly was the seller (Stubhub or a third party), the Hills sued Stubhub for scalping tickets. Stubhub moved to dismiss the plaintiffs’ suit, citing in part the immunity provided by Communications Decency Act (CDA).</p>
<p>The goal of the CDA is to “promote the continued development of the Internet and other interactive computer services.” 47 U.S.C. § 230(b)(1). As the court explained in Hill v. Stubhub, one way to achieve this goal is to distinguish between interactive service providers who chiefly provide access to the Internet from interactive content providers who are “responsible, in whole or in part, for the creation or development of information provided through the Internet.” Id. § 230(f)(3). In Hill v. Stubhub, CDA immunity depended on whether Stubhub was a mere access provider and not responsible for the actions of those who used its site to resell tickets, or whether Stubhub was also partly responsible for the resellers’ actions. </p>
<p>During oral arguments on the motions, Stubhub did not respond to the court’s inquiry about whether or not it actually sold the tickets in question or if it sold its own tickets to the concert. The plaintiffs claimed that even if the site did not actually sell the tickets itself, Stubhub only offers tickets to “hot acts,” where there are far more people who want to buy tickets than there are tickets. This necessarily guarantees price inflation and high commissions, both of which are prohibited in North Carolina. Ultimately, the court ruled discovery was needed to determine how much control Stubhub had over the third-party ticket sellers and whether they shape inflated market prices or merely reflect the actual market that already exists. While the CDA clearly favors immunity in close cases, the court held further inquiry was necessary and denied the motion to dismiss under section 230. This decision marked a possible answer to the question of how far immunity will be extended for internet service providers under the CDA.</p>
<p><a href=""http://cyberlaw.stanford.edu/system/files/Fehrs-StubHub-Defs-Rule21-Motions-2-13-08.pdf"">Fehrs v. Stubhub</a></p>
<p>Just two months later, an Oregon Circuit Court ruled for Stubhub’s motion to dismiss a similar case over tickets to a Bruce Springsteen concert in Portland, Oregon. The plaintiff, Sharon Fehrs, brought a class-action suit against both Stubhub and eBay (Stubhub is a subsidiary of eBay). In contrast with Hill v. Stubhub, Fehrs did not actually purchase the high-priced tickets she found on Stubhub and eBay. Instead, she brought suit under the Portland City Code, which prohibits the public nuisance of offering any ticket for resale at a “price greater than the retail price printed thereon.” She also brought a claim for tortious interference with her prospective advantage, and sought to enjoin StubHub from allowing ticket sales with inflated prices. </p>
<p>In September, the court granted the defendants’ motions to dismiss, both on the ground that the plaintiff’s claims are barred by the CDA and because the Portland City Ordinance relied on by the plaintiff is a city ordinance that does not provide a private cause of action to citizens. The terse two-page opinion does not mention Hill v. Stubhub or the issue of Stubhub’s control of the prices on its site, other than to highlight the protection the CDA guarantees service providers.</p>
",Architecture and Public Policy,2008-10-15 16:16,1,admin,News
5894,,United States,0,0,Copyright Owners Must Consider the Fair Use Doctrine when Issuing DMCA Takedown Notices,Copyright,"<p>Author: Stuart Loh </p>
<p>The plaintiff, Stephanie Lenz, posted a 29-second video clip on YouTube of her children dancing to the Prince song “Let’s Go Crazy.” Universal, the copyright holder of that song, issued a DMCA takedown notice with which YouTube complied. Lenz believed that her otherwise unauthorized use of the song was permissible under the fair use doctrine and issued a counter-notice. YouTube reinstated the video six weeks later. Under 17 U.S.C. § 512(c)(3)(A)(v), DMCA takedown notices must contain a statement that the issuer has a “good faith belief that use of the material in the manner complained of is not authorized by the copyright owner … or the law.” Lenz sued Universal and claimed that forming such a good faith belief required a consideration of the fair use doctrine. She argued that because Universal had allegedly not given such consideration, it had misrepresented in its takedown notice that it had, in breach of 17 U.S.C. § 512(f).</p>
<p>Universal moved to dismiss the case for failure to state a claim upon which relief may be granted, arguing that takedown notice procedures do not necessitate consideration of fair use and therefore there were no reasonable grounds upon which Lenz could base a claim. The motion was denied.</p>
<p>The court held that as a matter of statutory construction, it is “unambiguous” and accords with legislative purpose behind the DMCA and copyright legislation that use of copyrighted material in a manner “authorized by law” includes fair uses. Therefore, in evaluating whether use of copyrighted material is “not authorized,” a copyright owner must also evaluate whether such use constituted “fair use.”</p>
<p>Universal argued that the law should not force copyright owners to engage in a “fact-intensive” and potentially complicated inquiry to determine whether a use is fair use because that would impede owners’ ability to respond rapidly to potential infringements. However, the court was unconvinced. It noted that Rossi v. Motion Picture Ass’n of America, Inc., 391 F.3d 1000 (9th Cir. 2004) held that a “good faith belief” in the context of § 512(c)(3)(A)(v) encompasses a subjective standard, as opposed to a more stringent objective standard. Therefore, the extent of the relevant inquiry required is limited. A “full investigation … is not required” before a rights owner can form a good faith belief that a use does not constitute fair use.</p>
<p>Interestingly, the court flagged that it had “considerable doubts” that Lenz could, in the main proceedings, prove that Universal acted with “subjective bad faith.” It is unclear from the case the procedure that Universal undertook in deciding whether to issue the takedown notice. If the notice was issued via an automated mechanism without any human input, then perhaps Universal did not turn its mind towards whether fair use was involved, depending on how the relevant mechanism operates. If there was human input, subjective bad faith would probably be harder to prove, but the practical question remains: why, when all factors are considered, did Universal decide to issue a takedown notice at all, given the relatively innocuous use of its copyrighted material? In this instance, Lenz claimed that Universal issued the notice at Prince’s behest and “only to appease Prince” since he is “notorious for his efforts to control all uses of his material on and off the Internet.”</p>
",Copyright and Fair Use,2008-10-15 16:23,1,admin,News
5935,,United States,0,0,"Interference with ""Pay-Per-View"" Billing Information Prohibited under Section 553 and DMCA",Copyright,"<p>Author: Morgan Galland </p>
<p>Defendants, Jon Chaffee, Amy Chaffee and Ramalda Bou (""Chaffee""), appealed a summary judgment decision of the United States District Court for the District of Rhode Island holding that defendants violated the Cable Communications Policy Act of 1984, 47 U.S.C. § 553(a)(1), and the Digital Millennium Copyright Act, 17 U.S.C. § 1201. Chaffee argued that summary judgment was improperly granted and that Plaintiff CoxCom lacked standing to sue. Chaffee also appealed the District Court’s bench trial decision granting damages and injunctive relief. The United States Court of Appeals for the First Circuit affirmed in all respects.</p>
<p>CoxCom Inc. is a cable television company, offering services to subscribers in Rhode Island, Massachusetts and Connecticut. As part of this service, it leases cable boxes to subscribers. The cable boxes descramble incoming signals so that subscribers can watch ""pay-per-view"" programming and then transmit information, including pay-per-view billing details, back to CoxCom using low-frequency signals. Chaffee sells digital cable filters, which interfere with low-frequency signals in order to prevent the pay-per-view billing information from being transmitted back to cable companies (in addition to enhancing viewing quality). Chaffee sells these filters at computer trade shows, including in Rhode Island and Connecticut. Both in person and in written instruction sheets for the filters, Chaffee explicitly instructed customers how to use the filter to prevent billing information from being sent to their cable companies. </p>
<p>The First Circuit held that CoxCom had standing to sue, because even though CoxCom presented no proof that the filters had been used to deprive the company of any particular payment, the chain of events that could have resulted from the sale of filters in CoxCom’s service area was a sufficient loss of remuneration to warrant standing to sue under Article III.</p>
<p>The court next turned to the issue of whether summary judgment was properly granted. Section 553(a)(1) of the Cable Act provides that a person shall not ""intercept or receive or assist in intercepting or receiving any communications service offered over a cable system. . . ."" Section 554(a)(2) defines ""assist in intercepting or receiving"" to include the manufacture or distribution of equipment ""intended by the manufacturer or distributor for ""unauthorized reception"" or a service offered by a cable system. Chaffee argued that the filters were not intended to and in fact did not ""receive"" cable programming and therefore did not satisfy Section 553. Rejecting this argument, the First Circuit affirmed that the filters were intended for unauthorized reception of pay-per-view programming, in violation of Section 553(a). Relying on appellants’ advertising strategies, the court determined that they had specific knowledge of cable customers’ planned illegal use of the filters to receive programming without charge. </p>
<p>Chaffee also argued that that the district court improperly applied the anti-circumvention provisions of the DMCA. Section 1201 (a)(2) prohibits a person from selling any product that is produced for the purpose of ""circumventing a technological measure that effectively controls access to a work"" protected under the Copyright Act. Chaffee argued that this section did not apply to its case because the filters did not ""circumvent"" any technological measure controlling access to pay-per-view programming. The First Circuit again affirmed the district court decision, holding that Chaffee violated Section 1201 (a)(2) by trafficking in a filter technology that allowed subscribers to avoid or bypass CoxCom’s encoding and scrambling ""technological measure."" In its decision, the First Circuit avoided the question of whether CoxCom’s billing technology effectively controlled access to pay-per view programming. </p>
<p>Finally, the court affirmed the district court’s award of damages of $35,000 under Section 553 and $105,000 under the DMCA jointly and severally against the appellants. It also affirmed the issuance of a permanent injunction prohibiting appellants from future possession, sale or distribution of digital cable filters. In support of the damages decision, the court cited appellants’ waiver of a jury trial right by participating in the bench trial without objection. In support of the injunction, the court found that the case satisfied the eBay four-factor test described in eBay Inc v. MercExchange, L.L.C., 547 U.S. 388 (2006). </p>
<p><a href=""http://www.ca1.uscourts.gov/pdf.opinions/07-2030-01A.pdf"">CoxCom, Inc. v. Chaffee, 536 F.3d 101 (Aug. 4, 2008).</a> </p>
",Copyright and Fair Use,2008-11-17 15:06,245,Lauren Gelman,News
5937,,United States,0,0,"In Peer-to-Peer File-Sharing Case, ""Distribution"" Does Not Mean ""Making Available""",Copyright,"<p>Author: Matt Kellogg </p>
<p>At trial, the plaintiffs sought to prove that the defendant, a single mother in Duluth, had willfully infringed 24 of the plaintiffs' recordings by downloading and distributing them via the peer-to-peer program Kazaa. Finding that the defendant had infringed, the jury awarded the plaintiffs statutory damages of $9,250 per song, for a total of $222,000. The defendant filed a motion for a new trial or, in the alternative, for remittitur, calling for a reduction of excessive damages; the plaintiffs filed an unopposed motion to amend judgment, seeking an injunction. Instead, the court elected sua sponte to address the possibility of granting a new trial because of an incorrect jury instruction. </p>
<p>The jury instruction in question stated that ""making [songs] available"" for download on Kazaa violated the plaintiffs' ""exclusive right of distribution, regardless of whether actual distribution had been shown."" As a result of this instruction, the jury neglected to state in the verdict that it did or did not find actual distribution or any other specific reasoning for its decision. Although the jury might have decided that the defendant had violated the plaintiffs' right to reproduction or that dissemination to the plaintiffs' agent had formed the basis of infringement--both of which would have been valid conclusions, according to the court--ultimately the lack of specificity made it impossible to know if the verdict was based on permissible legal grounds.</p>
<p>The court's analysis began by considering the plain meaning of ""distribution."" Based on section 106(3) of the Copyright Act, the court found that ""distribution"" requires an actual transfer of possession or ownership, a definition supported by the dictionary and leading copyright treatises. Like the Patent Act, which did not cover ""offers to sell"" until amended by Congress to include that precise language, the Copyright Act should be interpreted as applying only to ""distribution"" and not to ""offers to distribute"" (i.e., ""making available"") until the text of the statute expressly states otherwise.</p>
<p>Next, the court refuted the plaintiffs' claim that ""distribution"" is synonymous with ""publication."" The Copyright Act defines ""publication"" as ""the offering to distribute copies . . . to a group of persons for purposes of further distribution."" In Harper & Row Publishers, Inc. v. Nation Enterprises, the Supreme Court distinguished the right to publish and the right to distribute as separate under the Copyright Act. This distinction further precludes expanding the plain meaning of ""distribution"" to incorporate offers to distribute.</p>
<p>The court then turned to the question of whether the Copyright Act creates a protected right to authorize distribution. The authorization clause, in section 106, states that ""the owner of copyright . . . has the exclusive rights to do and to authorize any of the following,"" including the right ""to distribute."" The court said that this language does not create an additional right in itself but instead serves as a basis for imposing secondary liability. To be secondarily liable, the defendant would have to induce or encourage another party to infringe and the encouraged party would actually have to infringe; encouragement alone would not be enough.</p>
<p>Following this discussion, the court cited National Car Rental System, Inc. v. Computer Associates International, Inc. as the relevant Eighth Circuit precedent. Because that case already considered and rejected the idea that ""distribution"" can mean ""making available,"" the court was bound to follow its holding, which it found to be ""consistent with the logical statutory interpretation"" of the Copyright Act. Briefly examining the implications of international law, the court also determined that non-self-executing U.S. treaty obligations cannot override the clear congressional intent noted above. </p>
<p>Ultimately, the court concluded that the jury instruction had in fact been erroneous in defining ""distribution"" as ""making available"" and thus ordered a new trial. In a coda to its opinion, the court pleaded for legislative reform, urging Congress to define more clearly the liability and damages structure for similar peer-to-peer cases. In this case, for example, the awarded damages equaled more than 4000 times the actual cost of the infringed songs. Because the defendants in these cases are consumers and not corporations, the court reasoned, the range of damages must be better calibrated to deter future infringement without going so far as to be ""oppressive.""</p>
<p><a href=""http://www.eff.org/files/filenode/capitol_v_thomas/10112270717.pdf"">Capitol Records et al. v. Thomas (D. Minn., Sept. 24, 2008)</a> </p>
",Copyright and Fair Use,2008-11-17 15:08,245,Lauren Gelman,News
6057,,United States,0,0,Google Books Reaches Settlement With Publishers And Authors,Copyright,"<p><br />Author: Matt Kellogg
</p><p>Google recently reached a settlement agreement with the authors and publishers who in 2005 sued the company for copyright infringement. As part of the arrangement, copyright owners will not only receive fees from Google for the use of digitized copies of their books in Google Book Search, they will also have the ability to choose how much—if any—of their works they wish to be displayed. The settlement provides for the creation of an independent organization to oversee its administration as well as special modes of access for public and university libraries.</p>
<!--break--><p>As announced in late 2008, Google reached a proposed agreement that would resolve the class-action lawsuit filed against the company in the United States District Court for the Southern District of New York by the Authors Guild, the Association of American Publishers, and a handful of other authors and publishers. The plaintiffs claimed that Google's Book Search program, which digitizes the text of books from major libraries around the world, infringed on author copyrights; Google responded that this digitization was protected as a fair use. Pending court approval, the settlement will allow the two sides ""to avoid the cost and risk of a trial"" while leaving the central legal question undecided.</p>
<p>The works covered by the settlement fall into two main categories: ""books"" and ""inserts."" ""Books"" are defined as written or printed works distributed under U.S. copyright that are not periodicals, personal papers, sheet music, public domain works, or governmental works. ""Inserts"" include forewords, afterwords, poems, letters, textual excerpts, musical notation, and tables, charts, and graphs. <br />Google Book Search displays information from digitized books in four formats, or ""display uses"": (1) ""display of bibliographical pages,"" which include the title page, copyright page, table of contents, and index; (2) ""snippet displays,"" which include the three or four lines of text surrounding a search term, with a limit of three snippet views per user per book; (3) ""preview uses,"" which allow a user to view up to 20% of a book but not print, copy and paste, or annotate; and (4) ""access uses,"" which provide viewing, printing, copying and pasting, and annotating for purchase by individuals, individual subscription, and library public access.</p>
<p>Google may use a digitized book in one of several ways, depending on that book's publication status and the rightsholder's preferences. If a book is currently in print and protected by copyright law, Google may not use it without consent from the rightsholder. If a book is currently out of print but still under copyright, Google will automatically include it in all display uses (as explained above), though the rightsholder may request that the book be excluded from any or all of these uses. Rightsholders may also exclude inserts from all—but not fewer than all—display uses. Books in the public domain will continue to be fully available and free of charge.<br />As compensation, rightsholders will receive 63% of the revenues earned from Google Book Search. These payments will include at least $45 million for books digitized by Google through May 5, 2009, at the rate of at least $60 per book, $15 per insert, and $5 per partial insert. (Rightsholders will receive only one payment per book or insert, regardless of how many editions in which it might appear. In the case of a collection like ""The Best American Short Stories,"" the entire collection is considered the ""book"" and each story an ""insert."") In exchange, participants forfeit the right to sue Google and participating libraries.</p>
<p>Google will also pay $34.5 to establish the Book Rights Registry, a not-for-profit organization founded to collect rightsholder information, manage their copyright interests, and collect and distribute revenues. The Registry's board will include at least four directors from the ""Authors"" sub-class of the lawsuit and four from the ""Publishers"" sub-class.</p>
<p>Participating libraries that allow Google to digitize their books will receive a digital copy of each book in return. The libraries may use these copies for a variety of purposes, such as providing access to readers with disabilities and replacing missing or damaged books. In addition, public and university libraries will each be eligible for ""Public Access Service"" licenses, which will provide on-site terminal access to all of Google Book Search's out-of-print and public-domain books.</p>
<p>Finally, through the creation of a ""Research Corpus,"" Google will makes its complete digital collection available for the study of image and linguistic analysis, automated translation, and other disciplines concerned with ""extracting information to understand or develop relationships among or within Books.""<br />According to the official settlement website, the terms of the agreement apply to every owner of a U.S. copyright as of January 5, 2009, including both U.S. and non-U.S. rightsholders. Members of the lawsuit class are also free to (a) opt out of the settlement or (b) register objections to certain aspects of the settlement. The court will consider these objections prior to approval or rejection of the agreement.</p>
<p>Before finalizing the agreement, the court will hold a fairness hearing on June 11, 2009. Class members must give notice of their intent to raise an objection at the hearing. For more information about the settlement, visit <a href=""http://www.googlebooksettlement.com"">www.googlebooksettlement.com</a>.</p>
<p><a href=""http://www.googlebooksettlement.com/r/view_settlement_agreement"">Google Book Search Settlement</a></p>
",Copyright and Fair Use,2009-02-05 16:08,335,Ryan Calo,News
6069,,United States,0,0,DMCA Safe Harbor for Service Providers Also Protects Non-Storage Activities Designed to Facilitate Access to User-Stored Content,Copyright,"<p><br /><br />Author: Stuart Loh
</p><p>Universal Music Group (“UMG”) sued Veoh Networks, Inc. (“Veoh”), an Internet-based service that allows users to share videos online, for copyright infringement. In the present proceedings, UMG moved for partial summary judgment that Veoh was not entitled to protection under 17 U.S.C. § 512(c), a safe harbor of the Digital Millennium Copyright Act designed to shield a service provider from liability arising from infringing conduct occurring “by reason of storage at the direction of the user.” In addition to storing videos uploaded by users, Veoh engaged in other activities (e.g., converting the format of the videos) to provide other users with access to them. UMG argued that because those other activities do not actually constitute storage, Veoh may not rely on § 512(c) as a shield to liability. The court denied UMG’s motion and rejected UMG’s narrow interpretation of the phrase “by reason of,” holding that such an interpretation was not consistent with its common meaning and that it would undermine the ability of § 512(c) to shield service providers from liability if they did anything with user-uploaded materials other than store it untouched. Instead, the court held that § 512(c) covers Veoh’s activities because they were designed to facilitate access to user-stored content.</p>
<!--break--><p>The defendant, Veoh Networks, Inc. (“Veoh”), operates an Internet-based service similar to YouTube that allows users to share videos online. Members of the Universal Music Group (“UMG”) sued Veoh for copyright infringement. While both parties agreed that Veoh did not have UMG’s authorization to make certain of UMG’s copyrighted works available for download, Veoh asserted an affirmative defense under 17 U.S.C. § 512(c), one of the safe harbors of the Digital Millennium Copyright Act (“DMCA”), which protects service providers from being held liable for “infringement of copyright by reason of storage at the direction of a user of material that resides on a system or network controlled or operated by or for the service provider.” In the current proceedings, UMG moved for a partial summary judgment that Veoh was not entitled to rely on that defense. The court denied UMG’s motion.</p>
<p>Apart from allowing users to upload videos, Veoh’s service also performed additional functions, including: automatically converting movie files uploaded by users into Flash-formatted video files; automatically creating copies of uploaded video files which are split up into smaller “chunks”; allowing users to access uploaded videos by streaming (whether through Veoh’s website or its standalone application); and allowing users to download uploaded videos. UMG argued that none of these functions constituted “storage at the direction of a user,” which therefore meant that § 512(c) was inapplicable.</p>
<p>The parties agreed that the additional functions at issue did not constitute “storage,” so the issue in this case was whether the phrase “by reason of” in § 512(c) should be construed broadly to encompass incidental activities arising as a result of storage by users, or, as UMG argued, whether it should be limited to storage functions only. The court held that the meaning of “by reason of” was “pretty clear,” pointing to the common sense usage of the phrase to mean “something that can be attributed to.” </p>
<p>The court also held that such an interpretation was necessary in order to give effect to the goals of the DMCA as disclosed by its legislative history – in particular, to limit the liability of service providers in certain situations so as to foster the continued development of the Internet. For example, if UMG’s narrow interpretation was adopted, the notice and takedown procedure in § 512(c) would be hamstrung by leaving a service provider liable for having provided access to stored material, despite complying with the procedure and taking down the infringing material. (Veoh had complied with such procedure in relation to UMG’s copyrighted works.) Furthermore, although no cases have expressly interpreted the “by reason of” language, service providers in cases with similar fact patterns have successfully employed the § 512(c) defense. </p>
<p>While the court did not identify the outer limits of its broad interpretation of the safe harbor, it held that the four activities conducted by Veoh were all designed to facilitate access to user-uploaded content and were, therefore, covered by the safe harbor. By contrast, the court distinguished a case involving similar language in § 512(d), Perfect 10, Inc. v. CCBill LLC, 488 F.3d 1102 (9th Cir. 2007), in which the defendant allowed consumers to use credit cards to pay for website subscriptions. The court said that the allegedly infringing activity in CCBill was too far removed from the function of providing access to qualify for protection under the safe harbor. </p>
<p>The court’s reasoning appears sound. It is difficult to envision an online service that would store material at the direction of users but would not offer any way to access that material. The commercial reality is that any service like Veoh must also provide access, in one form or another, to what users upload to it. The implication of UMG’s interpretation is that no service provider would be effectively shielded by the DMCA’s safe harbor provisions if it did anything with stored data other than storing it untouched. </p>
<p>More: <a href=""http://www.eff.org/files/UMG%20v%20Veoh%20order.pdf"">http://www.eff.org/files/UMG%20v%20Veoh%20order.pdf</a></p>
",Copyright and Fair Use,2009-02-12 14:25,283,Amanda Avila,News
6101,,United States,0,0,Internet Service Provider Potentially Liable for Copyright Infringement of Hosted Websites,Copyright,"<p>Author: Allison Pedrazzi Helfrich
</p><p>Following an investigation and notification attempts, clothing distributor Louis Vuitton Malletier filed a complaint against several websites that it believed were selling goods that infringed on Vuitton’s copyrights and trademarks, alleging contributory trademark infringement; vicarious trademark infringement; contributory copyright infringement; and vicarious copyright infringement. The court denied the defendants’ motion for summary judgment on the contributory copyright and trademark infringement claims. With respect to the contributory trademark infringement claim, the court held that the proper inquiry in this context was how much control the defendant had over the means of infringement.</p>
<!--break--><p>In late 2006, Louis Vuitton Malletier, S.A., famous for its luxury handbags and other prestige goods, discovered websites that it claimed were selling goods that infringed on its copyrights and trademarks. Several of the websites were using IP addresses provided by Akanoc Solutions, Inc. and Managed Solutions Group, Inc., both of which are owned by Steven Chen. Vuitton sent notices requesting that the offending websites be taken off the server, but several websites remained operable while others were moved to different IP addresses also owned by Chen. After ordering several items to ensure they were counterfeit products, Vuitton filed a complaint alleging contributory trademark infringement; vicarious trademark infringement; contributory copyright infringement; and vicarious copyright infringement. In response, defendants filed a motion for summary judgment on the theory that Vuitton provided no evidence of underlying direct infringement by third parties or that Akanoc, et al. contributed to the copyright or trademark infringement.<br />On December 23, 2008, a U.S. District Court in San Jose, California, issued an order denying summary judgment on the contributory infringement claims while simultaneously dismissing the vicarious infringement claims. With respect to contributory copyright infringement, the court held that the knowledge requirement was fulfilled by the plaintiff’s initial letters of complaint, notwithstanding Chen’s claim that investigating all such allegations would be impossible and standard practice is to send a take-down notice to any sites about whom they receive complaints. The court also determined that “knowingly providing the ‘site and facilities’ for infringing activity is a material contribution.”<br />The court went on to explain that the test for contributory trademark infringement was more difficult to satisfy, following a disjunctive test set out in Perfect 10: “(1) intentionally induced the primary infringer to infringe, or (2) continued to supply an infringing product to an infringer with knowledge that the infringer is mislabeling the particular product supplied.” Perfect 10, Inc. v. Visa International Service Assoc., 494 F.3d 788, 806 (9th Cir. 2007). However, the court added that the Ninth Circuit has found the rule less restrictive in cases involving services where the defendant exercised a high degree of control over the third parties means of infringement, suggesting it may no longer be acceptable for a defendant to maintain willful blindness over trademark infringement occurring on its network.<br />The court granted the motion for summary judgment in regards to the vicarious copyright infringement claims on the ground that there is no evidence Akanoc’s customers were drawn to the company because Akanoc was willing to turn a blind eye to their infringement activities. The court also dismissed the vicarious trademark infringement claim due to the lack of any “finding that the defendant and the infringer have an apparent or actual partnership, have authority to bind one another in transactions with third parties or exercise joint ownership or control over the infringing product.” Perfect 10, 494 F.3d at 807.</p>
<p>Opinion: <a href=""http://docs.justia.com/cases/federal/district-courts/california/candce/5:2007cv03952/194697/99/0.swf"">http://docs.justia.com/cases/federal/district-courts/california/candce/5:2007cv03952/194697/99/0.swf </a></p>
",Copyright and Fair Use,2009-03-11 15:39,283,Amanda Avila,News
6163,,United States,0,0,Pam Samuelson on Google Books,Copyright,"<p>Pam Samuelson offers some <a href=""http://radar.oreilly.com/2009/04/legally-speaking-the-dead-soul.html"">interesting reflections</a> on the Google book search agreement. Her warnings are worth listening to. Prof. Samuelson is quite critical about the agreement and the new creature it contemplates- the Book Rights Registry (BRR).</p>
<!--break--><p>The BRR is a to-be-formed entity which, among other things, will represent the interests of rightholders under the agreement and administrate the distribution of revenues among registered authors and publishers. Indeed, one of the big open questions concerns anti-competitive aspects of this class action settlement agreement. Though Google’s dominance in the domain of books digitization is hardly questionable, the competition issue is rather tricky. First, the permission to digitize and provide electronic access to books secured to Google under the agreement is not exclusive. In other words, rightholders are not binding themselves to doing business only with Google. Second, the agreement does not contain any explicit statement compelling the BRR – a non-for-profit entity having equal representation of Authors and Publishers in its board – to deal exclusively with Google in the long run. Once this highly complex institution is up and running, there seems to be no legal impediment <em>stemming from the agreement itself</em> that would prevent it from cooperating with other commercial digitizers.</p>
<p>Of course, the point critics never fail to emphasize is that competition between Google and other access providers would prove in practice an empty promise: No other entity is likely to be capable of creating a comparable depository of digitized books, and as Samuelson points out, one that would dare trying would risk in legal threats and lawsuits. And even according to the more optimistic scenario, where several digitizers are simultaneously cooperating with the BRR while competing among themselves (I ignore for the moment complications resulting from the class action status of the agreement), there is no guarantee for better access conditions or lower prices, and for that matter, more respect for fair use. </p>
<p>Google’s monopolistic position extends primarily to infrastructure – its giant store of digitized content, together with smart and high-power logical and logistic commercialization tools. It does not have a monopoly over content, however. Google did no purchase the copyright in all those books. Technically, it is a mere licensee, not even an exclusive one. The real “monopolists” here are, how surprising, the authors guild and the publishers’ association. And as the Statute of Anne festively marks this year its <a href=""http://www.alai2009.org/"">300th anniversary</a>, one may wonder whether there is anything new under the sun. </p>
<p>Well, of course there is. According to the pessimistic scenario, Google would become a global one-shop monster, the equivalent of a universal publisher with unmatchable position in the market of online literature, in possession of unfettered power to dictate availability, standards and terms of access. Even so, though Google is expected to profit considerably while occupying this position, legally it would operate as the long arm of actual rightholders: It would facilitates for authors and publishers what they cannot do themselves, cutting a sizable coupon for its services, to be sure. If critics’ predictions about the evolvement of the market materialized, and if the agreement led to abusive practices enabled by Google’s dominance, the anti-trust authorities might step in. But even then, it is not so clear that they would find a legal ground to interfere in the settlement. </p>
<p>Should we wake up one day into a reality, in which digital access to much of our literary heritage is dominated by a single giant enterprise, we should also remember that it is the current law which incubated that reality. In my view, it is premature to flatly condemn Google at this point. We still know too little on how this system will function in practice. To me, the most important lesson is that the process of public lawmaking has failed miserably in structuring comparable mechanisms for providing broad access, and at the same time, accommodating rewards for rightholders. It is not surprising that private actors with the necessary foresight and resources rush to fill this gap. What’s the point of lamenting that the contracts they draft lack the checks and balances we would expect to find in public regulation? Prof. Samuelson calls the BRR “a new collecting society”, which implicitly hits the mark: Technically, the term describes the BRR's principal functions and responsibilities. One main difference is, however, that real collecting societies are, for better or for worse, highly regulated entities (in Europe all the more). This is precisely what the BRR is not.</p>
",Copyright and Fair Use,2009-04-18 14:25,279,Zohar Efroni,News
6355,,United States,0,0,The Google Books Amended Settlement Agreement and International Works,Copyright,"<p>The long-awaited Amended Settlement Agreement (ASA) was filed yesterday. The relevant documents (including the new version of the settlement and a summery of the main changes) are available <a href=""http://searchengineland.com/revised-google-book-settlement-filed-29814"">here</a>. As someone who was looking into the international law aspects of the settlement recently, one of the first places for me to look was the new definition to a “Book”, which now reads as follows:</p>
<!--break--><p>
</p><blockquote>1.19 “Book” means a written or printed work that as of January 5, 2009 (a) had been published or distributed to the public or made available for public access as a set of written or printed sheets of paper bound together in hard copy form under the authorization of the work’s U.S. copyright owner, (b) was subject to a Copyright Interest, and (c) (1) if a “United States work,” as defined in 17 U.S.C. § 101, was registered with the United States Copyright Office, and (2) if not a United States work, either (x) was registered with the United States Copyright Office, or (y) had a place of publication in Canada, the United Kingdom or Australia, as evidenced by information printed in or on a hard copy of the work. Relevant information printed in or on a hard copy of the work may include, for example, a statement that the book was “Published in [Canada] or [the UK] or [Australia],” or the location or address of the publisher in one of those three countries.</blockquote>
<p>The crux hides in subsection (2)(x)-(y). According to the old definition, non-U.S. works were included in the settlement so long as they were published or made available for public access with authorization on or before January 5, 2009. That definition included virtually <em>all</em> non—registered international works published anywhere, legal copies of which were available in the U.S. as of that date. </p>
<p>The new definition does two things: First, it requires registration with the U.S. Copyright Office also with regard to international works. Alternatively, non-registered, non-U.S. works published only in Canada, the U.K. and Australia remain in the settlement.</p>
<p>The summery of changes explains this move as follows: </p>
<blockquote><p>As revised, the settlement will only include books that were either registered with the U.S. Copyright Office or published in the U.K., Australia, or Canada. After hearing feedback from foreign rightsholders, the plaintiffs decided to narrow the class to include only these countries, which share a common legal heritage and similar book industry practices. British, Australian, and Canadian rightsholders are joining the case as named plaintiffs and will also be represented on the Board of the Book Rights Registry.</p></blockquote>
<p>Now this is a major change that would significantly reduce the repertoire of works that the planned access services would be able to offer. I am not sure that this was the principal aim of most U.S. objectors to the settlement. I also think that international copyright law does not <em>obligate</em> the parties (or even the court) to exclude foreign works in this way. It was rather a policy-oriented maneuver intended to remove political pressures coming from abroad, which U.S. objectors have been effectively using as ammunition against the settlement. </p>
<p>Overall, I expect that many U.S. objectors to the settlement will not be all that satisfied with the scope of the revisions. What was taken out are the absolutely “no way” provisions, for instance, the direct conflict of interest between active rightsholders and owners of orphan works in the distribution of monies through the Registry, or the “most favored nation” provision, which would have secured to Google the best conditions to be reached in the future between the Registry and other service provides competing with Google.</p>
<p>In contrast to U.S. objectors, for some people in Europe (especially major publishers) the revised definition of Books is good news. Yet the dream and vision of having access to the <em>world’s</em> cultural heritage through Google’s digitization initiative will have to wait. The litigation in the U.S. certainly has mobilized the EC to <a href=""http://ec.europa.eu/information_society/newsroom/cf/itemdetail.cfm?item_id=5332"">set up an agenda</a> for copyright reform that would focus also on digitization of books and the creation of digital libraries. I am all anticipation to see how and when Europe catches up and how many more position and policy papers would have needed to be written and debated until that day comes.</p>
<p>This is obviously not the end of the saga. A date for the fairness hearing should soon be fixed, and I assume that in the meantime the harshest critics of the settlement will sharpen their arguments and tailor them to attack the new arrangement of the ASA. I expect the critique to become more pointed, however (privacy issues?), now that Continental Europe and other countries (like <a href=""http://www.nytimes.com/2009/10/31/technology/internet/31google.html"">China</a>?) that do not “share a common legal heritage and similar book industry practices” with the U.S. are out. Now, when the danger of <a href=""http://www.copyright.gov/docs/regstat091009.html"">“diplomatic stress”</a> with major trade partners of the U.S. is removed (is it indeed? After all, <em>registered</em> foreign works are in the settlement even without the express wish of their rightsholders unless they timely opt-out), the road ahead is wide open. Or is it not? Stay tuned...</p>
",Copyright and Fair Use,2009-11-14 3:02,279,Zohar Efroni,News
6357,,United States,0,0,An Unpopular View of Google Books,Copyright,"<p>I’m starting to feel like the only person who thinks the Google Books settlement with authors and publishers is a good deal. One voice that seems not to be heard, however, over the din of Google competitors, panicky law professors, and regulators who wouldn’t know a workable solution to a copyright problem (created by regulators) if it bit them, is anyone speaking for consumers.</p>
<p>My opinion piece today on CNET (see <a href=""http://news.cnet.com/8301-1023_3-10398838-93.html?tag=mncol;title"">http://news.cnet.com/8301-1023_3-10398838-93.html?tag=mncol;title</a>) argues that the real problem with the settlement has nothing to do with the 165-page document, which is increasingly coming to look like the sausage-making that it is.</p>
<!--break--><p>(Does anyone really expect authors or publishers or anyone other than lawyers to read this and make any sense of it?) </p>
<p>The problem is the insanity of “modern” copyright law, which grants endless rights to all content creators, rights only the richest media companies can enforce.</p>
<p>For everyone else, once the modest commercial life of a work has ended, the rights are abandoned but not eliminated, leaving a no-man’s land of millions of stranded or “orphaned” works. The Google Books settlement, at least for digital users, would elegantly solve the orphan works problem. But the Copyright Office and the Department of Justice, among other creators of this mess, don’t like having their authority stepped on or their difficulties made to look easy.</p>
<p>For more, see <a href=""http://larrydownes.com/an-unpopular-view-of-google-books/"">http://larrydownes.com/an-unpopular-view-of-google-books/</a></p>
",Copyright and Fair Use,2009-11-16 18:24,295,Larry Downes,News
6416,,United States,0,0,Google Books Redux:  The DoJ Tones Down its Objections,Copyright,"<p>I write today on CNET (see <a href=""http://"">""Gripes over Google Books go Technical""</a>) about the Department of Justice's filing last week in the Google Books case. The Amended Settlement Agreement (ASA), released in November, will be discussed by the parties at a fairness hearing on Feb. 18th.</p>
<p>The DoJ continues to object to the settlement, but now their objections to the most recent version are considerably muted from earlier filings.</p>
<!--break--><p>Principally, they now argue that the mechanisms of the class-action lawsuit is inappropriate for resolving long-standing problems in the law of copyright, most importantly the growing category of works whose rights holders are unknown and unknowable--the so-called ""orphan works.""</p>
<p>It's true that the litigation started out challenging Google's scanning and making available for search purposes the text of out-of-print books. The authors and publishers argued that action was wholesale copyright infringement. Google countered that it was a fair use, a statutory exception to the rule that requires the permission of the rights holder to copy all or part of a work. Rather than litigate that point, the parties decided to create a new business model for making out-of-print texts available in digital form. (Owners of rights to in-print texts have dealt separately with Google.)</p>
<p>The DoJ understands the need for a solution to the orphan works problem created by repeated and retroactive extensions of copyright terms, a problem created by Congress over the last several decades. They just don't think that the ASA, or more to the point class action litigation, is an appropriate legal vehicle to solve it.</p>
<p>I note in the piece that class actions serve a wide variety of important uses, and that it is not unusual for such lawsuits to stray far from their initial claims into something approaching the restructuring of broken industries. Whether this is such an occasion will be a matter first for the district court judge, Danny Chin, to decide. No doubt the case will eventually be appealed to the Second Circuit Court of Appeals, which may take a different view. The ASA may sink or swim on grounds other than its status as a class action.</p>
<p>That the government is largely falling back to technical objections, however, seems significant. We'll see how significant in the coming months.</p>
",Copyright and Fair Use,2010-02-11 16:29,295,Larry Downes,News
6419,,United States+France,0,0,Amazon Marketplace:  Liability in the Cloud?,Other IP,"<p>I don’t usually blog “personal” stories, but this one is irresistible. It raises disturbing questions at the border of digital and physical life, and legal problems of trademark and the emerging issues of cloud computing and data liability.</p>
<!--break--><p>EBay, as everyone knows, has been struggling to improve its customer experience in the light of disappointing results in the last few years. One problem in particular that the company has worked hard to address is the problem of sellers who either misrepresent their items or otherwise underperform in the transaction, tarnishing the image of eBay in the process.</p>
<p>There are of course legal consequences to some of these problems as well. EBay has been the subject of numerous lawsuits in the U.S. and abroad from trademark holders claiming that eBay sellers are offering knock-off or forged goods as branded merchandise, or selling items outside the often-strict terms under which authorized merchants may sell branded goods. (For example, selling outside assigned geographic territory, or selling below the authorized price or terms.)</p>
<p>I’ve written extensively about the eBay litigation, including lawsuits brought by Tiffany in the U.S. and the Louis Vuitton brands in France. The question in these cases comes down to a definition of what eBay actually “is”—a department store responsible for the merchandise sold on its premises (liable) or a community bulletin board offered as a convenience to connect buyers and sellers of a variety of unrelated products and services (not liable).</p>
<p>EBay is neither of these things—it is an example of a new kind of virtual marketplace enabled by digital technology. But the law here, as elsewhere, has not kept up with the changing realities of digital life, leaving judges to struggle with analogies that just don’t fit. EBay has scored strong victories in the U.S., and significant losses abroad. Whatever the results in these cases, the legal reasoning is always hopeless and the opinions useless as precedent. The law evolves slowly.</p>
<p>(In a new twist, just the other week eBay <a href=""http://www.boston.com/business/articles/2010/02/12/ebay_to_pay_vuitton_316500/ "">was ordered to pay over $300,000 by a French court in another dispute with Louis Vuitton.</a> This one involved eBay’s practice of purchasing advertising keywords that were common misspellings of LVMH marks that directed searches to eBay. EBay is appealing.)</p>
<p>Amazon’s third-party Marketplace, which has eaten into eBay’s market significantly over the years, has largely avoided these public legal skirmishes. Brand holders and their distributors may prefer to sell through Amazon than eBay, giving an incentive not to litigate when problems do arise. Amazon also manages a much smaller and generally more professional group of third party merchants than does eBay and, it appears, exercises more vigorous policing over the items that appear under the Amazon banner but which in fact are sold and distributed by third parties.</p>
<p>Well, maybe not. Recently I purchased a replacement camera battery from an Amazon third party merchant. (You can find <a href=""http://www.amazon.com/gp/product/B001288S76/ref=oss_product"">the listing here</a>, though I strongly suspect it will be changed or disabled very shortly for reasons that will become clear in a moment.)</p>
<p>For the rest of the story, see <a href=""http://larrydownes.com/note-to-ebay-a-chink-in-the-amazon-armor/""> ""Note to Ebay: A Chink in Amazon's Armor?""</a></p>
",Copyright and Fair Use,2010-02-20 7:22,295,Larry Downes,News
6429,,Germany,0,0,Sweeping Telecom Data Retention Law Held Unconstitutional in Germany,Other,"<p>The German Constitutional Court (GCC) this morning struck down a law that imposed on private telecom operators and service providers such as ISPs and telephone companies comprehensive duties to keep record of all communication data, including Internet activity, e-mails, SMS, MMS etc., for six months and without pre-screening or cause. It appears to be a glorious victory to privacy interests, yet some privacy advocates are disappointed since the GCC did not take the opportunity to declare such regulation as unconstitutional on its face. Either way, the Court imposed quite substantial restrictions on the legal formulation of the telecom data retention law, its application, and the way law enforcement agencies may use the data.</p>
<!--break--><p>The provisions at question intended to transpose in Germany the <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:32006L0024:EN:HTML"">European Directive 2006/24/EG (March 15, 2006)</a> and its relevant instructions concerning duties of telecom service providers concerning record-keeping of telecom information. The German legislation that followed introduced, among other things, some amendments to the Telecommunication Law (TKG), specifically sections 113a and 113b, which the GCC now declared disproportional and thus void as violating the constitutional rights of citizens in private communications. The <a href=""http://www.bundesverfassungsgericht.de/entscheidungen/rs20100302_1bvr025608.html"">decision</a> is quite long and complex (and, surprise-surprise, in German), so I’ll focus here on several interesting points and leave the rest to a later day.</p>
<p>The relevant Directive, bearing the charming title “[Directive] on the retention of data generated or processed in connection with the provision of publicly available electronic communications services or of public communications networks…”, imposes some important obligations on E.U. member states on matters of communication data retention (Art. 3 ff.). The list of the types of data covered is extensive, to say the least (Art. 5.1.). The GCC avoided saying that these provisions were irreconcilable with the Constitution. At the same time, it held that the German legislature in this case went too far and beyond the requirements of E.U. law, and that the resulting amendments of the TKG suffered from fatal flaws that must lead to their immediate annulment. Consequently, and quite strikingly, the decision obligates all telecom service providers to <em>delete without delay</em> all the data they were keeping in order to comply with that bad legislation!</p>
<p>The judges rejected this fiercely disputed law (about 34,000 petitioners joined the proceeding before the Constitutional Court) basically for two main reasons. Firstly, the duty on telecom service providers to keep a six-months track record of (and to report to a state agency) all communication data without discrimination (which, in any case, does not include the content of communications), was overboard and disproportional.</p>
<p>Secondly, the terms for using this data by state agencies such as police, the prosecution and intelligence services was not sufficiently determined to limit use only in the appropriate cases. As critics and ultimately the Court itself noticed, the data could be used for a variety of purposes, from fighting terrorism to terrorizing users of P2P networks. (By the way, in the case of copyright infringement over the Internet, the GCC now made it crystal clear that a back door to obtaining IP-address-related data of users via this telecom regulation – without passing through the front door of the copyright act requiring a court order against the ISP – is not available to copyright holders).</p>
<p>It was held that the law went beyond the mandate of the E.U. directive for allowing the state to retrieve and use the data not only for pursuing <em>grave</em> criminality but also for preventive acts and intelligence operations. The GCC did not neglect to mention Art. 10 of the <a href=""http://www.echr.coe.int/NR/rdonlyres/D5CC24A7-DC13-4318-B457-5C9014916D7A/0/EnglishAnglais.pdf"">European Human Rights Convention</a> - securing free speech rights – as ground for its intervention with the work of the legislative branch. More concretely, the law presented an unjustified harm to secrecy in private communication guaranteed under Art. 10(1) of the German Constitution.</p>
<p>As noted, the Court did not say that such regulation could never pass constitutional muster. The ball is now back with the government to draft a new law that would be more narrowly tailored and meet the constitutional proportionality standards.</p>
","Architecture and Public Policy, Privacy",2010-03-02 6:42,279,Zohar Efroni,News
6446,European Union,,0,0,The ECJ’s Ruling on Google Adwords,Other IP,"<p>The closely watched battle over the use of trademarks as keywords for purpose of triggering advertisements on Google’s search result pages (AdWords) reached high peak today with the release of the European Court of Justice’s <a href=""http://curia.europa.eu/jurisp/cgi-bin/form.pl?lang=en&alljur=alljur&jurcdj=jurcdj&jurtpi=jurtpi&jurtfp=jurtfp&numaff=&nomusuel=&docnodecision=docnodecision&allcommjo=allcommjo&affint=affint&affclose=affclose&alldocrec=alldocrec&docor=docor&docav=docav&docsom=docsom&docinf=docinf&alldocnorec=alldocnorec&docnoor=docnoor&radtypeord=on&newform=newform&docj=docj&docop=docop&docnoj=docnoj&typeord=ALL&domaine=&mots=&resmax=100&Submit=Rechercher"">ruling</a> on the French cases. In what appears to be a resounding win for Google, the ECJ managed to avoid some of the critical questions in a decision that, in fact, projects little new light on the multibillion dollars question: Is AdWording that involves marks as keywords legal in Europe?</p>
<!--break--><p>The French courts, in which some highly publicized keywording disputes were being litigated, have referred to the ECJ a series of questions relating to the practice of using protected trademarks to trigger advertisements placed by third parties without the permission of the markholders. </p>
<p>The key legal provisions are Articles 5(1)(a)-(b) and 5(2) of the European <a href=""http://oami.europa.eu/en/mark/aspects/direc/direc.htm"">Trademark Directive (1988)</a> (89/104/EEC). (In the meantime, a more recent <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:2008:299:0025:0033:EN:PDF""> trademark directive (2008)</a> went into effect, which is inapplicable to the disputes at hand, but which contains essentially similar provisions concerning the “[r]ights conferred by a trade mark” (Art. 5(1)-(2) of the 2008 Directive)). </p>
<p>Art. 5(1)(a) to the Trademark Directive governs use of signs identical to the protected mark in connection with goods or services identical or similar to the goods or services for which the mark is registered, whereas Art. 5(1)(b) covers use of identical <em>or similar</em> signs in a manner that causes likelihood of confusion. Art. 5(2), on its part, covers dilution situations, in which signs that are identical or similar to a reputable marks (aka “famous marks”) are used in relation to goods/services that are NOT similar to those for which the mark is registered. </p>
<p>The analysis of the ECJ proceeded on three levels. FIRST, according to E.U. law, claims against advertisers and against Google, in all three subsets of infringing activities, must show that the accused party has used the protected mark “in the course of trade.” In the context of identical signs, the threshold is very low: The use-in-the-course-of-trade test is satisfied “where [use] occurs in the context of commercial activity with a view to economic advantage and not as a private matter.” (¶50). Accordingly, the ECJ ruled that AdWords advertisers that use keywords identical to protected marks in order to trigger their ads certainly qualify, apparently including AdWords that do not exhibit the protected mark in any way (so-called “invisible use”). </p>
<p>However, the Court found that Google does not use the mark in the course of trade, even though it clearly draws economic advantage from AdWording practices that do. It is important to note that pulling Google off the hook already at this stage insulates it from allegations covered by <em>all three subsets of illicit activities</em> regulated under Art. 5(1) and Art. (2). How did the Court reach this conclusion? Unfortunately, the reasoning is quite murky (¶¶ 53-59). The Court seems to draw a distinction between Google and advertisers on the theory that Google, as opposed to advertisers, does not send its OWN message to consumers. (I think that the intuition behind this reasoning is correct, but, by the same token, the Court should have legitimized messages from advertisers to the public that do not mention the mark to consumers in any way). Interestingly, the Court characterized Google’s role as merely “storing” the keywords at question, which, as the Court concludes, does not qualify as use in the course of trade, but, as discussed below, is relevant in the context of the European safe harbor provisions. </p>
<p>On the SECOND level, an illicit use of an identical sign (Art. 5(1)(a)) requires use “in relation to goods or services.” Here, the ECJ applied an expansive standard that clearly covers also “invisible” use of the mark: Even in case that the advertiser makes no reference to the mark in the AdWord or otherwise while attempting to promote <em>its own</em> goods and services, use of the protected mark occurs simply by virtue of booking the keyword with Google. The Court explicitly rejected Google’s counter argument on this crucial point (¶¶ 64-73), thereby making a quite remarkable observation: </p>
<blockquote><p>It is also clear that in most cases an internet user entering the name of a trade mark as a search term is looking for information or offers on the goods or services covered by that trade mark. Accordingly, when advertising links to sites offering goods or services of competitors of the proprietor of that mark are displayed beside or above the natural results of the search, the internet user may, if he does not immediately disregard those links as being irrelevant and does not confuse them with those of the proprietor of the mark, perceive those advertising links as offering an alternative to the goods or services of the trade mark proprietor.</p></blockquote>
<p>Hmm. I am not aware of compelling empirical studies on this question (and I am not sure the Court has seen any either). Ads, by definition, relate in some way to goods or services, and most naturally, to goods/services of the same entity that pays for them. The presumption that ads appearing under the “sponsored links” rubric on the right side of the natural search results list always (or even often) offer goods/services “alternative” to goods/services of an entity that happens to hold trademark rights in the search term strikes me as speculative. </p>
<p>On the THIRD level, to constitute trademark infringement, the use must also have an adverse effect on the protected functions of the mark. In this respect, the ECJ mentioned two such protected functions. The first, more traditional function concerns the indication of origin. Can an “invisible use” of a mark that results in the placement of ads under the rubric of “sponsored links” harm this function? The analysis of the ECJ is inconclusive (¶¶82-90). The Court considers it a matter for national courts to resolve on a case-by-case basis. That said, the Court still added two important instructions to national courts in this regard: </p>
<blockquote><p>In the case where a third party’s [advertiser’s] ad suggests that there is an economic link between that third party and the proprietor of the trade mark, the conclusion must be that there is an adverse effect on the function of indicating origin.</p></blockquote>
<p>And:</p>
<blockquote><p>In the case where the ad, while not suggesting the existence of an economic link, is vague to such an extent on the origin of the goods or services at issue that normally informed and reasonably attentive internet users are unable to determine, on the basis of the advertising link and the commercial message attached thereto, whether the advertiser is a third party vis-à-vis the proprietor of the trade mark or, on the contrary, economically linked to that proprietor, the conclusion must also be that there is an adverse effect on that function of the trade mark.</p></blockquote>
<p>This latter instruction – the requirement to find “vagueness” concerning origin from the perspective of “normally informed and reasonably attentive internet users” is perhaps the crux – and the anticlimax – of the whole decision. The Court practically throws back to national courts the most controversial and difficult question, precisely the issue in which they have been desperate for some more guidance. This is the place where the ECJ should have come up with some more concrete instructions, but came up with a vague test of vagueness instead. </p>
<p>The ECJ also mentioned briefly the so-called “advertising function” of the mark, namely, the interest of a markholder in “using its mark for advertising purposes designed to inform and persuade consumers.” Here the Court offers something that comes closer to a bright-line rule: It held that possible “repercussions” on the advertising use caused by AdWords do not in themselves constitute adverse effect on the advertising function of the trademark (¶95). Further, “it must be concluded that use of a sign identical with another person’s trade mark in a referencing service such as that at issue in the cases in the main proceedings is not liable to have an adverse effect on the advertising function of the trade mark” (¶98). </p>
<p>The Court continued by evaluating liability under Art. 5(2) (dilution). It held that in case that an advertiser applies AdWords in order to promote the sale of imitations (e.g., of Louis Vuitton’s goods), the advertiser is liable for dilutive use, yet Google is not – for the reasons eluded to above: Merely “storing” the keyword does not amount generally to using it in the meaning of the Directive, so it cannot specifically violate its dilution provision. </p>
<p>Alongside the Trademark Directive, also the <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:32000L0031:EN:HTML"">E-Commerce Directive (2000)</a>, and specifically, its safe harbor provisions, received some limited treatment. Can Google enjoy the immunity provisions concerning “storage” of infringing information in accordance with Art. 14 of the E-Commerce Directive? </p>
<p>Well, also here the Court answers with a categorical 'it depends!' Namely, it delegates the task of assessing the role of Google on a case-by-case basis to national courts. More concretely, national courts are called to resolve whether Google’s operation qualifies it as a passive conduit, or, in other words, whether Google “is neutral in the sense that its conduct is merely technical, automatic and passive, pointing to a lack of knowledge or control of the data which it stores.” (In terms of Art. 14(1)(a), it is a condition to immunity that “the provider does not have actual knowledge of illegal activity or information and, as regards claims for damages, is not aware of facts or circumstances from which the illegal activity or information is apparent.” The ECJ did not add much substance on top of the plain language of the Directive on this point.)</p>
<p><b>Bottom line</b>: In the aftermath of this ruling, much remained unsettled. I think that the unequivocal language concerning the satisfaction of the use “in relation to goods or services” requirement should make European advertisers who use keywords identical to marks very, very concerned. It might even kill this practice in certain European countries, hardly a reason for celebration in Google’s quarters, to be sure. At the same time, the core legal question, whether invisible use of marks in AdWords constitutes trademark violation by advertisers, did not receive a satisfactory answer. Finally, though Google can now rest assured that direct liability for trademark infringements committed by advertisers will not attach to its own activity as a platform provider, many questions concerning secondary liability, both for trademark infringement and for other violations (such as unfair competition) remain wide open.</p>
",Copyright and Fair Use,2010-03-23 14:53,279,Zohar Efroni,News
6447,,United States,0,0,Google v Everyone,General,"<p>I had a long interview this morning<a href=""http://www.csmonitor.com/Money/2010/0323/By-standing-up-to-China-Google-returns-to-its-roots?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+feeds%2Fwam+%28Christian+Science+Monitor+%7C+Money%29""> with the Christian Science Monitor</a> . Like many of the interviews I’ve had this year, the subject was Google. At the increasingly congested intersection of technology and the law, Google seems to be involved in most of the accidents.</p>
<p>The interview got me thinking about why one company seems to be so central to problems of law and innovation, and the result is a very long post on my website, which I'll summarize here. (For the whole thing, see <a href=""http://larrydownes.com/google-v-everyone/"">http://larrydownes.com/google-v-everyone/</a>.)</p>
<!--break--><p>Just to name a few of the more recent pileups, consider the Google books deal, net neutrality and the National Broadband Plan, Viacom’s lawsuit against YouTube for copyright infringement, Google’s very public battle with the nation of China, today’s ruling from the European Court of Justice regarding trademarks, adwords, and counterfeit goods, the convictions of Google executives in Italy over a user-posted video, and the reaction of privacy advocates to the less-than-immaculate conception of Buzz.</p>
<p>In some ways, it should come as no surprise to Google’s legal counsel that the company is involved in increasingly serious matters of regulation and litigation. After all, Google’s corporate goal is the collection, analysis, and distribution of as much of the world’s information as possible, or, as the company puts it,” to organize the world's information and make it universally accessible and useful.” That’s a goal it has been wildly successful at in its brief history, whether you measure success by use (91 million searches a day) or market capitalization ($174 billion).</p>
<p>As the world’s economy moves from one based on physical goods to one driven by information flow, the mismatch between industrial law and information behavior has become acute, and Google finds itself a frequent proxy in the conflicts.</p>
<p>As I argue in <a href=""http://larrydownes.com/the-laws-of-disruption/"">“The Laws of Disruption”</a>, the unusual economic properties of information make it a poor fit for a body of law that’s based on industrial-era assumptions about physical property. That’s not to say there couldn’t be an effective law of information, only that the law of physical property isn’t it. Particularly not when industrial law assumes that the subject of any conflict or effort to control (the <strong><em>res</em></strong> as they say in legal lingo) is visible, tangible, and unlikely to cross too many local, state, or national borders—and certainly not every border at the same time, all the time.</p>
<p>For more, see <a href=""http://larrydownes.com/google-v-everyone"">""Google v. Everyone.""</a></p>
","Architecture and Public Policy, Copyright and Fair Use",2010-03-23 18:00,295,Larry Downes,News
6453,,France,0,0,eBay's Win is a Matter of Economic Necessity,Other IP,"<p>As the Wall Street Journal is already reporting, today eBay sustained an important win in its long-running dispute with Tiffany over counterfeit goods sold through its marketplace. (The full opinion is available here.)</p>
<p>I wrote about this case as my leading example of the legal problems that appear at the border between physical life and digital life, both in “The Laws of Disruption” and a 2008 article for CIO Insight.</p>
<p>To avoid burying the lede, here’s the key point: for an online marketplace to operate, the burden has to be on manufacturers to police their brands, not the market operator. Any other decision, regardless of what the law says or does not say, would effectively mean the end of eBay and sites like it.</p>
<!--break--><p>Back to the beginning. Tiffany sued eBay over counterfeit Tiffany goods being sold by some eBay merchants. The luxury goods manufacturer claimed eBay was “contributorily” liable for trademark infringement—that is, for confusing consumers into thinking that non-Tiffany goods were in fact made by Tiffany.</p>
<p>The problem of counterfeit items has been a long-standing problem for electronic commerce, and as one of the largest and first online marketplaces it’s little surprise that eBay has found itself so often in the cross-hairs of unhappy manufacturers. While the company has generally won these lawsuits, it lost an important case in France at about the same time the trial court in the Tiffany case ruled it its favor in 2008.</p>
<p>(A related problem that was explicit in the French case is that luxury goods manufacturers are unhappy in general with secondary markets given the tight—sometimes illegal—control they exert over primary channels. Electronic commerce doesn’t respect local territories, fixed pricing and regulating discounting, perhaps the bigger headache for companies such as Tiffany’s.)</p>
<p>The struggle for courts is to apply traditional law to new forms of behavior. Many of the opinions in these cases tie themselves in knots trying to figure out just what eBay actually is—is it a department store, where a variety of goods from different manufacturers are sold? Is it a flea market, where merchants pay for space to sell whatever they want? Or is it a bulletin board at a local grocery store, where individuals offer products and services?</p>
<p>Of course eBay is none of these things. But courts must apply the law they have, and the case law for trademark infringement is based on these kinds of outdated classifications. In the “common law” tradition, judges decide cases by analogy to existing case laws. That means when there isn’t a good analogy to be found, the law is often thrown into confusion for a long period of time while new analogies get worked out. Disruptive technologies create such discontinuities in the law, particularly for common law.</p>
<p>For more, see <a href=""http://larrydownes.com/ebay-wins-important-victory-against-tiffany/"">""EBay Wins Important Victory Against Tiffany""</a>on my site.</p>
",Copyright and Fair Use,2010-04-01 14:46,295,Larry Downes,News
6498,,International,1,1,ACTA Communique: “ACTA is the predictably deficient product of a deeply flawed process”,Copyright+Other IP,"<p>Representatives from the US, the EU, Japan, South Korea, Canada, Mexico, Australia, and New Zealand will convene this Monday in Lucerne for the <a href=""http://www.med.govt.nz/templates/MultipageDocumentTOC____43582.aspx"">Ninth round of ACTA negotiations</a>. President Obama has expressed his commitment to <a href=""http://www.michaelgeist.ca/content/view/5051/196/"">“conclude these negotiations soon.”</a></p>
<p>Last week, a group of 90 academics, practitioners and public interest organizations gathered to analyze the most recent <a href=""http://sites.google.com/site/iipenforcement/acta""> ACTA draft</a> and have released this <a href=""http://www.wcl.american.edu/pijip/go/acta-communique""> statement</a> detailing the ways ACTA threatens public interests. </p>
<p>Despite the April 2010 release of the draft text after Round 8 of negotiations, the shadowy, <a href=""http://news.cnet.com/8301-13578_3-20004450-38.html"">“Gollum-like”</a> ACTA remains worrisome on both process and substance. Overall, the ACTA text and the process that generated it have followed a path of private drafting and public equivocation.</p>
<p>One example from the April 2010 draft text: ACTA Article 2.14 would mandate criminal liability for “willful trademark counterfeiting or copyright or related rights piracy on a commercial scale.” It goes on to define “willful copyright or related rights piracy on a commercial scale” as including “willful copyright or related rights infringements that have <i>no direct or indirect motivation of financial gain</i>.” Any agreement that envisions “commercial scale activity” as including actions that have ""no direct or indirect motivation of financial gain"" should be negotiated out in the open, if only so the logic behind such linguistic contortions could be fully appreciated by the people who may eventually be subject to this form of criminal liability.</p>
<p>Negotiators insist that ACTA <a href=""http://www.euractiv.com/en/infosociety/eu-defends-itself-attack-acta-news-368771"">will not change existing law</a>. AUSTR Stanford McCoy, for example, <a href=""http://www.ft.com/cms/s/0/27dc0fd6-1147-11df-a6d6-00144feab49a.html"">wrote</a> that “The ACTA negotiations are one of many international efforts to fight counterfeiting and piracy – not to ‘transform’ already strong US and European Union copyright laws.”</p>
<p>But, this is true only in a narrow and technical sense -- ACTA will not [directly] change [statutory] law. What it stands to do, however, is <a href=""http://www.publicknowledge.org/node/2893"">freeze</a> US law in current form, enshrine robust liability abroad without ensuring that equally vigorous <a href=""http://www.cdt.org/policy/acta-debate-gets-specific#2"">limitations</a> exist to protect, among other things, expression and user rights, and powerfully influence legal norms surrounding IP law.</p>
<p>The Obama administration’s plan to pass ACTA as a sole executive agreement also raises <a href=""http://www.washingtonpost.com/wp-dyn/content/article/2010/03/25/AR2010032502403.html"">constitutional concerns</a>.</p>
<p>The folks at Public Knowledge have provided an <a href=""http://www.publicknowledge.org/action/whitehouse_acta""> online form</a> for submitting concerns about ACTA to the offices of the President, Vice President, and USTR.</p>
",Copyright and Fair Use,2010-06-24 15:32,349,Alex Feerst,News
6499,,United States,0,0,Viacom v Google:  Who is the Least Cost Avoider?,Copyright,"<p>I’m late to the party, but I wanted to say a few things about the District Court’s decision in the <span style=""text-decoration: underline;"">Viacom v. YouTube</span> case this week and. This will be a four-part post, covering:</p>
<p>1. The holding</p>
<p>2. The economic principle behind it</p>
<p>3. The next steps in the case</p>
<p>4. A review of the errors in legal analysis and procedure committed by reporters covering the case</p>
<!--break--><p>I’ve written before (see <a href=""http://larrydownes.com/two-smoking-guns-and-a-cold-case/"">“Two Smoking Guns and a Cold Case”</a>, <a href=""http://larrydownes.com/google-v-everyone/"">“Google v. Everyone”</a> and <a href=""http://cyberlaw.stanford.edu/node/5269"">“The Revolution will be Televised…on YouTube</a>”) about this case, in which Viacom back in 2007 sued YouTube and Google (which owns YouTube) for $1 billion in damages, claiming massive copyright infringement of Viacom content posted by YouTube users.</p>
<p>There’s no question of the infringing activity or its scale. The only question in the case is whether YouTube, as the provider of a platform for uploading and hosting video content, shares any of the liability of those among its users who uploaded Viacom content (including clips from Comedy Central and other television programming) without permission.</p>
<p>The more interesting questions raised by the ascent of new video sites aren’t addressed in the opinion. Whether the users understood copyright law or not and whether their intent in uploading their favorite clips from Viacom programming was to promote Viacom rather than to harm it, were not considered. Indeed, whether on balance Viacom was helped more than harmed by the illegal activity, and how either should be calculated under current copyright law, is not relevant to this decision, and are saved for another day and perhaps another case.</p>
<p>That’s because Google moved for summary judgment on the basis of the Digital Millennium Copyright Act’s “safe harbor” provisions, which immunize service providers from any kind of attributed or “secondary” liability for user behavior when certain conditions are met. Most important, a service provider can dock safe from liability only if it can show that it :</p>
<p style=""padding-left: 30px;"">- did not have “actual knowledge that the material…is infringing,” <strong><em>or</em></strong> is “not aware of facts or circumstances from which infringing activity is apparent” <strong><em>and</em></strong></p>
<p>
</p><p style=""padding-left: 30px;"">- upon obtaining such knowledge or awareness “acts expeditiously to remove…the material” <strong><em>and</em></strong></p>
<p>
</p><p style=""padding-left: 30px;"">- does not “receive a financial benefit directly attributable to the infringing activity, “in a case in which the service provider has the right ability to control such activity,” <strong><em> and</em></strong></p>
<p>
</p><p style=""padding-left: 30px;"">- upon notification of the claimed infringement, “responds expeditiously to remove…the material that is claimed to be infringing….”</p>
<p>Note that all four of these elements must be satisfied to benefit from the safe harbor</p>
<p>The question for Judge Stanton to decide on YouTube’s motion for summary judgment was whether YouTube met all the conditions, and he has ruled that they did so.</p>
<p>For the details, see, <a href=""http://larrydownes.com/viacom-v-youtube-the-principle-of-least-cost-avoidance/""> ""Viacom v. YouTube: The Principle of Least Cost Avoidance.</a>""</p>
",Copyright and Fair Use,2010-06-26 21:24,295,Larry Downes,News
6530,European Union,,0,0,Google's New Adwording Policy in Europe,Other IP,"<p>As of yesterday, Google’s <a href=""http://adwords.google.com/support/aw/bin/answer.py?hl=en&answer=177578"">new policy</a> concerning registration of trademarks as keywords for triggering contextual advertisement in many European countries went into effect. The new policy, which strongly relies on the recent <a href=""http://cyberlaw.stanford.edu/node/6446"">ECJ decision</a> on Google’s potential liability for TM infringement via its adwords practice, demonstrates a notable shift in Google’s approach.</p>
<!--break--><p>From now on, registration of TM adwords by third parties will not be restricted, causing the ad to appear next to the organic results list when users enter the keyword as a search term. Angry TM holders are invited to submit their reservations to Google, which, on its part, will then conduct a “limited investigation” to determine whether “a keyword in combination with particular ad text is confusing as to the origin of the advertised goods and services.” That investigation will take into consideration the following factors for allowing registration:</p>
<p>•ads using a trademarked term in a descriptive or generic way, such as not in reference to the term as a trademark; </p>
<p>•ads for competing products or services;</p>
<p>•ads for informational sites about a product or service corresponding to the trademark; </p>
<p>•ads for resale of the trademarked goods or services;</p>
<p>•ads for the sale of components, replacement parts, or compatible products corresponding to a trademark. </p>
<p>It appears that this policy applies only in cases in which the advertiser does not use the mark in the body of the adword. In case Google finds the text of the ad, in combination with the (invisible, TM-related) keyword, confusing as to the source, it will remove the ad but in any case not prevent the registration of the relevant keyword.</p>
<p>There is a number of interesting aspects to the new policy, one of which is the fact that the open list of factors is remarkably similar to exceptions in TM law that could apply where the mark, through the activity of the defendant, becomes perceptible to consumers. For example, generic use of the mark normally will have to mention it. The same applies to the other factors (comparative advertising, informational texts, resale etc.) Therefore, applying these criteria where the mark is invisible to consumers seems a bit odd. </p>
<p>By extension, it is unlikely one of these criteria (or any other criterion that Google may choose to apply) will not provide basis for the conclusion that source confusion is too remote. In addition, the new policy does not take into consideration questions of dilution, in which confusion as to the source is generally irrelevant. </p>
<p>European mark holders who are unsatisfied with the result of Google’s limited investigation can of course go to court, and in that case, Google will almost certainly lose its potential benefits as a passive conduit under the European E-Commerce Directive.</p>
",Copyright and Fair Use,2010-09-15 5:53,279,Zohar Efroni,News
6579,,United States,0,0,Sony v. Tenenbaum: Amicus Brief Urges Due Process Review of Copyright Damages Awards,Copyright,"<p>On Monday we filed an amicus brief on behalf of the Electronic Frontier Foundation in the Sony v. Tenenbaum case, pending in in the First Circuit Court of Appeals. Tenebaum was sued and found liable for copyright infringement for sharing 30 music files. The jury awarded the record label plaintiffs $675,000 in damages. The District Court reduced that award to $67,500, citing constitutional and fairness concerns. Our brief urged the First Circuit to to affirm the reduced award and to comply with the requirements of due process by ensuring that damages in copyright infringement cases bear a reasonable relationship to actual harm inflicted. We were co-counsel on the brief with the Samuelson Law, Technology & Public Policy Clinic and EFF.</p>
<p>A copy of the brief is attached.  </p>
<p>And you can read more here: <a href=""https://www.eff.org/press/archives/2011/01/04"">https://www.eff.org/press/archives/2011/01/04</a></p>
",Copyright and Fair Use,2011-01-05 13:25,325,Julie Ahrens,News
6585,,United States,0,0,Uncertain Implications of Ninth Circuit Ruling on Copyright Licensing,Copyright,"<p>If you have ever actually read through a software end user license agreement, you know that they are often full of restrictions on how you can use the software. Typically, the agreement states that the license to use the software is contingent upon compliance with all of those restrictions. If you violate any of those provisions, you are breaching the agreement. But are you also committing copyright infringement? According to the Ninth Circuit Court of Appeals, it depends.</p>
<p>In its recent <a href=""http://www.ca9.uscourts.gov/datastore/opinions/2010/12/14/09-15932.pdf""> opinion </a> in MDY Industries v. Blizzard Entertainment, the Ninth Circuit held that violation of a provision in a license agreement is only copyright infringement if the provision violated has a ""nexus"" to one of the exclusive rights granted under copyright law -- reproduction, public performance or display, distribution, and creation of derivative works. That means, for example, that failure to obey a license provision prohibiting cheating in a copyrighted video game is not copyright infringement. But violation of a prohibition on creating derivative works of the game would be. This holding has important implications. As EFF has <a href=""http://www.eff.org/deeplinks/2010/12/mixed-ninth-circuit-ruling-mdy-v-blizzard-wow"">pointed out</a>, the court's decision will help prevent copyright owners from using copyright law to enforce onerous requirements on licensees. (Copyright law provides much stronger legal remedies than contract law.) But on the other hand, it is not clear what the decision means for public licensing schemes.<br />{C}</p>
<!--break--><p>Public copyright licenses, such as those provided by Creative Commons, allow creators to grant public access to their works under certain conditions. Often those conditions are directly tied to the exclusive rights of copyright, such as the requirement that the user not modify or create derivative works based on the material. But other public license provisions, such as the requirement of attribution, are not rooted in the exclusive rights of the copyright owner. (American copyright law does not provide for attribution rights.) In 2008, the Federal Circuit held in <a href=""http://jmri.sourceforge.net/k/docket/cafc-pi-1/08-1001.pdf""> Jacobsen v. Katzer </a>that the provisions of public licenses, including attribution requirements, were conditions to the license. Accordingly, a violation of those provisions was a violation of copyright.</p>
<p>But the MDY case seems to call that principle into question. It is possible to distinguish the holdings of the two cases (see e.g., Jeff Neuburger's <a href=""http://newmedialaw.proskauer.com/2011/01/articles/copyright/ninth-circuit-rules-on-license-conditions-versus-contract-covenants-in-dispute-over-world-of-warcraft-bots-mdy-v-blizzard-part-i/"">analysis</a>), but the tension here is undeniable.</p>
",Copyright and Fair Use,2011-01-11 16:44,337,Sarah Hinchliff Pearson,News
6589,,Israel,0,0,Israeli Court Enforces for the First Time a Creative Commons License,Copyright,"<p>A court in Israel found that taking CC-licensed pictures from Flickr and publishing them in a book violated the copyright in each and every picture separately. (Source: <a href=""http://www.law.co.il/news/copyright/2011/01/14/israeli-court-enforced-creative-commons-license/"">www.law.co.il</a>, including a link to the decision in Hebrew).</p>
<!--break--><p>The facts are trivial: Plaintiffs, amateur photographers, uploaded their pictures to Flickr under a CC attribution, non-commercial, no-derivative license. Defendant, a commercial publisher, published the pictures both in a physical format (a book) and some of them also on its website.</p>
<p>To the court it was evident that such unauthorized use violated all three conditions of the Creative Commons license. It did note devote even one single word to the nature of the CC license and the consequences of its arguable breach. It was simply an infringement of copyright. Period.</p>
<p>The court further rejected the fair use defense briefly raised by defendant, and this is probably the most interesting aspect of the decision. A violation of the right of attribution (a classic moral right) pulled the rug from under any possible fair use protection. In other words, no fair use to violators of moral rights, which gives a very interesting twist to fair use law in Israel. The ruling implies that fair use is not all about economic interests. Fair use, (perhaps as in <a href=""http://en.wikipedia.org/wiki/Fair_trade"">Fair Trade</a> or Fair Game), also involves questions of ethical behavior.</p>
<p>The court considered the question of damages the main issue in this litigation, which connects to the question whether publishing the 15 photographs under dispute in one publication constituted one single “bad act”, or rather, fifteen separate violations.</p>
<p>On this point the court accepted the position of plaintiffs and ordered statutory damages for each and every infringed photograph. The reasons: the purpose of the law in protecting authors, promoting original creation and deterring infringers in order to minimize to the extent possible instances of copyright violations.</p>
<p><b>UPDATE:</b><br />Haim Ravia, who represented plaintiffs in this case, draws my attention to the following points:</p>
<p>- Only one photo was published on defendant’s website in addition to being published in the book.<br />- It is not the first time a court rules that fair use (or, in its former incarnation in Israeli CR doctrine, “fair dealing” defense of-a-sort) does not apply to violations of moral rights.</p>
<p>Which makes me think again about what I said above, suggesting that “[t]he ruling implies that fair use is not all about economic interests.” The opposite is just as plausible: fair use has <em>absolutely nothing to do</em> with moral rights, for the good and for the bad. The bottom line remains the same: fair use cannot excuse violation of moral rights.</p>
",Copyright and Fair Use,2011-01-14 3:44,279,Zohar Efroni,News
6599,,France,0,0,Who Said France Does Not Have Fair Use?,Copyright,"<p>Valérie Laure Benabou, a law professor at the University of Versailles and an esteemed expert on French and international copyright law, kindly agreed to share her thoughts on the Google vs. SAIF case decided yesterday by the Paris Court of Appeals: </p>
<blockquote><p>An important decision of the Paris Court of Appeal was rendered yesterday in a litigation between Google and a French Collective Society for Visual Works (SAIF). The Collective Society claimed that Google was infringing on the copyright of its authors members by reproducing and displaying their works in the form of thumbnails on the pages of Google Image service and also by reproducing their works through Google caching system. Before the Court of First Instance, the Judge considered the applicable law to be the U.S. Copyright Act, and consequently, the court applied the fair use defense in line with the Arriba and Perfect 10 decisions.</p>
<!--break--><p>The Court of Appeal disagreed and applied French law. Nevertheless, it too rejected plaintiff's claim and decided that Google benefited from the ""safe harbor"" provisions of the <em>Loi sur la Confiance dans l'Economie Numérique</em> [the relevant French statute]. It considered Google as being a ""neutral"" actor and the reproduction of the photos necessary to provide the service. It also refused to consider a sort of contributory infringement liability when Google refers to works available on the Internet without the consent of the rights holder. </p>
<p>The Court’s decision seems to rely on the fact that Google refers automatically (by a robot crawler) to the images residing on the website. It held that the sole fact that the search algorithm was conceived by Google does not exclude the neutral character of the reference in the absence of any proof to the contrary. It also emphasized that website administrators have the means to exclude their pages from the being indexed by the automated process performed by the search engine. The French judges seem to be in line with the opt-out system already enforced lately by the <a href=""http://ipkitten.blogspot.com/2010/04/bgh-googles-image-search-is-no.html"">German BGH</a>. </p>
<p>It also stated that the fact that the thumbnail can directly point out to the image file without consulting the webpage is not considered a real control over the online content. Providing such a link does not amount to playing an active role in the meaning of the LCEN. The judge did not take into consideration the fact that Google Image service does not only link to the content but also reproduce the picture at different scales on its own pages and that unlike Youtube, the content is not placed by the rights holders on a specific service platform, but is being searched and selected by Google. </p>
<p>In another paragraph, the judges say that the possibility to store the image in Google's caching system after it has been removed from its original page has the purpose of rendering the network fluent and that this transient reproduction is justified by the utility of the system, which provides a quick circulation of information. The Court indicates that this reproduction must therefore be ""tolerated"" per se... Consequently the ""fluency"" of the network appears to be a new exception to copyright, the Court not directly quoting the exception for temporary and transient reproduction deriving from the <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:32001L0029:EN:HTML"">EC 2001 Directive</a>, but ambiguously referring to some of its conditions. </p>
<p>The Court also considers that displaying the thumbnails with the website’s URL only responds to the necessary functionality of the specific tool provided by Google and shall not be considered as exceeding the simple technical service corresponding to the exclusive research of indexed images on the Internet. </p>
<p>The Court seems to aim at establishing a proportionality test between the restrictions of copyright and the functionality required to obtain a quick research of information. Yet, it clearly made the interests of the search engine prevail over the interests of the rights holders who must therefore ""tolerate"" the restrictions on their monopoly for Google's sake. It is remarkable that unlike the decision of first instance, the Court of Appeal did not rely on the alleged gratuity of Google services. That is to say, for the French judges, there is no point at sharing the profit of the search engine with the rights holders even if such profit is derived from uses of protected work without their consent. </p>
<p>Had such a position been adopted when the radio, television, cable, satellite (which are also very useful and provide quick information) came up, copyright would have been long dead. Being mostly a copyright lawyer, I sincerely begin to look for new legal fields to investigate... </p>
<p>Professor Valérie Laure Benabou, University of Versailles (and also consultant at Gilles Vercken Law Office that represented the collective society).</p></blockquote>
",Copyright and Fair Use,2011-01-28 3:41,279,Zohar Efroni,News
6610,,United States,0,0,Anti-transparency,General+Copyright,"<p>Quoted verbatim from a recent DMCA takedown letter:</p>
<blockquote><p>IMPORTANT NOTICE: None of the information contained in this legal notice is to be transmitted and/or released to any third party, including but not limited to Chilling Effects (chillingeffects.org), without the express written permission of the the copyright owner and or his agent. As stated in Section 512 of the Digital Millennium Copyright Act, and in the normal course of processing and notifying the infringing counter party, recipient must only include information specific to that counter party's infringement and must not include this entire notice. Any re-transmission in whole or in part of this legal notice by the intended recipient will be a direct violation of U.S. and International Copyright Law and will be prosecuted to the fullest extent of the law by the copyright owner. </p>
<p>Please also note that with the express permission of the copyright owner, in addition to being forwarded to certain members of the United States Congress and the U.S. Department of Justice, MiMTiD will send this legal notice to a third-party that aggregates repeat infringer data gathered by different agencies and infringement mitigation service companies around the globe and provides centralized access to that data to be used by global policy makers and law enforcement agencies to create and enforce copyright law. As such, this legal notice will included in The Chilling Report (http: //<a href=""http://www.chillingreport.com"">www.chillingreport.com</a>). To obtain secure access to the Chilling Report please email The Chilling Report at xxxxx @chillingreport.com or call (713) xxx-xxxx.</p></blockquote>
<p>This is a step in the <i>opposite</i> direction of optimizing copyright for the cloud, which was the subject of my remarks at the <a href=""http://cyberlaw.stanford.edu/node/6560"">WIPO conference in November</a>.</p>
<!--break--><p></p>
",Copyright and Fair Use,2011-02-08 9:25,265,Tom Rubin,News
6630,,International,1,1,Media Piracy in Emerging Economies,Copyright,"<p>Media Piracy in Emerging Economies is a new, comprehensive study on the impact and role of piracy on/in some of the biggest developing countries: Brazil, Russia, India. The study is out: <a href=""http://www.scribd.com/doc/50196972/MPEE-1-0-1"">http://www.scribd.com/doc/50196972/MPEE-1-0-1</a><br />Follow the latest development at <a href=""http://piracy.ssrc.org/"">http://piracy.ssrc.org/</a></p>
<p>From the Introduction:</p>
<p>Media piracy has been called “a global scourge,” “an international plague,” and “nirvana for criminals,”1 but it is probably better described as a global pricing problem. High prices for media goods, low incomes, and cheap digital technologies are the main ingredients of global media piracy. If piracy is ubiquitous in most parts of the world, it is because these conditions are ubiquitous. Relative to local incomes in Brazil, Russia, or South Africa, the price of a CD, DVD, or copy of Microsoft Office is five to ten times higher than in the United States or Europe. Licit media goods are luxury items in most parts of the world, and licit media markets are correspondingly tiny. Industry estimates of high rates of piracy in emerging markets—68% for software in Russia, 82% for music in Mexico, 90% for movies in India—reflect this disparity and may even understate the prevalence of pirated goods.</p>
<!--break--><p>Acknowledging these price effects is to view piracy from the consumption side rather than the production side of the global media economy. Piracy imposes an array of costs on producers and distributors—both domestic and international—but it also provides the main form of access in developing countries to a wide range of media goods, from recorded music, to film, to software. This last point is critical to understanding the tradeoffs that define piracy and enforcement in emerging markets. The enormously successful globalization of media culture has not been accompanied by a comparable democratization of media access—at least in its legal forms. The flood of legal media goods available in high-income countries over the past two decades has been a trickle in most parts of the world.</p>
<p>The growth of digital piracy since the mid-1990s has undermined a wide range of media business models, but it has also disrupted this bad market equilibrium and created opportunities in emerging economies for price and service innovations that leverage the new technologies. In our view, the most important question is not whether stronger enforcement can reduce piracy and preserve the existing market structure—our research offers no reassurance on this front—but whether stable cultural and business models can emerge at the low end of these media markets that are capable of addressing the next several billion media consumers. Our country studies provide glimpses of this reinvention as costs of production and distribution decline and as producers and distributors compete and innovate.</p>
",Copyright and Fair Use,2011-03-07 2:26,270,Balazs Bodo,News
6656,,Israel,0,0,The Israeli Google Books Class Action,Copyright,"<p>Last week, Google Books suffered another legal attack in the form of a <a href=""http://www.globes.co.il/serveen/globes/docview.asp?did=1000637282&fid=1725"">class action</a>, this time in Israel. I have been reading through the complaint and the class action motion this morning. Below my short description and initial assessment.</p>
<!--break--><p>Plaintiff is the author and sole rights holder in a book printed and published in Israel in 2003. Google, which introduced Google Books in Israel in 2010, scanned among many others also that book, and has been providing snippets view to short excerpts from the text.</p>
<p>Plaintiff filed an action for copyright infringement and unjust enrichment, as well as a motion for approval of the suit as a class action under the <a href=""http://www.google.com/url?sa=t&source=web&cd=6&sqi=2&ved=0CD4QFjAF&url=http%3A%2F%2Fwww.law.stanford.edu%2Fdisplay%2Fimages%2Fdynamic%2Fevents_media%2FIsraeliClassActionLaw_2006.pdf&rct=j&q=israel%20class%20action%20law%202006&ei=cmOlTeC8LorEswa678jtDg&usg=AFQjCNEA4ip69CXabgyqFAI93opooq910A&cad=rja"">Israeli Class Action Law of 2006 </a>(inofficial translation). </p>
<p>The complaint describes Google Books as the “the broadest and bluntest copyright infringement in books in human history.” (All translations are mine.) According to plaintiff, Google has already scanned, stored and publicly displayed “thousands of books (perhaps even tens or hundreds of thousands of books) in the Hebrew language by Israeli authors, as well as books initially published in Israel, which are protected under Israeli copyright law.” </p>
<p>The complaint states that Google Books activities in Israel infringe four exclusive copyrights secured under the <a href=""http://www.google.com/url?sa=t&source=web&cd=1&sqi=2&ved=0CCIQFjAA&url=http%3A%2F%2Fwww.tau.ac.il%2Flaw%2Fmembers%2Fbirnhack%2FIsraeliCopyrightAct2007.pdf&rct=j&q=israel%20copyright%20act%202007&ei=KomlTeTsNYrZsga09qCYCA&usg=AFQjCNEcKU1aJuvoAQHOSc9-qsiwaqpN-w&cad=rja"">Copyright Act of 2007</a>, namely, the reproduction right, the public display right, the broadcasting right and the exclusive right to make works publically available.</p>
<p>According to plaintiff’s “very conservative” estimate, the aggregated monetary damage to all class members reaches the order of hundreds of millions of NIS. The remedies sought include a declaratory judgment concerning the infringing nature of Google’s operations, an injunction for stopping all infringing activities, the removal and/or deletion and/or destruction of all scans unlawfully created and damages. </p>
<p>A few words about Israeli class action law in context: As in the United States, a class action suit requires a court approval. A class plaintiff must have a cause to sue, in certain matters, and that cause must invoke substantial questions of fact or law shared by a group of people in the name of that group.</p>
<p>A court may approve the lawsuit as a class action if certain statutory requirements are met:<br />- The suit raises substantial questions of fact or law shared by all members of the group, and there is a reasonable chance for a decision in favor of this group regarding those questions;</p>
<p>-A class action constitutes the efficient and fair way of solving the dispute under the circumstances;</p>
<p>-There is a reasonable basis to assume that the interest of all class members be properly represented and managed;</p>
<p>-There is a reasonable basis to assume that the interest of all class members be represented and managed in good faith. </p>
<p>Plaintiff argues that all conditions are satisfied here. The motion for class action approval defines the class as “all publishers and all authors that are owners of copyrights under Section 8 of the Copyright Act.” This definition includes books first published in Israel and unpublished books of which authors were citizens or residents of Israel at the time of creation. </p>
<p>Approving a suit as a class action, the court must define the class (either as pleaded by plaintiff or otherwise). The definition cannot include persons having causes of action created subsequently to the approval as class action. (As a side note, it appears that including owners of yet-to-be-scanned-books is impossible, and, by extension, the so-called “looking forward” business models Judge Chin has criticized in his decision cannot be subject of a settlement also under Israeli law.) </p>
<p>Indeed, Israeli class action law is familiar with the instrument of a class action settlement. Such settlement is subject to a court approval, and sec. 19(a) to the Class Action Law stipulates that a court shall not approve a settlement unless it has found it to be “adequate, fair and reasonable” (sounds familiar?), while taking into account the interests of all class members. </p>
<p>Down the road, it is conceivable the parties would prefer to settle and submit the settlement draft for a court approval. The readiness of the parties to negotiate a class action settlement would likely be a function of their chances to win or lose in trial. Take the accusation Google violates the reproduction right, for instance. I do not think it could be seriously argued that scanning and storing complete titles does not implicate that right, whether under Israeli law or under the law of any county member of the Berne Convention. However, unlike most copyright jurisdictions worldwide, Israel has a fair use provision modeled very similarly after its American predecessor.</p>
<p>Google most certainly will raise this fair use provision as a principal defense. Regarding scanning for indexing purposes and snippets view, it might even convince the court to apply this recent and virtually untested provision in its favor. In that event, an Israeli court might have the chance to scrutinize a fair use defense to Google Books earlier than courts in other jurisdictions.</p>
<p>By virtue of the class definition, a settlement or a judgment here would cover significantly fewer works and authors compared to the parallel proceeding in the United States. In this respect, it is of less interest to outside observers. For fair use fans, however, perhaps the fun is just about to start. </p>
<p>-Thanks to Nati Polinger (attorney for plaintiff) for providing quick access to the court documents.</p>
",Copyright and Fair Use,2011-04-13 6:54,279,Zohar Efroni,News
6752,,United States,0,0,David Post: Occupy Hollywood (and stop SOPA),Copyright,"<p>Last July, I signed on to a <a href=""http://blogs.law.stanford.edu/newsfeed/files/2011/07/PROTECT-IP-letter-final.pdf"">letter</a> from more than 100 law professors urging Congress to reject the PROTECT-IP Act. A new version of that bill -- referred to as both the E-PARASITE Act and SOPA -- was introduced in the House last week, and it is even more dangerous than its predecessors. See David Post's <a href=""http://volokh.com/2011/11/04/how-about-occupy-hollywood/"">critique</a> at the Volokh Conspiracy. Hear Mark Lemley's <a href=""http://marketplace.publicradio.org/display/web/2011/10/27/tech-report-new-house-bill-could-kick-you-and-your-website-off-internet/?refid=0"">discussion</a> on APM's Marketplace. Once you do, you'll probably ask <b>""what can I do to stop this?""</b> You can start by signing this <a href=""https://wwws.whitehouse.gov/petitions#!/petition/stop-e-parasite-act/SWBYXX55"">petition</a> at whitehouse.gov, and using this tool from EFF to <a href=""https://wfc2.wiredforchange.com/o/9042/p/dia/action/public/?action_KEY=8173"">write your Senator and Congressperson</a> -- wherever you live. </p>
<!--break-->
","Architecture and Public Policy, Copyright and Fair Use",2011-11-04 12:24,281,Anthony Falzone,News
6762,,United States,0,0,Opposition To SOPA Continues To Grow,Copyright,"<p>Representatives Anna Eshoo and Zoe Lofgren joined eight other members of Congress in urging the House Judiciary Committee to reject SOPA because it would cause ""serious and long term damage to the technology industry"" -- ""one of the few bright spots in our economy.""</p>
<p>Nine of the leading internet companies, including Google, Facebook, Twitter and Zynga also sent a letter to key member of the Committee explaining that SOPA would jeopardize protections that ""have been a cornerstone of the U.S. Internet and technology industry’s growth and success.""</p>
<p>Both letters are attached below, and you can find lots more information on the <a href=""http://www.protectinnovation.com/"">Protect Innovation homepage</a>.</p>
<!--break-->
","Architecture and Public Policy, Copyright and Fair Use, Privacy",2011-11-15 11:36,281,Anthony Falzone,News
6764,,United States,0,0,Stop Censorship: The Problems With SOPA,Copyright,"<p>Today Congress held hearings on the latest IP legislation, the Stop Online Piracy Act (SOPA). We are taking part in American Censorship Day to help spread the word and stop this bill. We’ve outlined five of the most important problems with SOPA.</p>
<p><b>1. SOPA violates due process.</b> Under SOPA, any private copyright or trademark owner can cut-off advertising and payments to any website by alleging that the operator “avoid[ed] confirming a high probability” that “a portion” of its site is being used to infringe copyrights. Advertisers and payment companies (e.g. Visa, Mastercard, and PayPal) are then required to stop doing business with that site. It seems likely that content owners (or people merely claiming to be content owners) will often succeed in shutting down websites without ever going to court. The proposed legislation also gives the Attorney General and the Justice Department the power to shut down websites before they are actually judged infringing. Courts will be able to order any Internet service provider to stop recognizing an accused site immediately upon application by the Attorney General, after an ex parte hearing. By failing to guarantee the challenged websites notice or an opportunity to be heard in court before their sites are shutdown, SOPA violates due process. Read more: <a href=""http://www.scribd.com/doc/72807693/Law-Profs-Letter-Against-SOPA-PROTECT-IP"">Letter to Congress</a> from over 100 law professors techdirt explains that SOPA would create the <a href=""http://www.techdirt.com/articles/20111026/12130616523/protect-ip-renamed-e-parasites-act-would-create-great-firewall-america.shtml"">Great Firewall of America.</a></p>
<p><!--break--></p><p><b>2. SOPA censors lawful speech.</b> As described above, the legislation allows any content provider or the Attorney General to accuse a website of promoting infringing content and have that site blocked from the Internet. The legislation’s vague standards for liability mean that the only way for Internet service providers and websites to avoid liability is to over-block content, including non-infringing speech. And by ordering Internet service providers to remove any offending domain name, it would require the suppression of all sub-domains associated with the domain-- censoring thousands of individual websites with vast amounts of protected speech containing no infringing content. Read more: Law professor David Post on <a href=""http://volokh.com/2011/11/04/how-about-occupy-hollywood/"">SOPA, due process, and speech</a> More coverage from <a href=""http://arstechnica.com/tech-policy/news/2011/07/dozens-of-law-professors-protect-ip-act-is-unconstitutional.ars"">ars technica</a> and <a href=""http://www.techdirt.com/articles/20111111/16242216727/first-amendment-expert-floyd-abrams-admits-sopa-would-censor-protected-speech-thinks-its-okay-collateral-damage.shtml"">techdirt</a>.</p>
<p><b>3. SOPA breaks the Internet’s infrastructure.</b> By tampering with the Domain Name System (DNS), SOPA breaks Internet security and encourages the development of an insecure, offshore pirate DNS. Read more: Experts explain why SOPA's DNS filtering provisions raise such <a href=""http://www.shinkuro.com/PROTECT%20IP%20Technical%20Whitepaper%20Final.pdf"">serious technical and security concerns.</a> techdirt concludes that SOPA's <a href=""http://www.techdirt.com/articles/20110531/13331214491/why-protect-ip-breaks-internet.shtml"">collateral damage</a> will be significant.</p>
<p><b>4. SOPA blows up the safe harbor.</b> Under existing law, providers are shielded from liability for their users’ possible copyright infringement so long as they remove allegedly infringing material when they get complaints. SOPA turns this system upside down. Under SOPA, content owners can require advertisers and payment companies to stop doing business with any website that allegedly has any portion used to infringe copyrights or trademarks. Content owners will have the power to shut down websites without ever going to court. Read more: Public Knowledge explains why SOPA is a <a href=""http://www.publicknowledge.org/blog/house-version-rogue-websites-bill-adds-dmca-b"">DMCA bypass.</a> EFF illustrates how SOPA could be used to <a href=""https://www.eff.org/deeplinks/2011/10/sopa-hollywood-finally-gets-chance-break-internet"">strangle sites</a> that have been found to be legal. techdirt concludes that SOPA is the <a href=""http://www.techdirt.com/articles/20111027/00083116531/e-parasites-bill-end-internet-as-we-know-it.shtml<br />"">end of the internet as we know it.</a></p>
<p><b>5. SOPA kills innovation.</b> By vastly increasing the risks associated with hosting user-generated content, SOPA will make it far more difficult to start new internet companies. If SOPA had been the law, it is doubtful that Facebook or YouTube would have been able to launch. Read more: <a href=""http://politechbot.com/docs/sopa.google.facebook.twitter.letter.111511.pdf"">Letter to Congress</a> from internet and technology companies <a href=""https://docs.google.com/document/d/14CkX3zDyAxShrqUqEkewtUCjvvFdciIbKjC18_eUHkg/edit?hl=en_US&authkey=CNHr3I4L&ndplr=1&pli=1"">Letter to Congress</a> from dozens of venture capitalists <a href=""https://www.dropbox.com/s/9zuzi16dv7gcoq0/Ulevitch_Letter_To_Congress.pdf"">Letter to Congress</a> from OpenDNS Brad Burnham on <a href=""http://bradburnham.tumblr.com/post/12739727902/i-believe-in-the-internet-the-content-industry"">SOPA and innovation</a> Union Square Ventures explains how SOPA will <a href=""http://www.usv.com/2011/06/the-protect-ip-act-will-slow-start-up-innovation.php"">slow start-up innovation</a> and <a href=""http://www.usv.com/2011/11/help-protect-internet-innovation.php"">what you can do about it.</a></p>
","Architecture and Public Policy, Copyright and Fair Use",2011-11-16 15:13,325,Julie Ahrens,News
6769,European Union,,0,0,The ECJ's Scarlet Decision: No Broad Filtering Duty for European ISPs,Copyright,"<p>Per today's ruling, injunctions against European ISPs requiring them to apply filtering tools that monitor traffic to prevent copyright infringement officially violate EU law. The <a href=""http://curia.europa.eu/jurisp/cgi-bin/form.pl?lang=EN&Submit=rechercher&numaff=C-70/10"">Scarlet decision</a> puts a major stick in the wheel of wholesale copyright holders fighting against file sharing activities. With the expected implementation of the <a href=""http://en.wikipedia.org/wiki/Anti-Counterfeiting_Trade_Agreement"">ACTA</a> in mind, this ruling by the European Court of Justice (ECJ) will likely affect both prospective copyright legislation in Europe and offensive strategies of rights holders in their operations against intermediaries.</p>
<!--break--><p>A summary of the facts and the holding is available <a href=""http://curia.europa.eu/jcms/upload/docs/application/pdf/2011-11/cp110126en.pdf"">here</a>. In a nutshell, a Belgium company (SABAM), described as “a management company which represents authors, composers and editors of musical works in authorising the use of their copyright-protected works by third parties”, demanded that a certain ISP (Scarlet) monitored all passing-through communications, identify copyright infringements in music and video files and intercept on-the-fly unauthorized exchange of copyrighted data over file sharing protocols.</p>
<p>The ECJ ruled today that imposing such a duty on ISPs could not be reconciled with several principles of EU law. The filtering system in question was supposed to have several components that, taken together, make a powerful control mechanism: </p>
<p>1.It would indiscriminately monitor all traffic that passes through the ISP communication infrastructure.</p>
<p>2.It would apply indiscriminately to all end-users.</p>
<p>3.It would serves as a preventive measure, other than enforcement after an infringement has taken place.</p>
<p>4.The ISP must bear the entire costs of implementing the system.</p>
<p>5.For an unlimited period of time.</p>
<p>Given these features of the system, the Court had good reasons to make sure it will never see the light of day, at least not via injunctions coercing ISPs to install such filters for the sake of preventing copyright infringement. And so it did. </p>
<p>One key norm is section 15(1) of the E-Commerce Directive (2000/31/EC) that explicitly prohibits imposing “a general obligation on providers … to monitor the information which they transmit or store, nor a general obligation actively to seek facts or circumstances indicating unlawful activity.”</p>
<p>This prohibition, which concerns a general ISP monitoring duty, does not mean that the option of issuing injunctions (also as a preventive measure) becomes unavailable. In fact, the Information Society Directive (2001/29/EC) and the Enforcement Directive (2004/48/EC) set out the circumstances under which such preventive measures per national law might pass muster. Accordingly, preventive measures must be (1) fair (2) proportionate and (3) they must not be excessively costly. </p>
<p>The Court concluded that, reading all the relevant Directives together, a general monitoring obligation concerning the entire ISP traffic cannot survive. The fairness and proportionality parameters require balancing preventive measures against fundamental rights of both ISPs (to conducts a business) and users (to receive or impart information).</p>
<p>Finally, blocking communication suspected as infringing, without allowing application of copyright exceptions or determining a public domain status of a given work, would overly undermine the freedom of information tenet. </p>
<p>In addition, since the system would involve analyzing personal data of end-users, also privacy considerations weighted against the filtering system copyright holders sought to impose.</p>
<p>The absurdly broad demands of rights holders in this case made its easy on the court to quickly brush them away. At least in theory, however, courts might still issue less restrictive injunctions against ISPs, for instance, when the filter is not applied to all traffic of data, when rights holders agree to share the costs, or when the filter is activated for a limited period of time. In other words, the facts make this ruling easily distinguishable from other instances of monitoring and filtering. </p>
<p>One last observation: The binding part of the decision seems to be targeting the scope of injections courts may issue under existing laws, not necessarily new legislation. At the same time, the strong reference the Court makes to constitutional norms would make it difficult for both national and European legislatures to turn a blind eye to the role freedom of information now plays within the ongoing process of forming legal frameworks for cyberspace.</p>
<p>I wonder what the ECJ (with its demonstrated sensitivity here to fairness, proportionality and freedom of information) would have to say about something akin of the <a href=""http://en.wikipedia.org/wiki/Stop_Online_Piracy_Act""> SOPA</a>, especially on its section concerning ISPs liability.</p>
","Copyright and Fair Use, Architecture and Public Policy",2011-11-24 12:51,279,Zohar Efroni,News
6774,,United States,0,0,Controversial Copyright Bills Would Violate First Amendment--Letters to Congress by Laurence Tribe and Me,Copyright+Freedom of Expression,"<p><em>Cross posted from <a href=""http://ammori.org/2011/12/08/controversial-copyright-bills-would-violate-first-amendment-letters-to-congress-by-laurence-tribe-and-me/"" target=""_blank"">Marvin Ammori's Blog Ammori.org</a>.</em></p>
<p>Today, both Professor Laurence Tribe and I submitted letters and legal memoranda to Congress explaining that proposed copyright legislation would violate the First Amendment and be struck down in court. (His letter is <a href=""http://www.net-coalition.com/wp-content/uploads/2011/08/tribe-legis-memo-on-SOPA-12-6-11-1.pdf"">available here</a>, and <a href=""http://ammori.files.wordpress.com/2011/12/ammori-first-amd-sopa-protectip.pdf"">mine is available here</a>.)</p>
<p>Professor Tribe is perhaps the nation's <a href=""http://www.law.nyu.edu/journals/annualsurveyofamericanlaw/dedications/laurencetribe/index.htm"">leading constitutional law expert</a> and among its greatest Supreme Court advocates. My expertise is in Internet law, and I <a href=""http://www.nytimes.com/2010/05/16/us/politics/16court.html"">research</a>, <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1791125"">write</a> on, and <a href=""http://tedxtalks.ted.com/video/TEDxUofM-Marvin-Ammori-Freedom"">litigate</a> issues concerning the 21st Century First Amendment.</p>
<p>We both felt compelled to write because of the threat to freedom of speech from the PROTECT IP Act in the Senate and the Stop Online Piracy Act (or SOPA) in the House.  Others have also come out to oppose the bills, including <a href=""http://americancensorship.org/"">the leading civil liberties organizations</a> (at home and <a href=""http://www.net-coalition.com/wp-content/uploads/2011/08/SOPA-letter-from-Intl-human-rights-community-1.pdf"">abroad</a>), <a href=""http://news.cnet.com/8301-31001_3-20074110-261/vcs-to-congress-antipiracy-bill-will-chill-tech-investment/?tag=mncol;txt"">venture capitalists</a>, the leading technology platforms <a href=""http://www.protectinnovation.com/downloads/letter.pdf"">from Facebook and Google</a> to <a href=""http://techcrunch.com/2011/11/16/tumblr-takes-fight-against-sopa-up-a-notch-censors-user-dashboards/"">Tumblr</a> and Zynga, and (today) <strong>hundreds</strong> of entrepreneurs. <a href=""http://www.washingtonpost.com/business/economy/sopa-opposition-goes-viral/2011/11/22/gIQAZX7OmN_story.html"">In fact</a>, a million people emailed Congress and well over 90,000 personally called their Members to oppose the bills, many during a coordinated ""<a href=""http://americancensorship.org/"">American Censorship Day</a>"" inspired by the bills' free speech burdens, a day organized by <a href=""http://fightforthefuture.org/"">Fight for the Future</a>, <a href=""http://demandprogress.org/"">Demand Progress</a>, <a href=""https://www.eff.org/"">Electronic Frontier Foundation</a>, <a href=""http://publicknowledge.org/"">Public Knowledge</a>, and <a href=""http://www.mozilla.org/"">Mozilla</a>, among others. Over 90 law professors have also come out <a href=""http://arstechnica.com/tech-policy/news/2011/07/dozens-of-law-professors-protect-ip-act-is-unconstitutional.ars"">against</a> the Senate version and even more <a href=""http://www.scribd.com/doc/72807693/Law-Profs-Letter-Against-SOPA-PROTECT-IP"">against</a> the House version.</p>
<p>The bills are not limited; they're sledgehammers not scalpels.</p>
<p>They do not, as often advertised by the copyright industry, merely target foreign ""rogue"" sites <a href=""http://torrentfreak.com/mpaa-lists-notorious-pirate-sites-to-u-s-government-111028/"">like the Pirate Bay</a>. They are not even limited to sites guilty of <em>any</em> copyright infringement, direct or even contributory infringement. Instead, the bills would extend not only to foreign but also to<em> domestic</em> websites that merely ""facilitate"" or ""enable"" infringement.  Thus, in their language, the bills target considerable protected speech on legitimate sites such as <a href=""http://arstechnica.com/tech-policy/news/2011/11/on-wednesday-reddit-which-like.ars"">YouTube</a>, Twitter, and Facebook.  The bills also affect non-infringing speech by search engines, advertisers, and domain name providers.</p>
<p>Coupled with this overbroad scope, the bills authorize remedies that lack the usual procedural safeguards, ensuring that even more protected, non-infringing speech will be restricted. Even though a judicial determination is generally required to remove speech from circulation, the House version empowers copyright-holders to send notices to payment processors and advertisers to shut off funding for non-infringing sites that meet the bill's broad definitions. The bills also encourage over-enforcement by making companies immune from suit for mistakenly punishing sites outside even the bills' over-expansive scope.</p>
<p>My letter addresses the threshold question of why standard First Amendment scrutiny applies to these bills. Some suggest that the bills should get a constitutional pass because they merely suppress copyright infringement, and copyright statutes generally receive relaxed scrutiny under the First Amendment. But, as noted above, these bills target considerable speech by speakers who are engaging in no direct or indirect infringement, from websites ""enabling"" infringement to advertisers engaged in truthful, non-infringing commercial speech and search engines delivering results. Because these bills restrict considerable protected non-infringing speech, several different doctrines would trigger standard First Amendment scrutiny. These doctrines include the Supreme Court's doctrines of overbreadth, vagueness, and prior restraint, as well as its decisions in <em>United States v. Stevens</em> and  <em>Eldred v. Ashcroft</em>.  Standard First Amendment scrutiny, not any standard applicable to copyright infringement, would logically apply for restrictions on non-infringing, protected speech by search engines, domain name providers, and advertisers. Under standard First Amendment scrutiny, both PROTECT IP and SOPA are clearly unconstitutional in restricting these categories of protected speech.</p>
<p>Professor Tribe's letter reaches the same conclusion, focusing on the House version of the bill, SOPA, and focusing on the application of standard First Amendment principles, rather than my letter's focus on justifying these principles' application. His analysis concludes that portions of the bill are unconstitutional as prior restraints, as unconstitutionally vague, and for not being narrowly tailored to a compelling or important interest as required to pass the heightened scrutiny applicable to speech restrictions. Professor Tribe also responds to the arguments provided <a href=""http://www.scribd.com/doc/72589996/Floyd-Abrams-Stop-Online-Piracy-Act-Letter-To-House-Judiciary-On-Free-Speech"">by Floyd Abrams</a> that SOPA is not an unconstitutional prior restraint; he explains that Mr. Abrams's own analysis provides evidence that SOPA's provisions are in fact unconstitutional. (Abrams' clients are copyright companies; Tribe's are consumer electronics companies; mine are tech companies.)</p>
<p>Professor Tribe and I make some overlapping arguments, even without coordination or planning, because the House and Senate bills so evidently violate core principles of First Amendment doctrine--overbreadth, vagueness, prior restraint and others.</p>
<p>Civil liberties organizations describe the bills as encouraging ""American censorship,"" a weighty charge; the legal analysis by Professor Tribe and I support that conclusion. At least, according to the American Supreme Court's established First Amendment jurisprudence.</p>
<p>Congress does not need to pass bills sure to be struck down after years of litigation, uncertainty, and millions of taxpayer dollars wasted in fruitless litigation. Congress need not send a message to the Internet that it seeks to censor the web.</p>
<p>Congress can, in fact, remedy the bills by narrowing them to conform to constitutional limits. As both Professor Tribe and I suggest, Congress should begin by focusing its bills on actual infringement, rather than on speech far beyond infringement. And Congress should ensure adversary judicial proceedings before the silencing of speech available to Americans.</p>
<p>I provide greater detail  in the last few pages of <a href=""http://ammori.files.wordpress.com/2011/12/ammori-first-amd-sopa-protectip.pdf"">my memorandum</a> on the particular steps Congress should take to narrow the bills enough to survive First Amendment scrutiny--steps that can preserve freedom of speech for the future users and creators on the Internet.</p>
","Architecture and Public Policy, Copyright and Fair Use",2011-12-08 12:07,362,Marvin Ammori,News
6787,,United States,0,0,CIS Is Going Dark To Stop SOPA,Copyright,"<p>A <a href=""http://www.forbes.com/sites/garyshapiro/2012/01/11/americans-revolt-against-copyright-powergrab/"">wave</a> of opposition has crashed over the House's Stop Online Piracy Act (SOPA) and the Senate's Protect I.P. Act (PIPA) based on the tremendous threat they pose to free speech and innovation online. It appears the House may be poised to abandon SOPA after the White House issued a <a href=""https://wwws.whitehouse.gov/petition-tool/response/combating-online-piracy-while-protecting-open-and-innovative-internet"">statement</a> making clear it would not support the bill. But the Senate is still pressing ahead with PIPA's most dangerous provisions intact, including those that would force internet service providers to block access to entire sites through DNS blocking and other means that threaten both the universality and the security of the internet itself.</p>
<p>If this legislation passes -- in this version or another -- legitimate websites will be threatened. Some will disappear. Tomorrow, the CIS website will disappear (along with many others) to protest the misguided approaches SOPA and PIPA employ, and to demonstrate the threat they pose. We'll be back on Thursday. In the meantime, <a href=""http://cyberlaw.stanford.edu/sopa/"">read up</a> on the dangers these bills pose, and what you can do to make a difference.</p>
<p>If you want take your site down, here are some tools from <a href=""http://techcrunch.com/2012/01/16/cloudflare-builds-stop-censorship-app-lets-sites-easily-black-out-against-sopa/"">CloudFlare</a> and <a href=""http://www.webmonkey.com/2012/01/protest-sopa-blackout-your-website-the-google-friendly-way/"">Webmonkey</a> that make it easy.</p>
<!--break-->
","Architecture and Public Policy, Copyright and Fair Use",2012-01-17 10:45,281,Anthony Falzone,News
6795,,United States,0,0,Megaupload: A Lot Less Guilty Than You Think,Copyright,"<p>The recent Department of Justice decision to indict Megaupload for copyright infringement and related offenses raises some very thorny questions from a criminal law perspective. A few preliminaries: I’m responsible for the musings below, but I thank Robert Weisberg of Stanford Law School for taking the time to talk through the issues and giving me pointers to some relevant cases. Also, an indictment contains unproven allegations, and the facts may well turn out to be different, or to imply different things in full context.</p>
<p>DMCA SAFE HARBOR: BELIEVE IT AND IT WILL BECOME REAL: As a matter of criminal law, the discussion of whether Megaupload did what it needed to do to qualify for the DMCA Safe Harbor misses the point. Did they register an agent? Did they have a repeat infringer policy? These are all interesting CIVIL questions. But from a criminal law perspective, the important question is did Defendants BELIEVE they were covered by the Safe Harbor? This is because criminal infringement requires a showing of willfulness. The view of the majority of Federal Courts is that “willfulness” means a desire to violate a known legal duty, not merely the will to make copies.</p>
<!--break--><p>In other words, for criminal liability, it doesn’t really matter whether the service qualifies, so long as Defendants believed it qualified. If so, they were not intentionally violating a known legal duty, and so their conduct would not satisfy the willfulness element of the offense. For criminal liability after the DMCA safe harbor, as in horseshoes, close may be good enough.</p>
<p>SECONDARY COPYRIGHT LIABILITY AND CRIMINAL LAW:</p>
<p>The heart of this case is whether and when an enterprise can be held criminally liable for the conduct of its users. (For example, both copyright infringement claims (Counts 4 and 5) identify aiding and abetting as a basis for the charge.)</p>
<p>Aiding and abetting is something like the civil liability inducement theory the U.S. Supreme Court created in the 2005 Grokster case. Experts opine that the indictment makes out a pretty good inducement case against Megaupload. But the first question from a defense perspective has to be “Can the Grokster theory of CIVIL liability even be the basis for CRIMINAL copyright claims?” This has never been decided by any Court.</p>
<p>However, the pending Second Circuit case of Puerto 80 Projects v. USA (“Rojadirecta“), raises the issue squarely. There, the plaintiff is challenging the ICE seizure of its Rojadirecta domain names based on an allegation of criminal copyright infringement. For background on the case, and on the ICE domain seizures, check out Techdirt’s coverage.</p>
<p>Rojadirecta’s lawyers at Durie Tangri have challenged the U.S. Government’s assertion that criminal liability arises from linking to infringing content. The lawyers argue that judge-made secondary infringement liability theories, including Grokster style inducement, cannot be the basis for a criminal copyright violation because the criminal copyright statute doesn’t mention secondary liability. Congress considered and rejected statutes that would have created such liability, in COICA and PROTECT IP. In sum, due process doesn’t allow incarceration under a civil legal theory that the Supreme Court dreamed up in 2005. The issues yet to be decided in Rojadirecta apply to the Megaupload case as well.</p>
<p>AGREEMENT + CIVIL VIOLATION = PRISON?: Count 2 is a conspiracy to commit copyright infringement claim, and references unknown parties as members of the conspiracy. Conspiracy entails an agreement to commit an offense and an overt act in furtherance of that agreement. The act in furtherance need not itself be illegal, but there must be an agreement to do an illegal act. The list of overt acts show that the object of the conspiracy was infringement by Mega users. If Defendants agreed with each other to induce others to infringe, and Rojadirecta’s lawyers are correct that inducement is not a crime, there’s a conspiracy only to violate a CIVIL law. If the idea is that Mega conspired with its users to infringe, those users may or may not have been criminally infringing copyright. They were located all over the world, and may or may not have acted willfully, i.e. intended to violate U.S. law. Again, the government would basically have alleged an agreement to violate a U.S. CIVIL law, including by many people who are not subject to U.S. rules.</p>
<p>Is it a federal crime to conspire to induce others to violate a U.S. civil law?</p>
<p>The answer to that is an obvious “no”. The conspiracy statute itself makes clear that the object of the conspiracy must be an offense or fraud against the United States, in other words, a federal crime. 18 U.S.C. 371. It is true that Oliver North and John Poindexter were prosecuted for conspiracy to violate Boland Amendment, which prohibited Defense Department spending on the Nicaraguan Contras, but was not itself a crime. And there is a 1979 case (U.S. v. Ruffin, 613 F.2d 408 (2nd cir. 1979), where the defendant was convicted of conspiracy when he convinced an unwitting person to divert federal funds to the defendant’s personal benefit. But both cases constituted fraud involving U.S.taxpayer dollars, which is also a basis for conspiracy liability. Civil violations simply are not.</p>
<p>For these reasons, prosecuting this case against Mega, especially if Defendants get good criminal lawyers who also understand copyright law, is going to be an uphill battle for the government.</p>
<p>A few other points. Some direct infringement convictions look easy, but COUNT 4 IS WEIRDLY INCOMPLETE: I agree with the copyright law experts interviewed by Ars Technica that the most damning allegations in the indictment are the claims of direct infringement, particularly for the prerelease movies. Interestingly, the indictment identifies four films that the defendants supposedly distributed before release: The Green Hornet, Thor, Bad Teacher, Twilight–Breaking Dawn Part 1. But Count 4 only charges one such act of prerelease infringement, the movie Taken. What about the other films? Why were those not also charged? </p>
<p>Finally, this case is extremely interesting from a JURISDICTIONAL standpoint. One of the very first issue to be litigated will be extradition to the United States. Does the United States have jurisdiction over anyone who uses a hosting provider in the Eastern District of Virginia? What about over any company that uses PayPal? That’s a very broad claim of power, and I expect it will be vigorously contested.</p>
","Architecture and Public Policy, Copyright and Fair Use",2012-01-26 11:47,240,Jennifer Granick,News
6797,,United States,0,0,First Amendment Challenges in the Digital Age,Freedom of Expression,"<p>Next Friday, February 10, the <em>Stanford Technology Law Review</em> is holding its annual symposium, and this year's topic is an important one:<a href=""http://www.law.stanford.edu/calendar/details/5884/Stanford%20Technology%20Law%20Review%20Symposium/""> First Amendment Challenges in the Digital Age</a>. Of the three panels, one is devoted to privacy and another to copyright. The third is devoted to a long, ambitious law review article ... written by me. The panel participants joining me to discuss the article are two of the nation's great free speech scholars--Harvard's Yochai Benkler and the University of Virginia's Lillian BeVier. The article is called <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1791125"">First Amendment Architecture</a>. In it, I argue that the First Amendment plays an important role in ensuring adequate physical and digital spaces for speech, and that this role is not some exceptional outgrowth of First Amendment doctrine but is central to understanding what the First Amendment ""means."" While I submitted the paper for publication in February 2011, the subsequent events of the Arab Spring, the Occupy Movement, and the fight over SOPA/PIPA have all highlighted the significance to democratic speech of open physical and digital spaces.</p>
<p>I am using the occasion of this symposium panel to blog about <em>First Amendment Architecture</em>. Law review ""articles"" generally add up to 30,000 words, or 60 pages, and have hundreds of footnotes and use semi-colons; this article is definitely a creature of that genre. My language in the piece is <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1791125"">simple</a> I think, but the blog genre is better for discussing the same arguments in bite-sized, digestible pieces. Several people have already blogged about my article briefly (saying nice things even), such as law professors Tim Wu (calling it ""<a href=""http://www.concurringopinions.com/archives/2011/03/brewing-free-speech-scholarship.html"">important work</a>"") and Susan Crawford (calling it ""<a href=""http://scrawford.net/blog/reading-brown-v-entertainment-merchants-assn/1445/"">a terrific article</a>""), as well MSNBC host Dylan Ratigan (saying it addresses ""<a href=""http://www.dylanratigan.com/2011/11/04/bought-justice-and-the-supreme-court/"">important ... First Amendment questions</a>"") .</p>
<p>This first post is more about the amazing panel and about why I chose to research and write this article. The next pieces will present the article's arguments more fully.{C}</p>
<!--more--><p>
<strong>First, the amazing panel.</strong> I am so nerd-excited that two of the nation's leading First Amendment scholars will critique and respond to the arguments I have been marking.  Harvard's Yochai Benkler may agree with me at points and Lillian BeVier of UVA will likely disagree with me at many points. For those unfamiliar with Benkler, Larry Lessig calls him ""the <a href=""http://www.ted.com/speakers/yochai_benkler.html"">leading intellectual</a> of the information age,"" and he is a leading <a href=""http://www.benkler.org/WhitePaper.pdf"">free speech</a> theorist. He was also my professor and <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=699823"">paper advisor</a> when I was in law school. (That had a major effect on the trajectory of my life.) He is also one of the kindest people I've ever met. BeVier is also a giant in First Amendment scholarship, having made important contributions to constitutional law on impenetrable topics ranging from the state action doctrine to the public forum doctrine. I have learned a lot from her work. It's an honor that she will take the time out of her schedule to disagree with me on the  panel. In a phone call, she has kindly called my article ""um... ambitious."" I'll take that.</p>
<p><strong>Second, why I wrote this paper.</strong> My mom knows that I have led something of a double life over the past few years, with one foot in public policy and one in academia. (I now keep toes in policy and the think tank world.) But a lot of people from one world don't realize I have worked in the other. For example, last week, I had lunch with technology lawyers in Washington, DC. These lawyers knew me from my work to help advance <a href=""http://en.wikipedia.org/wiki/Network_neutrality"">network neutrality</a> and to help defeat the <a href=""http://ammori.org/2011/12/08/controversial-copyright-bills-would-violate-first-amendment-letters-to-congress-by-laurence-tribe-and-me/"">Stop Online Piracy Act (SOPA)</a>, etc. These lawyers asked me if I had ever heard of the Space and Cyberlaw Program at the University of Nebraska. I had indeed heard of it—while a law professor for a few years, I was a co-founder of the program and helped build it into a program educating many of the US Air Force's cyber-lawyers and educating some of DC's <a href=""http://newamerica.net/user/347"">rising</a> <a href=""http://ammorigroup.com/luke-pelican/"">legal</a> stars in tech. Similarly, years ago, while at Nebraska, on the day the DC Circuit struck down the FCC’s <em>Comcast/BitTorrent</em> order in April 2010, several of the other law professors on my faculty noticed the headlines on the front pages of the <em>WashingtonPost.com</em>, the <em>NYTimes.com</em>, and even the <em>Huffington Post</em>, which had run the ominous banner headline “The Day the Internet Lost.” While several students offered me condolences on the decision, three of my colleagues on the faculty asked me, “Hey, have you heard about this Internet case everyone is talking about?” I had indeed heard of—I had <a href=""http://articles.philly.com/2008-07-31/news/25246196_1_comcast-customers-marvin-ammori-jonathan-s-adelstein"">brought</a> the case before the FCC and argued it (and <a href=""http://ammori.org/2010/04/07/how-i-lost-the-big-one-bigtime/"">lost</a>) before the DC Circuit.</p>
<p>I saw the need for this article because of that double life. Much of my work strikes me as pretty unified: as a lawyer, working in several areas, I have thought about how to promote freedom of speech broadly for everyone. To me, freedom of speech and debate are necessary inputs in solving any of our nation's problems, from homelessness and economic inequality to banking, the environment, and national security. Freedom of speech is what Larry Lessig would call a ""<a href=""http://rootstrikers.org/"">root</a>"" issue; working on free speech is striking at a root issue.</p>
<p>Thinking about free speech brought me to media regulation, as Americans access so much of their political and cultural speech through mass media. That led me to work on the FCC's media ownership rules beginning in 2005 to fight media consolidation, working with those at Georgetown's IPR, Media Access Project, Free Press and others. I then turned to the Internet as the core speech tool of our age, and in 2006 worked on Congress's first network neutrality bills, addressing an issue that people often called the <a href=""OPINION"">foremost</a> First Amendment issue of our time. It was through this work that I worked with Stanford's Barbara van Schewick and Columbia's Tim Wu, among others in academia. I also worked on unlicensed spectrum and privacy and copyright, including recently on SOPA, and wrote about national security and civil liberties, and global free speech matters. All of these were unified by free speech concerns.</p>
<p>But the policy arguments were not enough ...  we needed to articulate a compelling constitutional framework. The media, telecom, and studio giants, and many speech scholars, assumed and advanced First Amendment framework that would render unconstitutional media ownership caps, network neutrality rules, and many other rules designed to promote individuals' access to spaces to speak to receive diverse sources of speech. Just as <em>Citizens United</em> privileged the free speech rights of powerful corporations over the speech of average Americans, in my opinion, some common views of the First Amendment privilege giant telecom, cable, and media corporations over average Americans.</p>
<p>That is, even if Congress or the FCC did adopt the pro-free-speech rules or laws for which we advocated, the Supreme Court would be the next hurdle, as suggested by several industry lawyers and even prominent constitutional scholars. For example, while Harvard Professor Laurence Tribe and I <a href=""http://ammori.org/2011/12/08/controversial-copyright-bills-would-violate-first-amendment-letters-to-congress-by-laurence-tribe-and-me/"">agreed</a> on the unconstitutionality of SOPA, we disagreed on the <a href=""http://balkin.blogspot.com/2009/12/net-neutrality-and-21st-century-first.html"">constitutionality</a> of network neutrality.</p>
<p>So my scholarship has attempted to articulate a framework for advancing freedom of speech in our time--and my advocacy has worked, in a small way, to advance that same goal. In my scholarship, particularly in a series of three articles (<a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=699823"">here</a>, <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1078483"">here</a>, and in <em><a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1791125"">Architecture</a></em>), I try to build on the important work of C. Edwin Baker, Yochai Benkler, Jerome Barron, Jack Balkin, Owen Fiss, Joshua Cohen, and many many scholars in my generation (Greg Magarian, among others, comes to mind). I have tried to help build a framework that recaptures the First Amendment as a principle to empower all Americans, politically and personally, through access to plentiful, diverse communications spaces.</p>
<p><em>Architecture</em> is my biggest contribution to that project, a project that many of us are working on from different angles.</p>
<p>So, over the next weeks, I will aim to post a few bite-sized blog pieces setting out its arguments.</p>
","Architecture and Public Policy, Copyright and Fair Use",2012-01-31 6:43,362,Marvin Ammori,News
10348,,United States,0,0,SOPA/PIPA Copyright Bills Also Target American Sites,Copyright,"<p><em><a href=""http://ammori.org/2011/12/31/sopapipa-copyright-bills-also-target-domestic-sites/"" target=""_blank"">Crossposted from Ammori.org</a></em>.</p>
<p>The <a href=""http://techcrunch.com/2011/12/22/over-40-internet-companies-have-come-out-publicly-against-sopa/"">tech</a> and <a href=""http://www.aclu.org/blog/free-speech/sopa-markup-hail-nerds"">civil liberties</a> communities have been fighting proposed copyright legislation. <a href=""http://arstechnica.com/tech-policy/news/2011/12/sopa-faces-growing-opposition-among-conservatives.ars?utm_source=rss&utm_medium=rss&utm_campaign=rss"">Critics</a> have argued that the proposed legislation would break the Internet, create the Great Firewall of America, and lead to censorship while doing little to stop piracy itself. The bills are called the Stop Online Piracy Act (SOPA) in the House and the PROTECT IP Act (PIPA) in the Senate.</p>
<p>The point of this post is more narrow than explaining all that is wrong with the bills. It responds to one particular argument: defenders of SOPA and PIPA keep saying that the legislation would not affect domestic sites. They say that the bills only affect foreign infringing sites like The Pirate Bay and MegaUpload.</p>
<p>Unfortunately, they’re wrong. They’re wrong for at least three reasons.</p>
<p><strong>First:</strong> The bills apply to the many American sites that have domestic and foreign domain names. This means Google.ca, Amazon.co.uk, and all the other foreign sites registered to American companies. (See the <a href=""http://ammori.files.wordpress.com/2011/12/bills-112s968rs-marked-up-pipa-protect.pdf"">marked up version of PIPA</a>, page 33, and the <a href=""http://ammori.files.wordpress.com/2011/12/hr-3261-managers-amendment.pdf"">Manager’s Amendment to SOPA</a> page 4. To understand the reference to registrar and registry, see definitions <a href=""http://blog.vastusdomains.com/2011/difference-domain-registrar-web-hosting"">here</a>.) The definition of a “website” in the bill includes even a “portion” of the site. So if even a few pages on Amazon.co.uk include copyright-infringing material, such as used bootleg CDs, then Amazon would have to respond to the bill.</p>
<p><strong>Second:</strong> The bills’ anti-circumvention provisions don’t even pretend to limit the bills to foreign sites. They clearly apply to American sites. Any tool that helps anyone “circumvent” the bills’ remedies are illegal. Since the bills’ remedies include domain-name breaking and removal from search engines, any American sites that permit you to search for, or find, The Pirate Bay’s new domain name is potentially liable for circumvention. At least some people will tell you where to find The Pirate Bay, and they will use their Facebook status, their Twitter posts, their Tumblr, their blog on WordPress or Blogger, a Youtube video, or a webpage indexed by Google to do it. That means all of those American sites displaying the information might be subject to SOPA and PIPA as anti-circumvention tools. The language is pretty vague, but it appears all these companies must monitor their sites for anti-circumvention so they are not subject to court actions “enjoining” them from continuing to provide “such product or service.” What “product or  service” might be shut down?  The language is unclear. What could be shut down is the particular tweet or the entire Twitter service; one video or all of YouTube . (If it were just one tweet or video, the existing laws, such as the Digital Millennium Copyright Act would suffice, so the proposed law may be read more expansively.) (For evidence of this point, read the marked up PIPA, page 56, and the Manager’s Amendment to SOPA, pages 20-21.) Apparently, the SOPA/PIPA supporters are saying there’s “immunity”; they mean YouTube and Twitter wouldn’t pay damages-fees for circumvention. But YouTube and Twitter could be shut down. They would be “enjoined” from providing service, whatever that means. That’s an even bigger threat than damages.</p>
<p><strong>Third:</strong> Beyond the first two, the enforcement provisions regarding even The Pirate Bay obviously impose a burden almost exclusively on American companies. Search companies have to remove links from their search engine, imposing compliance costs. This applies to Google, Bing, Yahoo, StumbleUpon, and also to smaller search engines like Blekko. The American domain-name providers must break the connection between some domains and IP addresses. This applies to large and small American DNS-providers alike. And the advertising and payment processing provisions apply to American companies. (For evidence, note even the bills’ defenders admit the bills will commandeer American intermediaries to target foreign sites. Indeed  it deliberately commandeers American intermediary companies not involved in any infringement.)</p>
<p>So, for these three reasons, the sites burden American sites and American speech.</p>
<p>In fact, I don’t think ThePirateBay.org and MegaUpload.com are even covered by the bills–despite all the invective against them. The bills define foreign sites based on their domain names, and .ORG and .COM are not foreign.</p>
<p>But it would <strong>not</strong> end the story if the legislation only targeted foreign sites: the <a href=""http://ammori.org/2011/12/08/controversial-copyright-bills-would-violate-first-amendment-letters-to-congress-by-laurence-tribe-and-me/"">First Amendment protects</a> Americans’ ability to access non-infringing foreign speech no less than it protects our ability to access domestic speech. It protects our right to read books by Voltaire, Vaclav Havel, or James Joyce no less than our right to read Milton Friedman, Scott Fitzgerald, and Sabina Murray.</p>
<p>(Note: in addition to loving the Internet and being a long-time free speech lawyer and scholar, I also now <a href=""http://ammorigroup.com/"">represent</a> some tech companies, some of which are on record against these bills. Also, if I misunderstood the import of the bills’ language in some way, I am happy to correct.)</p>
","Architecture and Public Policy, Copyright and Fair Use, Intermediary Liability",2011-12-30 21:00,362,Marvin Ammori,News
10887,,United States,0,0,How Copyright Law Censors Campaigns,Copyright,"<p><img alt="""" src=""/files/images/take%20down.png"" style=""width: 400px; height: 245px; border-width: 1px; border-style: solid; margin: 5px; float: right; "" />Once again, political campaign videos are being <a href=""http://www.latimes.com/news/opinion/opinion-la/la-ol-mitt-romney-barack-obama-al-green-copyrights-20120717,0,3137934.story"">censored by copyright law</a>. This time, Mitt Romney is the victim. After President Obama created an <a href=""http://www.youtube.com/watch?v=Ud3mMj0AZZk"">ad</a> mocking Romney’s tuneless performance of <i>America the Beautiful,</i> Romney responded with an ad featuring a few seconds of Obama singing Al Green’s <i>Let’s Stay Together</i>. Unfortunately for Romney, his ad was hit by a takedown notice from BMG Rights Management and was removed from YouTube.</p>
<p>BMG’s takedown notice is baseless. Romney’s video plays a tiny snippet of President Obama singing the lyric “I’m so in love with you.” At the same time, the video suggests that Obama has shown love only for large donors. Accurate or not, this is core political speech and the ad uses the original content as fodder for its commentary. Moreover, the video does not harm Al Green commercially. Indeed, this kind of attention is much more likely to <a href=""http://www.spin.com/articles/only-barack-obama-can-save-music-industry-now"">improve </a> the market for Green’s songs. Fair use law clearly protects Romney’s use.</p>
<p>In a <a href=""http://www.huffingtonpost.com/2012/07/16/mitt-romney-ad_n_1677874.html?ilink=1"">statement</a>, BMG said:</p>
<blockquote><p>Our duty is to protect the rights of our songwriters and other clients without regard to political party or cause. In this case, the use of the music in question was not approved by the rights holder. As a result normal take down procedure was followed.</p></blockquote>
<p>But BMG misses the point. It is simply irrelevant that the music was not approved by the rights holder; fair use exists precisely to allow for use without permission. In reflexively shutting the video down, BMG is asserting rights it does not have.</p>
<p>If Romney’s ad was protected, why did it get taken down? Under the <a href=""http://www.chillingeffects.org/dmca512/faq.cgi#QID713"">DMCA’s takedown process</a>, the copyright holder is <a href=""http://www.chillingeffects.org/dmca512/faq.cgi#QID588"">usually</a> able to remove content even when its claim is weak. To get the material back online, the poster must then file a counter-notice. The material will typically stay down for at least ten days. As <a href=""http://arstechnica.com/tech-policy/2012/07/major-label-uses-dmca-to-take-down-romney-ad-of-obama-crooning/"">others have pointed out</a>, ten days can be an eternity in a political campaign.</p>
<p>This is a recurring problem. During the 2008 election, both <a href=""https://www.cdt.org/report/campaign-takedown-troubles-how-meritless-copyright-claims-threaten-online-political-speech"">Obama and McCain had videos removed as a result of baseless takedown notices</a>. The upshot is that copyright holders can act as private censors, using DMCA to silence speech at the height of a political campaign.</p>
<p>Update: Romney has <a href=""http://www.latimes.com/news/opinion/opinion-la/la-ol-mitt-romney-barack-obama-sings-al-green-resinstated-20120719,0,6400494.story"">succeeded</a> in getting his video back up on YouTube. Rather than wait the full ten business days under the DMCA, YouTube has restored the video. In this case, it appears that the widespread news coverage might have led to a quick resolution. Unfortunately, this is the exception, not the norm. Private censorship of campaign videos is likely to continue.</p>
",Copyright and Fair Use,2012-07-19 16:44,368,Daniel Nazer,News
11555,,United States,0,0,Recurring Myths About the Legal Obligations of Online Platforms,General,"<p><i><a href=""http://ammori.org/2013/09/05/recurring-myths-about-the-legal-obligations-of-online-platforms/"">Cross-posted from Ammori.org</a></i></p>
<p align=""center"" style=""text-align:left;"">In recent months, some copyright holders, pharmaceutical companies, and <a href=""http://msbusiness.com/businessblog/2013/06/06/attorney-general-hood-asks-google-to-address-illegal-counterfeit-goods/""> state attorneys general</a> have made allegations against Internet companies that help users find and share information. In short, they claim that because some <i>users</i> engage in copyright infringement, sell counterfeit products, or otherwise encourage potentially criminal activity on the Internet, the users’ Internet <i>platforms</i> should be held responsible for these misdeeds. That is, Google should be punished for any user’s copyright infringement on YouTube, Facebook for any user’s harassing post, and Twitter for any user’s slanderous tweet. According to the critics, that is, these companies should screen all users’ speech and take on the role of editors or publishers, rather than being open platforms for the speech of millions.</p>
<p>Many of these allegations focus exclusively on the biggest company in the space, Google, even though Google already invests considerable resources in reducing infringement, counterfeiting, and unlawful activity on its platforms. One state attorney general accused Google of “a<a href=""http://www.agjimhood.com/images/uploads/forms/GoogleLetters.pdf""> failure</a> to stop illegal sites from selling stolen intellectual property,” as though Google has the obligation or even the ability to stamp out copyright infringement on every “site” on the Internet.</p>
<p>For those who follow Internet policy, these types of arguments should sound familiar, stale, and still misguided. These arguments have failed<a href=""http://en.wikipedia.org/wiki/Doe_v._MySpace""> repeatedly</a> in<a href=""http://en.wikipedia.org/wiki/Viacom_International_Inc._v._YouTube,_Inc.""> federal courts</a>, Congress, and the court of public opinion. One wonders why, like zombies in a classic horror movie, these arguments just keep coming back from the dead.</p>
<p>As recently as 2011, some in Congress supported a now-infamous bill called SOPA designed to target Internet intermediaries for their users’ copyright misdeeds. SOPA’s co-sponsors also targeted Google and similarly served on committees focused on intellectual property—committees that often show an unbalanced attentiveness to the copyright industry’s concerns over those of average users and over important principles of free speech more generally.</p>
<p>To ensure digital platforms for user expression, Congress has wisely held that speech platforms should generally not be guilty of their users’ misdeed. Congress has done so through established and widely praised laws such as section 230 of the Communications Decency Act and Section 512 of the Digital Millennium Copyright Act.<a href=""http://en.wikipedia.org/wiki/Doe_v._MySpace""> Courts</a> have construed 230 of the CDA “broadly in all cases arising from the publication of user-generated content.”</p>
<p>Nonetheless, every few years, we see attempts to undermine intermediary immunity. While many such attempts might be well-intentioned they are deeply flawed and would threaten the Internet’s role as an engine of free expression for hundreds of millions of Americans.</p>
<p>In this post, I respond to the recent allegations by rights-holders and state attorneys general. These critics mistakenly accuse companies of turning a blind eye to users’ potentially illegal behavior on search engines and video platforms. They also advance legal claims that technology platforms should be liable for any abuse on any of its services, despite a lack of support for such claims in the case law (and considerable support for the opposite position). As many of these arguments are specific to Google, I reply to those arguments and explain how my responses apply more broadly to other Internet companies.</p>
<p> </p>
<p>The allegations fall into four categories:</p>
<p>(1) that Google does little to identify and remove objectionable content and is uncooperative with law enforcement;</p>
<p>(2) that the law should punish Internet intermediaries for hosting or linking to any objectionable content;</p>
<p>(3) that search autocomplete predictions and search results “aid and abet” violations of law;</p>
<p>(4) and that placing advertising alongside harmful content demonstrates Google’s intention to profit from harmful activity.</p>
<p>Each of these arguments is mistaken, both in fact and principle, and accepting their legal implications would undermine free expression and legitimate economic activity online.</p>
<p><b>Myth 1: Google does little to identify and remove objectionable content and does not cooperate with law enforcement.</b></p>
<p>Google owns YouTube, the most popular site for individuals to upload and share videos online. The Digital Citizens Alliance, an advocacy group with the backing of pharmaceutical companies and the copyright industry, has pointed to videos that promote illegal activity, such as forging passports or buying prescription drugs illegally. Based on those videos appearing on YouTube, DCA<a href=""http://www.digitalcitizensalliance.org/cac/alliance/getobject.aspx?file=YouTube""> claims</a> that YouTube is “hosting evil on its servers.” Moreover, one state attorney general has<a href=""http://www.agjimhood.com/images/uploads/forms/GoogleLetters.pdf""> suggested</a> that Google is unwilling to make “meaningful reforms” to address harmful activity.</p>
<p><b>Reality: Google devotes considerable resources to removing objectionable content and working well with law enforcement.</b></p>
<p>Google cooperates with a host of partners and implements a wide range of tools to minimize objectionable content<b>, </b>while also balancing the interests of hundreds of millions of users to legitimately share and consume speech. A “zero-tolerance” policy punishing speech-platforms for the most objectionable content uploaded by the least sympathetic users would cripple YouTube, Twitter, Facebook, and other platforms that comprise today’s digital town square.</p>
<p>YouTube supports the speech of billions of users. Over a billion users watch or share videos on YouTube every month, for free.<a href=""http://www.youtube.com/yt/press/statistics.html""> One-hundred</a> hours of video are uploaded to YouTube every single <i>minute</i>. These videos include cute kittens, protests in Tahrir Square, breaking news reports, and commentary in war zones. Users can share their videos, respond to videos posted by others, express themselves, and provide instant news on such a massive scale only because Google does not screen every second of every uploaded video before posting. Google’s general search engine indexes almost every publicly accessible webpage—30 trillion of them. It handles more than a million searches per minute.</p>
<p>Minimizing objectionable content while enabling billions of speakers is a difficult task. YouTube’s rules, outlined in its<a href=""http://www.youtube.com/static?template=terms""> Terms of Service</a> and<a href=""http://www.youtube.com/t/community_guidelines""> Community Guidelines</a>, forbid the posting of child exploitation and other sexual content, hate speech, copyright infringement, and illegal activities that have an inherent risk of serious physical harm or death, among other things. YouTube removes content violating these rules and may also terminate the offending user’s account.</p>
<p>YouTube has a multifaceted process, involving technology and community reporting, to remove content violating its rules. YouTube developed a tool called<a href=""http://www.youtube.com/t/contentid""> Content ID</a> that identifies copyrighted content and empowers rights holders to earn ad revenue from the video or request its removal from the site.</p>
<p>Google has also devised robust tools for its search engine. In August 2013 alone, according to its<a href=""http://www.google.com/transparencyreport/removals/copyright/""> Transparency Report</a>, Google processed over 18 million requests to remove URLs from its search results based on copyright concerns. According to Google’s numbers, during the period from July 2011 to December 2011, it removed 97% of the requested URLs.</p>
<p>That said, current technology doesn’t provide for perfect filtering tools at the scale at which companies like Google, Facebook, and Twitter operate. Google offers robust community flagging tools to law enforcement, rights-holders, and the public at large. If a video violating YouTube’s rules is available on the site, a law enforcement officer can<a href=""http://youtu.be/ZA22WSVlCZ4""> flag it</a> with a click. Google will then review the video, confirm that it should be removed, and remove the content within 24 hours. If law enforcement (or any other interested party) seeks to remove any content, Google has provided a<a href=""http://support.google.com/bin/static.py?hl=en-gb&ts=1114905&page=ts.cs&&rd=1""> step-by-step complaint tool</a> to make such a request. Google also provides the AdWords <a href=""http://services.google.com/inquiry/aw_counterfeit?"">Counterfeit Goods Complaint Form</a> for rights-holders to report advertisements for counterfeit good. Copyright holders can file notices based on the procedure set out in section 512 of the<a href=""http://en.wikipedia.org/wiki/Online_Copyright_Infringement_Liability_Limitation_Act""> Digital Millennium Copyright Act</a>, requiring online service providers to take down specific content following a simple notice-and-takedown procedure.</p>
<p>With over a billion users as potential flaggers, community flagging is a central part of YouTube’s policy enforcement processes. It has proven to be the most effective way to address illegal content and is the simplest, most effective way for law enforcement or anyone else to request harmful videos be removed from YouTube.</p>
<p>Many in the law enforcement community already use these tools. Between 2011 and 2012, requests from law enforcement resulted in the removal of<a href=""http://www.google.com/transparencyreport/removals/government/data/""> approximately 18,000 videos</a> from YouTube.</p>
<p>Moreover, in addition to the availability of these tools, Google cooperates directly with law enforcement. In 2012, Google<a href=""http://googlepublicpolicy.blogspot.com/2013/06/combating-rogue-online-pharmacies.html""> joined forces</a> with the Food and Drug Administration, INTERPOL, and a variety of other organizations in “Operation Pangea.” The operation was a major international law enforcement effort targeting online sales of illegal counterfeit drugs.</p>
<p>The DCA and State Attorneys General have found a number of outrageous videos that may be inappropriate and violate YouTube’s community guidelines. This is unsurprisingly considering the tens of millions of videos on YouTube. Flagging inappropriate videos for removal is a narrow, measured approach that can properly target harmful or illegal content while protecting controversial content that is otherwise permissible under the law. One wonders why the DCA didn’t just flag objectionable videos.</p>
<p><b>Myth 2: Online services should be held responsible for any objectionable content in search or should pre-screen all links and content on its sites.</b></p>
<p>A state attorney general has accused Google of “a<a href=""http://www.agjimhood.com/images/uploads/forms/GoogleLetters.pdf""> failure</a> to stop illegal sites from selling stolen intellectual property” and pointed to “the prevalence of illegal drugs and other products that are promoted and even sold through Google platforms” to suggest Google is breaking the law. This attorney general also complained that enterprising users can find ways to “purchase drugs without a prescription through Google.”</p>
<p><b>Reality: Imposing strict liability on Internet intermediaries would cripple free speech online and conflict with decades of federal law.</b></p>
<p>Imposing liability on speech platforms and forcing them to pre-screen and filter all content would threaten free expression online. Congress, the courts, and the American public have repeatedly rejected it as opposed to our nation’s profound commitment to freedom of speech.</p>
<p>If a service were legally responsible for every video displayed even once, or any website in its search directory, then it would have to pre-screen every upload and every link. That would require screening hundreds of hours of video on YouTube every single minute. It would also include trillions of links to everything that Google indexes on the web.</p>
<p>Despite desires of some regulators, accurate real-time filtering technology does not exist. Algorithms underlying Google’s Content ID can spot some (by no means all) copyright infringement. Those algorithms must merely match specific sound sequences or video images. But algorithms cannot reliably evaluate the harmfulness of specific videos, even if DCA wishes that Google can use its “vaunted analytical systems” to identify and remove questionable videos. For example, in<a href=""https://www.cdt.org/speech/pennwebblock/20040910memorandum.pdf""> CDT v. Pappert</a>, a federal court struck down a Pennsylvania state law requiring filtering of child pornography sites. While the intention of the law was obviously noble, and every decent person would agree that we should rid the world of such sites, the filtering technology available blocked 1,190,000 innocent websites and less than 400 child pornography websites. That is, according to district court findings, 99.9% of the blocked sites were innocent; almost 3,000 innocent sites were blocked for every one criminal site. The court that struck down that law for “significant overblocking.” (Nonetheless, of course, companies like Google and Facebook do actively combat and report to authorities instances of child pornography found on their systems.)</p>
<p>Even if it were possible, such large-scale pre-screening of every video and link would dramatically impact the free flow of information online. It would impose huge delays and costs on users, transforming YouTube’s immediate and free nature, or closing down the service.</p>
<p>Imposing liability for any posted content would cripple every one of today’s top digital speech platforms. If Twitter were responsible for the illegality in any text tweet, photo, or video, it too would have to pre-screen its’ users’ content. That pre-screening would likely force Twitter to dramatically change its service, as Twitter<a href=""https://blog.twitter.com/2013/celebrating-twitter7""> now processes</a> 400 million tweets each day and serves 200 million active users around the world each month. Facebook would have an even bigger challenge if punished for any user’s post. Facebook has<a href=""http://newsroom.fb.com/Timeline""> 1.15 billion monthly</a> active users who upload<a href=""http://files.shareholder.com/downloads/AMDA-NJ5DZ/2301311196x0xS1326801-13-3/1326801/1326801-13-3.pdf""> 350 million photos</a> a day. Tumblr users<a href=""http://www.tumblr.com/press""> upload</a> 86 million posts per day. Dropbox has over one hundred million users, with<a href=""http://gizmodo.com/5987300/guess-how-many-files-are-uploaded-to-dropbox-every-day""> one billion files</a> uploaded ever 24 hours, millions of which are shared with others. For these companies, and others, to pre-screen all content would transform their businesses, suppress user expression, and put many of them out of business.</p>
<p>To ensure that hundreds of millions of Americans can continue to use powerful digital platforms for speech, intermediaries should not be liable for every piece of content that slips through their existing processes for minimizing objectionable content.</p>
<p>Indeed, Congress, the courts, and the American public have repeatedly chosen to provide immunity to speech platforms—through sections 230 of the CDA and 512 of the DMCA, through court decisions broadly interpreting those immunities, and through popular public uprisings to clumsy attempts to impose intermediary liability through bills like SOPA. Indeed, imposing such liability could go against hundreds of years of American law. For example, phone companies carry the speech of others and they have never been liable for every drug deal, fraud, or price-fixing transacted on their lines.</p>
<p>Enabling law enforcement and rights-holders easily to flag videos after uploading—rather than punishing intermediaries and forcing pre-screening of all content—properly balances the need to address harmful content with the Internet’s revolutionary ability to empower the average speaker.<b> </b></p>
<p><b>Myth 3: Google “aids and abets” rights-violations through certain autocomplete suggestions in search.</b></p>
<p>Some critics have complained about Google’s autocomplete, a search-engine function that proposes commonly searched phrases or words based on a user’s initial keystrokes. One critic has even gone so far as to<a href=""http://www.agjimhood.com/images/uploads/forms/GoogleLetters.pdf""> claim</a> that Google is somehow “aiding and abetting [crime] by allowing autocomplete to lead users to legally dubious websites and even encourage its users to illegal activity.”<b> </b></p>
<p><b>Reality: Google removes many objectionable phrases from autocomplete even though “aiding and abetting” liability cannot conceivably apply here.</b></p>
<p>Google removes many objectionable phrases from autocomplete, autocomplete does not encourage crime, and the standard for “aiding and abetting” crime is understandably far higher than an autocomplete suggestion.</p>
<p>Google removes many objectionable phrases from autocomplete. Autocomplete is a common feature<a href=""http://news.yahoo.com/search-engines-opinions-google-bing-yahoo-duckduckgo-152422870.html""> offered by</a> Google, Bing, DuckDuckGo, and Yahoo search engines. Type “Barack” and Google or Bing will suggest “Obama” to complete the query. Technically, autocomplete relies on<a href=""http://searchengineland.com/how-google-instant-autocomplete-suggestions-work-62592""> complex algorithms</a> based on users’ past searches and common searches by other users. A <i>Slate</i> writer explains that “[a]utocomplete is one of those modern marvels of real-time search technology that almost feels like it’s reading your mind.” The writer pointed to two obvious benefits: “efficiency gains of not having to type as much” and suggestions that “can be serendipitous and educational, spurring alternative query ideas.”</p>
<p>Search engines exclude some terms from autocomplete. In doing so, they must balance ease-of-use and access to information with a principle not to make it easier for users to find harmful or illegal activity. Google has explained that search is the “<a href=""http://googleblog.blogspot.com/2010/04/controversial-content-and-free.html"">least restrictive</a>” of its services as search results “are a reflection of the content of the web.” Consistent with that philosophy, Google<a href=""https://support.google.com/websearch/answer/106230?hl=en""> excludes</a> from autocomplete “a narrow class of search queries related to pornography, violence, hate speech, and copyright infringement.” While some rights-holders continue to complain, as early as<a href=""http://googlepublicpolicy.blogspot.com/2011/09/making-copyright-work-better-online.html""> January 2011</a>, Google announced it was working to modify the algorithm to reduce the appearance of terms that are frequently associated with online piracy. Other search engines also exclude only a small class of terms and phrases, putting the choice in the hands of users. Google and Bing both offer autocomplete features, and their excluded terms have<a href=""http://www.slate.com/articles/technology/future_tense/2013/08/words_banned_from_bing_and_google_s_autocomplete_algorithms.single.html""> considerable overlap</a>. No evidence suggests one search engine clearly excludes more terms.</p>
<p>There is no evidence that autocomplete encourages users to engage in illegal activity. Nor does evidence or logic suggest that law-abiding, non-hypnotized users will search out illegal drugs or untrustworthy foreign pirating sites merely because one of the autocomplete suggestions might lead them to choose that autocompleted query, then click on particular results to that query, and then order or download the illegal products they were not already seeking.</p>
<p>Finally, autocomplete clearly does not “aid and abet” criminal activity. To my knowledge, no court has found “aiding and abetting” liability in any case remotely similar to autocomplete suggestions.</p>
<p>Generally someone<a href=""http://openjurist.org/336/us/613""> must</a> “in some sort associate himself with the venture, that he participate in it as something that he wishes to bring about, that he seek by his action to make it succeed.” The law is clear that a company does not aid and abet crime even if it is foreseeable that a small portion of it users will use its services for illegal purposes. The same is true when someone merely<a href=""http://www.chrisconrad.com/expert.witness/conant.htm""> provides information</a> that may lead to illegal activity.</p>
<p>The<a href=""http://www.law.cornell.edu/supremecourt/text/311/205""> Supreme Court</a> and other courts have repeatedly provided “broad latitude of immunity” in these situations. As a result, Exxon is not liable for the acts of gasoline-using arsonists. Ford is not liable for reckless drivers and getaway cars. AT&T is not liable for customers calling prostitutes. Apple is not liable for theater-goers recording new film. Elmer’s is not liable for users who sniff glue.</p>
<p>Finally, companies cannot be liable for aiding and abetting someone who<a href=""http://openjurist.org/982/f2d/173/united-states-v-superior-growers-supply-incorporated""> does not</a> commit a crime. Many of the videos on YouTube advocating for illegal activity are themselves legal. While it may be illegal to smoke marijuana, it is legal for random people (or famous rock stars) to encourage others to smoke marijuana. In <i>Watts v. United States</i>, the Supreme Court has decided a case making this principle clear: firing a gun at the president is illegal but saying that you would like to shoot the president can be perfectly legal, <a href=""http://caselaw.lp.findlaw.com/scripts/getcase.pl?court=us&vol=394&invol=705"">protected political speech</a>. Conduct may be illegal while speech about the conduct is perfectly legal. Where Google and other platforms are hosting or linking to controversial or distasteful speech, it is often not illegal.</p>
<p><b>4. Myth: Google deliberately profits from illegal activities, evidenced by the fact that Google’s platform sometimes has advertisements for illegal products or has lawful advertising accompanying illegal content .</b></p>
<p>The Digital Citizens Alliance also claims that Google and YouTube are “advertising partners” with counterfeit drug peddlers and copyright infringers. In the case of search results leading to online pharmacies selling counterfeit drugs, some law enforcement officials have used rhetoric suggesting that Google is “an accessory before fact to the sale of counterfeit items.” In short, they argue that Google sometimes places some legitimate advertising alongside illegal videos and that Google sometimes places advertising for illegal products alongside legal videos. They suggest this is evidence that Google aims deliberately to profit from illegal activity.</p>
<p><b>Reality</b>: <b>Google makes considerable efforts to minimize advertising for illegal products or placing advertising alongside illegal content, though a few outliers fall through the cracks.</b></p>
<p>This myth is just another variation of earlier arguments that Google should be strictly liable for any content—advertising or otherwise—on its sites. Google is not liable. Nonetheless, Google has robust policies to avoid advertising on or for illegal products and services. With billions of advertisements, videos, searches, and page views, some abuses slip through the cracks but Google tools enable interested parties to easily flag the abuses for removal.</p>
<p>Google is not at all liable for the misdeeds of its advertisers, thanks to the First Amendment and the U.S. Supreme Court. In the 1962 case of<a href=""http://supreme.justia.com/cases/federal/us/370/478/case.html""> Manual Enterprises, Inc. v. Day</a>, the Supreme Court held that a small magazine appealing to homosexuals could not be suppressed by the Post Office—even if the Court found the content disgusting and published with “sordid motives.” In the decision, the Court made it clear that the even publishers “cannot practicably be expected to investigate each of their advertisers.” If they were required to do so, then publishers “might refrain from accepting advertisements from those whose own materials could conceivably be deemed objectionable.” Unlike the magazine in that case, Google is held to a far lower liability standard than a publisher and has far more advertisers. If Google were liable for every advertisement, then it too would reject ads from legally protected content that could even “conceivably” be deemed objectionable.</p>
<p>Nonetheless, Google does not want to advertise products alongside illegal content nor advertise for illegal products. Google adopts practices to minimize the likelihood that it will do so.</p>
<p>On YouTube, the placement of ads with videos is dependent on a variety of factors. When a YouTube user uploads a video, users provide metadata about the video (<i>e.g.</i>, video title) and can categorize their video based on its subject matter. This metadata is then used to algorithmically determine what ads are placed with the video. The control afforded to the millions of users uploading videos means that, in some cases, the system will be abused with the initial upload and advertisements will wrongly accompany infringing videos.</p>
<p>There are mechanisms to address that abuse, however, such as the community flagging system and ContentID. Aggrieved copyright holders and other interested parties are in the best position to help end the monetization of inappropriate content by flagging the offending videos. Rights-holders can choose to either have the video taken down or instead to authorize the use and share in the advertising revenue generated from the content. Finally, users can apply to become a<a href=""https://support.google.com/youtube/answer/72857""> YouTube partner</a>, which allows them to monetize videos. Becoming a partner requires users to comply with the YouTube Terms of Use and Community Guidelines. Violating those policies can result in a termination of the partnership and removal of the content in question. This means there is a built-in safeguard against profiting from illegal or harmful videos.</p>
<p>Search advertising on Google works a bit differently. Google employs highly restrictive policies for its advertising products “because they are commercial products intended to generate revenue.” Google’s<a href=""https://support.google.com/adwordspolicy/topic/1308252?hl=en&ref_topic=2585946""> policies</a> forbid the advertising of any illegal products (including<a href=""https://support.google.com/adwordspolicy/answer/176026?hl=en&ref_topic=1310883""> fake passports</a>,<a href=""https://support.google.com/adwordspolicy/answer/176024?hl=en&ref_topic=1310883""> illegal drugs</a>, and<a href=""https://support.google.com/adwordspolicy/answer/176017?hl=en&ref_topic=1346942""> counterfeit goods</a>) and restricts the use of terms relating to<a href=""https://support.google.com/adwordspolicy/answer/176031?hl=en&ref_topic=1310883""> prescription drugs</a>.</p>
<p>These policies aren’t simply window dressing – Google enforces them, using a combination of automated and manual systems to monitor ad content and identify potential violators. According to Google, in<a href=""http://googleblog.blogspot.com/2012/03/making-our-ads-better-for-everyone.html""> 2011</a> it disabled over 130 million ads it found to be in violation of its various advertising policies, and managed to shutdown 15,000 accounts that were attempting to advertise counterfeit goods, and another<a href=""http://googleblog.blogspot.com/2012/06/ads-integrity-alliance-working-together.html""> 65,000 accounts</a> that were otherwise violating Google’s policies. That same year, Google<a href=""http://googlepublicpolicy.blogspot.com/2011/03/keeping-counterfeits-out-of-ads.html""> introduced</a> a complaint form for brand owners to notify Google of ads for counterfeit goods; Google responds to complaints within 24 hours.<b> </b></p>
<p><b>Conclusion</b></p>
<p>The allegations against Google misunderstand basic facts about Google’s practices and rest on mistaken legal theories. Google’s practices balance the rights of billions of users to share and access billions of videos and trillions of websites while minimizing content that violates its guidelines and the law. Moreover, Google should not be liable for any content that slips through the cracks. Such a principle would cripple YouTube, Facebook, Twitter, and other platforms for free expression and political debate. It would also fly in the face of decades of established law that have ensured robust digital speech platforms for millions of Americans.</p>
<p>While I focused on Google, other speech platforms are also working very hard to promote a safer Internet for all users while preserving what makes the Internet so valuable to so many people. Law enforcement, copyright holders, and other interested parties can work cooperatively with these technology platforms rather than rushing to the wrong factual conclusions and making the same tired, flawed arguments to upset established law for speech platforms.</p>
<p><b>Disclosure:</b> I am a First Amendment lawyer and I advise several companies, including Google, on free expression and public policy.</p>
","Copyright and Fair Use, Intermediary Liability",2013-09-05 9:36,362,Marvin Ammori,News
11561,,Italy,0,0,Alalalai! . . . Rojadirecta is Up for Battle Again in Italy,General,"<p><img alt="""" src=""/files/images/20130909-giancarlo-a_0.jpg"" style=""width: 791px; height: 430px;"" /></p>
<p>The ongoing claims against the Rojadirecta website for linking to streams of sporting events are novel and quite important in defining the rights and responsibilities of intermediaries that host links to possibly infringing content stored elsewhere.  While the U.S. case against Rojadirecta was resolved a few years, ago, litigation continues in Italy.  As an Italian scholar who just moved to the Center for Internet and Society to serve as the Intermediary Liability Fellow, I’d like to update readers on the latest Italian episode of the Rojadirecta saga and to locate this new case within the broader Italian legal framework for intermediary liability.</p>
<p>First, some background:</p>
<p>As you may remember, Rojadirecta is a website offering an exhaustive, well-maintained database of links to sporting events streamed over the Internet by other entities, mostly illegally. In 2011, entities owning the rights to broadcast sporting events prevailed on U.S. authorities to seize the rojadirecta.com and .org domain names as part of the ‘<a href=""http://www.ice.gov/news/releases/1111/111128washingtondc.htm"">’Operation in Our Sites</a>” anti-piracy campaign. Stanford Law School’s Mark Lemley filed an appeal the Second Circuit arguing that links to streaming video are not themselves infringing, therefore Rojadirecta was not directly or secondarily liable for criminal copyright infringement, and the domain name therefore should be returned. [You may find the appellate brief <a href=""http://www.scribd.com/doc/65234499/Puerto-80-Projects-v-USA-Opening-Brief"">here</a>]. Meanwhile, the influential Judge Posner issued an opinion in <a href=""http://scholar.google.com/scholar_case?case=1140687521579547092&hl=en&as_sdt=2&as_vis=1&oi=scholarr""><em>Flava Works, Inc. v. Gunter</em></a> holding that links do not infringe copyright. Also known as the myVidster case, <em>Flava Works</em> absolved the “social bookmarking” website that allowed users to link to videos hosted elsewhere from direct or secondary copyright liability. The parallels with Rojadirecta were clear, and soon thereafter, the U.S. Department of Justice agreed to return the rojadirecta domain names to the registrant. </p>
<p>Meanwhile, in Spain, Rojadirecta’s owners were acquitted of criminal charges for copyright infringement by an April 2010 decision of the <em>Audiencia Provincial</em> <em>de Madrid</em>, the Madrid Appellate/Provincial Criminal Court, in a case promoted by <a href=""http://www.bufetalmeida.com/598/rojadirecta-victory.html"">Audiovisual Sports</a>. In a nutshell, the Madrid courts saw Rojadirecta as a “mere intermediary” simply providing links to enable users to watch sport events, without any involvement with the actual infringement that was occurring elsewhere. Additionally, the judicial authority noted, although the site included advertising, no profits were made in direct connection with any act of infringement.</p>
<p>After “victories” in Spain and the United States, the Rojadirecta battle cry sounded for a third time in Italy. There, Rojadirecta faces a <a href=""http://www.oppic.it/index.php?option=com_docman&task=doc_download&gid=395&Itemid=60"">civil action</a> from 2011, and a criminal copyright charge under <a href=""http://www.interlex.it/testi/l41_633.htm#171"">Art. 171 of the Italian Copyright Law</a>, which is the main focus of this post. Unlike in the U.S., authorities did not seize the Rojadirecta domain. Rather, in July an Italian <em>Giudice delle Indagini Preliminari</em> of the Tribunal of Milan, a magistrate in charge of preliminary investigations in a criminal case, ordered Italian Internet Service Providers to prevent access within Italy to all present and future IP numbers associated with the Rojadirecta domain names. This action against Rojadirecta takes places against a broader trend of using criminal charges to confront alleged copyright infringement because civil claims are perceived as ineffective. In particular, in January 2013, the same judge as in the pending Rojadirecta case blocked access to ten other websites streaming sports events for free, upon a criminal complaint from Mediaset.</p>
<p>In Rojadirecta’s Italian case, the court ordered the website blocked <em>ex parte </em>– with no notice to the domain registrant and no adversary hearing of any kind – upon a preliminary finding of criminal copyright infringement. If the domain’s registrant does not react to this initial decision, the court conducts no further review and ISPs must continue to block access to the sites. However, Rojadirecta has opposed the preliminary decision and asked the Tribunal of Milan for a reexamination of the case. Rojadirecta’s reaction is the first case of this kind in Italy. Therefore, the next procedural developments are set to become a critical moment for defining criminal liabilities, under Italian law, of websites linking to infringing materials online.</p>
<p>Argument in the case has already taken place and a decision is expected sometimes after the summer. The ultimate decision will depend on the court’s resolution of a few important copyright issues under Italian law: (i) what are the rights directly infringed by streaming sporting events without the necessary authorization; (ii) are indexing and linking infringing; (iii) is preliminary injunctive relief to block access to the allegedly infringing sites appropriate; and, finally, (iv) how to resolve the constitutional concerns raised by applying a measure inhibiting access to IP numbers.</p>
<p><strong>First,</strong> are sport events copyrightable or are there other rights that would be infringed by streaming a sport event online? Both in Europe and the United States, sports events as such are not a valid copyright subject matter. In the October 2011 <a href=""http://curia.europa.eu/juris/liste.jsf?language=en&num=C-403/08"">Football Association Premier League Ltd and Others v. QC Leisure and Others</a> decision, the European Court of Justice denied the possibility of claiming copyright in soccer “matches themselves, as those sporting events cannot be considered to be an author’s own intellectual creation.” In the United States, the Second Circuit Court of Appeals came to a very similar conclusion almost fifteen years ago, discussing basketball games in <a href=""http://www.law.cornell.edu/copyright/cases/105_F3d_841.htm"">NBA v. Motorola</a>.  </p>
<p>However, the European Court of Justice has upheld the admissibility of alternative legal tools to protect sporting events. The ECJ justified the creation of <em>sui generis</em> rights to protect sport events by noting that “sporting events, as such, have a unique and, to that extent, original character which can transform them into subject-matter that is worthy of protection comparable to the protection of works, and that protection can be granted, where appropriate, by the various domestic legal orders.”  A <em>sui generis</em> right – or quasi-copyright– is a legal instrument that may be specifically created to cover subject matters that would fall outside of the scope of copyright and to which different requirements of protection might apply.</p>
<p>Italy has adopted one of such provisions granting a <em>sui generis</em> protection to sports events with the Legislative Decree N. 9 of January 9, 2008. These <em>sui generis</em> “audiovisual rights” last for 50 years from the time the events take place and include fixation, reproduction, and communication or making available to the public of the audiovisual content of the event through electronic means. Websites streaming sporting events online would therefore directly infringe these <em>sui generis</em> rights, if they do not obtain in advance the necessary permission, for each specific territorial segment, from the sport teams and the federations managing the competition. </p>
<p>This arrangement is not very dissimilar from that in place in the United States, where through a mixture of jurisprudentially made quasi-property rights, copyright law and antitrust provisions, the ownership of the broadcasting rights in sports events is primarily held by the professional sports teams staging the events and the leagues. Usually, both in Europe and the United States, sporting teams and leagues license their rights to media and broadcasting companies.</p>
<p><strong>Second,</strong> the court has to decide whether a web portal’s indexing, and linking to, those infringing sites violates the same “audiovisual rights.” In this instance, the Italian supreme court has come to the opposite conclusion of that recently embraced by Judge Posner in <em>Flava Works</em>. The Italian governing caselaw here is the result of an action initiated against <a href=""http://www.penale.it/doc/Cass_III_Pen_4_07_2006_N33945_Calciolibero.pdf""><em>Coolstreaming and Calciolibero</em></a> by the TV broadcaster Sky. Coolstreaming and Calciolibero facilitated access to soccer games, which were originally streamed by a Chinese broadcaster, by providing online information and links allowing viewers to connect directly to the Chinese servers. Initially, the first two levels of judicial review had denied any form of infringement of others’ exclusive rights through this conduct. However, the Italian <em>Corte di Cassazione</em>, the judicial body of last resort in Italy, reversed. The <em>Corte di Cassazione</em> construed indexing and linking as a contributory infringement because “undeniably, the defendants have aided and abetted, through the provision of a system of online guidance, the connection and synchronization to the sporting event; absent the defendants’ activities, the making available to the public of the protected works would not have occurred or would have occurred to a more limited extent.”</p>
<p>In the Court’s view, the illegal conduct can be distinguished from, say, a common search engine because Coolstreaming and Calciolibero had come up with actions that causally determined the infringement by providing the users with an online guidance that made the infringement possible. In particular, the Court noted that such guidance included the provision of the necessary technical means to watch the sporting event, such as information on the software that the users had to download in order to watch the stream and links both to the software and the streamed event. The 2011 civil action between <a href=""http://www.oppic.it/index.php?option=com_docman&task=doc_download&gid=395&Itemid=60"">Reti Televisive Italiane and Rojadirecta</a> – the sole Italian precedent discussing Rojadirecta’s conduct – also concluded that Rojadirecta “consciously and willfully” aided and abetted the infringement of the right to broadcasting sporting events because “the linking activity, which may in itself be legit, is functionally integrated in a broader activity facilitating and contributing to the infringement of the exclusive rights [of the rightholder].” In conclusion, the Court stated, “undoubtedly, Rojadirecta had a willful knowledge of the unlawfulness of its actions which have been carried out with the clear goal of commercially exploiting the broadcasted sporting events through the placement of advertisements.”</p>
<p>These arguments may sound familiar to U.S. readers as they resemble Grokster-like conclusions, at least to the extent that the Italian jurisprudence refers to the notion of “aiding and abetting” infringement, although it does not specifically refer to any notion that may be connected with that of “inducement.” However, the Italian judicial approach, which tend to rely more on principles of law rather that fact-finding, seems not to be helpful in satisfactorily qualifying the contributory infringing conduct, as Grokster instead does. In particular, Grokster is based on a definition of inducement that is narrowed down by specific evidence of bad intent. In contrast, in Italian caselaw, it is difficult to identify what that evidence of bad intent is or how bad it has got to be before triggering liability. This, in turn, potentially expands intermediary liability in unknown directions, does not provide other courts with a clear set of factually based principles to discern lawful from unlawful conducts, and leaves intermediaries in a state of legal uncertainty.</p>
<p>However, standing on the mentioned Italian precedents, in the Rojadirecta case of July 2013, the Judge stated that Rojadirecta “represents a portal for the abusive communication to the public of sporting events in violation of others’ exclusive rights” and, as in the previous January decision, confirmed the “admissibility of a ‘preliminary seizure’ measure against Internet websites, which – by linking to foreign websites lacking any exclusive rights for the broadcasting on the Italian territory – allow Italian users to watch soccer games in violation of the copyright of the rightholder to whom the neighboring broadcasting rights belong.”</p>
<p>The Judge’s mention to validity and type of injunctive relief that can be granted introduces the<strong> third </strong>critical issue that courts must decide in intermediary liability cases. While Italian jurisprudence refers to “preliminary seizure”, no seizure of the domain takes place. Rather ISPs are ordered to prevent access to the website from Italian territory. The domain is still in the possession of the original registrant. Handing in its decision, the Judge concluded that “blocking [Rojadirecta] through ordering the Internet service Providers to inhibit access to the website stands as the sole possible measure to contrast [the copyright infringement].”</p>
<p>The validity of ‘preliminary seizure’ measures in intermediary liability and, more broadly, Internet cases has been long debated in Italy. The measure was applied for the first time in 2008 by a Judge in Bergamo in the <em>Piratebay</em> case and then confirmed by the Italian <a href=""http://www.ilsole24ore.com/fc?cmd=document&file=/art/SoleOnLine4/Norme%20e%20Tributi/2009/12/cassazione-sentenza-49437-2009.pdf?cmd=arthttp://www.ilsole24ore.com/fc?cmd=document&file=/art/SoleOnLine4/Norme%20e%20Tributi/2009/12/cassazione-sentenza-49437-2009.pdf?cmd=art""><em>Corte di Cassazione</em></a>. The solution finally adopted by the Italian jurisprudence departs considerably from the legal principles at work under U.S. law. The <em>Cassazione</em> has endorsed a principle upon which the judiciary is entrusted with the power of ordering the intermediaries to provide a material aid to prevent further copyright infringement by blocking access to websites which are found guilty of the crime provided under Art 171-ter (2) a-bis) – holding criminally liable “any person who [in breach of the exclusive right to communicate and make available to the public], <em>for profit</em>, communicates to the public a work protected by copyright, or part thereof, by inserting it into a system of computer networks, through connections of any kind.” In the own words of the <em>Cassazione</em>, not only “the court may order the preliminary seizure of the website through which the operator contributes to the criminal activity of disseminating copyrighted works on the Internet, without authorization,” but may also require, “at the same time, that the <em>Internet Service Providers block access to the site in order to debar the activity of illegal dissemination</em> of these works.”</p>
<p>In applying the injunctive relief and ordering the ISPs to block access to the website, the recent Milanese decision against Rojadirecta has found the “for profit” motive requested by Art 171-ter (2) a-bis) of the Italian Copyright Law by emphasizing the fact that the activities of Rojadirecta are “for profit” due to “online advertising”. As the judge noted, Rojadirecta “appropriates volumes of online traffic generated by users’ watching the sporting event for free, therefore making a profit from the numerous online ads.”</p>
<p>The Rojadirecta cases show that Italy is setting up one of the harsher online environments for intermediaries. It often pursues copyright as a criminal case, rather than civil. This, in turn, allows the judicial authority to force Internet Service Providers to inhibit access to the infringing sites, which is a remedy unavailable in civil proceedings.</p>
<p>This brings us to the <strong>final concern</strong>, the use of these blocking orders to force innocent ISPs to participate in online censorship. The <a href=""http://censura.bofh.it/""><em>Osservatorio Censura</em></a>, a watchdog documenting the state of online censorship in Italy, has listed close to 200 websites that have been censored by orders of the criminal judicial authority, which have quadrupled in the last year or so with roughly 150 new domains blocked since the beginning of 2012. (The entire list includes approximately 6000 censored websites, most of which, in fact, are blocked upon order of the Italian Border Authority and the National Center Against Online Child Pornography). Criminal enforcement – especially if deployed against indirect copyright infringement – can raise constitutional concerns and curtail civil liberties and users’ rights. In particular, as Fulvio Sarzana di Sant’Ippolito, the Italian attorney defending Rojadirecta in this last case before the Tribunal of Milan, has noted, “blocking access to IP numbers from the Italian territory, which has been adopted as a standard by Italian judicial authorities, may raise serious concerns in connection with the violation of basic constitutional freedoms.” If multiple domains are hosted on the same IP address – and there may be even several thousand domains hosted on one IP – blocking access to IP numbers may trample users’ rights to access online resources, website owners’ right of free speech and website owners’ right of conducting business. These are constitutionally mandated rights in Italy, so courts ought to carefully review the implications of applying any legal rule that may put those superior principles in jeopardy.</p>
<p>We’ll keep watching Rojadirecta, as efforts to stop the site push some of the most interesting copyright decisions toward judicial examination.</p>
<p>Meanwhile, have a great day. . . and remember to check on the Stanford CIS intermediary liability focus section once in a while to hear the next “alalalai” in the ongoing world war for final domination of the digital realm (and, again, please leave your comments; they would be very much appreciated, and, if you do, I may even tell you what “alalalai” is all about).</p>
<p><font size=""1"">Photo Credit: <a href=""http://www.flickr.com/photos/steffsmith_fotos/5100824983/in/photostream/"" target=""_blank"">steffofsd</a></font></p>
",Intermediary Liability,2013-09-06 23:30,505,Giancarlo Frosio,News
11588,,United Kingdom,0,0,"UK High Court Orders ISPs to Block IP Address, Erroneously Takes Down Hundreds of Sites",Copyright+Other IP,"<p>A recent UK case shows how court orders mandating ISPs to block access to IP numbers hosting allegedly infringing websites can go wrong. The London High Court, Chancery Division, upon a claim from the Football Association Premier League (“FAPL”) and related organizations, issued an <a href=""http://www.bailii.org/cgi-bin/markup.cgi?doc=/ew/cases/EWHC/Ch/2013/2058.html&query=FirstRow1.eu&method=boolean"">injunction</a> against the six main UK retail ISPs – which own close to 100 percent of the UK Internet users’ market share – to block access to the FirstRow Sports website (“FirstRow”). FirstRow “facilitates access to streams of television broadcasts of sporting events.” Basically, it offers services similar to those of Rojadirecta, whose activities we have reviewed in a <a href=""http://cyberlaw.stanford.edu/blog/2013/09/alalalai-rojadirecta-battle-again-italy"">previous post</a>.</p>
<p>However, rather than suing FirstRow, the claimants sought an injunction against the ISPs pursuant to <a href=""http://www.legislation.gov.uk/ukpga/1988/48/section/97A"">Article 97A</a> of the UK Copyright, Designs and Patent Act 1988, which implements <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:2001:167:0010:0019:EN:PDF"">Article 8 (3) of the Information Society Directive of 2001</a> (InfoSoc Directive). That Article provides that “Member States shall ensure that rightholders are in a position to apply for an injunction against intermediaries whose services are used by a third party to infringe a copyright or related right.” The UK implementation of the InfoSoc Directive authorizes courts to enjoin ISPs with “actual knowledge” of a third parties’ infringing activity. Amongst other circumstances, ISPs have “actual knowledge” if the ISP has received a notice including the name and address of the sender and details of the infringement in question.</p>
<p>The <em>Premier League/FAPL</em> case is the most recent in a long list of cases that lead to the blocking of major websites in the UK territory. The same London Court held for the first time in 2011 that it was appropriate to order ISPs to block in the case of <a href=""http://www.bailii.org/ew/cases/EWHC/Ch/2011/1981.html""><em>Twentieth Century Fox Film Corp v British Telecommunications</em></a>. The terms of that order were determined shortly thereafter in a <a href=""http://www.bailii.org/ew/cases/EWHC/Ch/2011/2714.html"">second case</a> involving the same parties. Later, similar orders were issued against ISPs to block access to The Pirate Bay website, in <a href=""http://www.bailii.org/ew/cases/EWHC/Ch/2012/268.html""><em>Dramatico Entertainment v British Sky Broadcasting</em></a>, and three other websites -- KAT, H33T and Fenopy -- in <a href=""http://www.bailii.org/ew/cases/EWHC/Ch/2013/379.html""><em>EMI Records v</em> <em>British Sky Broadcasting</em></a>. So far, the UK courts have always issued the blocking orders sought by copyright owners.</p>
<p>The procedural arrangement in these cases is peculiar. The allegedly infringing parties are not part of these lawsuits. Only the ISPs are. The alleged infringers are not given the opportunity to defend themselves in court, yet, the court must first find that the activity in question is infringing. Additionally, the defendants in these proceedings – the ISPs – may or may not oppose the blocking orders. With the exception of the first case reviewing the appropriateness of blocking orders in principle, ISPs have not opposed the orders and have agreed with the claimants in advance to the terms of the orders. The ISPs may argue over the scope and proportionality of the order, but there is no adversary incentivized to challenge the initial finding of infringement, which increases the likelihood that those decisions will be overbroad or erroneous. </p>
<p>For example, in determining whether FirstRow infringed the FAPL’s copyrights, a complicated decision <a href=""http://cyberlaw.stanford.edu/blog/2013/09/alalalai-rojadirecta-battle-again-italy"">as we see from the Rojadirecta case</a>, the London High Court ruled based on FAPL’s evidence and expert witness submissions only.</p>
<p>One of the thorniest questions is whether sites that link to streams are responsible for communicating copyrighted works to the public. In order to answer this question, the London High Court applied the findings of the European Court of Justice in <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:62011CJ0607:EN:HTML""><em>ITV Broadcasting v TVCatchup</em></a>, confirming that any retransmission of a terrestrial television broadcast over the Internet constitutes a communication to the public. Based on the ECJ ruling, the <em>Premier League</em> Court held that, although the technical effect of clicking on the link is to direct the stream from the UGC site to the users’ computer,<a href=""#_ftn1"" name=""_ftnref1"" title="""" id=""_ftnref1"">[1]</a> (i) the aggregation of a large number of streams, (ii) the indexing of those streams for the convenience of the users, (iii) the provision of a simple link to click in order to have access to the stream, and (iv) the fact that the stream is presented in FirstRow's frame or window makes the site directly liable for the communication. The Court placed special emphasis on fact that the streamed events were presented in a frame provided by FirstRow.</p>
<p>Additionally, the Court found that even if FirstRow were not a direct infringer, it would be jointly liable with the operators of the user generated content (UGC) websites that host the embedded streams and with the third party streamers who digitally capture the streams and do the embedding. In previous rulings, UK courts have already held that “two or more persons may participate in a common design to infringe [copyright] rendering them jointly liable.” Here, the High Court emphasized the fact that all the joint tortfeasors were motivated by a financial reward. The Court noted that FirstRow is likely to be generating between £5,360,680 and £9,505,564 in annual revenues from advertising and affiliated revenues. Additionally, many of the UGC streamers are motivated by the revenues they receive from adding their own advertisments to the streams.</p>
<p>The Court’s factual assumptions and legal conclusions are based on evidences and contentions provided by FAPL only. No one presented any evidence or arguments to the contrary. Although, indeed, the Court has full power to exercise its discretion in evaluating FAPL’s evidences and contentions, the absence of any contradictory evidence or arguments may raise due process concerns. The Court justified the absence of the affected websites in the litigation by saying, “given the difficulty of identifying, let alone bringing proceedings against, the operators of FirstRow, no other effective remedy is open to FAPL in this jurisdiction.” Still, even though it may be difficult to identify or take to court alleged infringers, that is the remedy that should be tried first. A blocking order should be issued only after a full-flagged review of the copyright case has occurred in a proceeding started against the alleged infringers, rather than the ISPs. Otherwise, operators of the target website can only apply for the modification or discharge of the order after their services have been already interrupted.  </p>
<p>After finding that FirstRow was either directly or contributorily liable for infringement, the Court instructed the ISPs to prevent access to a list of IP address numbers provided by FAPL and allegedly used by First Row. However, one of the blocked IP numbers was shared with hundreds of legitimate sites via the DSN Made Easy’s redirection service. Once the IP address was blocked, access to all the websites using the redirection service, spanning from BBC’s Radio Times to the search engine DuckDuckGo, was immediately shut down.</p>
<p>Faced with the disgruntled reactions of users and website owners, the ISPs stopped blocking that IP address shortly thereafter. Although the websites were only temporarily blocked, the implementation of the practical terms of the order nonetheless leave room for abuse. The rightholders tell the ISPs which IP addresses to block, and the ISPs comply without counterchecking the list in order to avoid blatant mistakes. Only after the ISPs realize that the instructions given by the rightholders to block a particular IP address do not meet the criteria of the court order and cover the IP number in error, they will re-enable access. If they do not do so, the <em>Premier League</em> ruling provides that “the operators of any other website who claim to be affected by [the blocking] order [ . . . ] are to have permission to apply to vary or discharge [the order].”</p>
<p>However, leaving to the rightholders the identification of the IP addresses to block may turn out to be an unsatisfactory arrangement. It is clear that the rightholders have an interest in blocking as many potentially infringing IP addresses as possible. If they are empowered to do so with a certain level of discretion by a court order, which is shielding them, and the ISPs, form liability, mistakes may easily ensue. At this point, innocent websites and users are forced either to depend on the ISPs to voluntarily restore their access to the Internet or face all the hurdles involved in seeking judicial redress.</p>
<p>In sum, under present UK law, a website indexing and linking to streamed sporting events is directly liable for communicating to the public protected works. Alternatively, that website is also jointly liable with the websites generating the streams and the third party streamers for participating in a common design to infringe.</p>
<p>Therefore, if proper notice of the infringement is given to the ISPs, a court order against the ISPs to block access to the indexing site is proportionate and appropriate. Meanwhile, a few hundred sites may be taken down by mistake, but those are friendly fire. We are at war after all.</p>
<div><br clear=""all"" /><br /><hr align=""left"" size=""1"" width=""33%"" /><div id=""ftn1"">
<p><a href=""#_ftnref1"" name=""_ftn1"" title="""" id=""_ftn1"">[1]</a> FirstRow does not transmit or generate any of the streams. The streams are digitally captured by third parties watching the broadcast on a television set or a computer. Those streamers send the captured broadcast in real time to a User Generated Content (“UGC”) website’s server, which is used by the streamers to create an “embed code” enabling the stream to be embedded into FirstRow. At this point, the streamer submits the embed code to FirstRow and, upon acceptance by FirstRow, the embed code is listed on FirstRow as a link, which other users can click to watch the stream.</p>
</div>
</div>
<p> </p>
",Intermediary Liability,2013-09-22 9:21,505,Giancarlo Frosio,News
11631,,Brazil,0,0,A Brazilian Judge Orders Facebook off Air if It Fails to Remove a Defamatory Discussion,Defamation or Personality Rights,"<p>On October 2, 2013, Judge Bonvicino of the Civil Court of São Paulo granted an injunction to shut down Facebook in Brazil if a discussion is not removed. The allegedly defamatory post regarded some trivial quarrel between a well-known TV presenter and her neighbor, apparently over the TV presenter’s dog trespassing into the neighboring property.</p>
<p>However, Judge Bonvicino has taken the case very seriously.  The named Defendant, Facebook Brazil, initially argued it was not responsible for managing the content and infrastructure of the site. The social network qualified this initial statement by noting that “[the task of managing content and infrastructure] is the responsibility of two other distinct and autonomous companies, called Facebook Inc and Facebook Ireland Ltd, located in the United States and Ireland respectively.”</p>
<p>The Court of São Paulo was not pleased. Judge Bonvicino stated that Facebook's reply was an “outrageous disregard” of Brazilian sovereignty, which is “aggravated by the notorious spying activities of the US government.” The Judge also noted that “Facebook is not a sovereign country superior to Brazil.” Hence, the Court concluded that if Facebook wants to operate in Brazil, it must be subject to the Brazilian laws, regardless of where the parent companies are incorporated.</p>
<p>The judge granted Facebook 48 hours to remove the discussion. If Facebook did not comply, the judge ordered the Brazilian telecoms to block all Facebook IP domains and redirect them to a courtesy page displaying the court order.</p>
<p>Facebook has complied and the crisis is over for now. However, Brazilian courts ought to be careful in threatening to shut down entire platforms over individual disputes. Tainted by nationalistic bias, these decisions may overlook the fact that millions of Brazilian users, businesses, and institutions, including the Tribunal of São Paulo, are using those platforms daily.</p>
",Intermediary Liability,2013-10-07 16:52,505,Giancarlo Frosio,News
11632,,Italy,0,0,The NEXA Center Responds to the Italian Communication Authority Proposal on Online Copyright Enforcement,Copyright,"<p>The Nexa Center for Internet and Society, an interdisciplinary research center based at the Polytechnic of Turin, has recently published its <a href=""http://nexa.polito.it/agcom-diritto-autore-452-13"">observations</a> on the Italian Communication Authority’s (AGCOM) regulatory proposal regarding online copyright enforcement.</p>
<p>The proposal is primarily intended to vest AGCOM with new administrative copyright enforcement powers. AGCOM would like to set up a system in which online copyright enforcement is done through administrative procedures, rather than civil or criminal actions.  Additionally, the proposed enforcement system would not target direct infringers but rather Internet Service Providers (ISPs). Upon notice of alleged infringement, AGCOM may order the ISPs to selectively remove the infringing digital works, disable access to those works, or automatically redirect the users to a courtesy webpage. In case of especially serious instances of infringement, the proposal provides for an expedited procedure that drastically reduces the timeframe in which the alleged infringers and ISPs may respond to the allegations and subsequently take down the materials.</p>
<p>The Nexa Center has reacted to the AGCOM Proposal by means of a set of observations, authored by the co-directors of the center, Professor Marco Ricolfi and Professor Juan Carlos De Martin, and three fellows of the Center, Carlo Blengino, Alessandro Cogo, and Federico Morando. The Nexa Center has highlighted problems with the proposed regulation.</p>
<p>First, the AGCOM regulation may be inconsistent with initiatives which are under discussion at the European level, namely those described in the EU Commission Staff Working Document “<a href=""http://ec.europa.eu/internal_market/e-commerce/docs/communications/130423_report-ecommerce-action-plan_en.pdf"">E-commerce Action Plan 2012-2015. State of Play 2013.</a>” The Commission specifically prioritizes tackling excessive fragmentation of notice-and-take down procedures in European jurisdictions. This fragmentation in turn leads to a high level of legal uncertainty that makes Europe an uneasy business environment for intermediaries.  As Nexa noted, “the adoption of the proposed AGCOM regulatory scheme would increase this fragmentation and legal uncertainty.”</p>
<p>Second, the Nexa Center stresses that at both the European and national level, legislatures have expressly reserved to judicial authorities the power to intervene against intermediaries whose services have been used to infringe copyright and related rights. In this respect, judicial authorities are better positioned than administrative authorities to protect the fundamental rights of all the involved parties due to the procedural guarantees and independency of the judicial review.</p>
<p>Third, the Nexa Center fully endorses the concerns of the UN special rapporteur Frank La Rue in connection to the promotion and protection of the right to freedom of opinion and expression online. In a UN <a href=""http://www2.ohchr.org/english/bodies/hrcouncil/docs/17session/A.HRC.17.27_en.pdf"">report</a>, La Rue noted that “given that intermediaries may still be held financially or in some cases criminally liable if they do not remove content upon receipt of notification by users regarding unlawful content, they are inclined to err on the side of safety by over-censoring potentially illegal content.” The Nexa Center observes that the preoccupation of La Rue becomes a certainty in case of an administrative authority issuing an order as a result of a non-adversarial procedure that does not entail participation from the intermediaries as well as the users.</p>
<p>Finally, the Nexa Center <a href=""http://nexa.polito.it/nexafiles/Nexa_consultazione_398-11.pdf"">restated</a> an argument that has been raised since AGCOM has proposed its <a href=""http://www.agcom.it/default.aspx?message=visualizzadocument&DocID=6694"">first regulatory scheme</a> in 2011. AGCOM lacks in fact the power to set up the proposed copyright enforcement system as the legislature has not entrusted AGCOM with this extent of enforcement power.</p>
<p>The public consultation on AGCOM regulatory scheme is now coming to an end and a final decision on the adoption of the proposal is expected in the next couple of months. Taking into consideration the results of the public consultation, AGCOM will have the final word on whether to implement the proposal. Despites many critical views, AGCOM seems very much inclined to strongly pursue the adoption of the proposed measures.</p>
",Intermediary Liability,2013-10-08 9:51,505,Giancarlo Frosio,News
11658,European Union,,0,0,The European Court of Human Rights Holds Delfi.ee Liable for Anonymous Defamation,Defamation or Personality Rights,"<p>A recent decision of the European Court of Human Rights (ECHR) may expand considerably web portals’ liability for hosting users’ comments. In <a href=""http://hudoc.echr.coe.int/sites/eng/pages/search.aspx?i=001-126635#{""itemid"":[""001-126635""]}"">Delfi AS v. Estonia</a>, the ECHR has found Delfi, one of the largest news portals on the Internet in Estonia, liable for anonymous defamation.</p>
<p>Delfi published an article that mentioned in its title that SLK, a company providing a public ferry transportation between the mainland and some islands, “Destroyed Planned Ice Roads,” which are public roads over the frozen sea. Although the article was not itself defamatory, it attracted 185 comments including personal threats and offensive language directed against a member of the advisory board of SLK. The target SLK board member was Jewish and several comments had a marked, and in some instances especially ignominious, anti-Semitic flare.</p>
<p>Delfi had in place a notice-and-take-down policy. Under this policy, (i) any reader could mark a comment as insulting, mocking or inciting hatred on the Internet, (ii) a system of automatic deletion of comments including obscene words was in place, and (iii) a victim of defamatory comments could directly notify Delfi.</p>
<p>Upon SLK’s request for removal of the comments, Delfi promptly removed the comments under its notice-and-take-down obligations. However, Delfi refused SLK’s additional claim for non-pecuniary damages.</p>
<p>After a long-lasting legal battle in Estonian courts, the Supreme Court upheld previous judgments and reiterated that Delfi is a provider of content services. As such, Delfi governs the content that is stored and should be distinguished from an information service provider, falling under the e-Commerce Directive and its Estonian national implementation, which has neither knowledge of nor control over information which is transmitted or stored. By integrating the comment environment into its news portal and inviting users to post comments, Delfi could decide which comments to publish or not.  The fact that Delfi did not use this capability did not mean that it had no control over the publishing of comments. In the Supreme Court’s view, because Delfi had a legal obligation to avoid causing damage to other persons, Delfi should have prevented unlawful comments from being published. Finally, the Estonian Supreme Court noted that both Delfi and the authors of the comments could be considered publishers of the comments. Therefore, the defamed party was free to choose against whom to bring the lawsuit.</p>
<p>Delfi finally sought redress from the ECHR. The ECHR was asked to determine whether the domestic judicial authorities’ decision to hold the Internet portal liable was an unjustified and disproportionate restriction on Delfi’s freedom of expression, according to Article 10 of the Convention for the Protection of Human Rights and Fundamental Freedoms (“Convention”). The ECHR was asked to strike a balance between freedom of expression under Article 10 of the Convention and the preservation of personality rights of third persons under Article 8 of the same Convention.</p>
<p>In striking this balance, the ECHR considered several factors. First, the Court examined the context of the comments. In this respect, the Court noted that, although the article itself was a balanced one, Delfi could have realized that the article might have caused negative reactions because readers and commenters had a great deal of interest in the matter, as shown by the above average number of comments posted on the article. In addition, the Court noted that the general negative reputation of comments on the Delfi news portal should have induced Delfi to exercise special caution. The ECHR seems to endorse a principle by which, if there is “a higher-than-average risk that the negative comments could go beyond the boundaries of acceptable criticism and reach the level of gratuitous insult or hate speech,” an Internet news portal is expected to exercise a special degree of caution in order to avoid being held liable for the infringement of other persons’ reputations.</p>
<p>Second, the ECHR considered the measures applied by Delfi in order to prevent or remove defamatory comments. Due to the notice-and-take-down policy in place, the Court could not find that Delfi had wholly neglected its duty to avoid causing harm to third parties’ reputations, but it nevertheless held the measures Delfi applied were insufficient. As the ECHR noted, the automatic word-based filter Delfi used was relatively easy to circumvent and as such insufficient for preventing harm to third persons. Similarly, the notice-and-take-down system did not ensure sufficient protection to third persons. In the ECHR’s view, Delfi was in a position to take technical or manual measures to prevent defamatory statements from being made public. Delfi exercised a substantial degree of control over the comments and did not make use of the full extent of the control at its disposal.</p>
<p>Third, the ECHR examined the liability of the actual authors of the comments as an alternative to Delfi’s liability. The ECHR highlighted the difficulties for an individual to establish the identity of the persons to be sued and considered it disproportionate, in light of Article 8 of the Convention, to put the onus of identifying the authors of the infringing comments on the injured person. The ECHR further justified this conclusion by noting that it was Delfi’s choice to allow comments of unregistered users. In sum, the ECHR concluded that Internet news portals assume a certain responsibility for allowing comments from non-registered users.</p>
<p>In close connection to this assumption, the ECHR looked at the conundrum represented by the potential advantage of anonymity in exercising freedom of expression, the ease of disclosure of information over the Internet and the difficulties for potentially injured parties to detect defamatory statements and remove them. In this regard, the ECHR concluded that “shifting the defamed person’s risk to obtain redress for defamation proceedings to the media company, usually in a better financial position than the defamer, [is] not such a disproportionate interference with the media company’s right to freedom of expression.”</p>
<p>Fourth, in order to determine the proportionality of the interference with Delfi’s freedom of expression, the ECHR emphasized the commercial and professional nature of Delfi’s activities. Redeploying an argument previously raised by domestic courts, the ECHR noted that Delfi had an economic interest in the comments, whose number had an effect on the portal’s traffic and thus on Delfi’s revenues from advertising. The ECHR found this argument relevant in weighing the disproportionality of the interference against freedom of expression. The ECHR seems to infer that commercial motivation may induce Internet portals to allow the maximum number of unchecked anonymous comments. If this is the case, the ECHR reasoned, Internet news portals should be held liable for this business decision.</p>
<p>This decision of the ECHR attempts to strike a balance between intermediaries’ liability, freedom of expression and personality rights. The ECHR tackled this conundrum by delineating a narrowly construed scenario in which liability supposedly does not interfere with freedom of expression. In a situation of higher-than-average risk of defamation or hate speech, if comments from non-registered users are allowed, a professionally managed and commercially based Internet news portal should exercise the full extent of control at its disposal – and must go beyond automatic filtering or ex post notice-and-take-down procedures – to avoid liability. Once again, liability of intermediaries seems to be on the rise and the role of intermediaries is dangerously blurred with that of entities obligated to police the net for infringing activities.</p>
",Intermediary Liability,2013-10-25 16:26,505,Giancarlo Frosio,News
11659,,United States,0,0,New Post: Hands Off Encryption! Say New Amici Briefs in Lavabit Case,Other,"<p>Over at Just Security, I have a <a href=""http://justsecurity.org/2013/10/26/hands-encryption-amici-briefs-lavabit-case/"">new post</a> looking at the legal issues and new amici briefs in the Lavabit case. The case is really important because the Fourth Circuit Court of Appeals is in the process of deciding the first legal challenge to government seizure of the master encryption keys that secure our communications with web sites and email servers.  The opinion could decide the future reliability of encryption protocols to protect all Internet communications.  This dispute involves Lavabit, a now-shuttered encrypted email service provider, which the federal court for the Eastern District of Virginia ordered to give to FBI investigators its SSL key to assist in its investigation of one of Lavabit’s users. While the government wants these keys to decrypt user information, there is really no acceptable way for the Court to order a secure communications service to break its encryption protocol.  The danger to innocent users is too great, and there are network effects that would shatter critical trust in SSL implementation as a whole. Aside from the danger to secured communications overall, nothing in our law requires providers of legitimate email services to turn over keys or otherwise dismantle the security on their systems to help out in a government investigation. Luckily, there’s an easy answer here.  Lavabit offered to decrypt itself the data the FBI wants on the suspect and disclose it to the government, and the government presumably can get a search warrant for that particular user. This is what the Fourth Circuit should order, rather than undermine cybersecurity for us all in the hunt for one person. For alot more, <a href=""http://justsecurity.org/2013/10/26/hands-encryption-amici-briefs-lavabit-case/"">click over and read the post</a>. <br /> </p>
","Intermediary Liability, Privacy",2013-10-26 9:35,240,Jennifer Granick,News
11741,,United States,0,0,The Stanford Intermediary Liability Lab,General,"<p>The first meeting of the Stanford Intermediary Liability Lab (SILLab) will take place on <strong>Thursday, November 21 at 4pm in room Neukom 104 </strong>at Stanford Law School.</p>
<p>The SILLab is a project of the new intermediary liability focus area of the Center for Internet and Society at Stanford Law School, whose core mission you may review at <a href=""https://cyberlaw.stanford.edu/focus-areas/intermediary-liability"">https://cyberlaw.stanford.edu/focus-areas/intermediary-liability</a>. The SILLab will serve the goal of allowing the SLS community to share knowledge on intermediary liability related issues, contribute to the creation of an online Intermediary Liability Map, organize conferences and workshops, write blog posts and papers, and reach out to the leading communications intermediaries and other platforms to find ways to work together to promote free speech and innovation on line.</p>
<p>The SILLab will organize bimonthly meetings to achieve these goals. We have set up a mailing list and a Facebook group at <a href=""https://www.facebook.com/groups/ILLab"">https://www.facebook.com/groups/ILLab</a>  to facilitate group interaction. If you are interested in participating to the activities of the SILLab, please join our Facebook group, provide us with your email address to be included in the mailing list and come to our meetings!</p>
<p>Please email me at <a href=""mailto:gcfrosio@law.stanford.edu"">gcfrosio@law.stanford.edu</a> for any additional information. A lengthier explanation of the SILLab’s activities can be found <a href=""https://cyberlaw.stanford.edu/downloads/20131119-ILSCIS-Project.pdf"" target=""_blank"">here</a>.</p>
<p>Join us and get involved with the SILLab!</p>
<p><strong>Everyone is invited to this event.</strong></p>
",Intermediary Liability,2013-11-19 15:23,505,Giancarlo Frosio,News
11748,,France,0,0,French Court Forces Google to Proactively Block Photographs of Sexual Escapade from Image Search,Obscene Content/Good Morals,"<p>The long standing saga of Max Moseley’s sexual images has recently offered European decision makers a new opportunity to strike a balance between freedom of expression and the right of privacy in light of the ubiquitous and unstoppable distribution of information propelled by the power of Internet search engines. When courts are confronted with novel questions, finding adequate solutions may be extremely challenging. But once again European courts seem to prefer to sideline freedom of expression in favor of protecting other fundamental rights.</p>
<p>In 2008, the newspaper News of the World published photos of Max Mosley, former head of the Fédération Internationale de l'Automobile, engaged in sexual roleplaying with prostitutes dressed as German prison guards. News of the World’s headline accompanying the photos referred to a “Sick Nazi Orgy.” Mosley successfully sued the newspaper in the <a href=""http://www.bailii.org/ew/cases/EWHC/QB/2008/1777.html"">UK</a> and later in France for breach of privacy. At the same time, Mosley <a href=""http://www.bailii.org/eu/cases/ECHR/2011/774.html"">unsuccessfully tried</a> to obtain a judgment from the European Court of Human Rights holding that member states should legislate under <a href=""http://www.hri.org/docs/ECHR50.html#C.Art8"">Article 8 of the European Convention of Human Rights</a> to prevent newspapers from publishing stories regarding individuals’ private lives without first warning the concerned party.</p>
<p>However, the Internet is more difficult to control than traditional newspapers. Mosley’s images went viral and people linked to them endlessly in cyberspace.  Since then, Mosley has started a personal battle with the Internet, specifically with search engines. He claims these tools are the “really dangerous thing” that allow the entire world to find what otherwise would be found only by “a few friends of the person who posts it.” Therefore, Google has become a primary target of Mosley’s discontent.</p>
<p>Mosley sued Google in several European countries, demanding the company filter out of search results any online photos of his sexual escapade, alleging the online publication of these images infringes Mosley’s right of privacy. The Tribunal de Grande Instance in Paris recently granted Mosley’s petition and ordered Google to remove from its image search results for a period of five years any appearance of nine images Mosley identified. The Court has given Google two months to comply. The order requiring Google to remove the images from the result page is, in the court’s view, intended to prevent Google from “contributing and amplifying the indisputable attacks through various websites” to Mosley’s private life.</p>
<p>The order goes beyond requiring the company to remove links to Mosley-related material on a case-by-case basis, which fits within Google’s existing policies and which the company has already done for hundreds of copies of the photos at issue. Rather, the French Court ordered Google to build an automated censorship machine. The filter should automatically detect pages containing the infringing photos and proactively block those photos from search results. In other words, the new software filter should catch and remove new versions of posted images continuously.</p>
<p>Some discussion has occurred regarding the enormous costs to Google to implement this censorship system. The French court, however, sidelined Google’s concerns based on other evidence to the contrary. In particular, the court noted that blocking the search results may be simple and inexpensive, and present technology, such as PhotoDNA, makes it possible to filter not only exact copies of identified images but also modified copies. In general, with these technologies, the risk of over-filtering may still be present insofar as this software cannot assess the context in which an image may appear. However, the French Court disregarded the problem of over-filtering, because the images have been found to be unlawful after multiple judicial reviews and the blocking measure is specifically requested by a judicial authority.</p>
<p>In the view of the French Court, Google’s liability stems from the inapplicability of the safe harbors provided by the French implementation of the Directive on Electronic Commerce. On one side, Google Image Search does not enjoy the caching exemption because search engines are not required to perform automatic storage of images in order to make their future transmission more efficient. On the other side, the hosting exemption is inapplicable because Google had at least knowledge of the unlawfulness of the content present in its Image Search. In this respect, the French court construed Google’s refusal to accept the request of Mosley to remove the unlawful pictures from the search engine results ex ante, rather than removing the pictures pursuant to a targeted request from Mosley, as an evidence of actual knowledge.</p>
<p>In passing, the Tribunal de Grande Instance also considered the fact that Google’s activity may not be “purely technical, automatic and passive” as required by the Directive for the exemption to be triggered. The Google Search engine’s algorithms are, in fact, based on “editorial choices” by the engineers who developed them. These “editorial choices” do not correspond to a neutral and passive role implicating that the host “has neither knowledge nor control over the information transmitted or stored,” as required by the Directive.</p>
<p>As Google said, this is “a troubling ruling with serious consequences for free expression.” This case creates unintended and undesirable consequences for freedom of expression online. Legitimate content, including news coverage related to the story, may inadvertently or accidentally be blocked as well. Additionally, France ordered Google to filter all image search results worldwide, regardless of the fact that different laws apply outside France. Other jurisdictions may strike a different balance between freedom of expression and privacy rights. The French Court justified measures targeting other sites than google.fr by asserting that it is up to Google to demonstrate that listings on Google’s other websites have no impact on the French territory where the images were found to constitute a criminal offense.</p>
<p>Under the assumption that it does not have an obligation to police the net and conduct ex ante surveillance of the content it indexes, Google has initially refused to comply with Mosely’s request and will appeal this French court decision. Meanwhile, a German court is reviewing the same matter and a decision is expected from it in the next few months.</p>
<p>The question these courts are trying to answer is part of the broader conundrum of the role of intermediaries in the digital environment. European courts are deciding whether and when search engines and other Internet platforms should help police the net, up to and including automated monitoring and advance blocking of published content. Placing the burden of proactively policing content on search engines may have multiple negative consequences.  It will stifle innovation and speech around the world. The way courts answer this question will either preserve the Internet’s free and open nature for the future, or damage it, potentially severely.  </p>
<p> </p>
",Intermediary Liability,2013-11-21 15:16,505,Giancarlo Frosio,News
11768,European Union,,0,0,EU High Court’s Advocate General Suggests ISP Blocking Orders Are Lawful with Some Restrictions,Copyright,"<p class=""MsoNormal"" style=""margin-top:12.0pt;margin-right:0in;margin-bottom:<br />
6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph""><img alt="""" src=""/files/images/4563862564_197cf7112e_z.jpg"" style=""width: 640px; height: 426px;"" /></p>
<p class=""MsoNormal"" style=""margin-top:12.0pt;margin-right:0in;margin-bottom:<br />
6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph"">An Advocate General with the European Court of Justice (ECJ) recently issued an <a href=""http://curia.europa.eu/juris/documents.jsf?num=C-314/12"" style=""line-height: 1.538em;"">opinion</a> that courts may order Internet Service Providers to block access to copyright infringing websites under European law. The non-binding but highly influential opinion says that ISPs can be required to block access to a website infringing copyright if the injunctions identify specific blocking measures and otherwise appropriately balance opposing fundamental rights of the copyright holders, the ISP’s economic interests, and the importance of Internet access in a democratic society.</p>
<p class=""MsoNormal"" style=""margin-top:12.0pt;margin-right:0in;margin-bottom:<br />
6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph""><p></p></p>
<p class=""MsoNormal"" style=""margin-top:12.0pt;margin-right:0in;margin-bottom:<br />
6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph"">The legality of blocking orders against ISPs was referred to the ECJ by the Austrian Supreme Court in connection with the proceedings in the Kino.to case. Kino.to was an online platform – which closed its operations in June 2011 – where users could download or view in streaming movies without the consent of rightsholders. Two such rightholders sued UPC Telekabel Wien (UPC), a major Austrian internet provider, in Austrian court, seeking an order forcing UPC to block access to Kino.to. UPC made neither internet access nor storage space available to the operators of the kino.to website, but UPC users could access that site, as with any other on the Internet. <p></p></p>
<p class=""MsoNormal"" style=""margin-top:12.0pt;margin-right:0in;margin-bottom:<br />
6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph"">In May 2011, the Austrian lower court ordered UPC to block the domain DNS and the present and future IP numbers of kino.to. The appellate court amended the first decision by ordering UPC to block access to the infringing site without specifying any concrete measure to be adopted. According to the appellate ruling, UPC allowed access to content unlawfully made available to the public, and was therefore liable, regardless of whether UPC’s users infringed copyright themselves or UPC had any contractual relationship with the operators of infringing website. Therefore, it was UPC’s responsibility to identify and implement any reasonable measures to achieve the result of impeding copyright infringement. This general obligation of achieving a specific result implied, in the appellate court’s view, that indicating specific blocking measures was unnecessary. In other words, UPC’s future secondary liability for infringement  would turn on a future court’s assessment of the reasonableness of its blocking measures.  <p></p></p>
<p class=""MsoNormal"" style=""margin-top:12.0pt;margin-right:0in;margin-bottom:<br />
6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph"">On further appeal, the Austrian Supreme Court suspended the proceedings and referred relevant questions to the ECJ regarding the interpretation of <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:2001:167:0010:0019:EN:PDF"">Article 8(3) of the Information Society Directive</a>. The Supreme Court asked:</p>
<ul><li class=""MsoNormal"" style=""margin: 12pt 0in 6pt; text-align: justify;"">whether it is “compatible with Union law, in particular with the necessary balance between the parties’ fundamental rights, to quite simply prohibit an access provider from allowing its customers access to a certain website (without ordering specific measures) as long as the material available on that website is provided exclusively or predominantly without the right­holder’s consent, if the access provider can avoid incurring preventive penalties for breach of the prohibition by showing that it had nevertheless taken all reasonable measures”; </li>
<li class=""MsoNormal"" style=""margin: 12pt 0in 6pt; text-align: justify;"">if no, whether “it is compatible with Union law, in particular with the necessary balance between the parties’ fundamental rights, to require an access provider to take specific measures to make it more difficult for its customers to access a website containing material that is made available unlawfully if those measures require not inconsiderable costs and can easily be circumvented without any special technical knowledge”.</li>
</ul><p class=""MsoListParagraphCxSpLast"" style=""margin-top:12.0pt;margin-right:0in;<br />
margin-bottom:6.0pt;margin-left:.5in;mso-add-space:auto;text-align:justify;<br />
text-justify:inter-ideograph;text-indent:-.25in;mso-list:l0 level1 lfo1""><p></p></p>
<p class=""MsoNormal"" style=""margin-top:12.0pt;margin-right:0in;margin-bottom:<br />
6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph"">The recently-issued ECJ Advocate General opinion is not binding on the ECJ but will strongly influence its final decision. <p></p></p>
<p class=""MsoNormal"" style=""margin-top:12.0pt;margin-right:0in;margin-bottom:<br />
6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph"">Preliminary, the Advocate General noted that an ISP whose services are used by a third party to infringe copyright may be subject to an injunction to prevent further infringement. The Advocate General applies literally the wording of Article 8(3) of the InfoSoc Directive providing that “Member States shall ensure that rightholders are in a position to apply for an injunction against intermediaries whose services are used by a third party to infringe a copyright or related right.” In construing the meaning of this provision, the Advocate General concludes that “also the services of an access provider of the Internet users [of a website which infringes copyright] are used by the infringers [the operators of that website] to violate copyright, regardless from the fact that the infringer has a contractual relationship with the access provider.”<p></p></p>
<p class=""MsoNormal"" style=""margin-top:12.0pt;margin-right:0in;margin-bottom:<br />
6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph"">Next, the Advocate General wrote that the identification of specific measures is a minimum requirement for the proportionality of a blocking order. A general obligation cannot be imposed upon the ISP under current European law because that would be incompatible with an appropriate balance of the fundamental rights of the parties. The fundamental right to be balanced is the ISP’s economic freedom, which is curtailed by a blocking order limiting the ISPs commercial provision of access to the Internet. <p></p></p>
<p class=""MsoNormal"" style=""margin-top:12.0pt;margin-right:0in;margin-bottom:<br />
6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph"">Finally, the Advocate General opined that, in principle, a specific blocking measure imposed on a provider is not disproportionate just because it entails considerable cost and can be easily circumvented without any special technical knowledge. However, “it is for the national courts, in the particular case, taking into account all relevant circumstances, to weigh the fundamental rights of the parties against each other and thus strike a fair balance between those fundamental rights.” In this respect, the Advocate General seems to suggest that national courts should consider blocking orders against ISPs only after the rightsholders “take action directly, if possible, first against the operators of the infringing website or their service providers.”  Balancing is especially important here, the Advocate General wrote, in light of the ISPs’ role of facilitating access to and circulation of information in a modern democratic society. <p></p></p>
<p class=""MsoNormal"" style=""margin-top:12.0pt;margin-right:0in;margin-bottom:<br />
6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph"">If the ECJ endorses the Advocate General’s view, some national judges may conclude that web-blocking, under specific circumstances, is an excessive and inadequate measure. But the issue will be decided on a case by case basis because of the balancing required.  <p></p></p>
<p class=""MsoNormal"" style=""margin-top:12.0pt;margin-right:0in;margin-bottom:<br />
6.0pt;margin-left:0in;text-align:justify;text-justify:inter-ideograph"">We will keep you updated on how the ECJ will answer the preliminary questions posed by Austrian Supreme Court and provide a binding decision on how interests must be balanced by national courts. For now, the opinion of the Advocate General would require the ECJ – and national courts when they will be invested of similar matters – to take into adequate consideration the necessity of balancing the rights of intellectual property owners with other fundamental rights, such as freedom of expression, freedom to access information, and freedom of undertaking economic activities. Moreover, the ruling says general blocking orders are not proportionate under European law, only those identifying specific blocking measures. Thus, the arrangement endorsed by the Advocate General, which limits the liability of intermediaries to those measures identified in advance by a judicial review, appears to reduce ISP legal uncertainty and make potentially overbroad blocking measures less likely.</p>
<p><font size=""1"">Photo Credit: <a href=""http://www.flickr.com/photos/piaser/4563862564/in/photostream/"" target=""_blank"">Gwenaël Piaser</a></font></p>
",Intermediary Liability,2013-12-04 19:12,505,Giancarlo Frosio,News
11769,,Italy,0,0,Italian Communication Authority Brushes Off Growing Discontent With Its Proposal for Administrative Enforcement of Copyright Online,Copyright,"<p><img alt="""" src=""/files/images/4411477657_346d395dc8_z.jpg"" style=""width: 640px; height: 427px;"" /></p>
<p>Civil society has <a href=""https://cyberlaw.stanford.edu/blog/2013/10/nexa-center-responds-italian-communication-authority-proposal-online-copyright"">reacted negatively</a> to the Italian Communication Authority (AGCOM) Proposal for an administrative system of online copyright enforcement. Approval of the regulatory scheme by AGCOM seems only a few weeks away, and discontent with the proposal is mounting. The Italian government and international organizations are siding with civil libertarians against a proposal that would constitute a unique arrangement among Western countries and dispossess courts from judicial review of findings of online copyright infringement and intermediary liability.</p>
<p>While visiting Italy to report on the state of freedom of expression in the country, Frank La Rue, the UN special rapporteur on the promotion and protection of the rights to freedom of opinion and expression, expressed his reservations against the new regulatory framework. La Rue, echoing the words of Italian academics and civil libertarians, especially Professor Marco Ricolfi, noted that “all norms regulating constitutional rights, in particular freedom of expression, should be approved by the Parliament.” AGCOM, La Rue opined, “has the power to adopt its own administrative regulations to the exclusive end of applying the present legal provisions.” The implementation of this new regulatory scheme by AGCOM would fall outside its prerogatives and – as many Italian constitutionalists and jurists have so far argued – cannot find a sustainable basis in any legal provision, although AGCOM may argue otherwise. Finally, La Rue stressed once again, in line with a position traditionally held by the European Union, that “removal of online content is a task to be demanded to the judicial authority.”</p>
<p>Members of the Italian Government and Parliament agreed. The Italian Minister of Foreign Affairs, Emma Bonino, repeated La Rue’s points almost verbatim, and expressed hope that the Senate and the Chamber of Deputies would intervene as soon as possible. Reacting to Minister Bonino’s call, both the President of the Italian Senate and the President of the Chamber of Deputies asked the Parliament to intervene with a new regulation in order to overcome the controversial proposal of AGCOM.</p>
<p>Besieged on multiple fronts, the President of AGCOM has reiterated his intention to proceed with the approval of the regulatory scheme. Further, he noted that the opponents to the proposal are either small groups of civil libertarians mistakenly perceiving the new regulation as a threat to civil liberties or accomplices of pirates that “fatten by reaping where other have sown.” In wondering to which category I may belong, I share the view of Frank La Rue and believe that online copyright enforcement should be left to judicial review and, in any event, it is up to the Parliament to come up with any regulatory scheme that may affect constitutional rights, such as freedom of expression. </p>
<p> </p>
<p><font size=""1"">Photo Credit: <a href=""http://www.flickr.com/photos/framino/4411477657/in/photostream/"" target=""_blank"">Francesca Minnone</a></font></p>
",Intermediary Liability,2013-12-05 10:35,505,Giancarlo Frosio,News
11806,,Brazil,0,0,Brazilian Court holds Facebook User liable for 'sharing' offensive content posted by another user,Defamation or Personality Rights,"<div>
<p>A <a href=""http://www.migalhas.com.br/arquivos/2013/12/art20131204-08.pdf"" target=""_blank"">decision</a> this week by the Court of Appeals of São Paulo dominated local news on Internet liability, triggering passionate discussions amongst Brazilian internet platforms.</p>
<p>So what is all the fuss about?  Basically, Brazilian Facebook users should now be especially aware of which Facebook posts they “share” and “like”, as they may be held jointly liable for damages caused by the contents of the material they thereby display to other users.</p>
<p>The story behind the case is relatively simple. A veterinarian who found his professional abilities grossly criticized’ through a Facebook post decided to sue not only the person who originally posted the offensive content, but also a woman who had “shared” the original post, thereby displaying it to other users. Surprisingly, the veterinarian decided not to sue Facebook, the intermediary, as is usually common in similar cases.   </p>
<p>Because no evidence was presented to sustain that the veterinarian had actually committed professional malpractice, the Court found both defendants liable for offending the veterinarian’s honor and for damaging his professional reputation. </p>
<p>According to the Court of Appeals’ Judge who wrote the opinion, those who “share” offensive content should be prepared to also be liable for the consequences of disseminating such information.</p>
<p>The veterinarian was awarded twenty thousand Brazilian Reais (roughly eight thousand dollars) as compensation for moral damages. </p>
<p>Despite the repercussion, the decision is still not final since defendants may attempt to appeal the case to the Brazilian Superior and Supreme Courts of Justice.</p>
<p> </p>
<p><em>The author of this blog post, Diego Spinola, is an LLM candidate at Stanford Law School and a qualified Brazilian attorney. He can be reached at </em><u>dspinola at stanford.edu</u>.</p></div>
<div> </div>
",Intermediary Liability,2013-12-10 14:13,642,Diego Spinola,News
11813,,Italy,0,0,Italian Communication Authority Approves Administrative Enforcement of Online Copyright Infringement,Copyright,"<p>In spite of an inflamed debate and strong opposition, as we have reported <a href=""https://cyberlaw.stanford.edu/blog/2013/12/italian-communication-authority-brushes-growing-discontent-its-proposal-administrative"">here</a> and <a href=""https://cyberlaw.stanford.edu/blog/2013/10/nexa-center-responds-italian-communication-authority-proposal-online-copyright"">here</a>, the Board of the Italian Communication Authority (AGCOM) approved its <a href=""http://www.agcom.it/default.aspx?DocID=12228"">regulatory scheme</a> for online copyright enforcement. The outgoing chairman of AGCOM hastily approved the scheme a few days before the new chairman was installed. The new regulation will allow AGCOM to administratively police copyright infringement online and will enter into force on March 31, 2014.</p>
<p><img alt="""" src=""/files/images/agcom_logo.jpg"" style=""width: 250px; height: 154px; margin: 5px; float: right;"" />The scheme grants AGCOM broad enforcement powers and provides a variety of avenues for right-holder policing of copyright infringement. After implementation, right-holders will be able to file complaints for online copyright infringement with AGCOM’s Directorate by using an online form available on AGCOM’s website (art. 6). The administrative procedure before AGCOM will not target users (art. 2, par. 3). Instead, it will focus exclusively on service providers, uploaders of the infringing content, and website operators hosting infringing material (art. 7). The relevant parties will be informed that a procedure has been started against them and they will have the possibility to immediately comply with the right-holders’ request by removing or blocking access to the infringing materials (art. 7, par. 2-3). If the party receiving the notice decides to resist the right-holders’ requests, it must do so by presenting counterarguments within five days of receiving the notice. Special terms and deadlines may apply if AGCOM’s Directorate deems the case especially complex (art. 7, par. 5).</p>
<p>Decisions over the complaints will be taken by an AGCOM decision body, which will receive the results of the investigation from the Directorate (art. 8). If the collegial body is satisfied that the alleged infringement has occurred, it will adopt – within 35 days from the filing of the initial complaint – the following measures to prevent further infringement:</p>
<p style=""margin-left:38.15pt;"">(1)   if the infringing website is hosted in a server located in Italy, the decision body will order hosting service providers to selectively remove the infringing digital works; in case of massive copyright infringement, the decision body may order the service providers to disable access to infringing works, in lieu of the selective removal (art. 8, par. 3);</p>
<p style=""margin-left:38.15pt;"">(2)   if the infringing website is hosted outside  Italy,  the decision body will order <em>mere conduit</em> (Internet) service providers to block access to the website (art. 8, par. 4);</p>
<p style=""margin-left:38.15pt;"">(3)   in any event, when access to content or website is disabled, the service providers must automatically redirect users to a courtesy page, which will be set up according to AGCOM’s instructions (art. 8, par. 4).</p>
<p>Service providers must comply with these measures within three days. If, upon a discretionary evaluation of the Directorate, the case is deemed to be a severe infringement of the economic right of exploitation of a digital work or a massive violation, the procedural terms may be shortened (art. 9).</p>
<p>AGCOM’s administrative online copyright enforcement scheme is the first of its kind in Europe. It raises concerns from multiple perspectives.</p>
<p>Constitutional concerns have plagued the regulation since its proposal. AGCOM claims that the Legislative Decree N. 44 of March 15, 2010 provides a legal basis for the enactment of the new regulatory scheme. Italian constitutionalists and jurists have repeatedly noted that this may not be the case. The Legislative Decree 44/10 would not entrust AGCOM with this extent of enforcement powers that may collide with constitutional rights of users. AGCOM is adopting a regulation it arguably has no power to adopt and is therefore vesting itself with powers with no legal basis. Put bluntly, it should be left to the Parliament to adopt regulatory schemes impinging on fundamental rights.</p>
<p>Also, AGCOM is <em>de facto</em> depriving users of judicial review over online copyright infringement. Copyright holders will gladly use the administrative procedure before AGCOM, rather than seeking judicial redress. Although per the AGCOM regulation, the administrative procedure will be immediately interrupted if one of the parties involved initiates proceedings before the judicial authority (art. 7, par. 7), there may not be any strong incentive for service providers to do so. Indeed, the majority of cases will be decided through AGCOM’s administrative procedure. In this respect, users are deprived of the “necessary balancing of opposing fundamental rights” that the <a href=""https://cyberlaw.stanford.edu/blog/2013/12/eu-high-court%E2%80%99s-advocate-general-suggests-isp-blocking-orders-are-lawful-some"">ECJ Advocate General</a> has recently evoked in the Kino.to case for a blocking order to be proportionate under European Law. Given this proportionality requirement, it is hard to see how AGCOM’s blocking orders might pass muster under European law.</p>
<p>Besides legal concerns, the practical implementation of this regulatory scheme will be a challenge for AGCOM. It remains to be seen how the AGCOM will cope with the new, increased workload associated with administering the enforcement procedure. Personnel and economic resources appear wholly inadequate at the moment.  AGCOM has suggested that it may seek the assistance of external research centers, which will raise concerns in terms of independency of the procedure.</p>
<p>Meanwhile, consumers’ associations already plan to challenge AGCOM’s regulatory scheme before the administrative tribunals. Additional challenges on constitutional and European law grounds may be expected as well. Also, Italian Government and Parliament are discussing copyright reforms that could make <em>de facto</em> irrelevant the newly approved regulatory scheme. All in all, AGCOM’s super-powers over online copyright enforcement may be short-lived or non-existent. And that may not be a bad thing.</p>
",Intermediary Liability,2013-12-17 1:34,505,Giancarlo Frosio,News
11835,,Germany,0,0,German Supreme Court Finds eBay Liable for Actively Promoted Third Party Copyright Infringements,Copyright,"<p><img alt="""" src=""/files/images/20131218-anna.jpg"" style=""width: 640px; height: 480px;"" /></p>
<p>According to a recently <a href=""http://juris.bundesgerichtshof.de/cgi-bin/rechtsprechung/document.py?Gericht=bgh&Art=en&Datum=Aktuell&Sort=12288&nr=65816&pos=9&anz=508&Blank=1.pdf"">published decision</a> of the German Federal Supreme Court (judgment of 16 May 2013, I ZR 216/11) eBay shall be liable for copyright infringements of third parties if it actively promotes the infringing offers by its own marketing campaign. In such cases the general liability privilege for information service providers, which arise from Section 7 and 10 <a href=""http://www.cgerli.org/fileadmin/user_upload/interne_Dokumente/Legislation/Telemedia_Act__TMA_.pdf"">German Telemedia Act</a>, does not apply and eBay must observe increased due diligence requirements.</p>
<p>In the concrete case (Kinderhochstühle im Internet II), a third party seller offered for sale on eBay certain chairs that were found to infringe the plaintiff’s copyright. The plaintiff alleged that eBay was liable for copyright infringement (under the so called “Störerhaftung” or liability for interference, a German legal concept similar to contributory liability) based on its promotion of the third party’s sales via a Google AdWords campaign run by eBay. When Google users entered the name of the chairs in the search engine, Google placed an ad on their page that lead users directly to the corresponding third party offer on eBay. At the time eBay started the AdWords campaign, it had already been notified through other sellers that the third party’s chairs were infringing.</p>
<p>Against this background the court decided that the liability privilege under German law, which gives information service providers a general safe harbor for third party infringements, did not apply. Due to its promotion of the chairs through Google AdWords, eBay was no longer acting as a neutral intermediary and took on a more active role. The court found that, because eBay took such an active role, it had to comply with an increased duty of care. Where the company takes such an active role, it will be required to manually review every offer linked to it through the Google AdWords campaign. Automatic control would not be sufficient, especially where there is evidence that eBay—or another similarly situated intermediary—knows of previous allegations of copyright infringement with respect to the same products and the same seller.</p>
<p>In conclusion, according to the court, such increased due diligence duties are not disproportionate because eBay no longer occupied a neutral position as an intermediary in the sense of Section 7 and 10 German Telemedia Act. Instead, eBay rather actively promoted the offers of a third party. Due to this fact, the general liability privilege of information service providers does not apply in this case. This implies for similarly situated intermediaries that they are required to manually review every offer when they actively link them to a specific promotion campaign, e.g. through Google Adwords.</p>
<p><em>The author of this blog post, Anna Zeiter, is an LLM candidate at Stanford Law School and a qualified German attorney. She can be reached at azeiter at stanford.edu.</em></p>
<p> </p>
<p><em>Photo Credit: <a href=""http://www.flickr.com/photos/percygermany/2726525613/in/photostream/"" target=""_blank"">PercyGermany</a></em></p>
",Intermediary Liability,2013-12-18 7:22,646,Anna Zeiter,News
11859,,Germany,0,0,New German Government Intends to Expand Hosting Provider Liability,Copyright,"<p>Almost three months after the federal elections in Germany, the leaders of coalition parties have finally concluded a non-binding coalition agreement that includes the prospect of expanded hosting provider liability for online copyright infringement.</p>
<p>The <a href=""http://www.bundesregierung.de/Content/DE/_Anlagen/2013/2013-12-17-koalitionsvertrag.pdf;jsessionid=67B2F577408758CB04F9ACA19DD81556.s3t2?__blob=publicationFile&v=2"">agreement</a> says one of the coalition’s aims is to combat mass infringements of copyright and therefore “internet service providers should take more responsibility.” In particular, the grand coalition plans to “improve enforcement in particular towards platforms whose business model is mainly based on the infringement of copyright.” To that end, the coalition would like to “ensure that such service providers no longer enjoy the general liability privilege as so-called hosting provider and in particular no longer receive advertising revenues.”</p>
<p>However, it is still unclear what the grand coalition would concretely do. The general liability privilege insulating information service providers from copyright infringement claims for the acts of their users currently arises from <a href=""http://www.cgerli.org/fileadmin/user_upload/interne_Dokumente/Legislation/Telemedia_Act__TMA_.pdf"">Sections 7 and 10 of the German Telemedia Act</a>. According to a recent <a href=""http://juris.bundesgerichtshof.de/cgi-bin/rechtsprechung/document.py?Gericht=bgh&Art=pm&Datum=2013&Sort=3&anz=142&pos=0&nr=65241&linked=urt&Blank=1&file=dokument.pdf"">decision</a> of the German Supreme Court, under those sections, host providers are already ineligible for the liability privilege if their business model is mainly based on copyright infringement. In addition, the new government’s ability to amend the existing legal framework is questionable because the German intermediary liability provisions are based on the EU ecommerce directive, which does not stipulate different liability levels for different kind of hosting providers. Against this background it remains to be seen if the coalition agreement amounts to anything other than lip service given the current state of German and European law.</p>
<p><em>The author of this blog post, Anna Zeiter, is an LLM candidate at Stanford Law School and a qualified German attorney. She can be reached at azeiter at stanford.edu.</em></p>
",Intermediary Liability,2014-01-06 1:44,646,Anna Zeiter,News
11884,,United States,0,0,Meeting of the Stanford Intermediary Liability Lab with Eric Goldman,General,"<div>The next meeting of the Stanford Intermediary Liability Lab (SILLab) will take place on Thursday, January 16 at 4pm in Room 230 at Stanford Law School.</div>
<div> </div>
<div>Professor Eric Goldman from Santa Clara Law School will join us for an informal discussion about intermediary liability. Professor Goldman is one of the major intermediary liability experts in the US and runs a well known blog dedicated to intermediary liability and Internet law at <a href=""http://blog.ericgoldman.org"" target=""_blank"">http://blog.ericgoldman.org</a>.</div>
<div> </div>
<div>As usual, the SILLab will also be an opportunity to discuss intermediary liability news worldwide and coordinate the World Intermediary Liability Map (WILMap) project. </div>
<div> </div>
<div>I look forward to meeting you on Thursday.</div>
<div> </div>
<div>***</div>
<div> </div>
<div><span style=""line-height: 1.538em;"">The <a href=""https://cyberlaw.stanford.edu/focus-areas/intermediary-liability"">SILLab is a project of the new intermediary liability focus area</a> of the Center for Internet and Society at Stanford Law School.</span></div>
<div> </div>
<div><span style=""line-height: 1.538em;"">The SILLab serves the goal of allowing the SLS community to share knowledge on intermediary liability related issues, contribute to the creation of an online Intermediary Liability Map, organize conferences and workshops, write blog posts and papers, and reach out to the leading communications intermediaries and other platforms to find ways to work together to promote free speech and innovation on line. The SILLab will organize bimonthly meetings to achieve these goals. We have set up a mailing list and a <a href=""https://www.facebook.com/groups/ILLab"" target=""_blank"">Facebook group</a> to facilitate group interaction. If you are interested in participating to the activities of the SILLab, please join our Facebook group, provide us with your email address to be included in the mailing list and come to our meetings!</span></div>
<div> </div>
<div>Please email Giancarlo at <a href=""http://mailto:gcfrosio@law.stanford.edu"">gcfrosio@law.stanford.edu</a> for any additional information. A lengthier explanation of the SILLab's activities can be <a href=""https://cyberlaw.stanford.edu/downloads/20131119-ILSCIS-Project.pdf"" target=""_blank"">found here</a>. Join us and get involved with the SILLab!</div>
",Intermediary Liability,2014-01-15 11:00,505,Giancarlo Frosio,News
11904,,Spain,0,0,Spanish Court Orders an ISP to Disconnect a Copyright Infringer,Copyright,"<div>
<p><em style=""line-height: 1.538em;"">Cross posted from <a href=""http://ispliability.wordpress.com/2014/01/22/nito/"" target=""_blank"">ISPLiability blog</a></em></p>
<p>In a recent ruling issued by the 15th Section of the Barcelona Court of Appeals – a Section specializing on IP – the Spanish ISP <a href=""http://www.mundo-r.com/portada/index_es.html"" target=""_blank"">R Cable y Telecomunicaciones Galicia</a> has been ordered to suspend, immediately and for good, the Internet connection of a user who engaged in copyright infringing file sharing. The text of the ruling (in Spanish) is available <a href=""http://estaticos.elmundo.es/documentos/2014/01/20/SentenciaAP.pdf"" target=""_blank"">here (PDF)</a>. This is the first ruling of this kind in Spain.</p>
<p>The action was brought by <a href=""http://www.promusicae.es/?lang=en_US"" target=""_blank"">Promusicae</a>, an association of Spanish music producers, along with the main music labels operating in Spain. Aided by <a href=""http://www.dtecnet.net/EN/DtecNet.aspx"" target=""_blank"">DtecNet</a>, an anti-piracy firm, Promusicae learned of an internet user who was making available more than five thousand music files in his hard drive shared folder, using the P2P network <a href=""http://en.wikipedia.org/wiki/Direct_Connect_%28file_sharing%29"" target=""_blank"">Direct Connect</a>. The investigative firm actually downloaded three files which corresponded to copyrighted songs owned by the plaintiffs. The user was identified by his nickname and IP address only. It was not possible to find out the user’s real identity as ISPs in Spain are <a href=""http://curia.europa.eu/juris/liste.jsf?language=en&num=C-275/06"" target=""_blank"">not obliged</a>to reveal the identity of their users for purposes of civil lawsuits.</p>
<p>Not knowing the identity of the file sharer, the plaintiffs brought the case directly and exclusively against the ISP, asking for an injunction under <a href=""http://www.boe.es/buscar/act.php?id=BOE-A-1996-8930&tn=1&p=20111231&vd=#a138"" target=""_blank"">articles 138 and 139.1.h) of the Spanish Copyright Act</a> which allow right holders to seek injunctions against intermediaries whose services are used by a third party to infringe copyright. The requested injunction consisted of suspending the provision of internet access to the infringer. The possibility of asking for injunctions against intermediaries is contemplated in art. 8(3) and Recital 59 of the <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:32001L0029:EN:HTML"" target=""_blank"">EU Copyright Directive</a>, though the specific modalities of such injunctions are left to Member States’ national law.</p>
<p>Strikingly enough, the ISP chose not to answer the complaint and didn’t intervene at all in the lawsuit. </p>
<p>The court of first instance dismissed the claim, holding that the user’s conduct was not infringing. The Court of Appeals reversed and held that the user’s acts were indeed infringing as they constituted unauthorized acts of reproduction and making available to the public. It held therefore that plaintiffs were entitled to the sought injunction.</p>
<p>Some difficult questions arise from this case – I will highlight just a few.</p>
<p>First, the user was not a party in the proceedings, as the lawsuit was filed only against the ISP. This poses the question of whether the infringement could be found without summoning the allegedly infringer – though it is of course unlikely that the user could have successfully invoked a defense against the finding of infringement.</p>
<p>Second, <a href=""http://www.boe.es/buscar/act.php?id=BOE-A-1996-8930&tn=1&p=20111231&vd=#a138"" target=""_blank"">articles 138 and 139.1.h) of the Spanish Copyright Act</a> require the injunction to be objective, proportionate and non-discriminatory. The court, however, did not assess at all whether such a radical measure satisfied the required proportionality.</p>
<p>Third, and closely linked to the question of proportion, an IP address does not necessarily identify a single individual as it could have been shared by different people.</p>
<p>Finally, the real effect of the injunction is rather dubious, as the infringer can easily shift to a different access provider.</p>
</div>
<p><em>The author of this blog post, Miquel Peguera, is a Professor of Law at Universitat Oberta de Catalunya in Barcelona. He can be reached at mpeguera at <a href=""http://www.uoc.edu/"" target=""_blank"">uoc.edu</a>.</em></p>
",Intermediary Liability,2014-01-22 19:26,678,Miquel Peguera,News
11917,,Brazil,0,0,Brazilian Supreme Court Found Google Liable for Videos Parodying Dafra’s Commercials,Copyright,"<p>Content platforms are under fire in Brazil. The Brazilian Superior Tribunal of Justice (“STJ”) recently found Google liable for copyright infringement for YouTube-hosted videos parodying a well-known commercial. The case raises concerns that copyright enforcement is interfering with freedom of expression and right of critique.</p>
<p>Dafra is a motorcycle manufacturer, which broadcasted a commercial titled “Meetings,” as part of a national advertising campaign known as ""Dafra – You on Top.” “Meetings” starred Wagner Moura, a famous Brazilian actor. Shortly after launching of the advertising campaign in March 2009, a YouTube user published a dubbed version of the original Dafra’s video, called a “fan-dub”. Fan-dubs replace the original soundtrack of an audiovisual recording, with another that is designed to alter substantially the message conveyed by the original work. In the <a href=""http://www.youtube.com/watch?v=luu_73y_hCk"">user-generated parody version</a> of the Dafra’s commercial, the actor's original voice was replaced by a very similar one making statements tarnishing Dafra’s goodwill.</p>
<p>Google took down the initial video per Dafra's request, but several other versions of the video were posted constantly by other users under different titles. Therefore, Dafra and the advertising agency Loducca decided to sue Google for copyright infringement.</p>
<p>The plaintiffs claimed that Google had not adopted the necessary measures to avoid further viewing of videos with the same content, regardless of the title that users may have given to those videos. The plaintiff had asked Google not only to remove the video but also to use search blocking mechanisms to prevent posting on YouTube any unauthorized material related to the “Dafra – You on Top” campaign. Dafra and Loducca also requested that the videos that were taken down be substituted with a personalized warning message highlighting that defamation was a civil wrong subject to damages.</p>
<p>In response, Google claimed ""technical impossibility"", arguing that it was impossible to take down all videos because there are currently no blocking filters able to identify all infringing materials. Further, Google disputed that the 24 hour turn around time demanded by the plaintiffs for the removal of the videos was sufficient.</p>
<p>The STJ confirmed the previous appellate decision, which had already upheld plaintiffs’ claims for copyright infringement. The STJ ordered Google to remove all the adulterated advertisements within 24 hours, under a penalty of R$ 500 per day for noncompliance. Two dissenting opinions, endorsed the longer term of 72 hours proposed by Google. However, the majority of the Court noted that a period of 24 hours “is enough to boost the damage generated, considering the speed with which information circulates on the Internet and it does not seem reasonable to dilate it even more.”</p>
<p>According to the decision, Google must remove not only the infringing video which is the object of the lawsuit but also any similar and related unauthorized videos, even if they are uploaded by other users and bear a different title. However, the Court recognized ""certain limitations of proactive control.” The judgment does not address future videos and Google’s obligation only reaches unauthorized videos with ""Dafra – You on Top"" in the title.</p>
<p>According to Justice Luis Felipe Solomon, the rapporteur of the case before the STJ, Google’s “technical impossibility defense” did not success because lack of a technical solution for fixing a defective new product does not exempt the manufacturer from liability, or from the obligation of providing a solution. In this respect, quite emphatically, Justice Solomon added that ""if Google created an 'untamable monster,’ it should be the only one charged with any disastrous consequences generated by the lack of control of the users of its websites.”</p>
<p>Unanimously, the STJ rejected plaintiffs request that Google post a personalized warning in response to the infringing video. Justice Solomon said the request goes further than the individual interests involved in the case, and is unnecessary, as the law already warns people about the consequences of criminal and civil violations.</p>
<p>Justice Solomon stressed the importance of imposing liability on intermediaries, saying that “violations of privacy of individuals and companies, summary trials and public lynching of innocents are routinely reported, all practiced in the worldwide web with substantially increased damage because of the widespread nature of this medium of expression.” In the Dafra case, however, imposing liability on information service providers as a reaction to the “Internet threat” may dangerously trample freedom of expression. In the United States and other countries, these videos would not be defamatory, and would probably be fair use—in other words, lawful. Blocking filters as those that Google was forced to implement are imperfect. Proactive filtering could mistakenly remove lawful speech on the basis of keywords included in the title. The line between critique and defamation should be policed on a case by case basis by a court of law and never by a machine. Looking for the answer to the machine in the machine, the “monster” that Justice Salomon evoked may have been tamed but right of critique silenced as well.</p>
",Intermediary Liability,2014-01-31 11:18,505,Giancarlo Frosio,News
11947,,United States,0,0,Meeting of the Stanford Intermediary Liability Lab with Dan Svantesson,General,"<p>The next meeting of the Stanford Intermediary Liability Lab (SILLab) will take place on <strong>Friday, February 14 at 11am in Room B13 </strong>at Stanford Law School.</p>
<p>Professor <a href=""http://apps.bond.edu.au/staff/profile.asp?s_id=320"">Dan Svantesson</a> from Bond University in Australia will join us for an informal discussion about recent intermediary liability updates in Australia. Professor Svantesson is an expert of Internet related matters and have recently received a prestigious Australian Research Council (ARC) Future Fellowship research grant to investigate the legal complexity of the Internet.</p>
<p>As usual, the SILLab will also be an opportunity to discuss intermediary liability news worldwide and coordinate the World Intermediary Liability Map (WILMap) project. </p>
<p>I look forward to meeting you on Friday.</p>
<p>                                                                                   ***</p>
<p>The <a href=""https://cyberlaw.stanford.edu/focus-areas/intermediary-liability"">SILLab is a project of the new intermediary liability focus area</a> of the Center for Internet and Society at Stanford Law School.</p>
<p>The SILLab serves the goal of allowing the SLS community to share knowledge on intermediary liability related issues, contribute to the creation of an online Intermediary Liability Map, organize conferences and workshops, write blog posts and papers, and reach out to the leading communications intermediaries and other platforms to find ways to work together to promote free speech and innovation on line. The SILLab will organize bimonthly meetings to achieve these goals. We have set up a mailing list and a <a href=""https://www.facebook.com/groups/ILLab"">Facebook group</a> to facilitate group interaction. If you are interested in participating to the activities of the SILLab, please join our Facebook group, provide us with your email address to be included in the mailing list and come to our meetings!</p>
<p>Please email Giancarlo at <a href=""http://mailto:gcfrosio@law.stanford.edu/"">gcfrosio@law.stanford.edu</a> for any additional information. A lengthier explanation of the SILLab's activities can be <a href=""https://cyberlaw.stanford.edu/downloads/20131119-ILSCIS-Project.pdf"">found here</a>. Join us and get involved with the SILLab!</p>
",Intermediary Liability,2014-02-12 16:56,505,Giancarlo Frosio,News
11952,,Turkey,0,0,Turkey Enlists Intermediaries to Censor and Surveil Internet Users,General,"<p>Despite fierce opposition from civil society and industry, the Turkish parliament recently amended Law no. 5651, entitled “Regulation of Publications on the Internet and Suppression of Crimes Committed by means of Such Publications”. The amendment was included in two omnibus bills (available <a href=""http://www.tbmm.gov.tr/sirasayi/donem24/yil01/ss524.pdf"">here</a> and <a href=""http://www2.tbmm.gov.tr/d24/2/2-1937.pdf"">here</a>) submitted to the Parliament and has been called a <a href=""http://www.huffingtonpost.com/arzu-kaya-uranli/controversial-internet-censorship_b_4634773.html"">controversial</a>, <a href=""http://www.pen.org/press-release/2014/01/22/turkish-parliament-must-reject-restrictive-internet-bill"">restrictive</a> <a href=""http://blogs.wsj.com/emergingeurope/2014/01/13/turkey-debates-new-law-to-control-web-users/"">law to control web users</a> that <a href=""http://www.dw.de/erdogan-pushing-internet-censorship-forward/a-17355251"">pushes Internet censorship forward</a>. People <a href=""http://www.alternatifbilisim.org/wiki/Internet_Censorship_is_Getting_Deeper"">within</a> and <a href=""http://www.ft.com/intl/cms/s/0/af179212-7b6b-11e3-a2da-00144feabdc0.html"">outside</a> Turkey criticized the law for enlisting intermediaries as censors for the government. The new Turkish regulation seems run against ECHR decisions, as well as EU and international human rights principles.</p>
<p>Law No. 5651 was Turkey’s first Internet-specific regulation. Before then, courts used the Turkish Criminal Code, Civil Code and Code of Intellectual and Artistic Works as the legal basis to issue blocking orders related to political and computer crimes, violation of privacy and reputation and intellectual property infringement.</p>
<p>Parliament approved Law No. 5651 in a rush just before the 2007 general elections. The provision set up the Presidency of Telecommunications and Communication (TIB), an administrative body that has the power to issue blocking orders. Law No. 5651 never received public support before or after its enactment. To the contrary, citizens criticized it for censoring thousands of websites, including a two-year ban on YouTube. The European Court of Human Rights has ruled against the law for its inconsistency with freedom of expression twice, in <a href=""http://hudoc.echr.coe.int/sites/fra/pages/search.aspx?i=001-115705"">2012</a> and <a href=""http://hudoc.echr.coe.int/sites/eng/pages/search.aspx?i=001-69196"">2011</a>. <a href=""http://cyberlaw.org.uk/"">Yaman Akdeniz</a> and <a href=""http://80.251.40.59/politics.ankara.edu.tr/altipar/"">Kerem Altiparmak</a>, Turkish legal scholars and human rights activists, wrote a book tracing the legal history of Law 5651 in a “<a href=""http://privacy.cyber-rights.org.tr/?page_id=256%20"">Critical Assessment of Internet Content Regulation and Censorship in Turkey</a>”.</p>
<p>The newly approved amendments will now make Law No. 5651 worse for Internet users by tightening control on intermediaries, increasing surveillance, and expanding website blocking and Internet filtering. First, the amendments will establish a state-controlled “association” for access providers within 3 months of their enactment. Intermediaries will be punished if they do not act expeditiously enough to establish the association within the 3-month deadline. All ISPs must participate into the association in order to be allowed to provide Internet services within Turkey. Additionally, all costs connected to the establishment of the association must be covered by the intermediaries.</p>
<p>Second, the amendments require hosting providers to store data about users' online activity for two years. Government officials from TIB will have access to these records without seeking prior court's permission. In other words, the government can track people’s Internet access, but the cost of this surveillance will be passed on to Internet users through their network providers.</p>
<p>Third, TIB will have greater content blocking powers. TIB can force service providers to block access to content that violates a person's ""private life,"" upon a claim of a natural or legal person. The “violation of private life” is a newly introduced criminal category, which has no clear definition. The Internet intermediary must comply with blocking orders within 4 hours. The law does not provide for any prior judicial review of the determination that the content at issue breaches the “private life” of the claimant.</p>
<p>The recent amendments to Turkish Internet regulations are an additional leap in this government’s ability to censor and control Internet activities. The law accomplishes this by placing enhanced monitoring, filtering and surveillance powers in governmental, rather than judicial, bodies. Italy recently embraced a very similar arrangement a few weeks ago, as we have reported <a href=""https://cyberlaw.stanford.edu/blog/2013/12/italian-communication-authority-approves-administrative-enforcement-online-copyright"">here</a>. Meanwhile, the laws expand intermediaries’ liabilities with the precise goal of enlisting them as Internet watchdogs under governmental control. The dream of the Internet as a venue for free and unrestrained democratic discourse seems to be increasingly fading away. </p>
<p><em>The author wishes to thank Avniye Tansug for the background information included in this blog post. Ms. </em><a href=""http://tansug.com/""><em>Tansug</em></a><em> is a Turkish Internet activist and </em><a href=""http://bilgicagininhukuku.blogspot.com.tr/""><em>blogger</em></a><em> and she can be reached at avniye at tansug dot com. </em></p>
",Intermediary Liability,2014-02-14 3:39,505,Giancarlo Frosio,News
12015,European Union,,0,0,Freedom of Linking in Europe?,Copyright,"<p>Recently, the European Court of Justice (ECJ) decided in <a href=""http://curia.europa.eu/juris/document/document.jsf?text=&docid=147847&pageIndex=0&doclang=EN&mode=lst&dir=&occ=first&part=1&cid=322255"">Svensson et al v Retriever Sverige</a> that links to authorized works freely available online do not infringe the E.U.-recognized exclusive right of communication to the public. The outcome accords with U.S. law and (so far) allows the Internet to continue to function. But the European high court’s reasoning raises many questions about when linking might violate copyright law that have been long resolved in the U.S., posing potential future danger to the World Wide Web.</p>
<p>The case involved journalists claiming that the website Retriever Sverige had improperly linked to news articles they had authored, thereby making those articles available to the public without permission, in violation of copyright law. Needless to say, if the journalists won, the entire World Wide Web would be illegal. Specifically, the Swedish referring court asked the ECJ whether linking to copyrighted materials constitutes “communication to the public” under EU copyright law, <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:2001:167:0010:0019:EN:PDF"">Article 3(1) of Directive 2001/29</a>. The Swedish court’s second question was whether the answer to question 1 depends on whether the copyright owner restricts access to the work.</p>
<p>For the first time, the ECJ announced a rule that links communicate works to the public, which is a copyright owner’s sole prerogative under EU law.  However, the court said that those links are not infringing and do not need additional authorization from the copyright owner unless they make the work available to a <em>new</em> public (par. 25-28). A new public must include people other than those who can access the work thanks to the rightsholders’ conduct. In other words, if the rightsholder publishes the work online, anyone can link to it without further permission.</p>
<p>Next, the ECJ decided that for copyright purposes, there is no difference between a link which takes the user to another website where the work (presumably) is lawfully displayed and one which embeds the work, giving the impression that it is appearing on the linking website. Because only a link that communicates the work to a “new public” infringes the copyright holders’ exclusive right (par. 30), copyright law does not offer any redress for this practice. However, the ECJ does not exclude the possibility that courts may still sanction this practice under some circumstances as a form of unfair competition.</p>
<p>Finally, the ECJ decided that Member States are not entitled to give wider protection to authors by defining “communication to the public” more broadly than is done in the InfoSoc Directive (par. 33-41).</p>
<p>While <a href=""http://blogs.wsj.com/brussels/2014/02/13/phew-europes-highest-court-decides-not-to-break-the-internet/"">some celebrated the Svensson ruling protecting linking</a>, the court’s reasoning is troublesome. It holds that linking to protected works “must be considered to be ‘making available’ and, therefore, an ‘act of communication’ . . .” (par.20), without any real explanation of this principle. In contrast, the European Copyright Society Opinion on the <em>Svensson</em> case would treat a link as a reference, as U.S. law does.</p>
<p>The ECJ’s failure to adopt the European Copyright Society’s and U.S.’s view leaves open many complicated questions that people considered long settled, raising serious concerns for anyone who uses the Internet.</p>
<p>For example, what if the copyright owner removes the linked-to material, or puts it behind a paywall? In practice, the links will probably not infringe, because they will be dead, or will direct the web user to the paywall.</p>
<p>Next, what if the rightsholder published the work on one website, but there’s an infringing copy on another site? A user links to the infringing rather than authorized copy. Is the linker infringing? We don’t know because the Court didn’t answer the question of whether links to infringing materials are infringing. But there’s an argument that the link does not make the work available to a new public, so it is not infringing. The person who posted the infringing copy would, however, be infringing, because the “new public” rule is a special rule just for links.</p>
<p>Does this answer change if the copyright owner in this scenario takes the authorized copy down? At this point, <em>the work is no longer available on the site</em> <em>where it was initially communicated</em> or it is available on that site only to a restricted public, “while being accessible on another Internet site without the copyright holders’ authorization” (par. 31). According to the court’s reasoning, the link that was once arguably legal might suddenly be infringing.</p>
<p>If this interpretation of the ECJ’s decision is correct, websites could have to constantly monitor that materials they link to are still freely available on some authorized website. So the initial coverage celebrating this opinion by <a href=""http://blogs.wsj.com/brussels/2014/02/13/phew-europes-highest-court-decides-not-to-break-the-internet/"">saying that the ECJ did not break the Internet</a> seems premature.</p>
<p>The ECJ’s ruling that linking is a regulated communication to the public could interfere greatly with the operation of the Internet. Linking is the heart of the World Wide Web. Any ruling that leaves open the possibility that links might require copyright owner authorization could interfere with the benefits of the Web, trap users in a net of entangled obligations, and limit public access to information and free speech.</p>
",Intermediary Liability,2014-03-10 13:13,505,Giancarlo Frosio,News
12075,,Turkey,0,0,New Turkish Internet Legislation at Work: Twitter and YouTube Down,General+Freedom of Expression,"<p>The Turkish Presidency of Telecommunications and Communication (TIB) has put Turkish Internet legislation enacted a few weeks ago to immediate use. As we discussed in a previous <a href=""https://cyberlaw.stanford.edu/blog/2014/02/turkey-enlists-intermediaries-censor-and-surveil-internet-users"">blog post</a>, TIB now enjoys enhanced powers to issue blocking orders, even without judicial review. Under this new legal framework, TIB has ordered both Twitter and YouTube blocked, despite national and international criticism. As multiple parties noted, these blocking orders undermine freedom of expression in Turkey.</p>
<p>The Turkish government’s discontent with social networking and users’ platforms has quite a long history now. In 2013, Twitter and YouTube played a key role in the <a href=""http://en.wikipedia.org/wiki/2013%E2%80%9314_protests_in_Turkey"">Gezi Park protest</a>, while State television opted for less inflammatory programming, as if nothing was happening in the streets of Istanbul.  Recently, users posted on both Twitter and YouTube embarrassing recordings related to a corruption scandal involving members of the Ankara government.  </p>
<p>TIB reacted to the governmental discontent by ordering Turkish Internet Service Providers to block access to Twitter first and Google a few days later. Both platforms had been ordered to remove allegations of corruptions involving senior officials of Erdogan’s party and governmental members. Supposedly, both intermediaries did not act expeditiously enough to meet the government’s request, especially with the municipal election day coming on March 30, 2014.</p>
<p>The ban on Twitter came after a rather strong warning from the government. The Press Adviser of the Prime Ministry made the following statement: “It is the case that the authorities of Twitter have remained insensitive towards the implementation of court orders obtained by citizens of the Republic of Turkey ordering the removal of some links. Indeed, throughout this process, [TIB] have taken the necessary initiatives in line with these court orders, yet the authorities at Twitter have been indifferent to these demands. It is stated that if such indifference persists and if court orders are disregarded, there will be no other option than to prevent access to Twitter in order to eliminate the grievance of our citizens.”</p>
<p>In the case of Twitter, TIB cited three court rulings and one prosecutorial decision as a basis for the blocking order issued to Turkish ISPs to block the microblogging platform by refusing to provide domain name services that translate the words twitter.com into the service’s IP address, as is necessary for URLs to work. In fact, <a href=""http://cyber-rights.org.tr/docs/ECHR_interim_web_ver.pdf"">Turkish scholars and activists have noted</a> that the courts orders cited by TIB did not require complete website access blocking. It was TIB’s arbitrary decision to implement a measure that silenced Twitter over the entire Turkish territory.</p>
<p>The ban on YouTube, however, is the first instance in which TIB has used its enhanced powers under the new law to block a website without any court order. TIB blocked YouTube unilaterally by saying: “after technical analysis and legal consideration based on the Law Nr. 5651, ADMINISTRATION MEASURE has been taken for this website (Youtube.com) according to Decision Nr. 490.05.01.2014.-48125 dated 27/03/2014 of Telekomünikasyon İletişim Başkanlığı.” The overbroad powers handed over to TIB by the recent Internet law reform, as feared by many Internet rights activists, proved immediately to be a powerful censorship tool.</p>
<p>In the aftermath of the Twitter’s ban, the <a href=""http://www.osce.org/fom/116682"">OCSE media freedom representative</a> expressed the international community’s concerns about media freedom and freedom of expression in Turkey: “[T]hese measures are devastating to free expression and freedom of the media and they curbs citizens' right to freely express themselves."" OCSE called for an immediate lifting of Twitter ban. The US and EU protested the decision in similar terms.</p>
<p>Domestically, both the Turkish President, Abdullah Gul, and the vice premier, Bulent Arinc, openly opposed the ban. Furthermore, an administrative court in Ankara actually ordered TIB to lift the ban on Twitter. The Court in Ankara has received an appeal filled by the Turkish Bar Association, Turkish Journalists Association and the Deputy President of the Nationalist Movement Party, Oktay Vural, directly against the decision of TIB. TIB has 30 days to appeal or implement the court ruling. At the moment, it is unclear if the government intends to lift the ban, as the decision of the administrative court should immediately go into effect. However, the adversarial relationship of Recep Tayyip Erdogan, the Turkish Prime Minister, with social platforms, and the recent additional blocking of YouTube seems to suggest that it will not. Meanwhile, incapable of reaching an agreement with the government, <a href=""https://blog.twitter.com/2014/challenging-the-access-ban-in-turkey"">Twitter has decided to challenge the access ban</a> by filing lawsuits in several Turkish courts.</p>
<p>Additionally, Yaman Akdeniz and Kerem Altiparmak, Turkish human rights scholars and activists, have petitioned the European Court of Human Rights for an urgent interim measure related to the blocking of Twitter in Turkey. A copy of the petition can be found <a href=""http://cyber-rights.org.tr/docs/ECHR_interim_web_ver.pdf"">here</a>. A few days earlier the same applicants lodged a similar petition before the Turkish Supreme Court. These scholars requested this urgent interim measure to protect the applicants’ “right to vote and be elected” and of freedom of expression in connection with the municipal elections that were held on Sunday, March 30, 2014. In the ECHR petition, Akdeniz and Altiparmak provided a reconstruction of the present Turkish political scenario. They noted that the recent amendments to the Turkish Internet Law No. 5651 and TIB’s orders blocking access to Twitter, and recently YouTube, have an effect on free elections in Turkey. These measures serve the goal of silencing discussion about the elections and allegations of corruption of some political players. </p>
<p>YouTube’s situation is still in flux. Rumors are that Google, the video site’s parent company, is in discussions with government officials to explore whether they will lift the ban. So far, Google confirmed that there is no technical issue on its side and they “have <a href=""http://googleonlinesecurity.blogspot.ru/2014/03/googles-public-dns-intercepted-in-turkey.html"">received several credible reports and confirmed with [their] own research</a> that Google’s Domain Name System (DNS) service has been intercepted by most Turkish ISPs (Internet Service Providers).” This makes it more difficult for users to circumvent this ban, as the Google’s free public DNS service has initially been used to that effect. As Open DSN Chief Executive David Ulevitch commented, “this hijacking of our traffic represents an escalation of censorship and data manipulation by the Turkish government that we have not ever seen previously anywhere outside of China.""</p>
<p>The Ankara government is using a heavy-handed approach to force platforms to censor Turkish citizens. As in the case of China, the sole option for platforms to operate and get back online may be to censor valid speech. The recent amendments to the Internet legislation are conducive to that goal. They turn decisions on website blocking into a wholly administrative matter, which is heavily influenced by governmental directives Although we may be witnessing an authoritarian turn in Turkish internal political affairs, a general lesson can be learned from the Turkish case.  Administrative enforcement of intermediary liability through governmentally controlled agencies, such as TIB, makes easier for governments tightly supervise the content that flows on the Internet.  </p>
<p>In the case of Turkey, users’ platforms that played a role in facilitating discussion on sensitive political matters were silenced just before elections. Even if the ban will be later lifted, the damage to the electoral and democratic process has already irremediably occurred. The Turkish governmental party has achieved its goal. Closing the stable door after the horse has bolted provides little help. The only positive side of this story is that free citizens may have learned how to circumvent government blocking. As Avniye Tansug, a Turkish Internet blogger and activist, explained, “blocking social media helped Turkish users to rapidly learn VPNs and other techniques.” Next time, we hope that the Turkish people can master tools to avoid such self-serving censorship. </p>
<p><em>The author wishes to thank Avniye Tansug for the background information included in this blog post. Ms. </em><a href=""http://tansug.com/""><em>Tansug</em></a><em> is a Turkish Internet activist and </em><a href=""http://bilgicagininhukuku.blogspot.com.tr/""><em>blogger</em></a><em> and she can be reached at avniye at tansug dot com.</em></p>
",Intermediary Liability,2014-03-31 21:40,505,Giancarlo Frosio,News
12087,,Turkey,0,0,Turkish Constitutional Court Says that Twitter’s Ban Violates Freedom of Expression,General+Freedom of Expression,"<p>We have <a href=""https://cyberlaw.stanford.edu/blog/2014/03/new-turkish-internet-legislation-work-twitter-and-youtube-down"">recently reported</a> on the ban of Twitter and Youtube by the Turkish Presidency of Telecommunications and Communication (TIB). The Turkish Constitutional Court has unanimously decided today that TIB's blocking of Twitter is unlawful and should be lifted as it violates freedom of expression and individual rights.</p>
<p>It is still unclear whether the decision will lead to a lifting of the ban. The ruling of the Turkish Constitutional Court comes after an administrative Court in Ankara also issued a stay of execution with regard to Twitter’s blocking order a few days ago. However, TIB did not execute that verdict so far. Kerem Altiparmak, one of the legal scholars and civil rights activists promoting the petition before the Supreme Court, said: ""[i]f there is anyone who believes there is rule of law and human rights in this country, TIB must execute the court verdict and lift the ban on Twitter.” Meanwhile, Metin Feyzioğlu, the president of Turkey's Bar Associations, stated that ""[i]f they don't abide by the ruling, we will file a criminal complaint against the TIB by attaching the ruling of the Constitutional Court.”</p>
<p>We will keep you posted as the situation evolves. </p>
",Intermediary Liability,2014-04-02 15:14,505,Giancarlo Frosio,News
12090,,Turkey,0,0,Turkey: Twitter is Back Online,General+Freedom of Expression,"<p>Today, Turkish authorities lifted the ban on Twitter. <span style=""line-height: 1.538em;"">See <a href=""http://www.reuters.com/article/2014/04/03/us-turkey-twitter-idUSBREA320E120140403. "">http://www.reuters.com/article/2014/04/03/us-turkey-twitter-idUSBREA320E...</a></span><span style=""line-height: 1.538em;"">The decision comes after the Turkish Constitutional Court <a href=""https://cyberlaw.stanford.edu/blog/2014/04/turkish-constitutional-court-says-twitter%E2%80%99s-ban-violates-freedom-expression"">spelled out</a> that the ban violated freedom of expression and individual rights in Turkey. “This is a major victory for democracy and freedom of expression in Turkey,” said Yaman Akdeniz. Akdeniz, a civil rights legal scholar and activist, challenged the ban before the Constitutional Court. </span></p>
<p><span style=""line-height: 1.538em;"">However, access to <a href=""https://cyberlaw.stanford.edu/blog/2014/03/new-turkish-internet-legislation-work-twitter-and-youtube-down"">Youtube is still blocked</a> in Turkey. Professor Akdeniz and others are preparing a new petition seeking to repel Youtube's blocking order as well. Akdeniz believes that the same principle applied by the Turkish Constitutional Court in the case of Twitter should also apply to YouTube: ""[i}t is disproportionate to block an entire site because of some content that is deemed to be illegal.” We will keep you updated and wish that Turkish users will </span><span style=""line-height: 1.538em;"">soon</span><span style=""line-height: 1.538em;""> </span><span style=""line-height: 1.538em;"">be able to access Youtube again.</span></p>
",Intermediary Liability,2014-04-03 18:20,505,Giancarlo Frosio,News
12100,,International,1,1,March 2014 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>March 2014 Retrospect is available here:</p>
<p><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2014-march"" target=""_blank"">http://www.internetjurisdiction.net/observatory/retrospect/2014-march</a></p>
<p>Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
<p><strong>MARCH 2014 IN RETROSPECT</strong></p>
<ol><li><a href=""#item1"">Brazilian Congress approves Marco Civil bill</a></li>
<li><a href=""#item2"">US Department of Commerce intents to give up control over IANA function</a></li>
<li><a href=""#item3"">Twitter blocked in Turkish jurisdiction at IP level</a></li>
<li><a href=""#item4"">European Parliament adopts EU data protection reform</a></li>
<li><a href=""#item5"">Freedom of Expression lawsuit against Chinese Baidu dismissed in US jurisdiction</a></li>
<li><a href=""#item6"">Turkish regulator blocks YouTube without court order</a></li>
<li><a href=""#item7"">Google’s YouTube and Viacom settle lawsuit in US jurisdiction</a></li>
<li><a href=""#item8"">ISPs blocks for copyright infringements are possible, says European Court of Justice</a></li>
<li><a href=""#item9"">Google encrypts searches in Chinese jurisdiction</a></li>
<li><a href=""#item10"">US and British privacy agencies sign Memorandum of Understanding</a></li>
<li><a href=""#item11"">ECPA reform in US might end stop access to emails without warrants</a></li>
<li><a href=""#item12"">French NGO opts for priority flagging instead of lawsuits against Twitter</a></li>
<li><a href=""#item13"">Google and Yahoo publish new numbers on data requests</a></li>
<li><a href=""#item14"">“Sponsored Stories” lawsuit against Facebook in Brazilian jurisdiction</a></li>
<li><a href=""#item15"">US Congress considers DMCA takedown regime reform</a></li>
<li><a href=""#item16"">French consumer group sues Google, Facebook and Twitter for Terms of Service</a></li>
<li><a href=""#item17"">UK court orders ISPs to block infringing streaming websites</a></li>
<li><a href=""#item18"">Terms of Service: Facebook restricts gun sales on its platform</a></li>
<li><a href=""#item19"">Macedonia blocks foreign gambling sites in its jurisdiction</a></li>
<li><a href=""#item20"">Apple bans sale of book with nude cover in France</a></li>
</ol><p> </p>
<p> </p>
<p><a id=""item1"" name=""item1""></a></p>
<p><strong>1. Brazilian Congress approves Marco Civil bill</strong></p>
<p> On March 25, 2014 the Brazilian Chamber of Commerce approved the <a href=""http://www.camara.gov.br/proposicoesWeb/prop_mostrarintegra?codteor=1238705&filename=Tramitacao-PL+2126/2011"" target=""_blank"">Marco Civil bill</a>. It’s scope and drafting process attracted international <a href=""http://arstechnica.com/tech-policy/2014/03/brazil-caves-to-google-new-bill-drops-local-data-storage-requirement/"" target=""_blank"">attention</a>: The legislation was drafted in 2009-10 in a crowd-sourced, public process in which nearly 2000 people participated. Moreover, the bill provides a first comprehensive legislative framework for the Internet in the Brazilian jurisdiction that has been compared to an Internet bill of rights. The Marco Civil now needs to be approved by the Federal Senate before being signed by President Dilma Rouseff. After long deliberations in the Congress, a data sovereignty provision introduced after the Snowden revelations was <a href=""http://www.reuters.com/article/2014/03/26/us-brazil-internet-idUSBREA2P08I20140326"" target=""_blank"">dropped</a> on March 18, 2014. It would have obliged Internet platforms serving Brazilian citizens to store personal data on the ground. The bill now considers that data of Brazilians is under Brazilian jurisdiction, regardless of the location of servers where they are stored. Intermediaries would only be liable for user-generated content if they do not comply with a court order. The bill also establishes net neutrality and data retention rules in the Brazilian jurisdiction.</p>
<p><strong>Read further:</strong><br />InfoJustice: <a href=""http://infojustice.org/archives/32527"" target=""_blank"">Brazilian Chamber of Deputies approves Marco Civil bill </a><br />Reuters: <a href=""http://www.reuters.com/article/2014/03/19/us-brazil-internet-idUSBREA2I03O20140319?irpc=932"" target=""_blank"">Brazil to drop local data storage rule in Internet bill</a><br />Brazilian Congress: <a href=""http://translate.google.com/translate?sl=auto&tl=en&js=n&prev=_t&hl=en&ie=UTF-8&u=http%3A%2F%2Fwww2.camara.leg.br%2Fcamaranoticias%2Fnoticias%2FCOMUNICACAO%2F464530-CAMARA-APROVA-PROJETO-DO-MARCO-CIVIL-DA-INTERNET.html"" target=""_blank"">House approves Marco Civil for the Internet</a></p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item2"" name=""item2""></a></p>
<p><strong>2. US Department of Commerce intents to give up control over IANA function</strong></p>
<p>On March 14, 2014 the US Department of Commerce’s National Telecommunications and Information Administration (NTIA) <a href=""http://www.ntia.doc.gov/press-release/2014/ntia-announces-intent-transition-key-internet-domain-name-functions"" target=""_blank"">announced</a> its intention to relinquish the US control over the Internet Assigned Numbers Authority (IANA) function. Linked to the invention of the Internet in the US jurisdiction, NTIA has contracted ICANN to perform the IANA function, which includes tasks such as the addition of new top-level domain name strings in the root zone <a href=""https://www.iana.org/domains/root/db"" target=""_blank"">database</a>. Under the current arrangement, which expires in September 30, 2015, NTIA validates requests for changes in the root made by ICANN before VeriSign executes changes and updates the root zone file. NTIA appointed ICANN to lead a global multi-stakeholder <a href=""http://www.icann.org/en/about/agreements/iana/functions-transfer-process-14mar14-en.pdf"" target=""_blank"">consultation process</a> to identify a global accountability mechanism for overseeing the IANA function. The announcement is not linked to the general question of ICANNs <a href=""https://www.icann.org/en/about/planning/strategic-engagement/intreg-development"" target=""_blank"">internationalization</a> and jurisdiction over the organization that is <a href=""https://www.icann.org/en/about/agreements/aoc/affirmation-of-commitments-30sep09-en.htm"" target=""_blank"">headquartered</a>in California. US House Republicans introduced the <a href=""http://thehill.com/blogs/hillicon-valley/technology/201991-house-republicans-move-to-block-internet-management-switch"" target=""_blank"">DOTCOM Act</a> to stop any oversight transition.</p>
<p><strong>Read further:</strong><br />Computerworld: <a href=""http://news.idg.no/cw/art.cfm?id=9A330F08-B3B9-B680-3CDB53246397206B"" target=""_blank"">US government to end formal relationship with ICANN</a><br />Gigaom: <a href=""http://gigaom.com/2014/03/14/the-u-s-seems-ready-to-give-up-control-of-the-internet/"" target=""_blank"">The US seems ready to give up control of the Internet</a><br />Domain Incite: <a href=""http://domainincite.com/16085-us-to-give-up-control-over-icann"" target=""_blank"">US to give up control over ICANN</a></p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item3"" name=""item3""></a></p>
<p><strong>3. Twitter blocked in Turkish jurisdiction at IP level</strong></p>
<p>On March 21, 2014 Turkish ISPs started blocking the US-based microblogging service Twitter. After addresses of alternative DNS servers circulated widely in Turkey to circumvent the URL ban, the country <a href=""http://www.hurriyetdailynews.com/turkey-widens-internet-censorship.aspx?pageID=238&nID=63954&NewsCatID=338"" target=""_blank"">extended</a> the Twitter block to the IP address level on March 22, 2014. Even requests to <a href=""http://www.pcmag.com/article2/0,2817,2455710,00.asp"" target=""_blank"">public DNS servers</a> that were used to circumvent the blocks were <a href=""http://www.renesys.com/2014/03/turkish-internet-censorship/"" target=""_blank"">re-routed</a>. The Twitter block is based upon the request of a public prosecutor and three court orders. Twitter complied with two court orders and removed the content in question, which also violated its global Terms of Service. The company refuses to comply with the third Turkish court order, a takedown request for an account that accused a former minister of corruption and filed a <a href=""https://blog.twitter.com/2014/challenging-the-access-ban-in-turkey"" target=""_blank"">petition</a> with a Turkish court on March 26, 2014. On the same day, the administrative court of Ankara ordered an injunction. The Turkish High Council for Telecommunication TIB was obliged to restore access to Twitter within <a href=""http://uk.reuters.com/article/2014/03/26/us-turkey-twitter-court-idUKBREA2P15G20140326"" target=""_blank"">30 days</a> until a full judgement is pronounced.</p>
<p><strong>Read further:</strong><br />Guardian: <a href=""http://www.theguardian.com/world/2014/mar/21/turkey-blocks-twitter-prime-minister"" target=""_blank"">Turkey blocks use of Twitter after prime minister attacks social media site</a><br />BBC: <a href=""http://www.bbc.com/news/technology-26749374"" target=""_blank"">Court in Turkey moves to suspend ban on Twitter</a><br />Techcrunch: <a href=""http://techcrunch.com/2014/03/22/turkey-moves-to-block-twitter-at-the-ip-level/"" target=""_blank"">Turkey moves to block Twitter at the IP level</a></p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item4"" name=""item4""></a></p>
<p><strong>4. European Parliament adopts EU data protection reform</strong></p>
<p>On March 12, 2014 the 766 members of the European Parliament <a href=""http://europa.eu/rapid/press-release_MEMO-14-186_en.htm"" target=""_blank"">passed</a> the proposed EU data protection reform package. It formally adopted the text of the EU General Data Protection Regulation (621 votes in favor) and adopted the <a href=""https://www.huntonprivacyblog.com/wp-content/files/2012/11/Proposed_Police_and_Criminal_Justice_Data_Protection_Directive.pdf"" target=""_blank"">Police and Criminal Justice Directive</a> for personal data (371 votes in favor). Under the new package, privacy protections would apply extraterritorially, regardless of the jurisdiction in which European personal data is processed. The two documents will now be <a href=""https://en.wikipedia.org/wiki/Legislature_of_the_European_Union"" target=""_blank"">discussed</a>by the EU Council of Ministers. The European Parliament also supported a <a href=""http://www.europarl.europa.eu/sides/getDoc.do?type=REPORT&mode=XML&reference=A7-2014-0139&language=EN"" target=""_blank"">resolution</a> by the Civil Liberties Committee that would veto the Transatlantic Trade and Investment Partnership unless US data protection standards are raised and calls for a suspension of the Safe Harbor framework. On March 26, 2014, the EU and US <a href=""http://www.out-law.com/en/articles/2014/march/us-to-strengthen-safe-harbour-framework-for-personal-data-transfers-from-eu-by-summer/"" target=""_blank"">announced</a> in a <a href=""http://eeas.europa.eu/statements/docs/2014/140326_02_en.pdf"" target=""_blank"">joint statement</a> to improve Safe Harbor privacy standards and create “a meaningful and comprehensive data protection umbrella agreement for data exchanges in the field of police and judicial cooperation in criminal matters, including terrorism”.</p>
<p><strong>Read further:</strong><br />Gigaom: <a href=""http://gigaom.com/2014/03/12/web-firms-face-a-strict-new-set-of-privacy-rules-in-europe-heres-what-to-expect/"" itemprop=""url"" rel=""bookmark"" target=""_blank"" title="" Web firms face a strict new set of privacy rules in Europe — here’s what to expect"">Web firms face a strict new set of privacy rules in Europe — here’s what to expect</a><br />Hunton Privacy Blog: <a href=""https://www.huntonprivacyblog.com/2014/03/articles/european-parliament-adopts-draft-general-data-protection-regulation-calls-suspension-safe-harbor/"" target=""_blank"">European Parliament adopts draft general data protection regulation </a><br />BlawBlaw: <a href=""http://blawblaw.se/2014/03/the-european-parliament%E2%80%99s-vote-on-extraterritoriality-in-data-privacy-one-step-forward-and-one-step-back/"" target=""_blank"">The European Parliament’s vote on extraterritoriality in data privacy – one step forward, and one step back</a></p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item5"" name=""item5""></a></p>
<p><strong>5. <strong><strong>Freedom of Expression lawsuit against Chinese Baidu dismissed in US jurisdiction</strong></strong></strong></p>
<p>On March 28, 2014 a US judge <a href=""http://gigaom.com/2014/03/28/us-judge-rules-chinese-search-engine-can-block-pro-democracy-websites/"" target=""_blank"">dismissed</a> a 2011 lawsuit filed in the district court of Manhattan that accused the Chinese search engine Baidu of suppressing political speech. The group of eight plaintiffs, all writers from New York, were seeking 16 million US dollar in damages for violations of their civil rights. The US judge <a href=""http://www.theregister.co.uk/2014/03/28/baidu_censorship_lawsuit_dismissed/"" target=""_blank"">decided</a> that “[t]he First Amendment protects Baidu’s right to advocate for systems of government other than democracy (in China or elsewhere) just as surely as it protects plaintiffs’ rights to advocate for democracy”. The judge moreover argued that blocking content on search engines on political grounds would constitute “in essence editorial judgements”, similar to print publications. The plaintiffs plan to appeal the verdict.</p>
<p><strong>Read further: </strong><br />New York Times: <a href=""http://www.nytimes.com/2014/03/29/business/us-judge-dismisses-lawsuit-against-chinese-search-engine.html"" target=""_blank"">U.S. Judge Dismisses Lawsuit Against Chinese Search Engine</a><br />Reuters: <a href=""http://www.reuters.com/article/2014/03/28/us-baidu-china-lawsuit-idUSBREA2Q1VS20140328"" target=""_blank"">China’s Baidu defeats U.S. lawsuit over censored search results</a><br />IT World: <a href=""http://www.itworld.com/legal/411926/us-judge-rules-baidus-censorship-protected-free-speech"" target=""_blank"">US judge rules Baidu’s censorship is protected as free speech</a></p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item6"" name=""item6""></a></p>
<p><strong>6. Turkish regulator blocks YouTube without court order</strong></p>
<p>On March 27, 2014 the Turkish High Council for Telecommunication<em>s</em> TIB <a href=""http://www.hurriyetdailynews.com/turkey-blocks-access-to-youtube-after-leaked-recordings-of-key-security-meeting.aspx?pageID=238&nID=64193&NewsCatID=339"" target=""_blank"">blocked</a> access to youtube.com in the Turkish jurisdiction without a court order. It was the first time that the agency used the new powers conferred upon it by <a href=""http://www.reuters.com/article/2014/02/18/us-turkey-government-idUSBREA1H1XL20140218"" target=""_blank"">amendments</a> to the Law Nr. 5651 that were adopted in February 2014. TIB reacted to a <a href=""http://www.bbc.com/news/world-europe-26773702"" target=""_blank"">leaked</a> recording of a high-level security meeting on Syria that circulated on YouTube.</p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item7"" name=""item7""></a></p>
<p><strong>7. <strong>Google’s YouTube and Viacom settle lawsuit in US jurisdiction</strong></strong></p>
<p>On March 18, 2014 Google <a href=""http://www.reuters.com/article/2014/03/18/us-google-viacom-lawsuit-idUSBREA2H11220140318"" target=""_blank"">settled</a> a multimillion-dollar copyright lawsuit with Viacom after seven years of litigation in the US. Viacom sued YouTube for 1 billion US dollar back in 2007 for hosting 79.000 infringing videos between 2005 and 2008. The settlement was not revealed. The <a href=""http://ipkitten.blogspot.fr/2014/03/the-seven-year-itch-viacom-v-youtube.html"" target=""_blank"">case was considered</a> as a test-bed for the limits of the Safe Harbor protection for intermediaries under the US Digital Millennium Copyright Act.</p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item8"" name=""item8""></a></p>
<p><strong>8. ISPs blocks for copyright infringements are possible, says European Court of Justice</strong></p>
<p>The European Court of Justice (ECJ) <a href=""http://europa.eu/rapid/press-release_CJE-14-38_en.htm"" target=""_blank"">decided</a> on March 27, 2014 that ISPs can be <a href=""http://www.euractiv.com/sections/innovation-enterprise/eu-court-upholds-blocking-copyright-infringing-websites-301207"" target=""_blank"">ordered</a> to block access to websites that contain content that infringes copyright. The case was brought to the ECJ by the Supreme Court of Austria. However, such orders must be <a href=""http://torrentfreak.com/eu-court-isps-can-be-forced-to-block-pirate-sites-140327/"" target=""_blank"">proportionate</a> and balance copyright protections with fundamental rights.</p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item9"" name=""item9""></a></p>
<p><strong>9. Google encrypts searches in Chinese <strong>jurisdiction</strong></strong></p>
<p>Google rolled out <a href=""http://www.pcmag.com/article2/0,2817,2454964,00.asp"" target=""_blank"">SSL-encrypted search</a> by default for users located in the Chinese jurisdiction in March 2014. The company announced to establish encrypted search by default progressively worldwide to limit the interception of online searches in national jurisdictions.</p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item10"" name=""item10""></a></p>
<p><strong>10. US and British privacy agencies sign Memorandum of Understanding</strong></p>
<p>The US Federal Trade Commission and the UK Information Commissioner’s office <a href=""https://www.huntonprivacyblog.com/2014/03/articles/u-s-ftc-uk-ico-sign-memorandum-understanding/"" target=""_blank"">signed</a> on March 6, 2014 a <a href=""http://www.ftc.gov/system/files/attachments/international-competition-consumer-protection-cooperation-agreements/140306ftc-uk-mou.pdf"" target=""_blank"">Memorandum of Understanding</a> on “Mutual assistance in the enforcement of laws protecting personal information in the private sector”. This will increase cooperation between the two agencies for both investigation and enforcement.</p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item11"" name=""item11""></a></p>
<p><strong>11. ECPA reform in US might end stop access to emails without warrants</strong></p>
<p>The US House of Congress is <a href=""http://thehill.com/blogs/hillicon-valley/technology/199625-support-builds-in-house-for-ending-warrantless-email"" target=""_blank"">discussing</a> a reform of the 1986 Electronic Communications Privacy Act that regulates how law enforcement can access private data such as emails. The <a href=""http://thomas.loc.gov/cgi-bin/query/z?c113:H.R.1852:"" target=""_blank"">Email Privacy Act</a> is gaining support. Currently, US law enforcement can access personal communication data such as emails if they are stored for more than 180 days without a warrant.</p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item12"" name=""item12""></a></p>
<p><strong>12. French NGO opts for priority flagging instead of lawsuits against Twitter</strong></p>
<p>The French anti-homophobia NGO SOS Homophobie <a href=""http://translate.google.com/translate?tl=en-us&u=http%3A%2F%2Fwww.pcinpact.com%2Fnews%2F85967-le-partenariat-avec-twitter-fonctionne-plutot-bien-pour-sos-homophobie.htm"" target=""_blank"">operates</a> since March 2013 a Twitter account to flag discriminatory tweets and hashtags with priority. One year later, this partnership with Twitter appears to work well and the NGO did not file lawsuits against the micro-blogging website since August 2013, after an anti-gay <a href=""http://www.huffingtonpost.com/2013/08/13/french-anti-gay-hashtag-gays-must-die-twitter-lawsuit_n_3744780.html"" target=""_blank"">hashtag</a> became a top trending topic in France.</p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item13"" name=""item13""></a></p>
<p><strong>13. <strong>Google and Yahoo publish new numbers on data requests</strong></strong></p>
<p>During the second half of 2013, Google witnessed an increase of requests for user data from different national jurisdictions, while Yahoo observed a decrease, compared to the first six months of 2013. New transparency reports <a href=""bits.blogs.nytimes.com/2014/03/27/government-data-requests-fall-at-yahoo-but-rise-at-google/"" target=""_blank"">show</a> that between July and December 2013, <a href=""https://www.google.com/transparencyreport/"" target=""_blank"">Google</a> received 27,477 requests from 65 different jurisdictions and <a href=""https://transparency.yahoo.com/"" target=""_blank"">Yahoo</a> 21,425 requests from 17 jurisdictions.</p>
<p><a href=""#top""><font size=""1"">Back to Top</font>/a></a><a id=""item14"" name=""item14""></a></p>
<p><strong>14.  “Sponsored Stories” lawsuit against Facebook in Brazilian jurisdiction</strong></p>
<p>Accusing Facebook of violating the privacy rights of 76 million Brazilian Facebook users, the Brazilian Institute of Computer Law has filed a 24 million euro <a href=""http://www.zdnet.com/facebook-hit-with-33m-sponsored-stories-lawsuit-in-brazil-7000027579/"" target=""_blank"">lawsuit</a> against Facebook. The social network<a href=""http://www.wired.com/2013/08/judge-approves-20-million-facebook-sponsored-stories-settlement/"" target=""_blank"">settled</a> a similar lawsuit in the US jurisdiction and <a href=""http://www.pcmag.com/article2/0,2817,2429389,00.asp"" target=""_blank"">announced</a> to end domain and open graph sponsored stories on April 9, 2014.</p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item15"" name=""item15""></a></p>
<p><strong>15. US Congress considers DMCA takedown regime reform</strong></p>
<p>The Judiciary Committee of the US Congress is <a href=""http://news.idg.no/cw/art.cfm?id=5D0C6946-A675-3B6F-2B05C4686517FE8E"" target=""_blank"">considering</a> changes to the US Digital Millennium Act. During a hearing on March 13, 2014 copyright holders demanded a reform of the notice and takedown system. They want that platforms that host user generated content employ filtering technologies.</p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item16"" name=""item16""></a></p>
<p><strong>16. <strong>French consumer group sues Google, Facebook and Twitter for Terms of Service</strong></strong></p>
<p>Google, Facebook and Twitter have been <a href=""http://news.idg.no/cw/art.cfm?id=C3C7C267-C627-69E4-7EC51002EF54B085"" target=""_blank"">sued</a> by the French consumer protection group UFC-Que Choisir and have to appear before the High Court of Paris. The group accuses the online platforms of having unclear Terms of Service that do not comply with French law. It is criticized that they link they link to conditions that are not translated into French.</p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item17"" name=""item17""></a></p>
<p><strong>17. UK court orders ISPs to block infringing streaming websites</strong></p>
<p>The High Court of London has <a href=""http://www.futureofcopyright.com/home/blog-post/2014/03/12/londen-high-court-ordered-uk-isps-to-block-4-piracy-websites.html?no_cache=1&cHash=25eaf1cf0cf37880a75c8e69f96122d0"" target=""_blank"">ordered</a> six British ISPs to block the access to four websites. They allow the streaming of copyright protected movies on their platforms or through links to third-party websites.</p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item18"" name=""item18""></a></p>
<p><strong>18. Terms of Service: Facebook restricts gun sales on its platform</strong></p>
<p>Facebook announced on March 5, 2014 new <a href=""http://news.idg.no/cw/art.cfm?id=C33B2835-CC7E-330B-0849E6577A752A88"" target=""_blank"">policies</a> that will restrict the sale of guns through its platform. In detail, the platform “<a href=""https://newsroom.fb.com/news/2014/03/facebook-instagram-announce-new-educational-and-enforcement-measures-for-commercial-activity/"" target=""_blank"">will not permit</a> people to post offers to sell regulated items that indicate a willingness to evade or help others evade the [US] law”. This new policy will also be enforced on Instagram, which was acquired by Facebook.</p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item19"" name=""item19""></a></p>
<p><strong>19<strong>. Macedonia blocks foreign gambling sites in its jurisdiction</strong></strong></p>
<p>To prevent the outflow of capital, the Macedonian government has <a href=""http://edri.org/macedonia-bans-gambling-raises-concern-censorship/"" target=""_blank"">announced</a> the blocking of gambling sites incorporated outside of the Macedonian jurisdiction for two years staring in March 2014. The <a href=""https://globalvoicesonline.org/2014/03/18/macedonian-government-to-introduce-internet-filtering/"" target=""_blank"">blocking measures</a> will be administered by the Agency for Electronic Communications and the Ministry for Information Society.</p>
<p><a href=""#top""><font size=""1"">Back to Top</font></a><a id=""item20"" name=""item20""></a></p>
<p><strong>20. <strong>Apple bans sale of book with nude cover in France</strong></strong></p>
<p>Apple has decided, based on its Terms of Service, </p>
",Intermediary Liability,2014-04-08 7:21,505,Giancarlo Frosio,News
12133,,United States,0,0,ECPA reform is not just a U.S. issue,Other,"<p>If US law enforcement officers want to access your private emails, they need to follow the requirements in the Electronic Communications Privacy Act.  ECPA is an old and imperfect piece of legislation.  Industry and civil society have long been pushing to update ECPA so that it is “technology neutral”; just as government agencies require a warrant to compel disclosure of a person’s locally-stored documents, government should have to obtain a warrant to access private documents stored in the cloud.  While this argument may seem self-evident, reform has been frustratingly slow.  Today, blogs have fired up (such as <a href=""http://thehill.com/blogs/hillicon-valley/technology/203206-groups-push-feds-on-email-privacy"">here</a>, <a href=""http://www.acslaw.org/acsblog/the-need-for-ecpa-reform"">here</a>, and <a href=""http://www.huffingtonpost.com/2014/04/10/sec-email-privacy_n_5127545.html"">here</a>) with arguments in favor of reform and criticising the Securities and Exchange Commission's opposition to reform.  However, what is missing in the current debate is that ECPA has implications beyond US borders. Technology neutrality is an important principle that should underpin the reform of ECPA.  However, I believe that the ECPA discussion should also include the question of “location neutrality” ie. foreign law enforcement officers' access to user data should be based on the same principles as access by US law enforcement.</p>
<p><strong style=""line-height: 1.3em;"">How is foreign access to non-content regulated?</strong></p>
<p>It doesn’t matter where in the world a police officer is, if he or she wants to access an individual’s Gmail or Facebook records (or many other US-based products), that access is governed by ECPA.  ECPA provides <em>some</em> limits on US law enforcement access to non-content information by requiring at least an administrative subpoena.  However, ECPA completely overlooks access by foreign governments because it defines “government entities” to mean only US government agencies.  This means that when foreign law enforcement officers ask for a user’s subscriber details or email contacts, it is up to the companies to decide whether or not they hand over that information.  Some companies refuse to provide any information voluntarily and insist on a request under a mutual legal assistance treaty (MLAT), supported by a court order.  Other companies will hand over information if they feel that it is appropriate in the circumstances.  In practice, there is no consistency, transparency, or oversight into when non-content information is handed over to foreign law enforcement.</p>
<p><strong>What about content?</strong></p>
<p>Foreign law enforcement must go through the MLAT process in order to access user content held in the US.  Before you get too excited in thinking that this provides good legal and procedural protections, you need to look a little more closely.  The current MLAT-based system for content access is basically due to a legislative oversight, not because of a well-reasoned policy decision.  ECPA doesn't mention whether or not a foreign law enforcement officer should be able to obtain either a subpoena or court order directly from a US court.  In order to overcome this, a foreign government can make an MLAT request, which effectively asks the US Government to obtain a warrant on behalf of the foreign government.</p>
<p>When it comes to the content of users’ emails, the current system might seem good on first glance because it only allows foreign governments to access user data through the MLAT system, which involves a US warrant process.  However, the MLAT system is not designed to cope with the large volume of requests for online data that are now being made or the tight timeframes that cyber-investigations demand (the <a href=""https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0CCkQFjAA&url=http%3A%2F%2Fwww.whitehouse.gov%2Fsites%2Fdefault%2Ffiles%2Fdocs%2F2013-12-12_rg_final_report.pdf&ei=8StHU-WcDqSRygHRwoDYDA&usg=AFQjCNECWMLdrUPs5Y3eiS_8G9CndI6kMw&sig2=6-IkQsJrmR-QHPk5vbeyHw&bvm=bv.64542518,d.aWc"">President’s Review Group</a> found that MLAT requests for online records take an average of 10 months!).  This means that either (1) legitimate criminal investigations and prosecutions are compromised because the evidence cannot be obtained quickly enough or (2) police find “creative” work-arounds and “informal” means to obtain the data, which undermines transparency, accountability and user protections.  Neither of these is a good outcome.</p>
<p><strong>Where to from here?</strong></p>
<p>In the context of ECPA, technology neutrality means that a user should have the same protections for their personal data, regardless of whether it is stored in physical format, in a locally-based electronic format, or in the cloud.  I suggest that another principle for ECPA should be location neutrality – ie a user’s personal data should have the same protections from <em>all</em> law enforcement agencies, regardless of whether that agency is based in the US or abroad.  </p>
<p><span style=""line-height: 1.3em;"">The reform of ECPA is certainly not just a US issue; it impacts millions of users outside of the US.  It</span><span style=""line-height: 1.3em;""> would be a great step forward to protect users’ data from unwarranted US law enforcement snooping.  However, this is only half the picture; we need to start talking about foreign law enforcement access to electronic communications as part of the ECPA reforms.</span></p>
",Architecture and Public Policy,2014-04-10 16:48,430,Kate Westmoreland,News
12134,,United States,0,0,"Fourth Circuit Upholds Contempt Against Lavabit, Doesn’t Decide Gov’t Access to Encryption Keys",Other,"<p>Today the Fourth Circuit refrained from deciding the first legal challenge to government seizure of the master encryption keys that secure our communications with web sites and email servers.  Nevertheless, the Court upheld contempt of court sanctions, because of the Lavabit owner’s foot dragging during proceedings. Lavabit had failed to raise the substantive issues below, it decided, thus precluding appellate review. There’s little in the opinion that would help us guess what the Court would have ruled if Lavabit had properly raised its legal arguments below, but the opinion is welcome in that it shows the Court understands quite well how asymmetric transport encryption like SSL works.</p>
<p>Hopefully future courts to review and decide this issue will be as sophisticated. Key disclosure is an even more obvious danger today than it was when the Lavabit appeal was filed. That’s because in January, President Obama announced that the government plans to keep information security flaws secret if they have “a clear national security or law enforcement” use. It’s hard to imagine customers around the world having any kind faith in the U.S. government’s self-restraint after this announcement. Obviously, having an SSL key to decrypt past and future traffic data would be useful to both the NSA and law enforcement.  </p>
<p>Nevertheless, it remains an open question whether and when the government can compel key disclosure.  That is because Lavabit and Levinson did not consistently have legal counsel throughout the proceedings below, and thus failed to raise legal issued sufficiently that the appellate court could review them.  Moral of the story: get good legal counsel immediately.  </p>
<p>For more, see <a href=""http://justsecurity.org/2014/04/16/fourth-circuit-upholds-contempt-lavabit-doesnt-decide-govt-access-encryption-keys/"">my post over at Just Security</a>.</p>
","Intermediary Liability, Privacy",2014-04-16 11:01,240,Jennifer Granick,News
12180,,Brazil,0,0,"Brazil Leads the Efforts in Internet Governance with its Recently Enacted ""Marco Civil da Internet"". What’s in it for Intermediary Liability?",General,"<p>On April 23, 2014, Brazil’s President Dilma Rousseff enacted the country’s long awaited Internet Bill of Rights, locally known as “Marco Civil da Internet”.</p>
<p>First introduced to the legislature in 2011, the bill was finally approved by Congress and submitted to the Senate in late March this year, after long public debate and several failed attempts of having it voted through the Congressional House. </p>
<p>Made a constitutional priority by the Brazilian Government following the revelations from Edward Snowden regarding American espionage, the bill moved unusually quickly through the Senate, within less than a month after being approved in Congress.</p>
<p>Upon the Senate’s approval, President Rousseff strategically held the enactment of the bill during the first day of “NETmundial”, hosted in Sao Paulo - Brazil’s most trenchant city. The event is a global forum on the future of Internet governance and features representatives of 97 countries, including the US, Brazil, Russia, France, Germany, India, and others.</p>
<p>The new law, which establishes rules on net neutrality, privacy, data retention and intermediary liability, amongst other issues, will become effective 60 days after its official publication held on April 24, 2014.</p>
<p><u>So how does it impact Intermediary Liability?</u></p>
<p>Despite controversial and passionate views from both enthusiasts and critics, the recently sanctioned law is viewed as a breakthrough for Brazil’s Internet Governance laws, impacting all players on the Internet, intermediaries included, of course.</p>
<p>Up until recently, the Country had not yet enacted a specific law regulating broad intermediary liability, or the Internet itself, for that matter. Instead, interactions over the Internet were governed by the Country’s general existing legislation, minor legislation updates, and overall case law.</p>
<p>The existing legal scenario created some level of uncertainty for intermediaries as to their liability for user-generated content, with different judicial interpretations arising out of the Country’s many courts.</p>
<p>For the last few years, Brazil has been one the leading countries in takedown requests and lawsuits, according to companies like <a href=""http://www.google.com/transparencyreport/removals/government/countries/"">Google</a> and <a href=""https://transparency.twitter.com/removal-requests/2013/jan-jun"">Twitte</a>r. In the recent past, several high profile intermediary liability cases also have gained international media attention.</p>
<p>The recently enacted Brazilian Law now provides a clear safe harbor for intermediaries, who will only be held liable for damages arising from user-generated content when failing to comply with a takedown order issued by a reputable Court. The exception will be for cases relating to private ‘sexual content’, when the intermediary could be held secondarily liable for damages, if failing to act upon user notification.</p>
<p>The new law – with its explicit safe harbor - is expected to provide breathing room for intermediaries operating in Brazil, partly reducing not only the amount of litigation exposure, but also the uncertainty towards liability relating to takedown requests made by users.</p>
<p>In order to propagate its efforts regarding Internet governance, the Brazilian Government is expected to soon release an official English version of its “Marco Civil da Internet”.</p>
<p>Until then, you can see the full text of the new law, in English, by clicking <a href=""https://thecdd.wordpress.com/2014/03/28/marco-civil-da-internet-unofficial-english-translation/"" target=""_blank"">here</a> (Unofficial Free Translation).</p>
<p><em>The author of this blog post, Diego Spinola, is an LLM candidate at Stanford Law School and a qualified Brazilian attorney. He can be reached at dspinola at stanford.edu.</em></p>
",Intermediary Liability,2014-04-30 14:39,642,Diego Spinola,News
12208,European Union,,0,0,"Internet Search Engines Are Liable for Processing Personal Data, Says the ECJ",Privacy or Data Protection+Right to Be Forgotten+Freedom of Expression,"<div>Earlier today, the European Court of Justice released its long-awaited decision in <em>Google Spain</em>. The ECJ ruled that ""an internet search engine operator is responsible for the processing that it carries out of personal data which appear on web pages published by third parties.” Thus, under certain circumstances, search engines can be asked to remove links to webpages containing personal data.</div>
<div> </div>
<div>The principle stated by the ECJ  redefines the digital conundrum at the intersection of data protection law, freedom of expression and intermediary liability by further expanding liabilities of intermediaries. The case will affect privacy/reputation-motivated takedown requests directed towards intermediaries. We will provide you with additional coverage of this case in the next few days. Meanwhile, the Press Release is available <a href=""http://curia.europa.eu/jcms/upload/docs/application/pdf/2014-05/cp140070en.pdf"">here</a> and the actual judgment is published <a href=""http://curia.europa.eu/juris/liste.jsf?language=en&td=ALL&num=C-131/12"">here</a>. </div>
<div> </div>
",Intermediary Liability,2014-05-13 4:11,505,Giancarlo Frosio,News
12270,,International,1,1,The World Intermediary Liability Map (WILMap) is Online!,General,"<div>The Center for Internet and Society at Stanford Law School is excited to announce the official launch of the <a href=""https://cyberlaw.stanford.edu/our-work/projects/world-intermediary-liability-map-wilmap"">World Intermediary Liability Map (WILMap)</a>.</div>
<div> </div>
<div>The WILMap is a detailed English-language resource comprised of case law, statutes, and proposed laws related to intermediary liability worldwide. The WILMap allows visitors to the CIS website to select information on countries of interest through a graphical user interface. </div>
<div> </div>
<div>The map will enable the public to learn about intermediary liability regimes worldwide and evolving Internet regulation affecting freedom of expression and user rights. Legal liability regimes that put Internet platform companies at legal risk for users’ online activity can imperil free expression and innovation. By their nature, Internet services are inherently global, but Internet companies face a real challenge understanding how those global regimes might regulate the services they offer to the public. This uncertainty can hurt users by potentially scaring companies away from providing innovative new services in certain markets. Additionally, companies may unnecessarily limit what users can do online, or engage in censorship-by-proxy to avoid uncertain retribution under unfamiliar laws.</div>
<div>
<div> </div>
<div>Today, the WILMap covers more than 50 jurisdictions in Africa, Asia, Australia, the Caribbean, Latin America and Europe. The WILMap is an ongoing project. In collaboration with a network of experts worldwide, CIS will continue to update and expand the map, with the goal of covering all jurisdictions.</div>
<div> </div>
<div>This project has been made possible by an awesome team of contributors, both individual researchers and institutions, providing the necessary information to set up the country pages. Having developed and coordinated this project as the Intermediary Liability Fellow at CIS, I want to personally thank all the contributors for the great work done. You may find their names and contact details at the bottom of each country page. Special thanks to Nicolo Zingales for helping to coordinate this project.</div>
<div> </div>
<div>After the launch, CIS hopes many other collaborators will join this project to create additional country pages, to update those already published, and to make this online resource as comprehensive and complete as possible. We also welcome more informal feedback <a href=""https://docs.google.com/forms/d/1rQ0FUpzU_tJxXz_5R4Z7-ZiaiWM7k8MYdsp43e6e5Mc/viewform"">here</a>.</div>
<div> </div>
<div>To learn about intermediary liability rules worldwide, and for information about joining the project, or otherwise contributing to the map, please visit the <a href=""http://cyberlaw.stanford.edu/our-work/projects/world-intermediary-liability-map-wilmap"">WILMap</a> page or contact us at gcfrosio at law.stanford.edu.</div>
</div>
<p> </p>
",Intermediary Liability,2014-07-07 6:15,505,Giancarlo Frosio,News
12274,,European Union,0,0,Should We Centralize the Right to be Forgotten Clearing House?,Privacy or Data Protection+Right to Be Forgotten+Freedom of Expression,"<div style=""text-align: justify;"">
<p>Being in Silicon Valley during the time when the honourable Court of Justice of the European Union ""cracks"" its epic right to be forgotten ruling, is a very interesting social experience. Suddenly, the European part of you receives a strange lot of attention among tech folks in all the small talks. No wonder.<a href=""http://curia.europa.eu/juris/liste.jsf?num=C-131/12""><i><strong> </strong>Google Spain</i> C-131/12</a> for me is both great and terrible.</p>
<p>It is <i>great</i> because the European data protection laws definitely should apply to companies that make a lot of money in Europe, and should regulate search engines. If small European companies manage, so can their American counterparts. The decision is, however, <i>terrible</i> for the (im)balance it strikes. And I know this is where most of the people get passionate. I think that the optimism of many people who commented on ruling is driven by the belief that the law will be changed (e.g. my friend <a href=""http://www.theguardian.com/technology/2014/may/21/what-did-the-media-miss-with-the-right-to-be-forgotten-coverage"">Julia Powles in the Guardian</a> and <a href=""http://www.wired.co.uk/news/archive/2014-05/15/google-vs-spain"">Wired</a>). If this is your framework, then I do agree. Yes, the decision will definitely move things ahead. </p>
</div>
<div style=""text-align: justify;"">
<p>This might be all true and great, but still, from the <i>short term perspective</i>, the decision with its (im)balance is just terrible. <a href=""http://eulawanalysis.blogspot.co.uk/2014/05/the-cjeus-google-spain-judgment-failing.html"">Steve Peers</a>, <a href=""http://blog.lehofer.at/2014/05/eugh-google-muss-doch-vergessen-das.html"">Peter Lehofer</a> and others already commented on the constitutionally striking language of the decision. Peter Lehofer eloquently characterized this reading of privacy as a <a href=""http://blog.lehofer.at/2014/05/eugh-google-muss-doch-vergessen-das.html"">""super-human-right""</a>. This blanket preference for one human right disturbs me, especially when it comes from a court that is increasingly taking the<a href=""http://www.verfassungsblog.de/seht-her-verfassungsgericht/""> role of a constitutional court</a> and even claiming to have <a href=""http://europeanlawblog.eu/?tag=case-c-39911-melloni"">the ultimate words on the content of those rights</a>. As all European law students learn, perhaps as the first thing in their human rights classes, that there is <i>no</i> hierarchical relationship between the conflicting human rights. That's why we need a test of proportionality. The CJEU now seems to disagree.</p>
</div>
<blockquote class=""tr_bq""><div style=""text-align: justify;"">
<p><strong>So why do I think that the current decision can <em>not</em> serve as a right balance for the future law? </strong></p>
</div>
</blockquote>
<div style=""text-align: justify;"">
<p>First of all, the Directive itself has very narrow exceptions for the use of personal data without the permission of the individual concerned [<i>""solely for journalistic purposes or the purpose of artistic or literary expression""</i>]. The fact that CJEU explicitly had no problem with giving a blessing to reading that precludes search engines and other websites from referring to a legitimate article (e.g. up-to-date news article), just because no explicit exception exists. This is deeply worrying. I think that a search engine should be able to invoke the same exception, which a source website is able to invoke (e.g. journalistic, scientific, etc.). This could potentially affect not only search engines, but anybody linking to an article with an anchor which uses personal data (or think of Tweets that encompass personal data when referring to a legitimate article). I think if we expand the notion of ""data controllers"" and thus data protection laws, we should also expand exceptions [yes, think here of the the old problem of the copyright laws]. Otherwise we might outlaw socially legitimate processing of personal data and artificially break the chain of speech online.</p>
</div>
<div style=""text-align: justify;"">
<p>Second, and this is where most of my European friends disagree, the right to object to ""no longer relevant"" processing of personal data, should be made <i>an exception</i> and not a general rule as CJEU tell us [the word ""relevant"" in Art. 6(1)(3) IMHO refers not to time-relevant, but proportionate]. I can personally see many instances when we want to give a second chance to people and relieve them from their personal history. Spent convictions for rehabilitated offenders, juvenile indiscretions or personal bankruptcies all share the same justification - a need to give a second chance to people. But this not universal. Not all outdated data have such properties and can be supported by such justification. In fact, I would argue it is only a small subset of all outdated information. Many people also seem to assume that a time dimension decreases the societal value of the information that has such merit. Yes in some cases, but in others it can even <a href=""http://www.cambridge-code.org/googlespain.html"">increase its societal value</a> (e.g. former radical now applying for job as a high school teacher or running for the public office, etc.). I just don't think that narrative of second chance really supports a universal right of this kind.</p>
<p><strong>Implemenatition also matters</strong></p>
</div>
<div style=""text-align: justify;"">
<p>But let's look into the application. Google just published its <a href=""https://support.google.com/legal/contact/lr_eudpa?product=websearch&hl=en"">European removal tool</a>. The company seems to be preparing for serious examination of all the requests. From a business perspective, this is no surprise, given that if Google wants to continue to provide its service with any meaningful value, it has to comply. Other it might potentially face criminal charges. And Google is of course capable of doing it. The problem is, however, by shifting the burden completely on a search engine, we just literally ""cemented"" search engine market by erecting incredibly high barriers to entry. Are mini-competitors of Google like Czech <a href=""http://www.seznam.cz/"">Seznam.cz</a> also capable of doing this? I doubt so. They will most likely just automate the process to save the costs.</p>
</div>
<div style=""text-align: justify;"">
<p>Of course you can argue that our preference for privacy is stronger than any concern of competition in the search engine market. But the search engine market is crucial to the online flow of information and any business online. I am not saying we should not regulate search engines, but trying to outsource some of the burden, so a more competitive environment can be preserved, would be desirable. For instance, <i>having to apply to data protection authorities prior to removal on grounds of ""no longer relevant""</i>, would be a good step [mind you, this is not about right to erasure]. </p>
</div>
<div style=""text-align: justify;"">
<p>This way, we have a state authority to determine such conflicts of freedom of expression and privacy. The authority, which is, unlike a private company, <i>directly</i> bound by human rights [because its a state power]. This would also centralize such decision making into one place, so the consistency can be achieved. And we can better discuss edge cases, because its all public [though anonymized]. The handling of ""no-longer-relevant"" complaints and defending of potential freedom of expression issues would not be in this way left to business incentives of companies, but to publicly accountable body. Again, the search engines represent a way more critical infrastructure [at least today] than any other service, and no-longer-relevant requests are way more difficult to assess than say copyright issues. So a different treatment, I think, it justified. </p>
</div>
<div style=""text-align: justify;"">
<p>This would also create more legal certainty for service providers and originators of objected speech. Because what is time-relevant for a society is determined by the state, not industry players. At the same time, it would outsource some of the decision making costs, so the barriers of entry would be lowered. Also the mental barrier for applications would be slightly increased, as filling a request to the administrative authority perhaps makes us think twice [even if its free of charge]. The examination effort of search engines would thus not be replicated many times, but be centralized to one decision-making process, with positive spill-over on less wealthy competitors.</p>
<p><strong>Decision as a political statement</strong></p>
</div>
<div style=""text-align: justify;"">
<p>To conclude. I think that the Google Spain ruling is really better understood as a political act of the CJEU than as some interpretation of the laws. CJEU members probably disgusted by the difficult policy debates about a new European data protection regulation and <a href=""http://www.foreignaffairs.com/articles/141435/henry-farrell-and-abraham-newman/forget-me-not"">""US overreach"" revealed by Snowden</a>, decided on this strong ruling to make a political statement. US tech companies have been blocking a new Regulation in Brussels, so the judges decided to mix up the pack of cards on the policy table from Luxemburg, to see what will happen now [thus proving that Coase’s theorem does not work in the political process as well].</p>
<p>Only the way this ruling will be practically carried will determine whether the history will list Google Spain as a good or bad move for the European society.</p>
<p><i>PS1: There are plenty of alternative options. In a conversation, <a href=""http://www.law.cam.ac.uk/people/research-students/julia-powles/4273"">Julia Powles</a>, for instance, suggested that if Google was really concerned about smaller players, it would look seriously at creating an independent, industry-sponsored platform to do this job, because it could be a faster option than any DPA. I personally favour state-implemented solution, given the direct obligations to respect human rights. But I agree that fragmentation and tardiness of DPAs is something that would need to be solved.</i></p>
<p><em>PS2: The original article was published on <a href=""http://www.husovec.eu/2014/05/should-we-centralize-right-to-be.html"">my Huťko's Technology Law Blog</a>.</em></p>
</div>
<p><em>The author of this blog post, Martin Husovec, is an IMPRS-CI Doctoral Research Fellow at Max Planck Institute for Innovation and Competition and currently a visiting researcher at Stanford Center for Internet and Society. He can be reached at <a href=""http://www.husovec.eu/"">husovec.eu</a>.</em></p>
","Intermediary Liability, Privacy",2014-05-30 13:28,759,Martin Husovec,News
12286,,International,1,1,April 2014 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>April 2014 Retrospect is available here:</p>
<p><span style=""line-height: 1.538em;""><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2014-april"">http://www.internetjurisdiction.net/observatory/retrospect/2014-april</a></span></p>
<p><span style=""line-height: 1.538em;"">Retrospect is the monthly newsletter of the </span><a href=""http://www.internetjurisdiction.net/"" style=""line-height: 1.538em;"">Internet & Jurisdiction Project</a><span style=""line-height: 1.538em;""> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</span></p>
",Intermediary Liability,2014-06-03 1:29,505,Giancarlo Frosio,News
12324,,International,1,1,Internet & Jurisdiction Case Collections 2012 and 2013 in Retrospect,General,"<div>The Internet & Jurisdiction Project launched officially the case compilations 2012 and 2013 in Retrospect. </div>
<div>
<div> </div>
<div>The case collections ”2012 in Retrospect“ and “2013 in Retrospect” are a compilation of 460 selected cases. They show the tension between the cross-border nature of the Internet with its transnational online spaces and the patchwork of geographically defined national jurisdictions. They provide a review of crucial dynamics to stimulate discussions and trigger research with special emphasis on intermediary liability cases. </div>
<div> </div>
<div>All featured cases were chosen because of their relevancy by the Internet & Jurisdiction Observatory network composed of 32 selected international experts from 26 different institutions in 13 countries.</div>
<div> </div>
<div>The case collections can be downloaded at <a href=""http://www.internetjurisdiction.net/retrospect-case-collections"">http://www.internetjurisdiction.net/retrospect-case-collections</a>.</div>
</div>
<p> </p>
",Intermediary Liability,2014-06-10 5:15,505,Giancarlo Frosio,News
12335,,Hong Kong,0,0,Hong Kong Government Introduces Copyright Bill Providing a “Safe Harbor” for OSPs for Copyright Infringement,Copyright,"<p>Today, the Hong Kong Government introduced the <a href=""http://www.ipd.gov.hk/eng/intellectual_property/copyright/copyright_2014_bill.htm"">Copyright (Amendment) Bill 2014</a> into the Legislative Council to revise Hong Kong’s copyright law so as to “keep pace with technological and overseas developments.”</p>
<p>One of the key proposals under the Bill includes a statutory “safe harbor” for Online Service Providers (OSPs). According to Clause 50 of the Bill, OSPs’ liability for copyright infringement occurring on their platforms could be limited when OSPs meet certain prescribed conditions, including the taking of reasonable steps to limit or stop copyright infringement when being notified. As stated by the <a href=""http://www.info.gov.hk/gia/general/201406/11/P201406110615.htm"">spokesperson</a> of the Hong Kong government, the proposal aims at facilitating OSPs’ handling of alleged infringements, balancing the interests between copyright holders and Internet users.</p>
<p>Although the amendment was drafted to strike a more appropriate balance favoring the remix culture, <a href=""http://www.scmp.com/comment/article/1534614/revised-copyright-bill-still-deep-disappointment-internet-users"">according to Peter Yu</a>, the revised copyright bill is still a disappointment to most Internet users, considering the limited scope of fair-dealing exceptions that the government included in the bill, contrary to the results of an <a href=""http://www.ipd.gov.hk/eng/intellectual_property/copyright/consultation_on_parody.htm"">earlier public consultation</a>.</p>
",Intermediary Liability,2014-06-17 18:55,813,Bolin Zhang,News
12344,European Union,,0,0,"European Libraries Don't Need Permission to Digitize Books in Their Collection, Says Advocate General of the ECJ",Copyright,"<p>Recently, an Advocate General with the European Court of Justice (ECJ) handed down an <a href=""http://curia.europa.eu/jcms/upload/docs/application/pdf/2014-06/cp140078en.pdf"">opinion </a>in <a href=""http://curia.europa.eu/juris/documents.jsf?num=C-117/13#"">Technische Universität Darmstadt v Eugen Ulmer KG</a> stating that European libraries may digize individual books in their collection without permission from the rightholders.</p>
<p>In this dispute, the German Federal Court of Justice <a href=""http://eur-lex.europa.eu/legal-content/en/TXT/PDF/?uri=uriserv%3AOJ.C_.2013.171.01.0010.01.ENG"">asked</a> the ECJ to clarify the scope of the exception to the right of reproduction and communication to the public for publically accessible libraries, which make works from their collections available to users by dedicated terminals. Eugen Ulmer KG, a German publishing house, sought to prevent (i) the Technical University of Darmstadt from digitizing a book in its collection published by Eugen Ulmer and (ii) users of the library from printing the book or saving it on a USB stick, (iii) after the university refused the offer of Eugen Ulmer to purchase and use as e-books the textbooks it publishes.</p>
<p>Preliminary, the Advocate General considers that ""even if the rightholder offers to a library the possibility of concluding licencing agreements for the use of his works on appropriate terms, the library may avail itself of the exception provided for in favour of dedicated terminals.""</p>
<p>Additionally, according to the Advocate General, European law does not prevent Member States ""from granting libraries the right to digitize the books in their collections,"" so as to make them available at electronic reading points. However, the opinion clarifies that the InfoSoc Directive 2001/29/EC does not permit ""the digitization of a collection in its entirety, but only the digitization of individual works.""</p>
<p>Finally, the Advocate General takes the view that while the directive ""does not allow the users of dedicated terminals to save the works [ . . . ] on a USB stick,"" the printing of the work ""may be covered by other exceptions provided for by the directive, in particular, the exception for private copying.""</p>
<p>The opinion of the Advocate General is not binding on the ECJ but will strongly influence its final decision. The full text of the opinion is available <a href=""http://curia.europa.eu/juris/celex.jsf?celex=62013CC0117&lang1=en&type=TXT&ancre="">here</a>.</p>
",Intermediary Liability,2014-06-18 22:15,505,Giancarlo Frosio,News
12351,,Canada,0,0,Canadian Court Forces Google to Delist Websites Worldwide,Other IP,"<p>A few days ago, the Supreme Court of British Columbia issued an order requiring Google to remove websites from its worldwide index in <a href=""http://www.courts.gov.bc.ca/jdb-txt/SC/14/10/2014BCSC1063.htm"">Equustek Solutions Inc. v. Jack</a>.  The dispute involved links to the website of a company that had been found to have stolen trade secrets from a competitor and used unfair competition tactics to lure customers into purchasing the copied products. The court order is unprecedented for Canada as it forces Google to remove links anywhere in the world, rather than only from the search results available through Google.ca.</p>
<p>Commenting on the international ramifications of this decision and the consequences for freedom of expression worldwide, Micheal Geist <a href=""http://www.michaelgeist.ca/content/view/7159/125/"">noted</a>: ""[t]he implications are enormous since if a Canadian court has the power to limit access to information for the globe, presumably other courts would as well. While the court does not grapple with this possibility, what happens if a Russian court orders Google to remove gay and lesbian sites from its database? Or if Iran orders it remove Israeli sites from the database? The possibilities are endless since local rules of freedom of expression often differ from country to country. Yet the B.C. court adopts the view that it can issue an order with global effect.""</p>
",Intermediary Liability,2014-06-20 19:21,505,Giancarlo Frosio,News
12353,,Argentina,0,0,Argentine Supreme Court To Decide Whether Intermediaries Must Monitor/Take Down Search Results,Defamation or Personality Rights,"<div>Recently, the Supreme Court of Argentina <a href=""https://www.youtube.com/watch?v=Bxlikawvc-I&list=TL1wk-p2lZ2gnWHyp0qw16j_O_2nDll_da"">heard arguments</a> in <em>Rodríguez, María Belén c/ Google Inc. y Otro s/ Daños y Perjuicios</em>. The case requires the Supreme Court to decide for the first time whether Internet intermediaries - in this case, search engines Google and Yahoo - are liable for linking to content that violates fundamental rights or infringes copyright. It will also decide whether Google Image Search’s “thumbnails” infringe copyright law. Argentina lacks a specific law defining Internet intermediary liability. So, the preliminary question here is whether the Supreme Court will suggest that Congress pass a law regulating the matter or, in contrast, will extend the existing Civil Code provisions to intermediaries, sanctioning infringing activities through a strict liability or a negligence standard.</div>
<div> </div>
<div>In the last few years, litigants—mainly models and actors—have filed hundreds of lawsuits against search engines claiming that: (1) their images and names appeared in search results linked to webpages displaying prostitution ads or pornography, in violation of their constitutional rights to reputation and privacy; and/or (2) the unauthorized commercial use of their images and names infringed the publicity rights protected by Article 31 of the Argentinian Copyright Law, both by linking to third parties’ content or by using them as search engines’ own generated content (“thumbnails”). </div>
<div> </div>
<div>A small number of cases were based on Argentinian Data Protection Law. In these instances, the plaintiffs argued that search engines are databases and, therefore, personal data should be deleted at the request of the data owner.</div>
<div> </div>
<div>However, the majority of the cases were decided according to Argentina’s general liability regime, which is based on negligence or strict liability. Some decisions - such as the Court of Appeal’s in the case <em>S. M., M. S. c/ Yahoo de Argentina SRL y Otro s/ daños y perjuicios</em> - found search engines strictly liable under Article 1113 of the Civil Code, which imposes liability, regardless of knowledge or intention, to those performing risky acts (e.g. indexing third party content creating wider audiences for illegitimate content) or serving as the “guardians” of the thing that generates the damage (e.g. the search engine’s software). Other courts decided that the conduct of search engines should be reviewed according to negligence rules.</div>
<div> </div>
<div>In the case now before the Supreme Court, the Court of Appeals took a negligence approach. The plaintiff, a former model, sought an order requiring Google and Yahoo to: (1) permanently block from the search results the links to webpages displaying prostitution ads and pornography whenever they included her name or images, which allegedly violated her constitutional rights; (2) stop any commercial unauthorized use of her image and name, which allegedly infringed her publicity right and, 3) pay damages. </div>
<div> </div>
<div>Specifically, the Court of Appeals first decided that strict liability is not compatible with freedom of expression and rejected the plaintiff’s request to apply strict liability.</div>
<div> </div>
<div>Second, Argentina’s doctrine for press media liability - under which the press are not liable for damages unless they fail to cite sources (“Campillay” doctrine) or act with some sort of bad intent (also known as the “real malice” doctrine) - is not necessarily applicable to other modes of expression. In contrast, the Advocate General, who represents the public interest and submits non-binding opinions prior to a Supreme Court decision, advocated the opposite view. </div>
<div> </div>
<div>Third, the Court of Appeals applied the negligence standard to search engines linking to third parties’ content in search results. The Court created a test under which search engines will not be liable, if (1) content is produced by a third party; (2) the claimant notifies the search engine, identifying the alleged infringing content; and (3) the search engine acts expeditiously to block the content via some “quick and effective filtering method.”</div>
<div> </div>
<div>Finally, the appellate court considered image “thumbnails” displayed in search’s results as “Google’s own content”. These, therefore, fail the first prong of the new negligence test. No fair use defense is available under Argentinean law. Thus, Google must pay damages caused by the thumbnails, including, both for copyright and non-copyright claims, actual and moral damages, but not statutory damages, which are unavailable in the Argentinean legal system.</div>
<div> </div>
<div>The question under review was especially thorny and the Court of Appeals may have overlooked at least two critical issues. First, this decision imposed on intermediaries an automatic private “notice and takedown” procedure while omitting any counter-notice. Second, the court did not distinguish between copyright infringement and, for instance, defamation or fundamental rights cases.</div>
<div> </div>
<div>The Supreme Court then accepted review of the case and called for a hearing, a practice that it reserves only for very impactful cases. </div>
<div> </div>
<div>At the Supreme Court hearing, the plaintiff insisted that search engines are liable under strict liability rules because they organize information according to their own criteria and they are the “guardians” of the robots that index the information. The Supreme Court Chief Justice promptly noted that linking to infringing materials would constitute negligence rather than risky activity. He also noted that if search engines had to be held liable as “guardians” of their own indexing software, any software developer could be held strictly liable under similar considerations. Finally, the Chief Justice also highlighted that search engines cannot know whether content is legitimate until they are notified by the rightsholder. In this case, the plaintiff did not notify the defendants prior to filing the lawsuit.</div>
<div> </div>
<div>Later in the hearing, the Supreme Court judges focused on whether Google actually blocks content and when and how it does it. The Court asked Google if, once notified of infringing content, it would agree to the solution proposed by the Court of Appeal to take down such content. Google lawyers made clear that deciding content legitimacy without a judicial order is extremely difficult. However, the company also clarified that under the current Argentinian system, if someone proves to be exercising a legitimate right, claiming copyright infringement or a fundamental right violation, and asks for a content takedown, Google will, more likely than not, take it down. Then, the Supreme Court turned to whether a negligence standard is applicable to the case by investigating whether Google has an “active role” in organizing the indexing criteria of its search engines and operates some kind of filtering mechanism. Actual control over the organization of search results according to established criteria would be a necessary element to establish negligence. Accordingly, if search engines do not have any control over third parties’ content, they could not be held liable at all. </div>
<div> </div>
<div>Finally, Yahoo explained that it decided to “over-block” any content related to the plaintiff, including some homonyms too), because it was the only option to avoid liability.</div>
<div> </div>
<div>All in all, it seems highly probable that the Supreme Court will not apply a “strict liability” approach. However, it is not clear to which extent it will favor a negligence rule, affirming the appellate decision or maybe reframing the test more narrowly. Most likely, the Supreme Court decision will focus on the <u>notification procedures and whether actionable take down demands can be purely private or would require judicial review</u>. Also, the Supreme Court will whether search engines and other Internet services are treated as press media, requiring a showing of “real malice” before courts may impose liability.</div>
<div> </div>
<div>How close is Google of being found liable for its “thumbnails” in Argentina? Close enough. This could be Argentina’s Congress’ opportunity to discuss copyright reform that includes a much-needed fair use exception for some unauthorized uses of protected works.</div>
<div> </div>
",Intermediary Liability,2014-06-23 15:38,840,Paula Vargas,News
12361,,International,1,1,May 2014 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>May 2014 in Retrospect is available here:</p>
<p><span style=""line-height: 1.538em;""><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2014-may"">http://www.internetjurisdiction.net/observatory/retrospect/2014-may</a></span></p>
<p><span style=""line-height: 1.538em;"">Retrospect is the monthly newsletter of the </span><a href=""http://www.internetjurisdiction.net/"" style=""line-height: 1.538em;"">Internet & Jurisdiction Project</a><span style=""line-height: 1.538em;""> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</span></p>
",Intermediary Liability,2014-06-24 13:36,505,Giancarlo Frosio,News
12378,,Argentina,0,0,The Argentine National Communications Commission Orders to Block The Pirate Bay,Copyright,"<p>Today, the Argentine National Communications Commission (NCC) <a href=""http://www.lanacion.com.ar/1705910-la-comision-nacional-de-comunicaciones-ordena-el-bloqueo-de-the-pirate-bay-en-la-argentina"">ordered</a> Internet Service Providers to block access to The Pirate Bay websites in the country within five days. The blocking order complied with an injunction issued by the District Court No. 64 in Buenos Aires in a case initiated by the Argentine Chamber of Phonographic Producers. The District Court issued a so called ""auto-satisfactive"" measure that does not need any further determination of the merits of the case. Therefore, at least until this decision is reversed on appeal, Argentina has joined the long <a href=""http://en.wikipedia.org/wiki/Countries_blocking_access_to_The_Pirate_Bay"">list of countries blocking access</a> to The Pirate Bay.</p>
<p>The full text of the NCC order (only in Spanish) is available <a href=""http://www.scribd.com/doc/232031432/cnc-tpb-argentina-pdf"">here</a>, while the district court's decision (only in Spanish) can be found <a href=""http://www.scribd.com/doc/232015119/CAPIF-CAMARA-ARG-DE-PRODUCTORES-DE-FONOGRAMAS-Y-OTROS-c-THE-PIRATE-BAY-s-MEDIDAS-PRECAUTORIAS"">here</a>. The website Accesso Directo published <a href=""http://acceso-directo.com/la-comision-nacional-de-comunicaciones-debera-bloquear-el-acceso-pirate-bay-en-argentina/"">here</a> the full list of IP numbers and DNS domains to be blocked.</p>
",Intermediary Liability,2014-06-30 19:00,505,Giancarlo Frosio,News
12380,,United States,0,0,"The Supreme Court Finds Aereo a Direct Infringer, Justice Brandeis (and Scalia) Dissent",Copyright,"<p>Recently, the United Sates Supreme Court decided <a href=""http://www.scotusblog.com/case-files/cases/american-broadcasting-companies-inc-v-aereo-inc/"">American Broadcasting Cos. v Aereo</a>, holding that “Aereo publicly performs copyrighted works, in violation of the <a href=""http://www.law.cornell.edu/uscode/text/17/101"">Copyright Act’s Transmit Clause</a>, when it sells its subscribers a technologically complex service that allows them to watch television programs over the Internet at about the same time as the programs are broadcast over the air.” However, the dissenting opinion argued that turning a secondary liability case into a direct liability case is a mistake and may work serious injury to the general public.</p>
<p>The Supreme Court described Aereo’s service as follows:</p>
<p style=""margin-left:.5in;"">Respondent Aereo, Inc., sells a service that allows its subscribers to watch television programs over the Internet at about the same time as the programs are broadcast over the air. When a subscriber wants to watch a show that is currently airing, he selects the show from a menu on Aereo's website. Aereo's system, which consists of thousands of small antennas and other equipment housed in a centralized warehouse, responds roughly as follows: A server tunes an antenna, which is dedicated to the use of one subscriber alone, to the broadcast carrying the selected show. A transcoder translates the signals received by the antenna into data that can be transmitted over the Internet. A server saves the data in a subscriber-specific folder on Aereo's hard drive and begins streaming the show to the subscriber's screen once several seconds of programming have been saved. The streaming continues, a few seconds behind the over-the-air broadcast, until the subscriber has received the entire show.</p>
<p>Essentially, the question before the Court was: “does Aereo ""transmit . . . a performance"" when a subscriber watches a show using Aereo's system, or is it only the subscriber who transmits?” Therefore, is Aereo directly liable for copyright infringement or only potentially liable for secondary infringement?</p>
<p>American Broadcasting Cos. argued that Aereo was a direct infringer and violated the broadcasters, television producers, marketers and distributors’ exclusive right to “perform” copyrighted works “publicly.”</p>
<p>Aereo had a different view and sustained that it did “no more than supply equipment that emulate[s] the operation of a home antenna and [digital video recorder (DVR)]. [ . . . ]. Like a home antenna and DVR, Aereo's equipment simply responds to its subscribers' directives. So it is only the subscribers who ""perform"" when they use Aereo's equipment to stream television programs to themselves.” Also, Aereo emphasizes that</p>
<p style=""margin-left:.5in;"">the data that its system streams to each subscriber are the data from his own personal copy, made from the broadcast signals received by the particular antenna allotted to him. Its system does not transmit data saved in one subscriber's folder to any other subscriber. When two subscribers wish to watch the same program, Aereo's system activates two separate antennas and saves two separate [ . . . ] copies of the program in two separate folders. It then streams the show to the subscribers through two separate transmissions-each from the subscriber's personal copy.</p>
<p>The Court agreed with the petitioners and held that “Aereo <em>performs</em> petitioners' works publicly within the meaning of the Transmit Clause. [ . . . ] It does not merely supply equipment that allows others to do so” (emphasis added). The Court came down to this finding by arguing that Aereo looks like a cable system, although in fact it is not, therefore it “performs” like cable systems do when they retransmit over-the-air broadcast, according to the Copyright Act.</p>
<p>In his <a href=""http://www2.bloomberglaw.com/public/desktop/document/Am_Broad_Cos_v_Aereo_Inc_No_13461_2014_BL_175778_US_June_25_2014_#id540752"">dissenting opinion</a>, joined by Justice Thomas and Alito, Justice Scalia strongly objected to the majority view and noted that “Aereo does not perform at all. The Court manages to reach the opposite conclusion only by disregarding widely accepted rules for service-provider [ . . . ] liability and adopting in their place an improvised standard (""looks-like-cable-TV"") that will sow confusion for years to come.”</p>
<p>The dissenting opinion argued that a “volitional-conduct requirement” must be met “when a direct-infringement claim is lodged against a defendant who does nothing more than operate an automated, user-controlled system.” The bright line rule that courts have applied here is whether the providers choose the content or not. If they do not choose the content and only the users do, they should not be held directly liable.</p>
<p>The majority decision now trades that clear rule for determining whether the provider of an automated, user-controlled system committed the infringing act with a broad “ad hoc rule for cable-systems lookalikes” and “provides no criteria for determining when its cable-TV-lookalike rule applies.”</p>
<p>As Scalia noted, the fact that apparently Aereo has engineered a system hacking a loophole in the law does not mean that “we need [to] distort the copyright act to forbid it.” Secondary liability for infringement of the right to perform still remains a potentially valid redress to prevent Aereo conduct as well as primary and secondary liability for infringement of the right of reproduction. If all this fails to provide a relief, “what we may have before us must be considered a loophole in the law” but “[i]t is not the role of this Court to identify and plug loopholes,” Scalia reminded the majority. Furthermore, the dissenting opinion continues:</p>
<p style=""margin-left:.5in;"">The injustice of such action is obvious. But to give relief against it would involve more than the application of existing rules of law to new facts. It would require the making of a new rule in analogy to existing ones. The unwritten law possesses capacity for growth; and has often satisfied new demands for justice by invoking analogies or by expanding a rule or principle. This process has been in the main wisely applied and should not be discontinued. Where the problem is relatively simple, as it is apt to be when private interests only are involved, it generally proves adequate. But with the increasing complexity of society, the public interest tends to become omnipresent; and the problems presented by new demands for justice cease to be simple. <em>Then the creation or recognition by courts of a new private right may work serious injury to the general public</em>, unless the boundaries of the right are definitely established and wisely guarded. In order to reconcile the new private right with the public interest, it may be necessary to prescribe limitations and rules for its enjoyment; and also to provide administrative machinery for enforcing the rules. It is largely for this reason that, in the effort to meet the many new demands for justice incident to a rapidly changing civilization, resort to legislation has latterly been had with increasing frequency. (emphasis added)</p>
<p>Oops…sorry my sources must have got mixed up. Actually, this was Justice Luis Brandeis delivering his dissenting opinion in <a href=""http://supreme.justia.com/cases/federal/us/248/215/"">International News Services v. Associated Press</a> in 1918, exactly at pages 262-263. The correct cite form Justice Scalia reads as follows: “[i]t is [ . . . ] the role of Congress to eliminate [loopholes] if it wishes. Congress can do that, I may add, in a much more targeted, better informed, and less disruptive fashion than the crude ""looks-like-cable-TV"" solution the Court invents today.”</p>
<p>Almost a century ago, Justice Brandeis argued that stretching copyright law in order to create new property rights over information and news may not have served the public interest. <em>INS v. AP</em> was a milestone in a long history of increasing enclosure of the public domain, which has helped the formation of large cultural conglomerates, restricted competition, and disempowered democratic process by making speech dependent on market power. Similarly, today, Justice Scalia warns the Court that expanding leverage power of property owners over innovation and technological development by substituting clear cut rules with broader amorphous standards may lower incentives for newcomers and innovators. The dissenting opinion stresses that “[i]t will take years, perhaps decades, to determine which automated systems now in existence are governed by the traditional volitional-conduct test and which get the Aereo treatment.” Meanwhile, in this blurred legal landscape, “automated systems now in contemplation will have to take their chances,” especially cloud storage providers.</p>
<p>The tradeoff, the rightsholders claim, is that broadcast television may be in danger. Aereo, they state, “is to the American [broadcasters] and the American public as the Boston strangler is to the woman home alone.” No, wait, that was <a href=""http://cryptome.org/hrcw-hear.htm"">Jack Valenti’s testimony</a> before the Congress prior to the <a href=""http://www.law.cornell.edu/copyright/cases/464_US_417.htm"">Sony decision</a> in 1982 and he was talking about the movie industry, rather than the broadcasters. Many apologies, I had my quotes mixed up once again. In the Aereo case, perhaps less emphatically, the rightsholders just claimed that ""the very existence of broadcast television as we know it"" is at stake. Whether this may have been the case in the present scenario, we cannot foresee. In stark contrast to Valenti’s statement, for example, the video rental market has contributed significantly to the present fortunes of the movie industry. However, I personally join Justice Scalia in believing that “the proper course is not to bend and twist the Act's terms in an effort to produce a just outcome, but to apply the law as it stands and leave to Congress the task of deciding whether the Copyright Act needs an upgrade.”</p>
<p>For now, Aereo finally had to disrupt its services in the aftermath of the Supreme Court decision. Fox <a href=""https://www.techdirt.com/articles/20140626/18375827694/aereo-fallout-begins-fox-uses-ruling-to-attack-dishs-mobile-streaming-service.shtml"" style=""line-height: 1.538em;"">immediately decided</a> to try to use this new ruling to shut down Dish mobile streaming services, after other broadcasters tried and failed in the past. Many more services may be taken down by a looks-like-something-that-is-protected-by-copyright-law rule in the near future. Others may never be developed because the incentives to create are now off set by the legal risks involved.</p>
",Intermediary Liability,2014-07-01 7:13,505,Giancarlo Frosio,News
12417,,China,0,0,Sohu vs Toutiao: Chinese Mobile News App Sued by News Publishers for Copyright Infringement,Copyright,"<div>Recently, a 120 million users mobile application, <a href=""http://www.toutiao.com/"">Toutiao</a> (“headline” in Chinese), got on the nerves of traditional and Internet news publishers in China. In late June, China's Internet giant <a href=""http://www.sohu.com/"" style=""line-height: 1.538em;"">Sohu</a> <a href=""http://tech.ifeng.com/internet/special/jrttqq/"" style=""line-height: 1.538em;"">sued</a> Toutiao for copyright infringement and unfair competition before the Beijing Haidian District Court. </div>
<div> </div>
<div>Like <a href=""http://www.wired.com/2010/07/is-flipboard-legal/"">Flipboard</a>, Toutiao offers customized news content aggregation based on users’ personal input or their social network activities. However, unlike Flipboard, Toutiao would crawl content and reformat it onto its own application. In doing so, ""we have to make a copy of the content on our own servers. But this is for better readability as well as compatibility when transfering content from webpages to our mobile application,"" Toutiao’s CEO Zhang Yiming <a href=""http://www.huxiu.com/article/35165/1.html"">explained</a>. </div>
<div> </div>
<div>Sohu claimed that Toutiao infringed its copyrights by reformatting Sohu’s original content onto Toutiao's own app. According to Sohu, this ""reformatting"" technology, instead of directing users to the original page, would divert traffic and ads revenues from Sohu's website. Sohu asked for injunctive relief and ￥11,000,000 in damages. </div>
<div> </div>
<div>Toutiao’s CEO responded that the app is <a href=""http://cn.tmagazine.com/technology/20140609/tc09toutiao/"">more like Google News</a>, which is not meant to produce or publish news but merely to recommend and deliver the aggregated and compiled news to users on their mobile phones. ""When third-party publishers do not want their contents to be recommended and displayed on our app, they can opt out by embedding a <a href=""http://web.toutiao.com/media_cooperation/"">no-transform protocol </a>on their webpage, so when users click the headline, they will be directed to the original page instead of our reformatted news article,"" Toutiao's website explains. </div>
<div> </div>
<div>Many analysts <a href=""http://www.bjreview.com.cn/nation/txt/2014-06/30/content_626717_2.htm"">considered</a> Toutiao a content provider, which may be infringing on the news publishers’ copyrights, rather than a mobile search engine. However, arguments favoring the public interest in accessing more information and knowledge are also flourishing. </div>
<div> </div>
<div>On July 9, Toutiao <a href=""http://tech.caijing.com.cn/20140709/3613035.shtml"">counter-claimed</a> against Sohu on business disparagement. This dispute might take some time to be decided and we will keep you updated on further developments. However, an initial conclusion can be drawn. Today’s Chinese news and media industry does not believe anymore that to “<a href=""http://jolt.law.harvard.edu/articles/pdf/v08/08HarvJLTech537.pdf"">steal a book is an elegant offense</a>.” </div>
","Copyright and Fair Use, Intermediary Liability",2014-07-15 23:09,813,Bolin Zhang,News
12423,,Italy,0,0,Intermediary Liability News from Italy: Courts block Mega and Mail.ru and Force YouTube to Proactively Monitor its Platform for Copyright Infringement,Copyright,"<div>
<div>
<div>In the last few days, Italian courts have been busy tackling online copyright infringement and sanctioning platforms that allegedly facilitate infringement. A criminal court in Rome blocked access in Italy to several websites for copyright infringement, including <a href=""https://mega.co.nz/"">Mega</a>, the new Kim Dotcom’s cloud storage service, and the Russian Internet giant <a href=""https://mail.ru/"">Mail.ru</a>. Meanwhile, the civil Court of Turin issued an injunction forcing YouTube to proactively monitor its platform for copyright infringement for certain South American soap operas uploaded by users.</div>
<div> </div>
<div>Let’s start with the most recent decision. Last week, the Tribunal of Rome ordered Internet Service Providers to block access in Italy to the ip addresses of 24 websites hosting copyrighted content without the rightsholders’ consent. Acting upon a claim of a small Italian independent distributor, the Italian authorities started a large-scale anti-piracy operation, labelled “Operation EyeMoon,” that lead to the injunction issued by the Roman court. The blocking order includes well known illegal movie streaming websites, such as cineblog01.net, cineblog01.tv, ddlstorage.com, divxstage.eu, easybytez.com, filminstreaming.eu, filmstream.info, firedrive.com, movshare.sx, nowdownload.ag, nowdownload.sx, nowvideo.sx, piratestreaming.net, primeshare.tv, putlocker.com, rapidvideo.tv, sockshare.com, uploadable.ch, uploadinc.com, video.tt, videopremium.me, youwatch.org. </div>
<div> </div>
<div>However, surprisingly, the order also targeted Mail.ru and Mega.co.nz. Mail.ru is the most-visited Russian website and the largest Russian Internet company. It is as if the court blocked access to Gmail, Yahoo!, or one of the leading Italian portals and email providers like <a href=""http://www.virgilio.it/"">Virgilio</a> or <a href=""http://www.libero.it"">Libero.it</a>. Mail.ru commented that the rightsholders “made no attempt to resolve the situation pretrial [ . . . ] No notification of illegal content or requirements to remove copies of films has been addressed to Mail.Ru Group from [Italian] law enforcement agencies."" As for Mega, it is a new cloud storage service created by Kim Dotcom. Because Kim Dotcom is a cyber-villain par excellence, the Italian court must have reasoned that his new online service must not have any substantial non-infringing uses. In fact, despite Kim Dotcom’s bad reputation, Mega is just another cloud storage service like Dropbox, Google Drive or Microsoft OneDrive. Unlike the old MegaUpload, Mega does not include any “cyberlocker” features remunerating those users uploading files that generate high traffic. It may host infringing materials as any other cloud storage service.</div>
<div> </div>
<div>Turning to the most recent Youtube affair in Italy, a few weeks ago, the Tribunal of Turin issued an injunction in favor of Delta TV against YouTube. Delta TV sued Google and YouTube for copyright infringement of certain South American soap operas that users had uploaded to YouTube. In this case, Google complied with its notice and take down policy, and the videos were removed as soon as the specific URLs were provided by Delta TV. Nevertheless the Court agreed with Delta TV’s claims, and ordered Google and YouTube to remove the infringing videos and to prevent further uploads of the same content through the use of its Content ID software (YouTube’s system for automatic detection of uploaded videos that infringe copyright) using as a reference the URLs provided by Delta TV. The Court stressed that these proactive monitoring obligations derive from the fact that YouTube is a “new generation” hosting service, a role that brought on it a greater responsibility to protect third parties’ rights.</div>
<div> </div>
<div>This decision revised en banc a previous judgment of the same Tribunal, which actually seemed to take in greater consideration the exclusion of a general obligation to monitor networks for infringing activities by the intermediaries, as provided by European law and its national implementation. On May 5, 2014, the Court of Turin rejected the request of Delta TV on the basis that (i) there is no obligation on the part of Google and YouTube, as hosting providers, to assess the actual ownership of the copyrights in videos uploaded by individual users; (ii) the only liability hypothetically attributable to Google and YouTube relates to cases where they are specifically informed of the unlawfulness of the uploaded videos and have not removed them; and (iii) there is not sufficient evidence to consider Google and YouTube as “active hosts” (thus not shielded by the hosting defense of the E-Commerce Decree).</div>
<div> </div>
<div>This growing Italian jurisprudential trend upholding harsh copyright enforcement measures against intermediaries is worrisome. It may produce chilling effects on innovation, especially on cloud storage and user generated content services.</div>
<div> </div>
</div>
<div><em>The author wishes to thank F. Saverio Ligi for some of the background information included in this blog post. Mr. Ligi is an Italian attorney and can be reached at saverio.ligi at bakermckenzie.com.</em></div>
</div>
<div> </div>
",Intermediary Liability,2014-07-22 6:35,505,Giancarlo Frosio,News
12426,,United Kingdom,0,0,Jurisdiction over user data - what is the ideal solution to a very real world problem?,Other,"<p> </p>
<p>Over the past ten days, <a href=""http://www.theguardian.com/technology/2014/jul/15/academics-uk-data-law-surveillance-bill-rushed-parliament"">civil society has been having kittens</a> over the <a href=""https://www.gov.uk/government/publications/the-data-retention-and-investigatory-powers-bill"">UK Data Retention and Investigatory Powers Bill</a>, partly because of its extraterritorial extension of UK surveillance powers.  This comes at a time when there is already heightened focus on issues of data and jurisdiction because the District Court is due next week to consider Microsoft’s challenge to the <a href=""https://s3.amazonaws.com/s3.documentcloud.org/documents/1149373/in-re-matter-of-warrant.pdf"">magistrate’s decision</a> to uphold a search warrant over data that is stored in Ireland.  When the District Court hears this matter, things will no doubt get very technical very quickly.  International jurisdiction can have you turning your mind inside out trying to work your way through layers of laws, precedents and analogies, none of which is actually directly applicable to the case at hand.  However, before we get swept up in the court’s analysis, let’s take a moment to step outside of the legalities of the Microsoft case and instead think about the fundamental principles behind them.  It’s a game of ‘what would we want the laws to look like if we didn’t have to rely on Congress to pass them?’.  </p>
<p> </p>
<p>The big question that I want to ask is, what criteria <em>should</em> jurisdiction for user data be based on?  The four key options that I see are:</p>
<ul><li>Data location</li>
<li>User location</li>
<li>Company location</li>
<li>Terms of service</li>
</ul><p> </p>
<p><u>Jurisdiction based on data location</u></p>
<p>This is essentially the approach that Microsoft is advocating.  If your biggest fear is the NSA-style overreach of US power, it has definite appeal.  It means that US law enforcement doesn’t get a shortcut to the world’s data just because US companies dominate much of the internet.  Instead, US law enforcement must use the Mutual Legal Assistance Treaty (MLAT) process or other methods of international cooperation if the data is hosted abroad, which feels reassuringly respectful of international borders and principles of sovereignty.</p>
<p> </p>
<p>However, if you’re a vulnerable user in an undemocratic regime, this may not be such an attractive option.  Companies that insist on Californian jurisdiction over their data can use this to protect their users’ data when they have concerns about the legitimacy of the foreign government’s request.  The Electronic Communications Privacy Act (ECPA) may be an imperfect guardian of user data, but it still provides a baseline level of protection for vulnerable users in undemocratic countries. </p>
<p> </p>
<p>Moreover, data is increasingly stored across multiple jurisdictions and moves quickly between them.  It seems arbitrary for users to be subject to different laws depending on where their data happens to be at a particular moment in time.  For some companies, it may even be difficult to determine where the data is located.</p>
<p> </p>
<p>If companies make decisions about where to store data based on legal considerations rather than technical requirements, it could compromise the ability to provide fast, reliable product offerings to consumers.  <a href=""http://googlepublicpolicy.blogspot.com/2013/11/testifying-before-us-senate-on.html"">Google highlighted this point</a> in their objections to Brazil’s attempt to legislate for data localization. </p>
<p> </p>
<p><u>Jurisdiction based on user location</u></p>
<p> </p>
<p>Something feels right about users being governed by their own countries’ laws because that’s how it’s traditionally been done. <a href=""http://www.pennlawreview.com/print/162-U-Pa-L-Rev-373.pdf"">Professor Kerr has argued</a> for US jurisdiction to be based on user location, so that US-based users would receive full statutory protections, regardless of where in the world their data is stored.  Applied more broadly, this could have the benefit of ensuring that users in countries with strong data protection and human rights laws receive the protection of their own countries’ regimes even when they’re using a foreign online product.  User-based jurisdiction could also facilitate legitimate access to data for criminal investigations by removing the international complications when law enforcement officers are investigating users within their own jurisdiction.</p>
<p> </p>
<p>However, companies with a very international user base could find themselves in a nightmarishly complicated situation of having to comply with 193 countries’ legal systems and apply the correct laws to each user wherever that user happened to be.  There are also difficulties in identifying where a user is at any given time.  Professor Kerr suggests a solution that permits (but does not <strong>require</strong>) providers doing business in the US to disclose foreign user data (using rebuttable presumptions about user location) in response to foreign legal requests.  This goes some way towards solving the problem.  However, I'm not sure that it is a complete solution by itself because, if mirrored in other jurisdictions around the world, it places a large amount of discretion in the hands of internet companies and creates significant conflict of laws issues.</p>
<p> </p>
<p><u>Jurisdiction based on company headquarters’ location</u></p>
<p>This is the approach adopted by companies such as Google, Twitter, and Facebook.  It has the advantage of being simple to understand, and ensures that there is at least a baseline level of legal protections (albeit a US-centric baseline). </p>
<p> </p>
<p>However, this approach risks entrenching the dominance of US laws and US values over an international space.  Countries may be left with limited ability to enforce laws over their own citizens within their own territory on issues such as data protection, intellectual property, or criminal law.  It means that countries have to go through the MLAT and US legal process.  This creates a large caseload for the US Department of Justice, FBI and US companies, as well as creating delays and frustrations for foreign law enforcement.  It is concerns like these that encourage moves towards data localization and fragmentation of the internet.</p>
<p> </p>
<p><u>Jurisdiction determined by terms of service</u></p>
<p>There is some attractiveness to the idea of being able to specify jurisdiction through the terms of service.  It gives a level of user consent and empowerment over their data choices. </p>
<p> </p>
<p>However, it is doubtful how many users read and understand the terms of service for every online service they access.  This approach also raises concerns about forum-shopping.  Terms of service should have to be combined with other indicia of jurisdiction (eg headquarter or user location), otherwise companies or users could just arbitrarily forum-shop for jurisdictions.</p>
<p> </p>
<p><strong>So what is the ideal solution?</strong></p>
<p>I’m not sure.  I think that the laws governing users and their data should be determined by reference to the location of the parties (ie the user, the provider and the requesting agency), rather than focusing solely on the location of the data.  However, no single one of these bases is ideal.  I think that we need a combination of factors that are required to provide the basis for jurisdiction.  When multiple States assert jurisdiction, there’s then a separate question of how to manage any potential conflict of laws (definitely a question for another day!).</p>
<p> </p>
<p><strong>Where does this leave us?</strong></p>
<p>Meanwhile, back in reality, we have to work with the laws that are on the books.  It’s important to distinguish the discussion about what the law <em>should</em> be from what it actually is.  Some of the arguments being raised in the context of the Microsoft case seem to blur that line by using perceived problems with the MLAT process to justify particular interpretations of the current laws.  While legal interpretation should be connected with practical realities, it’s important that the logic of the analysis and interpretation be able to stand on its own merits.</p>
",Architecture and Public Policy,2014-07-24 18:11,430,Kate Westmoreland,News
12428,,Italy,0,0,Another Win for Wikimedia in Italy (and Europe),Defamation or Personality Rights+Freedom of Expression,"<div>As <a href=""https://cyberlaw.stanford.edu/blog/2014/07/intermediary-liability-news-italy-courts-block-mega-and-mailru-and-force-youtube"">reported </a>a few days ago, Italian courts have been very active in the last few weeks in reviewing liability of online intermediaries. Recently, another Italian court issued a <a href=""https://upload.wikimedia.org/wikipedia/foundation/a/ad/Angelucci_judgement.pdf"">decision </a>addressing the <a href=""https://blog.wikimedia.org/2013/06/26/wikimedia-foundation-legal-victory-italy/"">Wikimedia’s</a> standing in Italy. The Civil Court of Rome found that Wikimedia is not liable for content that users upload on Wikimedia’s platforms. This decision confirms previous Italian and German rulings, which already exempted Wikimedia from liability for user-generated content.</div>
<div> </div>
<div>This last lawsuit was initiated four years ago by Italian politicians Antonio Angelucci and his son, claiming that Wikipedia pages related to the Angeluccis contained false statements supposedly harming the family’s reputation. The allegedly defamatory statements referred to bribery scandals involving the Angeluccis. Although, upon notice of Angelucci’s claim, Wikimedia removed the allegedly defamatory content, the Angeluccis sought €20,000,000 in damages from the Wikimedia Foundation. The plaintiffs argued that Wikimedia should be treated like a content provider, rather than hosting, and should be liable under the stricter standard that apply to the Italian press as an online journal.</div>
<div>  </div>
<div>The Court of Rome rejected plaintiffs' argument and stated that Wikimedia Foundation serves as a hosting provider in managing the online encyclopedia Wikipedia. Therefore, the liability standards applying to the Italian press cannot be extended to Wikimedia, as “unlike the case of press publication, there is no contractual relationship between the author of the [allegedly infringing] content and the hosting provider; and [casting liability upon] this [conduct], coupled with the enormous amount of data uploaded by users, would imply a form of objective liability that cannot find justification in the present [Italian] legal framework.” </div>
<div> </div>
<div>In coming down to this conclusion, the Roman Court noted that, while the Directive does not directly apply to the Wikimedia Foundation as a non-EU-based organization, the basic principles of the Directive apply. According to those principles, Wikipedia enjoys an exemption from liability, as a hosting provider, unless “it does not act to remove, or block access to, the infringing information, if it gets explicit notice of this information by the competent authorities.” </div>
<div> </div>
<div>Unlike a content provider, a hosting provider does not have any obligation to monitor the content published by its users to prevent defamation of a third party. The court stated that Wikipedia “offers a service which is based on the freedom of the users to draft the various pages of the encyclopedia; it is such freedom that excludes any [obligation to guarantee the absence of offensive content on its sites] and which finds its balance in the possibility for anybody to modify contents and ask for their removal.” </div>
<div> </div>
<div>The court also excluded any form of liability of Wikipedia for carrying out a “dangerous activity.” Theoretically, Article 2050 of the Italian Civil Code would provide a legal basis for this type of liability. As the Court noted, this liability may follow from the “danger of uncontrolled, immediate and pervasive circulation of news that the online platform [managed by Wikimedia] may allow to an indiscriminate number of people.” However, the Court went on to state that Wikimedia was very clear in its disclaimers about its neutral role in the creation and maintenance of content. This disclaimer about the truthfulness of any statements included in Wikipedia would “exclude any involvement of the hosting provider in the defamation.”</div>
<div> </div>
<div>This decision follows in the footsteps of an increasingly consistent case law exempting Wikimedia from liability in Europe. In a previous <a href=""https://blog.wikimedia.org/2013/06/26/wikimedia-foundation-legal-victory-italy/"">ruling</a>, dealing with a former Berlusconi advisor’s Wikipedia entry, the Court of Rome already declared that Wikimedia is a mere hosting provider that is not liable for user generated content. Likewise, the Higher Regional Court in Stuttgart <a href=""http://lrbw.juris.de/cgi-bin/laender_rechtsprechung/document.py?Gericht=bw&nr=17388"">ruled </a>in October 2013 that <a href=""https://blog.wikimedia.org/2013/12/02/legal-victory-german-court-wikimedia-foundation/"">Wikimedia </a>is a “service provider” and not a “content provider.” As a service provider, the German Court declared, Wikimedia is not liable for user generated content, nor should proactively check Wikipedia entries for allegedly illegal or inaccurate content.</div>
<div> </div>
<div>At this stage, it seems safe to assume that Wikimedia and other similar projects should fall within the E-Commerce Directive's safe harbors for hosting providers and do not need to proactively check their platforms for infringing content.  However, although European law rules out a general obligation on access and hosting providers to monitor information trasmitted or stored or to actively seek facts or circumstances indicating illegal activity, monitoring obligations on online intermediaries have been treated quite inconsistently by European courts in the last few years. In looking at <a href=""https://cyberlaw.stanford.edu/blog/2014/07/intermediary-liability-news-italy-courts-block-mega-and-mailru-and-force-youtube"" style=""line-height: 1.538em;"">recent Italian case law</a>, for example, it may be argued that courts tend to enforce proactive monitoring obligations on user-generated content platforms in case of copyright infringement, while excluding those obligations for allegedly defamatory content. However, the European Court of Human Rights' <a href=""https://cyberlaw.stanford.edu/blog/2013/10/european-court-human-rights-holds-delfiee-liable-anonymous-defamation"" style=""line-height: 1.538em;"">decision </a>in the Delfi case does enforce proactive monitoring obligations also for defamatory content uploded by users on news platform. If Europe wants to boost its market for user-generated content, legal certainty and consistency in judicial decisions must be better addressed. Innovators will hardly invest in a market where their liability and obligations are not cleraly spelled out.</div>
<div> </div>
",Intermediary Liability,2014-07-27 5:54,505,Giancarlo Frosio,News
12429,,Singapore,0,0,Singapore’s Amended Anti-Piracy Copyright Act Enables Streamlined Site-Blocking,Copyright,"<p>Singapore Parliament just <a href=""http://www.parliament.gov.sg/sites/default/files/Copyright (Amendment) Bill 16-2014.pdf"">passed an anti-piracy amendment</a> to its Copyright Act, which aims to block “flagrantly infringing online location” such as <a href=""http://en.kioskea.net/news/25095-pirate-bay-and-more-blocked-in-singapore"">The Pirate Bay</a> and <a href=""http://www.straitstimes.com/news/singapore/more-singapore-stories/story/goodbye-illegal-downloads-20140711"">KickAssTorrent</a>. According to the new bill, which will come into force at the <a href=""http://www.straitstimes.com/news/singapore/more-singapore-stories/story/anti-piracy-law-set-kick-soon-20140708"">end of August</a>, copyright holders can now submit an application to the High Court to order an ISP to block the offending website under § 193A of the amended Copyright Act.</p>
<p>Under the new regime, the High Court will determine “whether an online location has been or is being used to flagrantly commit or facilitate copyright infringement in materials” based on certain non-exhaustive factors, including (1) whether the primary purpose of the site is to commit or facilitate copyright infringment; (2) whether the site makes available or contains directories, indexes or categories of infringing materials; (3) whether the owner or operator of the site demonstrates disregard for copyright protection; (4) whether the site has been disabled by court orders from other jurisdictions as results of copyright infringements; (5) whether the site contains instructions to circumvent measures to disable access to the site; and (6) the volume of traffic to the site.</p>
<p>Currently, copyright holders can request ISPs to block infringing content on a case-by-case take down notice. However, the ISPs are not obliged to act on the <a href=""http://www.channelnewsasia.com/news/singapore/amended-copyright-act/1245230.html"">notices</a>. Alternatively, the owners can sue ISPs for copyright infringement or seek injunctive relief in court, but that means time and money. The new bill provides them with an <a href=""https://torrentfreak.com/singapore-passes-pirate-bay-blocking-anti-piracy-law-140708/"">express lane</a> to take down the content or block the hosting site within eight weeks, if the High Court signals a green light.</p>
<p>This legislative move has been welcomed by <a href=""http://www.musicweek.com/news/read/singapore-parliament-approves-website-blocking-bill/058980"">copyright holders</a> internationally after its approval in Parliament. However, several ISPs have <a href=""http://www.straitstimes.com/news/singapore/more-singapore-stories/story/goodbye-illegal-downloads-20140711"">questioned </a> practical aspects of the implementation of the new law. In particular, it is unclear how the courts will specify the blocking mechanism (e.g. by domain names or Internet Protocol (IP) address blocking). The costs may vary considerably for ISPs depending on the blocking mechanism chosen by courts, possibly shifting the economic burden of copyright enforcement on ISPs.</p>
",Intermediary Liability,2014-07-29 14:11,813,Bolin Zhang,News
12430,,Canada,0,0,British Columbia Court of Appeal Refuses to Stay Enforcement in Equustek Solutions v. Google,Other IP,"<p>As reported <a href=""https://cyberlaw.stanford.edu/blog/2014/06/canadian-court-forces-google-delist-websites-worldwide"">here</a>, on June 13, 2014, the Supreme Court of British Columbia ordered Google to block a website worldwide in <a href=""http://www.courts.gov.bc.ca/jdb-txt/SC/14/10/2014BCSC1063.htm"">Equustek Solutions Inc. v. Jack</a>. Later, Google applied for leave to appeal the decision and for an order staying the enforcement of the order. On July 23, 2014, the Court of Appeal of British Columbia granted Google leave to appeal the decision but refused to stay enforcement of the injunction.</p>
<p>The Court granted leave to appeal since “[t]his is clearly a case where there are arguable novel and complex issues raised on appeal.” (§ 21).</p>
<p>In refusing to stay the enforcement of the order to delist the infringing website worldwide, the Court of Appeal noted that “[t]he lack of evidence of irreparable harm, in particular, leads [. . . ] to the conclusion that Google’s application must be dismissed.” (§ 27). The Court continues by stating that:</p>
<p style=""margin-left:.5in;"">Google does not lead evidence to the effect, or argue, that it or the public will suffer irreparable harm as a result of the specific order made below. [ . . . ]. Google argues, rather, that it will suffer irreparable harm as a result of the precedent established by the granting and enforcement of the injunction. [ . . . ]. It argues the enforcement of the injunction and presumably its observation by Google may result in other jurisdictions regarding Google as a vehicle for global enforcement of their laws. It makes a “floodgates” argument to the effect that similar orders in other jurisdictions may result in global content on the Internet being reduced to the lowest common denominator. It is of the view that compliance with the order would cause users to lose trust in the credibility of the Google search engine and lead to a loss of business. (§ 30-31).</p>
<p>The Court finally concluded that this is an argument that should be rejected in principle and no weight should be given to</p>
<p style=""margin-left:.5in;"">the argument that Google’s reputation will suffer if it acts in accordance with the rule of law, appeals those decisions it believes will have an adverse impact on its clients, assiduously defends its business and its clients’ interests and pursues its appeal diligently. It would be wrong in principle for me to recognize, as irreparable harm, any damage to Google’s reputation that might result from its clients’ misapprehension of procedure in this jurisdiction [ . . . ]. (§ 36).</p>
<p>The full reasoning of the Court of Appeal in Equustek Solutions Inc. v. Google Inc.,  2014 BCCA 295 can be found <a href=""http://www.courts.gov.bc.ca/jdb-txt/CA/14/02/2014BCCA0295.htm"">here</a>.</p>
",Intermediary Liability,2014-07-28 12:07,505,Giancarlo Frosio,News
12432,,Australia,0,0,Australian Government's Leaked Proposal to Force ISPs to Monitor Copyright Infringement,Copyright,"<div>A discussion paper from the Australian Government titled ""<a href=""http://media.crikey.com.au/wp-content/uploads/2014/07/copyright.pdf"">Online Copyright Infringement</a>"" leaked a few days ago. The paper included proposals to amend Australian copyright law and force ISPs to monitor copyright infringment. Under the proposal, ISPs may be requested to help to prevent Australians from infringing copyright by blocking peer-to-peer traffic, slowing down internet connections, passing on warnings from industry groups, and handing over subscriber details to copyright owners.</div>
<div> </div>
<div>Additional coverage of the Australian anti-piracy proposal is available <a href=""https://theconversation.com/brandis-leaked-anti-piracy-proposal-is-unrealistic-29709"">here</a>. In this commentary, Nicolas Suzor and Alex Button-Sloan from the Faculty of Law of Queensland University of Technology noted that the ""leaked anti-piracy proposal is unrealistic."" They stressed that ""similar schemes have been tried around the world, but there is little evidence they actually work to reduce copyright infringement."" Actually, the proposal does nothing to address the problem that Australian users are not treated fairly by copyright industries, which should, first of all, ""provide better, cheaper, and more convenient legal ways for consumers to pay for access."" Suzor and Button-Sloan highlighted that the proposed measures may have unintended consequences. Requiring ISPs to serve as copyright police may (1) ""raise the price of internet access in Australia, as ISPs will pass on the increased costs of monitoring and enforcing copyright,"" (2) remove ""the safeguards that our courts provide in ensuring the law is applied fairly,""  and (3) ""create a strong incentive for ISPs to agree to rightsholder demands to protect their interests."" </div>
<div> </div>
<div>I agree with each of the arguments made by Suzor and Button-Sloan. If ever implemented, this proposal would trample heavily on users' rights. </div>
",Intermediary Liability,2014-07-30 2:28,505,Giancarlo Frosio,News
12435,,United Kingdom,0,0,"UK Parliament's Committee Labelled the ""Right to be Forgotten"" as Misguided and Unworkable",Privacy or Data Protection+Right to Be Forgotten+Freedom of Expression,"<p>The European Union Committee of the UK Parliament released a <a href=""http://www.publications.parliament.uk/pa/ld201415/ldselect/ldeucom/40/4002.htm"">report </a>on the implications of the European Court of Justice’s (ECJ) recent <a href=""https://cyberlaw.stanford.edu/blog/2014/05/internet-search-engines-are-liable-processing-personal-data-says-ecj""><em>Google Spain</em> decision</a>: ""EU Data Protection Law: a 'Right to be Forgotten'?"".</p>
<p>The Committee came out against the current set of proposals related to data protection that are being negotiated in the EU and recommended that the UK ""Government should persevere in their stated intention of ensuring that the Regulation no longer includes any provision on the lines of the <a href=""http://ec.europa.eu/justice/news/consulting_public/0006/com_2010_609_en.pdf"">Commission's 'right to be forgotten'</a> or the <a href=""http://ec.europa.eu/justice/data-protection/document/review2012/com_2012_11_en.pdf"">European Parliament's 'right to erasure'</a>."" The Committee noted that the <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:31995L0046:en:HTML"">Data Protection Directive of 1995</a> and the ECJ interpretation of the Directive in <em>Google Spain</em> do not reflect ""the current state of communications service provision, where global access to detailed personal information has become part of the way of life."" In the Committee's view, ""[i]t is no longer reasonable or even possible for the right to privacy to allow data subjects a right to remove links to data which are accurate and lawfully available."" Therefore, the Committee stated that ""the 'right to be forgotten' as it is in the Commission's proposal, and <em>a fortiori</em> as proposed to be amended by the Parliament, must go. It is misguided in principle and unworkable in practice.""</p>
<p>In particular, the Committee recommended that the term “data controller” should not be extended, in any new European Regulation, to search engines or users. The Committee highlighted that ""there are strong arguments for saying that search engines should not be classed as data controllers"" (Paragraphs 26-42 and 55 of the Report). In this regard, the Report discussed in details the feasibility for search engines of complying with the requests received. The Committee concluded that in fact it may be in practice possible for Google to comply with the ECJ ruling but compliance may be an insurmountable burden for smaller search engines. Smaller search engines, might ""automatically withdraw links to any material objected to because they would not have the resources to examine requests on a case by case basis [ . . . ] [t]his would effectively allow any individual an uncontested right of censorship."" Additionally, the Committee was especially concerned with ""a further question, whether it is right that the judgment on issues such as this should be left to Google and other search engines."" On this last point, the Committee concluded:</p>
<p style=""margin-left:.5in;"">[i]t is wrong in principle to leave to search engines the task of deciding many thousands of individual cases against criteria as vague as ""particular reasons, such as the role played by the data subject in public life"". We emphasise again the likelihood that different search engines would come to different and conflicting conclusions on a request for deletion of links.</p>
<p>However, the Report also anticipated that the UK view may not be shared by other Member States. The Report mentioned that, on July 3, 2014 the Italian Presidency circulated to the Working Group on Information Exchange and Data Protection a note entitled ""<a href=""http://register.consilium.europa.eu/doc/srv?l=EN&f=ST%2011289%202014%20INIT"">Right to be forgotten and the Google judgment</a>"" which, as the Committee noted, ""seem[s] to assume that the law as set out by the Court in its interpretation of the Directive must continue to be the law as stated in the draft Regulation."" The UK Committee stated that ""this is a profound error"" and called for the legislators to replace the current law with a better law, if the current law as interpreted by the ECJ is a bad law. Alalalai...the ""right to be forgotten"" is expected to become a hot battlefield in the next few months in Europe.</p>
",Intermediary Liability,2014-07-31 5:32,505,Giancarlo Frosio,News
12436,,United States,0,0,USA v. Microsoft: what the decision does and doesn't mean,Other,"<p>Somehow we went from mild interest in December when Microsoft challenged a search warrant over user data stored in Ireland to some kind of frenzy today when Chief US District Judge Loretta Preska ruled in the government’s favor.  I know it doesn’t make good sound bites, but this is not a case of good versus evil and today’s ruling is not necessarily a Bad Thing. It might be, but it’s just too soon to tell.  If Judge Preska’s decision survives the inevitable appeals, the most important thing will be the basis of her (and the appeal judges’) reasoning.  Until then, let’s cut through the hyperbole to see what the case does and does not mean.</p>
<p><strong>What it doesn’t mean</strong></p>
<p><em>US law enforcement can access your data anywhere in the world</em></p>
<p>It doesn’t actually mean that the <a href=""http://arstechnica.com/tech-policy/2014/07/microsoft-ordered-to-give-us-customer-e-mails-stored-abroad/"">world’s servers are now fair game for the FBI</a>.  The e-mail account was created with the US company, Microsoft Corporation, and the records were stored in Ireland.  This case applies to US-based companies, not to each and every internet provider in the world.</p>
<p><em>User data is completely unprotected and at the mercy of the FBI without any checks and balances.</em></p>
<p>We may all be a little punch-drunk from the seemingly endless revelations of NSA overreach in accessing user data, <a href=""http://www.dailydot.com/politics/microsoft-cloud-storage-warrant-judge-ruling-ireland/"">but this isn’t just another round in “NSA vs the World”</a>.  The data was sought under a search warrant.  The government still had to meet probable cause in order to access it.  The question is not whether the judiciary should be involved, but which judiciary applying whose laws.</p>
<p><em>Microsoft and the other companies in their corner are strong on defending foreign users’ rights.</em></p>
<p>When it comes to sharing user data with foreign governments, internet companies have large amounts of discretion (at least when it relates to non-content).  <a href=""http://cyberlaw.stanford.edu/blog/2014/05/are-some-companies-yes-men-when-foreign-governments-ask-user-data"">As noted previously</a>, there are very few checks and balances on this discretion, and different companies have quite different track records.</p>
<p><em>Tech companies are united in their objections to the government position.</em></p>
<p>Apple, Cisco, AT&T, and Verizon have voiced support for Microsoft’s position.  Other big providers have been silent.  <a href=""http://cyberlaw.stanford.edu/blog/2014/06/whose-laws-control-your-data-implications-microsoft-search-warrant-challenge"">This could be because they take a different approach </a>to data storage and jurisdiction.  Importantly, it shows that there is definitely not unanimity on how best to solve this issue.</p>
<p><strong>What it does mean</strong></p>
<p style=""margin-left:18.0pt;""><em>The rest of the world is watching</em></p>
<p style=""margin-left:18.0pt;"">Every law enforcement agency in the world is struggling with the question of how to stay one step ahead of criminals and no country really wants to have to go through the involved process of mutual legal assistance in time-sensitive cases if they can avoid it.  This doesn’t mean that it will be a total free-for-all on user data; this decision would only apply to companies that are within that country’s borders.  It may, however, encourage other countries to adopt more expansive legislation and policies.</p>
<p style=""margin-left:18.0pt;""><em>There is potential for conflict of laws issues and questions of sovereignty</em></p>
<p style=""margin-left:18.0pt;"">It is permissible for a country to have legislation with extraterritorial effects, but not to go into another country to enforce it.   If this case ends up creating a principle that a search or seizure occurs at the time that a US company copies data from their server in a foreign country, then the US might be trying to exercise enforcement jurisdiction in another country.  This is one of the few areas of international law on jurisdiction that’s pretty clear; it’s a no-no.</p>
<p style=""margin-left:18.0pt;"">On the other hand, if the search or seizure doesn’t occur until the data is handed over to US authorities, you have a conflict of laws.  This is because a user’s data could be affected by both the US law and the <a href=""http://bits.blogs.nytimes.com/2014/07/31/judge-rules-that-microsoft-must-turn-over-data-stored-in-ireland/?_php=true&_type=blogs&_r=0"">other country’s data protection laws</a>.<em> </em></p>
<p style=""margin-left:18.0pt;""><em>This could have significant implications for cloud computing and remote data storage</em></p>
<p style=""margin-left:18.0pt;"">There are definitely downsides to an approach that uses data location as the basis for jurisdiction.  One of these is that it would mean that companies will make decisions about data location based on legal priorities rather than technical needs, which could compromise the speed and robustness of new products.</p>
<p style=""margin-left:18.0pt;""><em>We’re going to have to wait for legal certainty</em></p>
<p style=""margin-left:18.0pt;"">The Magistrate’s decision, the ensuing briefs from Microsoft and the government, and the various amicus briefs each focused on different legal issues.  Is this essentially a fourth amendment case or a question of statutory interpretation of the Electronic Communications Privacy Act?  This is actually a big deal and goes to the heart of issues such as where does an electronic search or seizure occur?  To some extent, it is not the outcome of this case that really matters, but the reasoning upon which it is based.</p>
",Architecture and Public Policy,2014-07-31 22:36,430,Kate Westmoreland,News
12438,,International,1,1,WILMap Updated...and to Be Further Expanded (with Your Help),General,"<p>After <a href=""https://cyberlaw.stanford.edu/blog/2014/07/world-intermediary-liability-map-wilmap-online"">launch in July 2014</a>, the <a href=""https://cyberlaw.stanford.edu/our-work/projects/world-intermediary-liability-map-wilmap"">World Intermediary Liability Map (WILMap)</a> has been steadily and rapidly growing.</p>
<p>New country pages were added to the WILMap, including<span style=""line-height: 1.538em;""> the </span><a href=""https://cyberlaw.stanford.edu/page/wilmap-african-union"" style=""line-height: 1.538em;"">African Union</a><span style=""line-height: 1.538em;"">, </span><a href=""https://cyberlaw.stanford.edu/page/wilmap-belgium"" style=""line-height: 1.538em;"">Belgium</a><span style=""line-height: 1.538em;"">, the </span><a href=""https://cyberlaw.stanford.edu/page/wilmap-european-union"" style=""line-height: 1.538em;"">European Union</a><span style=""line-height: 1.538em;"">, </span><a href=""https://cyberlaw.stanford.edu/page/wilmap-iran"" style=""line-height: 1.538em;"">Iran</a><span style=""line-height: 1.538em;"">, </span><a href=""https://cyberlaw.stanford.edu/page/wilmap-ireland"" style=""line-height: 1.538em;"">Ireland</a><span style=""line-height: 1.538em;"">, </span><a href=""https://cyberlaw.stanford.edu/page/wilmap-malaysia"" style=""line-height: 1.538em;"">Malaysia</a><span style=""line-height: 1.538em;"">, </span><a href=""https://cyberlaw.stanford.edu/page/wilmap-nigeria"" style=""line-height: 1.538em;"">Nigeria</a><span style=""line-height: 1.538em;"">, </span><a href=""https://cyberlaw.stanford.edu/page/wilmap-south-korea"" style=""line-height: 1.538em;"">South Korea</a><span style=""line-height: 1.538em;""> and </span><a href=""http://cyberlaw.stanford.edu/page/wilmap-venezuela""><span style=""line-height: 1.538em;"">Venezuel</span>a</a>.</p>
<p><span style=""line-height: 1.538em;"">Other pages were updated with recently enacted legislation and judicial decisions. Several pages, such as Austria, Bangladesh, Estonia, Greece, </span>Kazakhstan<span style=""line-height: 1.538em;"">, Liberia, </span><span style=""line-height: 20.0063037872314px;"">Pakistan,</span><span style=""line-height: 20.0063037872314px;""> and </span><span style=""line-height: 1.538em;"">Portugal are in the making and will be soon online.</span></p>
<p>The goal of featuring all the world countries is within reach. We hope to achieve this goal soon with the help of new contributors.</p>
<p>Please contact us <a href=""http://docs.google.com/forms/d/1rQ0FUpzU_tJxXz_5R4Z7-ZiaiWM7k8MYdsp43e6e5Mc/viewform"">here </a>or reach me directly at my <a href=""mailto:gcfrosio@law.stanford.edu"">email address</a> if you want to help to create additional country pages, update those already published, and make the WILMap as comprehensive and complete as possible.</p>
",Intermediary Liability,2015-01-22 11:30,505,Giancarlo Frosio,News
12440,,Iran,0,0,Iran’s Internal Battle for Internet Control: President Rouhani and Supreme Leader Khamenei,General+Freedom of Expression,"<div>Despite Iranian President Hassan Rouhani’s 2013 campaign promises to lighten internet censorship, little has changed in the way of content filtering or bloggers’ arrests during his first year in office. </div>
<div> </div>
<div>After the moderate politician’s election to the presidency in summer 2013, he signaled his intention to carry through on his promises of internet freedom by opening a Facebook account, along with his fifteen cabinet members. Yet the Committee for Determining Instances of Criminal Web Content (CDICWC), the body tasked with identifying content to be filtered, has continued to block platforms and applications such as WeChat in December 2013 and Viber—albeit temporarily—in January 2014. Other platforms, including Facebook, which was initially blocked in 2009, have not been made available under Rouhani’s presidency. </div>
<div> </div>
<div>This disparity between stated policy and implementation comes at least in part from the complicated division of authority over the internet in Iran. The CDICWC is subject to the direction of the Supreme Council of Cyberspace (SCC), created in 2012 by Supreme Leader Ali Khamenei, a political hardliner who does not support the liberalization of Iran’s censorship policies. Although Rouhani is the chairman of the SCC, his moderate voice is often outnumbered by hardliners on the Council; of the Council’s 22 current members, nine were directly appointed by Khamenei. </div>
<div> </div>
<div>The resulting power struggle over internet censorship between Rouhani and Khamenei became public in May 2014, when Rouhani and Communication Minister Mahmoud Vaezi tried to veto the CDICWC’s decision to block WhatsApp. CDICWC Head and Prosecutor General Gholam-Hossein Mohseni-Eje’i accused Rouhani and Vaezi, the latter of whom is also a member of the CDICWC, of unlawfully refusing to carry out the ruling to block WhatsApp. In the end, the Communications and Information Technology Ministry that Vaezi leads implements filtering decisions. Vaezi later <a href=""http://smallmedia.org.uk/sites/default/files/u8/IIIP_May14.pdf#page=12"" style=""line-height: 1.538em;"">stated </a>that the blocking of WhatsApp would not take place due to a flaw in the CDICWC’s voting on the day of the decision: one of the council members who voted was in fact no longer part of the Council. </div>
<div> </div>
<div>Although the WhatsApp decision was the first public conflict over internet censorship between hardliners and moderates in Iran’s government, it is unlikely to be the last. However, it should be noted that moderates only argue for continued access to platforms such as WhatsApp “until an Iranian alternative can be made available” or until a more intelligent filtering system can be designed, both of which are in production at the request of the government. </div>
<div> </div>
<div><em>Hannah Chartoff is a Research Associate for the Council on Foreign Relations</em>.</div>
<div> </div>
",Intermediary Liability,2014-08-19 1:09,831,Hannah Chartoff,News
12455,,International,1,1,July 2014 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p style=""line-height: 20.0063037872314px;"">July 2014 in Retrospect is available here:</p>
<p style=""line-height: 20.0063037872314px;""><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2014-july"">http://www.internetjurisdiction.net/observatory/retrospect/2014-july</a></p>
<p style=""line-height: 20.0063037872314px;"">Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"" style=""line-height: 1.538em;"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
",Intermediary Liability,2014-09-08 11:21,505,Giancarlo Frosio,News
12461,European Union,,0,0,European Public Libraries Have the Right to Digitize Works in their Collections with Some Limitations,Copyright,"<p>On September 11, 2014, the European Court of Justice (ECJ) decided <a href=""http://curia.europa.eu/juris/documents.jsf?num=C-117/13#"">Technische Universität Darmstadt v Eugen Ulmer KG</a> stating that European libraries may digitize books in their collection without permission from the rightholders. The decision confirmed a previous opinion of the ECJ's Advocate General, as reported <a href=""https://cyberlaw.stanford.edu/blog/2014/06/european-libraries-dont-need-permission-digitize-books-their-collection-says-advocate"">here</a>.</p>
<p>The ECJ noted that European law ""must be interpreted to mean that it does not preclude Member States from granting to publicly accessible libraries [. . . ] the right to digitise the works contained in their collections . . . ."" However, several caveats attach to this general statement. First, such act of reproduction must be necessary for the purpose of making those works available to users, by means of dedicated terminals, in public libraries, for the purpose of research or private study. (par. 46). Second, the ECJ recognizes this right provided that ""specific acts of reproduction"" are involved. Therefore, the public library may not digitize their entire collections. (par. 44-45). Third, ""the number of copies of each work made available to users by dedicated terminals [cannot be] greater than that which those libraries have acquired in analogue format."" (par. 48). Finally, ""although [ . . . ] the digitisation of the work is not, as such, coupled with an obligation to provide compensation, the subsequent making available of that work in digital format, on dedicated terminals, gives rise to a duty to make payment of adequate remuneration."" (par. 48).</p>
<p>Also, as the ECJ clarified, this right does not extend to acts such as the printing out of works on paper or their storage on a USB stick, carried out by users from dedicated terminals. However, such acts may be authorised under national legislation transposing the exceptions or limitations included in Article 5(2)(a) or (b) of the Directive 2001/29/EC.</p>
<p>The full text of the opinion is available <a href=""http://curia.europa.eu/juris/document/document.jsf;jsessionid=9ea7d2dc30d6016305ffccc845069a34b26a09c6c4c2.e34KaxiLc3qMb40Rch0SaxuOb350?text=&docid=157511&pageIndex=0&doclang=EN&mode=req&dir=&occ=first&part=1&cid=189537"">here</a>.</p>
",Intermediary Liability,2014-09-15 0:53,505,Giancarlo Frosio,News
12485,,New Zealand,0,0,New Zealand Court of Appeal Found a Facebook Page Owner Not Liable for Defamatory Comments Posted by Others,Defamation or Personality Rights,"<p>Recently, the Court of Appeal of New Zealand decided <a href=""http://www.courtsofnz.govt.nz/cases/christopher-robert-murray-and-ors-v-ian-wishart/at_download/fileDecision"">Christopher Robert Murray And Ors v Ian Wishart</a> and ruled that a third party publisher - the owner of a Facebook page that contained comments by others - was not liable for defamation without actual knowledge, overturning a previous 'ought to have known' test.</p>
<p>Mr. Wishart is the author of a book called Breaking Silence, about a woman named Macsyna King, whose baby twins died in unclear circumstances from non-accidental injuries. Ms. King was implicated in the murder, although only the father of the twins was charged with their murder but acquitted. When Mr. Murray learned of the impending publication the book, he established a Facebook page called “Boycott the Macsyna King book,"" where several comments were posted by numerous people other than Mr. Murray. Some of those comments were later found defamatory. </p>
<p>The Court of Appeal had to review an ""ought to have known"" standard, which was adopted by the court of first instance. In finding Mr. Murray liable, the previous ruling applied the following test, distinguishing between an ""actual knowledge"" test and a ""ought to know"" test: </p>
<p style=""margin-left:.5in;"">[t]hose who host Facebook pages or similar are not passive instruments or mere conduits of content posted on their Facebook page. They will [be] regarded as publishers of postings made by anonymous users in two circumstances. The first is if they know of the defamatory statement and fail to remove it within a reasonable time in circumstances that give rise to an inference that they are taking responsibility for it. A request by the person affected is not necessary. The second is where they do not know of the defamatory posting but ought, in the circumstances, to know that postings are being made that are likely to be defamatory.</p>
<p>Unanimously, the judges of the Court of Appeal reversed the previous decision and endorsed the ""actual knowledge"" test. In particular, the Court noted that </p>
<p style=""margin-left:.5in;"">the ought to know test makes the Facebook page host liable on a strict liability basis, solely on the basis of the existence of a defamatory comment. Once the comment exists, he or she cannot do anything to avoid being treated as its publisher. [ . . . ] It can be argued that the ought to know test is not entirely a strict liability one, because it applies only where the circumstances are such that the host should reasonably anticipate the posting of a defamatory statement. That is akin to making the host liable for the defamatory comment because he or she has been negligent in not taking steps to prevent the defamatory comment being made. Imposing liability for damage to someone’s reputation on the basis of negligence rather than an intentional act is contrary to the well-understood nature of the tort of defamation as an intentional tort.</p>
<p>Therefore, the Court ruled that a third party publisher was not liable for comments by other people simply because he ""ought to have known"" that they were defamatory. Instead, owners of a Facebook page would only be liable for posters' defamatory comments, if (1) they had actual knowledge that those comments were on the Facebook page and (2) failed to remove them within a reasonable time.</p>
<p>The ruling included also a roadmap for applying this test to other content hosts by reviewing a large number of national and international authorities. However, a common principle to be applied to all content providers seems hard to distil as the role of online entities is somewhat fact sensitive. Reference to analogies in non-internet circumstances may be a helpful tool for courts to apply, although analogy may not be appropriate in all cases. In this respect, the Court noted:</p>
<p style=""margin-left:.5in;"">[o]ur analysis of the authorities shows how sensitive the outcome can be to the particular circumstances of the publication. The fact that many of the authorities relate to publication in one form or another on the internet does not provide any form of common theme, because of the different roles taken by the alleged publisher in each case. [. . . ] Many of the decisions show an effort by the relevant Court to reach a conclusion by reference to an analogy in a non-internet circumstance. We agree that is a helpful form of reasoning, but it must be acknowledged that the analogies are only analogies, and there is room for debate about their appropriateness in particular cases.</p>
<p>The full text of the decision is available <a href=""http://www.courtsofnz.govt.nz/cases/christopher-robert-murray-and-ors-v-ian-wishart/at_download/fileDecision"">here</a>.</p>
<div>
<div> </div>
<div> </div>
</div>
<div style=""line-height: 20.0063037872314px;""> </div>
",Intermediary Liability,2014-09-23 17:53,505,Giancarlo Frosio,News
12487,,Italy,0,0,Italian Constitutional Court to Decide Whether Administrative Enforcement of Online Copyright Infringement is Constitutional,Copyright,"<p>A few days ago, an Italian administrative Tribunal referred to the Italian Constitutional Court a question regarding the constitutionality of the Italian Communication Authority's ('AGCOM') <a href=""http://www.agcom.it/documentazione/documento?p_p_auth=fLw7zRht&p_p_id=101_INSTANCE_kidx9GUnIodu&p_p_lifecycle=0&p_p_col_id=column-1&p_p_col_count=1&_101_INSTANCE_kidx9GUnIodu_struts_action=%2Fasset_publisher%2Fview_content&_101_INSTANCE_kidx9GUnIodu_assetEntryId=771920&_101_INSTANCE_kidx9GUnIodu_type=document"">Regulation on Online Copyright Infringement</a> (“Regulation”). As we have reported in <a href=""https://cyberlaw.stanford.edu/blog/2013/12/italian-communication-authority-approves-administrative-enforcement-online-copyright"">previous blog posts</a>, the Regulation, which entered into force on April 1, 2014, empowered AGCOM to enforce online copyright infringement. Under the Regulation, AGCOM may order access and hosting providers to block access to websites hosting infringing materials or remove allegedly infringing contents after a short administrative procedure.</p>
<p>Following a claim brought by a number of consumer associations, the Regional Administrative Tribunal of Lazio asked the Constitutional Court whether website blocking orders issued by an administrative body, such as AGCOM, comply with constitutional principles, including freedom of expression, economic freedom and proportionality. Additionally, the administrative Tribunal questioned the constitutionality of the whole notice and take down system put in place by the Italian implementation of the EU E-Commerce Directive. In fact, the administrative Tribunal asked the Constitutional Court to review the constitutionality of those European provisions allowing “a court or administrative authority” to require Information Service Providers to “terminate or prevent” infringement. Those provisions served as the legal basis for the enactment of the AGCOM Regulation.  In referring the review of these provisions to the Constitutional Court, the administrative Tribunal noted:</p>
<p style=""margin-left:.5in;"">The “double track,” administrative and judicial, provided for by the European Directives that AGCOM referred to [as a legal basis to enact the “Regulation”], should be construed by taking into consideration the necessity that the limitations to access the Internet in order to protect copyright should be balanced with other rights protected by European law, such as the principle of proportionality.  However, those limitations should be subject to a preliminary judicial review. In any event, it should be considered that the implementation of those Directives in the Italian legal system cannot undermine the protection provided by our Constitution to other potentially conflicting fundamental rights.</p>
<p>The question of the constitutionality of the AGCOM Regulation was <a href=""https://cyberlaw.stanford.edu/blog/2013/10/nexa-center-responds-italian-communication-authority-proposal-online-copyright"">raised several times</a> by Italian academics and civil society during the procedure that brought to the enactment of the new Regulation.  Finally, the Italian Constitutional Court will have a chance to review this question. It will probably take some time but we will keep you updated as soon as the Constitutional Court will reach a decision.</p>
",Intermediary Liability,2014-09-28 4:19,505,Giancarlo Frosio,News
12513,,Netherlands,0,0,First Application of Google Spain by a National Court in Europe: the Right to be Forgotten Gets Reduced in the Netherlands,Privacy or Data Protection+Right to Be Forgotten+Freedom of Expression,"<p>Recently, a European national court applied for the first time the <a href=""https://cyberlaw.stanford.edu/blog/2014/05/internet-search-engines-are-liable-processing-personal-data-says-ecj"">Google Spain</a> ruling of the European Court of Justice (“ECJ”). The Court of Amsterdam dealt with one of the “right to be forgotten” requests that Google refused to comply with by rejecting the claims of the plaintiff and reinforcing the role of freedom of speech. In particular, the Dutch Court narrowed down the ECJ’s test by stating that the Google Spain ruling “does not intend to protect individuals against all negative communications on the Internet, but only against ‘being pursued’ for a long time by ‘irrelevant’, ‘excessive’ or ‘unnecessarily defamatory’ expressions.”</p>
<p>In the case before the Court of Amsterdam, the owner of an escort agency wanted to have links to online publications reporting on a crime he had committed removed from Google search engine. Google refused to comply fully with this request. Therefore, the complainant brought suit against Google to have all the search results referring to his conviction removed.</p>
<p>In handing down its decision, the Court of Amsterdam provided a more balanced view than the ECJ and did not imply that privacy should prevail over freedom of speech and information. The Court stressed that a person convicted for a serious crime will hardly meet the criteria that the communication is (1) irrelevant, (2) excessive, and (3) unnecessarily defamatory.  Actually, the Court argued that the conviction for a serious crime, and the negative publicity as a consequence thereof, in general provide information about an individual that will remain relevant. The criteria provided by the Court may be met only in very exceptional circumstances, “for instance when the offense committed is brought up again without a clear reason, apparently for no other purpose than to damage the individual involved, if reporting is not factual but rather a ‘slanging-match’.”</p>
<p>A summary in English of the judgment is available <a href=""http://inforrm.wordpress.com/2014/09/27/dutch-google-spain-ruling-more-freedom-of-speech-less-right-to-be-forgotten-for-criminals-joran-spauwen-and-jens-van-den-brink/"">here</a>.</p>
",Intermediary Liability,2014-10-07 0:17,505,Giancarlo Frosio,News
12534,,Italy,0,0,"Mega and Other File-Hosting Services’ Blockade is Overbroad, Italian Authorities Say",Copyright,"<div>As we reported <a href=""https://cyberlaw.stanford.edu/blog/2014/07/intermediary-liability-news-italy-courts-block-mega-and-mailru-and-force-youtube"">here</a>, this summer an Italian court blocked access to several websites for copyright infringement, including Mega and the Russian Internet giant Mail.ru. A few days ago, Italian authorities finally lifted that ban.</div>
<div> </div>
<div>Some websites, including Mega, negotiated a court settlement with the Office of the Prosecutor of Rome. Other sites successfully appealed the decision before the Court of Appeal of Rome. In both instances, the Italian authorities agreed with the argument that the blocking orders were overbroad, especially because the copyright infringement occurred on individual pages and a blockade of the entire website was disproportionate.</div>
<div> </div>
<div>Additional coverage in English is available <a href=""http://torrentfreak.com/court-lifts-overbroad-piracy-blockade-of-mega-and-other-sites-141009/"">here</a>.</div>
<div> </div>
",Intermediary Liability,2014-10-13 3:33,505,Giancarlo Frosio,News
12536,,Spain,0,0,Right to Be Forgotten: Google Sentenced to Pay Damages in Spain,Privacy or Data Protection+Right to Be Forgotten+Freedom of Expression,"<p>The CJEU judgment on the right to be forgotten, <em><a href=""http://curia.europa.eu/juris/liste.jsf?language=en&num=C-131/12"">Google Spain v. Mario Costeja</a></em>, hit the search engine on an unexpected front – damages. On the basis of the CJEU’s judgment, the Barcelona Court of Appeals <a href=""http://www.poderjudicial.es/search/doAction?action=contentpdf&databasematch=AN&reference=7173091&links=08019370162014100388&optimize=20140929&publicinterface=true"">ordered Google</a> to pay damages to an individual who, like Costeja, sought the removal of links to some old, damaging information from the search results.</p>
<p>In 1981, the plaintiff of this case was criminally charged for violating ""public health"" regulations. He was finally convicted by the Spanish Supreme Court in 1990. Nine years later, he was granted pardon. The Royal Decree granting this pardon was subsequently published in the <em>Boletín Oficial del Estado</em> (Official Gazette), as is required by the law. When typing plaintiff’s name in Google, links to the Official Gazette would appear, thus revealing that this person had committed a crime about thirty years ago.</p>
<p>In 2009, he filed a complaint against Google Spain SL before the Spanish Data Protection Authority (DPA). The DPA <a href=""http://www.agpd.es/portalwebAGPD/resoluciones/tutela_derechos/tutela_derechos_2010/common/pdfs/TD-00921-2009_Resolucion-de-fecha-19-01-2010_Art-ii-culo-6.4-LOPD_Recurrida.pdf"">ordered</a> Google Spain SL to adopt the measures necessary to withdraw the data from its index and to prevent access to the data in the future. Like in many other similar cases – including the Costeja’s case – Google appealed this decision to the Audiencia Nacional, where it is still pending.</p>
<p>On March 22, 2011, long before the CJEU rendered the <em>Google Spain</em> ruling, the plaintiff brought also a civil lawsuit asking for damages. This is the case now decided by the Barcelona Court of Appeals. The complaint asked for the removal of the links, and for damages. However, at an initial stage of the proceedings, the plaintiff acknowledged that the contested links had already been removed, and thus only the claim for damages survived in the lawsuit.</p>
<p>Initially, the first instance court rejected the complaint, and the plaintiff appealed. On July 17, 2014 (albeit only recently reported), the court of appeals handed down its ruling granting the plaintiff’s claim and awarding damages, although dramatically reducing the exaggerated amount demanded. The court relied heavily on the CJEU <em>Google Spain</em> judgment and held that Google infringed the subject’s data protection rights by failing to remove the links when requested to do so. The plaintiff was awarded moral damages for the period of time the links were accessible.</p>
<p>The <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:31995L0046:en:HTML"">Data Protection Directive (95/46)</a> orders Member States to “provide that any person who has suffered damage as a result of an unlawful processing operation or of any act incompatible with the national provisions adopted pursuant to this Directive is entitled to receive compensation from the controller for the damage suffered.” This provision was transposed into <a href=""https://www.boe.es/buscar/act.php?id=BOE-A-1999-23750&tn=1&p=20110305&vd=#a19"">art. 19 of the Spanish Data Protection Law</a>, which is the basis for the complaint.</p>
<p>Google successfully claimed that the safe harbor for search engines (<a href=""https://www.boe.es/buscar/act.php?id=BOE-A-2002-13758&tn=1&p=20140510&vd=#a17"">art. 17 of the Law on Information Society Services</a>) applied to it. However, according to the court, Google lost the safe harbor when it obtained the actual knowledge of the offending links, at the time it knew about the DPA decision. While this claim for damages is independent from any administrative proceeding, the court came to the conclusion that Google was liable from the moment it was notified about the DPA decision, and up to the moment the links were removed – a time span of about ten months.</p>
<p>As noted, the defendant in this case was not Google Inc., but its Spanish subsidiary, Google Spain SL – along with some other entities. The court rejected the defendant’s contention that because the search engine is operated by Google Inc. – a different entity – Google Spain SL cannot be held liable.</p>
<p>The text of the ruling, which has been appealed before the Supreme Court, is available <a href=""http://www.poderjudicial.es/search/doAction?action=contentpdf&databasematch=AN&reference=7173091&links=08019370162014100388&optimize=20140929&publicinterface=true"">here</a> (in Spanish). Please note that the names of individual parties are anonymized. </p>
",Intermediary Liability,2014-10-14 1:29,678,Miquel Peguera,News
12551,,Argentina,0,0,Argentine Supreme Court Decides Landmark Intermediary Liability Case,General+Copyright,"<p>(with <a href=""https://cyberlaw.stanford.edu/users/paula-vargas"">Paula Vargas</a>)</p>
<p> </p>
<p>On October 29, the Argentine Supreme Court issued a landmark decision on intermediary liability in the case “<em><a href=""http://www.csjn.gov.ar/docus/documentos/verdoc.jsp"">R.M.B c/Google y ot. s/ Ds y Ps (Fallo R.522.XLIX.)</a></em>”. As reported in a <a href=""http://cyberlaw.stanford.edu/blog/2014/06/argentine-supreme-court-decide-whether-intermediaries-must-monitortake-down-search"">previous blog post</a>, the case discussed the question whether search engines are liable for linking in search results to third-party content that violates fundamental rights or infringes copyright. The decision was largely favorable to search engines. The Court (1) repudiated a strict liability standard and adopted a test based on actual knowledge and negligence; <span style=""line-height: 20.0063037872314px;"">(2) requested judicial review for issuing a notice to take down content (except in a few cases of ""gross and manifest harm""); </span><span style=""line-height: 1.538em;"">(3) rejected any filtering obligation to prevent infringing links from appearing in the future;  and, finally, (4) construed Google Image thumbnails as links and not Google’s own content.</span></p>
<p>The Court drew a bright line rule, which rejected a general obligation for search engines to monitor infringing content online and repudiated strict liability for intermediaries for torts derived from third-party content. In view of the Court, the application of a strict liability standard would have constituted an unreasonable burden to freedom of expression with serious chilling effects. Instead, the Court adopted a negligence rule, establishing that intermediaries would only be held liable if, after acquiring actual knowledge about a specific infringing content, they do not remove it promptly.</p>
<p>The Court decided that the appropriate mechanism to provide search engines with actual knowledge about third-party infringing content would be a notification from the affected party. In this case, the plaintiff never notified the defendants, Google and Yahoo, prior to the lawsuit. Therefore, the Court concluded that the search engines never acquired actual knowledge. As a result, they were not negligent for not removing the content nor liable for the third-party infringing content.</p>
<p>However<strong>, </strong>the Court did not require any counter-notice option for the uploader of the infringing content. The lack of counter-notice may be balanced by the fact that in most cases this notice and take down system will be judicially administered, rather than privately. Actually, the Court distinguished ostensible infringing content from other content. As the Court puts it, ostensible infringing content would be</p>
<p style=""margin-left:.5in;"">child pornography, data that might be useful to commit a crime, that might endanger people’s lives, that promotes genocide, racism or any other discriminatory or violent action, that might trump crime investigations, that are a serious offense to honor, obviously faked pictures, or any serious invasion to privacy, publishing images that because of its nature are intended to be private, even if not sexual.</p>
<p>In the case of ostensible infringing content, a private notification from any person, <em>not necessarily the affected party</em>, would suffice. For any other content, a court or other competent authority should decide on its illegality and issue a notification to the search engines if any is necessary.</p>
<p>Moreover, the Court rejected any proactive monitoring obligations for search engines, such as adopting a filtering mechanism in order to permanently block links to the infringing content and prevent them from appearing in the future. The Chief Justice, Dr. Lorenzetti, signed a partial dissent on this point. Dr. Lorenzetti authored the new Civil Code, which was recently enacted (and, therefore, has no bearing on this case) and adopted a so called “damaging prevention principle.” Accordingly, in Dr. Lorenzetti’s dissenting opinion, this means that, after a notification, search engines could be ordered to prevent the content to be republished online, if technology allows that and the injunction is sufficiently specific.</p>
<p>Finally, the Court rejected the claim that the reduction of images into thumbnails turns them into Google’s own content. Links to third-party images, even if reduced in size, still remain third-party content. The web pages hosting the unauthorized images should be held liable for that infringing content. Google will be liable only if, after receiving a notification, it fails to remove the thumbnails linking to the infringing images. The Court gives equal treatment to links to images and text, considering both as “mere links.”</p>
<p>In conclusion, this case gives some breathing space to search engines that have been bombarded with lawsuits in the last few years in Argentina. The Argentine Supreme Court introduced a very high standard for taking down infringing content online. Judicial review will be always needed to take down or de-index content, except in a few specifically enumerated cases of blatant illegality. The reaction of the Argentine Congress to this decision is still to be seen. For now, this is a major win for freedom of expression.</p>
",Intermediary Liability,2014-11-05 6:37,505,Giancarlo Frosio,News
12567,,International,1,1,September 2014 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p style=""line-height: 20.0063037872314px;"">September 2014 in Retrospect is available here:</p>
<p style=""line-height: 20.0063037872314px;""><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2014-september"">http://www.internetjurisdiction.net/observatory/retrospect/2014-september</a></p>
<p style=""line-height: 20.0063037872314px;"">Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"" style=""line-height: 1.538em;"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
",Intermediary Liability,2014-10-17 15:20,505,Giancarlo Frosio,News
12585,,International,1,1,October 2014 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p style=""line-height: 20.0063037872314px;"">October 2014 in Retrospect is available here:</p>
<p style=""line-height: 20.0063037872314px;""><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2014-october"">http://www.internetjurisdiction.net/observatory/retrospect/2014-october</a></p>
<p style=""line-height: 20.0063037872314px;"">Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"" style=""line-height: 1.538em;"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
",Intermediary Liability,2014-11-06 15:39,505,Giancarlo Frosio,News
12588,,United Kingdom,0,0,Cartier vs BSkyB: UK Judge Orders ISPs to Block Websites Infringing Trademarks for the First Time in Europe,Other IP,"<p>As <a href=""https://cyberlaw.stanford.edu/blog/2013/09/uk-high-court-orders-isps-block-ip-address-erroneously-takes-down-hundreds-sites"">reported</a>, UK courts issued over the last few year a series of orders requiring access providers to block access to websites infringing copyright pursuant to Section 97A of the UK Copyright Act. Recently, a UK court issued a similar blocking order in  <em>Cartier, Montblanc and Richemont v BSkyB, BT, TalkTalk, EE and Virgin (Open Rights Group intervening)</em> [2014] EWHC 3354 (Ch), a case involving an attempt to combat trademark infringement rather than copyright infringement. This was the first occasion in the European Union that a court ordered access providers to block access to a website for trademark infringement.</p>
<p>In this case, the owners of a large number of registered trademarks in the UK, such as Cartier, Montblanc, IWC and others, brought an action against the five main retail internet service providers in the UK. The claimants sought an order requiring the ISPs to block access to six websites which advertised and sold counterfeit goods and thereby infringed their trademarks.</p>
<p>Justice Arnold from the High Court of Justice of London granted the website-blocking order in an impressive 266 paragraphs decision. The decision largely draws from the principles applied by Justice Arnold himself in a series of previous judgments issuing blocking orders against website infringing copyright. Those orders were issued according to <a href=""http://www.legislation.gov.uk/ukpga/1988/48/section/97A"">Section 97A</a> of the Copyright Act, which implements <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:2001:167:0010:0019:EN:PDF"">Article 8(3)</a> of the Information Society Directive in the UK.</p>
<p>The Court noted that there is no statutory counterpart in the field of trademarks to sections 97A of the UK Copyright Act. However, the Court granted the injunction construing the Court's general jurisdiction to issue injunctions in the context of <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:32004L0048R(01):EN:HTML"">Article 11 of the Enforcement Directive</a>. Article 11 of the Enforcement Directive has a broader scope than Article 8(3) of the Information Society Directive and applies to intellectual property infringement at large, rather than only to copyright infringement:</p>
<p style=""margin-left:.5in;"">Member States shall also ensure that rightholders are in a position to apply for an injunction against intermediaries whose services are used by a third party to infringe an intellectual property right, without prejudice to Article 8(3) of Directive 2001/29/EC.</p>
<p>On the point of the application of Article 11 of the Enforcement Directive, Justice Arnold had to resolve first the question of the lack of specific implementation of that provision in the UK. At the time of the implementation the Enforcement Directive, the UK Government deemed not to be necessary a specific implementation of Article 11. In particular drawing on the decision of the European Court of Justice in <a href=""http://curia.europa.eu/juris/liste.jsf?language=en&num=C-324/09"">L'Oreal v eBay</a>, Justice Arnold concluded:</p>
<p style=""margin-left:.5in;"">even if the Court would not have power to grant a website blocking injunction in a trade mark case upon a purely domestic interpretation of <a href=""http://www.legislation.gov.uk/ukpga/1981/54/section/37"">section 37(1) [of the Supreme Court Act 1981]</a>, section 37(1) can and should be interpreted in compliance with the third sentence of Article 11 by virtue of the <a href=""http://curia.europa.eu/juris/liste.jsf?language=en&jur=C,T,F&num=106/89&td=ALL"">Marleasing</a> principle.  If it were otherwise, the UK would be in breach of its obligations under the Directive. (Par. 132)</p>
<p>The order finally approved by the Court included also a number of safeguards against abuse. A first set of safeguards concerned the possibility of discharging or varying the order by different interested parties. First, access providers may apply to the Court to discharge or vary the orders in the event of any material change of circumstances, including in respect of the costs, consequences for the parties and effectiveness of the blocking measures from time to time. Second, the operators of the target websites may apply to the Court to discharge or vary the orders. Third, the order should expressly permit affected subscribers to apply to the Court to discharge or vary the orders. In this regard, the page displayed to users who attempt to access blocked websites should also identify the party or parties which obtained the order and state that affected users have the right to apply to the Court to discharge or vary the order.</p>
<p>Finally, Justice Arnold noted that website blocking orders should not endure longer than necessary. Concerned about the number of websites that trade mark owners may seek to target, the Court incorporated a “sunset clause” into the orders. According to this clause, the orders will cease to have effect at the end of a defined period unless either (1) the ISPs consent to the orders being continued or (2) the Court orders that they should be continued. The provisional view of the Court was that the sunset period should be two years. This is a considerable departure from previous blocking orders made by UK Courts, which have all been open-ended, although they may have been discharged or varied in the event of a change of circumstances.</p>
<p>The full judgment is available <a href=""http://www.bailii.org/cgi-bin/markup.cgi?doc=/ew/cases/EWHC/Ch/2003/3354.html&query=Cartier&method=boolean"">here</a>.</p>
",Intermediary Liability,2014-11-07 19:28,505,Giancarlo Frosio,News
12656,European Union,,0,0,EU Data Protection Authority Adopts Guidelines on the Implementation of the Right to be Forgotten,Privacy or Data Protection+Right to Be Forgotten+Freedom of Expression,"<p>On November 26, 2014, the European data protection authorities (DPAs) assembled in the <a href=""http://ec.europa.eu/justice/data-protection/article-29/index_en.htm"">Article 29 Working Party (WP29)</a> adopted guidelines on the implementation of the judgment of the European Court of Justice (ECJ) on the right to be forgotten. These guidelines contain the common interpretation of the ECJ’s ruling. They also include the common criteria to be used by the national DPAs when addressing complaints.</p>
<p>The guidelines clarified several points addressed by the <a href=""https://cyberlaw.stanford.edu/blog/2014/05/internet-search-engines-are-liable-processing-personal-data-says-ecj"">Google Spain v Costeja</a> ruling.</p>
<p>(<strong>1</strong>) <strong>Search engines qualify as data controllers</strong> under Directive 95/46/EC to a search engine insofar as (<strong>a</strong>) the processing of personal data is carried out in the context of the activities of a subsidiary on the territory of a Member State, (<strong>b</strong>) set up to promote and sell advertising space on its search engine in this Member State with the aim of making that service profitable. In this case, the processing of data by search engines, “must be distinguished from, and is additional to that carried out by publishers of third-party websites.”</p>
<p>(<strong>2</strong>) A <strong>fair balance between fundamental rights</strong> and interests <strong>may lead to a</strong> <strong>limited impact of de-listing on the access to information</strong>. (<strong>a</strong>) As the ECJ originally states, “the rights of the data subject prevail, as a general rule, over the economic interest of the search engine and that of internet users to have access to the personal information through the search engine.” (<strong>b</strong>) However, a balance must be made between the nature and sensitivity of the data and the interest of the public to have access to that information. (<strong>c</strong>) If the data subject plays a role in public life, the interest of the public will be significantly greater. (<strong>d</strong>) Therefore, the guidelines concluded, the impact of de-listing on individual’s rights to freedom of expression and access to information will be very limited. When DPAs assess the relevant circumstances, de-listing will not be appropriate, if the interest of the public overrides the rights of the data subject.</p>
<p>(<strong>3</strong>) The <strong>original information will always remain accessible</strong> and no information is deleted from the original source. The right only affects the results obtained from searches made on the basis of a person’s name. That is, the original information will still be accessible using other search terms, or by direct access to the source.</p>
<p>(<strong>4</strong>) <strong>Data subjects</strong> seeking the de-listing of information do <strong>not have an obligation to contact the original website</strong> in order to exercise their rights towards the search engines. Likewise, <strong>search engines do not have a legal obligation to inform the webmasters on the delisting</strong> of specific links. However, the guidelines strongly encourage the search engines to provide the delisting criteria they use, and to make more detailed statistics available.</p>
<p>(<strong>5</strong>) As per the <strong>data subjects’ entitlement to request delisting</strong>, the guidelines stated that “DPAs will focus on claims where there is a clear link between the data subject and the EU, for instance where the data subject is a citizen or resident of an EU Member State.” This statement has the effect of narrowing down the application of the ECJ’s ruling in light of the general principle that, under EU law, everyone has a right to data protection.</p>
<p>(<strong>6</strong>) On the <strong>territorial effect of de-listing decisions</strong>, the guidelines noted that limiting de-listing to EU domains cannot be considered a sufficient means to satisfactorily guarantee the rights of data subjects according to the ruling. In practice, ""this means that in any case <em>de-listing should also be effective on all relevant .com domains</em>."" (emphasis added)</p>
<p>The guidelines also contain <strong>13 main criteria which the national DPAs will apply to handle the complaints</strong> filed with their offices following refusals of de-listing by search engines. Criteria will be applied on a case by case basis, and each criteria has to be read in the light of the “the interest of the general public in having access to [the] information”.</p>
<p>According to these criteria, DPAs must investigate whether</p>
<p>(<strong>1</strong>) the search results relate to an individual and come up against a search on the data subject name, including pseudonyms and nicknames;</p>
<p>(<strong>2</strong>) the data subject play a role in public life, or is a public figure, and there is an interest of the public in having access to information about them;</p>
<p>(<strong>3</strong>) the data subject is a minor (which clearly makes the DPAs more likely to require the de-listing of the results);</p>
<p>(<strong>4</strong>) the data is accurate;</p>
<p>(<strong>5</strong>) the data is relevant and not excessive and (<strong>a</strong>) relate to the working life of the data subject, (<strong>b</strong>) the search results link to information which allegedly constitutes hate/speech/slander/libel or similar offences against the complainant, and (<strong>c</strong>) is clear that the data reflect an individual’s personal opinion or it appears to be verified fact;</p>
<p>(<strong>6</strong>) the information is sensitive according to Article 8 of the Data Protection Directive, such information about a person’s health, sexuality or religious beliefs;</p>
<p>(<strong>7</strong>) the data is up to date or made available for longer than is necessary for the purpose of the processing;</p>
<p>(<strong>8</strong>) the data processing is causing prejudice to the data subject and has a disproportionately negative privacy impact on the data subject;</p>
<p>(<strong>9</strong>) the search results links to information that can leave the data subjects open to risks, such as identity theft or stalking, for example;</p>
<p>(<strong>10</strong>) the data subject (<strong>a</strong>) voluntarily made public the content or (<strong>b</strong>) could have reasonably known that the content would have been made public or (<strong>c</strong>) the content was intended to be made public at all;</p>
<p>(<strong>11</strong>) the original content was published in the context of journalistic purposes, although this criterion alone does not provide a sufficient basis for refusing a request;</p>
<p>(<strong>12</strong>) the publisher of the data has a legal power or obligation to make the personal data publicly available;</p>
<p>(<strong>13</strong>) the data relate to a criminal offence, which should be handled by DPAs according to national approaches to the public availability of information about offenders, although “as a rule, DPAs are more likely to consider the de-listing of search results relating to relatively minor offences that happened a long time ago, whilst being less likely to consider the de-listing of results relating to more serious ones that happened more recently.”</p>
<p>The guidelines provide a number of specific suggestions for the DPAs to interpret and properly balance each criterion (pp. 13-19). The WP29 guidelines are available <a href=""http://ec.europa.eu/justice/data-protection/article-29/documentation/opinion-recommendation/files/2014/wp225_en.pdf"">here</a>. The WP29 press release can be found <a href=""http://ec.europa.eu/justice/data-protection/article-29/press-material/press-release/art29_press_material/20141126_wp29_press_release_ecj_de-listing.pdf"">here</a>.</p>
",Intermediary Liability,2014-11-28 5:30,505,Giancarlo Frosio,News
12662,,France,0,0,France: DailyMotion Pays Damages for Late Removal of Infringing Materials,General+Other IP,"<div>Recently, the Paris Court of Appeals handed down a decision awarding €1.3M in damages to the French commercial TV broadcaster TF1 against <a href=""http://www.dailymotion.com/"">DailyMotion</a>, which failed its duty of promptly removing infringing materials from its platform. However, the Court stated that DailyMotion enjoys limitation of liability as a hosting provider and is not required to proactively monitor users' infringing activities.</div>
<div> </div>
<div>
<div>Likewise the lawsuit Viacom v. YouTube in the U.S., TF1 engaged DailyMotion in a longlasting legal battle in France. TF1 started proceedings in 2007 against DailyMotion after finding available on the video-sharing platform content included in TF1's catalog. The infringing materials ranged from episodes of Heroes, Martin Scorsese's The Departed, to other satirical and political shows broadcasted by TF1.</div>
<div> </div>
<div>The Court awarded the damages for failure of DailyMotion to act promptly upon notification to remove the infringing content. For the judges, these delays ""constitute unfair and parasitic competition, which is a misconduct triggering civil responsibility."" </div>
<div> </div>
<div>However, the Court found that DailyMotion was entitled to the safe harbor protection as a hosting provider and rejected TF1'argument that video sharing platform was the publisher of the content posted by users.</div>
<div> </div>
<div>Additionally, the Court rejected the proactive filtering obligations that TF1 and others requested to impose on DailyMotion. The plaintiffs demanded to remove all content featuring their logos. The Paris Court noted that ""[French law] does not impose on the hosting provider a general obligation to monitor the information it transmits or stores, or a general duty of care and proactive filtering, therefore there is no reason to grant requests for removal of all content including TF1 and/or LCI logos, and for the establishment of a system for proactively filtering online content posted on this site."" However, the court upheld a measure, which was already ordered by the judges in 2012. DailyMotion must exclude ""TF1"" and ""LCI"" from the site's keyword search since these terms provide ""easy access to programs produced by these two companies and illegally made available online.""</div>
</div>
<div> </div>
<div>The full decision in French is available <a href=""http://static.pcinpact.com/medias/ardailymotion021214.pdf"">here</a>.</div>
",Intermediary Liability,2014-12-08 0:55,505,Giancarlo Frosio,News
12663,,France,0,0,French High Court Orders to Block The Pirate Bay,Copyright,"<div>A few days ago, France joined the <a href=""http://en.wikipedia.org/wiki/Countries_blocking_access_to_The_Pirate_Bay"">list of countries</a> blocking access to The Pirate Bay. The High Court of Paris ordered ISPs to “implement all necessary measures to prevent access from the French territory to the music file-sharing site the Pirate Bay and its redirection sites and mirror sites.”</div>
<div> </div>
<div>The French Court, which clearly sees The Pirate Bay just as a music file-sharing site, acted upon a claim of the Société Civile des Producteurs Phonographiques [Civil Society of Phonogram Producers] (SCPP).</div>
<div> </div>
<div>The blocking order was issued on the basis of <a href=""http://www.legifrance.gouv.fr/affichCodeArticle.do;jsessionid=99E090F66E1063B039AFC4319EBAB768.tpdjo15v_1?idArticle=LEGIARTI000020740350&cidTexte=LEGITEXT000006069414&dateTexte=20141209"">Article L336-</a><a href=""http://www.legifrance.gouv.fr/affichCodeArticle.do;jsessionid=99E090F66E1063B039AFC4319EBAB768.tpdjo15v_1?idArticle=LEGIARTI000020740350&cidTexte=LEGITEXT000006069414&dateTexte=20141209"">2 of the French Code of Intellectual Property</a>. The article implements <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:2001:167:0010:0019:EN:PDF"" style=""line-height: 1.538em;"">Article 8(3) of the EU Information Society Directive</a> by providing that “in the presence of an infringement of a copyright or related right caused by the content of a public online communication service, the high court [ . . . ] may order at the request of rights holders [ . . . ] all appropriate measures to prevent or stop such infringement of a copyright or related right, against anyone who might help to find a remedy to the infringement.”</div>
<div> </div>
<div>To enhance its effectiveness, the order covers also a list of specifically enumerated redirection sites, mirror site, and proxies.</div>
<div> </div>
<div>The full decision in French is available <a href=""https://www.scribd.com/document_downloads/249239785?extension=pdf&from=embed&source=embed"">here</a>.</div>
<div> </div>
",Intermediary Liability,2014-12-09 14:22,505,Giancarlo Frosio,News
12677,,International,1,1,November 2014 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p style=""line-height: 20.0063037872314px;"">November 2014 in Retrospect is available here:</p>
<p style=""line-height: 20.0063037872314px;""><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2014-november"">http://www.internetjurisdiction.net/observatory/retrospect/2014-november</a></p>
<p style=""line-height: 20.0063037872314px;"">Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"" style=""line-height: 1.538em;"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
",Intermediary Liability,2014-12-16 17:42,505,Giancarlo Frosio,News
12694,,United States,0,0,The Sony Hack: A Warning for Internet Policy,Other,"<p>The Sony incident reminds us again about the fragile yet constantly shifting state of cybersecurity and Internet policy.  Clearly the international political <a href=""http://www.globalresearch.ca/us-strategic-negligence-north-korea-and-the-sony-sideshow/5421938"">ramifications</a> of this incident, who <a href=""https://www.schneier.com/blog/archives/2014/12/more_data_on_at.html"">actually</a> did it, and Sony's potential <a href=""http://www.thewrap.com/sony-slapped-with-lawsuit-by-former-employees-over-hack-attack/"">culpability</a> remain unknown. However, the purpose of this commentary is not to dwell on such issues since there is far too much being generated about them already - most of it is nothing more than wasteful, wishful, or boastful speculation that changes on a daily basis anyway.  Frankly, I am less concerned about the possible immediate '<a href=""http://www.nytimes.com/2014/12/20/world/fbi-accuses-north-korean-government-in-cyberattack-on-sony-pictures.html"">responses</a>' to this incident (now including <a href=""http://www.bloomberg.com/news/2015-01-02/u-s-slaps-new-sanctions-on-n-korea-in-response-to-sony-hack.html"">sanctions </a>of questionable purpose and effect) than how it may be exploited to influence future Internet policy discussions and technology more broadly.</p>
<p>For decades, the entertainment industry has long been a major influence in the development of technology policy around the world, particularly as it relates to products and services that facilitate the creation and distribution of what it deems 'content' -- movies, music, and other forms of intellectual property.  From the VCR to computers, from FM music radio to Spotify, from the iPod to Pandora, and from radio to television to cable and the Internet as delivery mechanisms, the entertainment industry's always sought to ensure its business interests were protected during periods of technological innovation and social evolution (think of digital rights management (DRM) for starters.)  All of which, we are told, is to support the industry's goal of crafting compelling and dramatic narratives that can be packaged, sold, streamed, and licensed to capture the hearts and minds of audiences around the world -- but only on <a href=""http://orrentfreak.com/netflix-cracks-down-on-vpn-and-proxy-pirates-150103/"">terms</a> that it approves.</p>
<p>Unfortunately, the industry (i.e., ""Hollywood"") has a history of using these same techniques to craft its own version of reality when defending its business practices, legitimacy, and alleged vulnerability to technological change.</p>
<p>In doing so, Hollywood plays fast-and-loose with facts allegedly portraying reality in order to gain the support of legislators and regulators to expand its generally self-serving policy agenda in order to preserve its role in society. For example, between 2005-2011, despite record-breaking box office and video sales metrics, the industry frequently claimed significant losses due to piracy -- yet those figures were proven subject to broad interpretation, challenged by insiders as 'fantasy' or <a href=""http://www.counterpunch.org/2012/01/24/how-hollywoods-own-reality-undermines-its-position-on-internet-policy/"">deemed</a> 'meaningless' by government regulators, researchers, and think-tanks.  If that's not evidence enough, the Sony incident <a href=""https://www.techdirt.com/articles/20141224/06321429517/sony-hack-reveals-that-mpaas-big-80-million-settlement-with-hotfile-was-lie.shtml"">revealed</a> that Hollywood's much-hyped $80 million settlement with Hotfile in 2013 was only $4 million -- but the industry kept repeating the larger bogus number in public statements anyway. Moreover, the leak also <a href=""http://gizmodo.com/leaked-slides-reveal-hollywoods-blind-google-fiber-fear-1676100540"">shows</a> the entertainment industry's ongoing paranoid reaction to new technologies such as Google Fiber's blazingly-fast internet access because since such access, would, it believes, lead to significant losses due to those connections being used for illegal infringement and piracy. Whether concocting its own facts or automatically presuming its worst-case existential fears already are an absolute truth, Hollywood routinely uses such antics in its efforts to influence (or control) Internet policy and global technology use generally.</p>
<p>As the saying goes, if you repeat something often enough it will become common belief until proven otherwise.  But I'm also reminded of the late Senator Daniel Patrick Moynihan's admonition that although one is entitled to their own opinion, they are not entitled to ""their own facts.""  </p>
<p>That being said .... the cybersecurity and diplomatic ramifications of the Sony incident, important as they may be in the short-term (and making a compelling media-friendly storyline!) should be less worrisome to society than the very real potential of the entertainment industry cartels transforming this incident into a semi-fictional narrative arguing for expanded controls over technology and the Internet under the guise of ""preventing future [cybersecurity] incidents"" along the lines of its failed - and quite controversial - SOPA and PIPA proposals from 2012.</p>
<p>Should -- I mean, when, that happens, <em>anything the entertainment industry presents to the public about this incident used to support their legislative lobbying efforts for greater cybersecurity or intellectual property protections should be taken with a healthy dose of skepticism</em>. By extension, legislators and pundits must not simply accept such information on face value, either. (Don't hold your breath!)</p>
<p>Looking ahead in 2015, I expect to see another round of Internet-centric intellectual property protection proposals hitting Washington given the more pro-business, pro-Hollywood majority soon controlling Congress. However, to ease any initial public outcry (a lesson learned from SOPA or CISPA) I believe such proposals will be framed as part of a larger legislative package of 'cybersecurity' measures and marketed with the usual feel-good bromides of ensuring national security, economic competiveness and jobs, preventing terrorism, and of course, ""<a href=""https://www.youtube.com/watch?v=Qh2sWSVRrmo"">protecting the children</a>.""  As such, I predict seeing renewed desires to: eliminate ""safe harbor"" protections for Internet providers, modify the proper functioning of the Internet, and allow companies to digitally 'strike back' against alleged attackers or other cyber-miscreants, among other broadly-worded fantasies lurking on Hollywood's legislative wishlist.  Accompanied, of course, by the traditional tone-deafness the entertainment industry and its supporters display when challenged by intelligent questions arising over the effacay or viability of their ideas.</p>
<p>To be clear: I am completely supportive of meaningful cybersecurity policies and practices by organizations and industries to protect proprietary or sensitive information. However, I am vehemently opposed to using cybersecurity measures to infringe upon online privacy, the legal flow of information and expression, the safe functioning of the Internet, or as the means of protecting an intractable industry's outdated business model. Moreover, I am troubled by the ongoing desire by organizations to assume a victim mentality that prefers pointing fingers at others when incidents occur, even if they are partially (or fully) to blame for the event themselves -- but that's a topic for a different day. </p>
<p>The ultimate causes and consequences of the Sony incident remain unknown. However, as citizens of the Internet and global society, we must remain alert to any attempt by the entertainment industry to exploit this high-profile incident to broaden its already excessive influence and control over Internet policy, technology, and global information flows.</p>
<p>In other words, Hollywood's expertise in crafting fictional narratives must not continue to influence the evolution of reality-based outcomes.</p>
<p>And may I simply add:  FIRST POST 2015! ;)</p>
","Architecture and Public Policy, Copyright and Fair Use",2015-01-02 9:46,416,Richard Forno,News
12719,,Germany,0,0,The Reception of Google Spain v Costeja in Germany: Obedience and Disobedience,Privacy or Data Protection+Right to Be Forgotten+Freedom of Expression,"<div>National courts continue to try to interpret what the European Court of Justice's (ECJ) <em>Google Spain v Costeja</em> (Right to Be Forgotten) ruling means. On December 9, 2014, the District Court of Heidelberg (Germany) had to decide whether Google had to remove links to a web page which claimed to “expose” racists, i.e. the plaintiffs. The Court ordered Google to remove the links and awarded damages for the company's failure to remove the links promptly upon notification. The Court specifically referred to the ECJ ruling in its reasoning. In a different case, on November 7, 2014, the District Court of Hamburg had similarly ordered Google to remove search results which suggested that the plaintiff had owned a brothel.</div>
<div> </div>
<div>These rulings have ignited heated debate. <a href=""http://www.bundesverfassungsgericht.de/EN/Richter/Erster-Senat/BVR-Prof-Dr-Masing/bvr-prof-dr-masing_node.html;jsessionid=13274FFE21FA578129D3B1D4AA02829B.2_cid370"">Prof. Johannes Masing</a>, Justice of the German Federal Constitutional Court (Bundesverfassungsgericht) and rapporteur for all media related cases, has published his thoughts in <a href=""http://www.verfassungsblog.de/en/ribverfg-masing-vorlaeufige-einschaetzung-der-google-entscheidung-des-eugh/#.VLRgNivF9EJ"">Germany’s leading law blog</a>. The blog post is based on a <a href=""http://www.verfassungsblog.de/ribverfg-masing-vorlaeufige-einschaetzung-der-google-entscheidung-des-eugh/#.VJ_bOf_AA"">note </a>which had been originally intended for internal use at the Court. Masing expresses “serious concerns” about the ECJ’s emphasis on extended intermediary liability and makes clear that he disagrees with the ECJ’s finding that the right to be forgotten “override[s], as a rule, not only the economic interest of the operator of the search engine but also the interest of the general public.” Furthermore, he says that settled caselaw in the German Constitutional Court establishes “the presumption in favor of the permissibility of freedom of speech”. Information that has been lawfully published by third parties enjoys exceptional constitutional protection. That precedent would demand the opposite result in both these ""right to be forgotten"" cases.   </div>
<div> </div>
<div>Nevertheless, Masing does not say how exactly the German Constitutional Court could navigate between the ECJ ruling and German law. Even though he recognizes the superiority of European Union law, he indicates that he favors some kind of “concurrent protection of fundamental rights” that would establish a leeway for national courts. Indeed, Masing will have the opportunity to clarify his view on these points in a <a href=""http://www.dgri.eu/index.php/fuseaction/download/lrn_file/dgri_stellungnahme_apollonia-fall-exec-.pdf"">case</a><a href=""http://www.dgri.eu/index.php/fuseaction/download/lrn_file/dgri_stellungnahme_apollonia-fall-exec-.pdf""> regarding online archives</a> (file number “1 BvR 16/13”), which is pending before the Constitutional Court and Masing will decide as part of the judging panel. </div>
",Intermediary Liability,2015-01-12 16:07,1057,Alexander Milstein,News
12742,,International,1,1,December 2014 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p style=""line-height: 20.0063037872314px;"">December 2014 in Retrospect is available here:</p>
<p style=""line-height: 20.0063037872314px;""><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2014-december"">http://www.internetjurisdiction.net/observatory/retrospect/2014-december</a></p>
<p style=""line-height: 20.0063037872314px;"">Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"" style=""line-height: 1.538em;"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
",Intermediary Liability,2015-01-26 7:48,505,Giancarlo Frosio,News
12743,,Italy,0,0,Italian Court Decides an Important Case on Liability of Video-sharing Platforms,Copyright,"<div>A few days ago, an important Italian judicial precedent on hosting providers’ liability has been overturned by the Milan Court of Appeal. The appellate court rejected any general monitoring obligations to be imposed on videosharing hosting providers for copyright infringement. </div>
<div> </div>
<div>In <em style=""line-height: 1.538em;"">Reti Televisive Italiane S.p.A. (RTI) v. Yahoo! Italia S.r.l. (Yahoo!) et al.</em>, decided on September 9, 2011, the Court of Milan found Yahoo! liable for copyright infringement. Infringement supposedly occurred with the publication of fragments of television programs through the now-terminated Yahoo! Video service. The Court stated that the hosting safe harbor of the E-Commerce Directive could not be applied where the service is not a mere passive hosting of users' data, but is instead an ""active hosting"".</div>
<div> </div>
<div>The Court of Appeal has now reversed that earlier decision. The appellate decision clarified that RTI had the obligation to indicate in a ""detailed, precise and specific manner"" the videos that Yahoo! had to remove. Additionally, in view of the Court of Appeal, the court of first instance did not have the power to ""impose to a hosting provider general orders or, even worse, general monitoring obligations, which are forbidden by Directive 2000/31/EC."" Intermediary liability may arise only if the hosting provider does not act promptly upon a ""detailed, precise and specific"" notice. Actually, RTI never sent this notice to Yahoo!, therefore the appellate court found in favor of Yahoo! and rejected RTI's claims.</div>
<div> </div>
<div>RTI, a Mediaset company, will most likely take this case before the Italian Supreme Court. Meanwhile, several other cases brought by Mediaset against video-sharing platforms, including Google, are still pending. For example, another recent decision of the Court of Turin took an opposite view from that of the Milan Court of Appeal. The Court of Turin stated that any hosting providers, whether active or passive, have an obligation to prevent the repetition of further infringements once they have actual knowledge of the infringement, according to the principle <em style=""line-height: 1.538em;"">cuius commoda, eius et </em><em>incommoda </em>(""a party enjoying the benefits [of an activity] should bear also the inconveniences""). This civil law principle refers to a form of extra-contractual (or tort) liability for which whoever benefits from a certain activity should be liable for any damages that that activity may cause. Similar principles have been applied also by the the Brazilian Supreme Court in a recent case dealing with infringement occurring on YouTube, as we reported <a href=""https://cyberlaw.stanford.edu/blog/2014/01/brazilian-supreme-court-found-google-liable-videos-parodying-dafra%E2%80%99s-commercials"">here</a>. Standing this confuse judicial framework, a decision of the Italian Supreme Court on this matter is certainly welcome.</div>
<div> </div>
<div>The text of the decision of the Milan Court of Appeal is available <a href=""http://www.scribd.com/doc/253854923/Yahoo-RTI-CA-Milano-Sentenza-7-1-2015#scribd"">here</a> (Italian only). We will update you as soon as new developments will occur.</div>
<div> </div>
<div> </div>
<div><em><a href=""http://www.bakermckenzie.com/ourpeople/?attorney=6f5f05cd-4b8a-40fe-a32f-d8c221e2b710"">Saverio Ligi</a> in an attorney with Baker & Mckenzie in Rome.</em></div>
",Intermediary Liability,2015-01-27 5:04,505,Giancarlo Frosio,News
12744,,Spain,0,0,Spanish Copyright Reform Enters into Force: Special Focus on Online Intermediaries,Copyright,"<div>At the beginning of January, most of the controversial reform of the Spanish Copyright Act entered into force. As it has been widely publicised, the reform has introduced a compulsory levy for news aggregators, also known as “Google tax”. It has also strengthened the enforcement provisions by (<strong>i</strong>) giving more powers to the Copyright Commission – an administrative body which can order injunctions against internet service providers who infringe on copyright –; (<strong>ii</strong>) providing that ISP could be obliged in some situations to reveal the identity of a subscriber who allegedly engages in copyright infringement; and (<strong>iii</strong>) introducing for the first time the doctrines of secondary liability – inducement, contributory and vicarious liability – in the Copyright Act. Along with these amendments, other relevant changes in the law affect the private copy exception and its economic compensation, and the regulation of copyright collecting societies.</div>
<div> </div>
<div>The ‘Google Tax’ is by far the most controversial provision (<a href=""https://www.boe.es/buscar/act.php?id=BOE-A-1996-8930&tn=1&p=20141105&vd=#a32"">Art. 32(2)</a>). It refers to the aggregation of non-significant fragments of informative or entertainment contents already published in periodicals or websites. The making available of those fragments – meaning probably headlines and snippets – by online aggregators will not require authorization by the publisher. However, the publisher will have the right to receive an economic compensation. This publisher’s right cannot be waived, and must be managed by a collecting society. In contrast, the making available of images will need authorization. On the other hand, search engines which merely provide links to the stories based on search queries will not be subject to the levy. As a consequence of this provision, Google decided to <a href=""http://googlepolicyeurope.blogspot.co.uk/2014/12/an-update-on-google-news-in-spain.html"">terminate its Google News service </a>in Spain. The levy, however, will need secondary legislation to be practically implemented. </div>
<div> </div>
<div>The reform grants more enforcement powers to the Copyright Commission (<a href=""https://www.boe.es/buscar/act.php?id=BOE-A-1996-8930&tn=1&p=20141105&vd=#a158ter"">Art. 158 ter</a>). The Commission will target in particular websites which provide links to infringing works in a purposeful and massive way. Under the new enforcement powers, the Commission may require advertising, payment, and access service providers to stop providing their services to copyright infringers. </div>
<div> </div>
<div>Additionally, the reform amended the Civil Procedure Act (<a href=""https://www.boe.es/buscar/act.php?id=BOE-A-2000-323&tn=1&p=20141105&vd=#a256"" style=""line-height: 20.0063037872314px;"">Art. 256(11)</a>) to provide rightholders with a new enforcement tool.  This provision allows rightholders to apply for a court order forcing ISPs to disclose the identity of subscribers allegedly infringing copyright. In 2012, the European Court of Justice (ECJ) decided the <a href=""http://curia.europa.eu/juris/liste.jsf?language=en&jur=C,T,F&num=c-461/10&td=ALL"">Bonnier Audio</a> case, which may have influnced this specific portion of the reform. In <em>Bonnier Audio</em>, the ECJ upheld national legislation providing for such a disclosure as long as it enables the national court “to weigh the conflicting interests involved, on the basis of the facts of each case and taking due account of the requirements of the principle of proportionality”.</div>
<div> </div>
<div>Finally, the amendment introduces the notion of secondary liability for copyright infringement (<a href=""https://www.boe.es/buscar/act.php?id=BOE-A-1996-8930&tn=1&p=20141105&vd=#a138"">Art. 138</a>) into the Spanish legal system. So far, the Copyright Act – as generally understood by courts – covered only direct infringements. The new provision imposes liability on anyone who either </div>
<ol><li>knowingly induces the infringement, or </li>
<li>knowing or having reason to know about the infringement cooperates to it, or</li>
<li>having a direct economic interest in the results of the infringement has the ability to control the infringer’s conduct.</li>
</ol><div>It remains to be seen how the courts will actually apply these principles, which are inspired to a large extent by the US doctrine of secondary liability for copyright infringement. This liability will not accrue where the intermediary is sheltered by  the <a href=""https://cyberlaw.stanford.edu/page/wilmap-european-union"">eCommerce Directive</a> mere conduit, caching, and hosting exemptions.</div>
<div> </div>
<div>The text of the amending Act may be found <a href=""https://www.boe.es/diario_boe/txt.php?id=BOE-A-2014-11404"">here </a>(in Spanish). A consolidated text of the Copyright Act reflecting the new amendments can be found <a href=""https://www.boe.es/buscar/act.php?id=BOE-A-1996-8930"">here </a>(in Spanish). </div>
<div> </div>
",Intermediary Liability,2015-01-27 12:30,678,Miquel Peguera,News
12746,,Italy,0,0,AGCOM Regulation Challenged before the Italian Constitutional Court: an Update,Copyright,"<p>As we reported <a href=""https://cyberlaw.stanford.edu/blog/2014/09/italian-constitutional-court-decide-whether-administrative-enforcement-online-copyright"" style=""line-height: 20.0063037872314px;"">here</a>, the Regional Administrative Tribunal of Lazio (TAR Lazio) referred the question of constitutionality of the AGCOM Regulation regarding Online Copyright Enforcement (AGCOM Regulation) to the Italian Constitutional Court. The Regulation empowers the Italian Communication Authority (AGCOM) to administratively enforce copyright infringement by ordering online intermediaries to block allegedly infringing websites. The case before the Italian Constitutional Court will be the first constitutional test for an administrative copyright enforcement scheme.  </p>
<p>The decision of the Italian Constitutional Court may take up to two years. Meanwhile, we managed to get a copy of the referral and thought of interest to share a summary in English of the ordinance with you. Actually, in referring the case to the Constitutional Court, the administrative court made some preliminary findings along the way. Below you find a break-down of the key points of the court's reasoning. </p>
<p>(<strong>1</strong>) The associations for the defense of freedom of information as well as those representing web-tv, micro web-tv, micromedia hyperlocal, blogs and video blogs, information portals, aggregators and video companies active in the online press are entitled to challenge the AGCOM Regulation. </p>
<p>(<strong>2</strong>) The AGCOM Regulation does not primarily enforce copyright but instead any failure to comply with an order of the Authority. Therefore, such an order cannot be considered illegitimate for (<strong>a</strong>) AGCOM's incompetence to introduce a para-judicial procedure to enforce copyright or (<strong style=""line-height: 20.0063037872314px;"">b</strong>) inconsistency between this procedure and the rules of law which entrust to the ordinary courts the enforcement of copyright, or even, for (<strong>c</strong>) breach of the principle of the <a href=""http://www.refworld.org/pdfid/4a7837af2.pdf"">""natural judge""</a> in so far as judicial review of AGCOM measures is done by the administrative judge, rather than civil or criminal. </p>
<p>(<strong>3</strong>) The AGCOM Regulation does not violate EU or national law in so far as it provides that its measures are directed only to hosting and access providers and not to uploaders and website operators. This is because EU and national law provide that ISPs may be subject to supervisory authorities' measures aimed at limiting the negative externalities of their activities (see <a href=""https://cyberlaw.stanford.edu/page/wilmap-european-union"">Art. 8(3), Dir. 2001/29/EC</a> and <a href=""https://cyberlaw.stanford.edu/page/wilmap-european-union"">Art. 11, Dir. 2004/48/EC</a>). </p>
<p>(<strong>4</strong>) The AGCOM Regulation does not violate the adversarial principle in so far as it provides a very short deadline for the submission of counter-arguments. Actually, this principle governs criminal and civil proceedings, and possibly administrative proceedings of contentious nature. It does not apply to purely administrative proceedings, which are governed by the principle of ""participation in the proceedings"", which can be limited for reasons of urgency that the authority may identify. </p>
<p>(<strong>5</strong>) However, the question of the constitutionality of Articles 5(1), 14(3), 15(2), and 16(3), Legislative Decree 70/2003 and Article 32bis(3), Legislative Decree 177/2005, on the basis of which the AGCOM Regulation was adopted,  ""is not manifestly unfounded."" Those provisions may infringe on (<strong style=""line-height: 20.0063037872314px;"">a</strong>) the principles of ""statutory reserve"" and judicial protection provided in defense of freedom of expression and economic initiative, as well as (<strong>b</strong>) the criteria of reasonableness and proportionality in the exercise of legislative discretion and (<strong>c</strong>) the principle of the natural judge, because of the lack of legal guarantees and judicial safeguards for the exercise of freedom of expression online, at least equivalent to those laid down for the press. </p>
<p>The full text of the decision can be found <a href=""https://cyberlaw.stanford.edu/files/blogs/Tar%20lazio%20ord.anso_.pdf"">here </a>and <a href=""http://www.neldiritto.it/appgiurisprudenza.asp?id=10792#.VNDYG514r_l"">here </a>(Italian only).</p>
<p> </p>
<p> </p>
<p> </p>
",Intermediary Liability,2015-02-03 4:30,505,Giancarlo Frosio,News
12747,,Turkey,0,0,Intermediary Liability Updates from Turkey: Forcing Online Intermediaries to Create a Website Blocking-Friendly Infrastructure,General,"<p>Turkish governmental control of web traffic is on the rise. Recently, the Information Technology and Communications Authority (the ""ITC Authority"") updated the Authorization Regulation in the Electronic Communications Sector (“Authorization Regulation”) and the Administrative Sanctions Regulation. This is an administrative implementation of <a href=""https://cyberlaw.stanford.edu/blog/2014/02/turkey-enlists-intermediaries-censor-and-surveil-internet-users"">previously enacted legislation</a>, which however introduces new obligations on telecommunications operators. In particular, the amended regulation makes website blocking in Turkey easier. Meanwhile, a new omnibus bill was introduced before the Turkish Parliament to give the prime minister or any ministers the right to block websites without a court order for protection of public order.</p>
<p>According to Article 12(5) of the Electronic Communication Act and Article 6A of Law No. 5651 (the “Internet Law”), authorized operators, without regard to their scope of services, are requested to upgrade their infrastructure, according to ITC Authority standards and principles. The infrastructural upgrade must facilitate access blocking requests by the Presidency of Telecommunications and Communication - Telekomünikasyon İletişim Başkanlığı (“TIB”).</p>
<p>The amended Authorization Regulation and Administrative Sanction Regulation have now attached harsh consequences for operators that fail to fulfill the infrastructural obligations and TIB's blocking requests.</p>
<ol><li>Authorizations for operators who do not fulfill the infrastructural requirements will be revoked.</li>
<li>Any operators who do not upgrade their infrastructure appropriately (<strong>a</strong>) will be prohibited from offering their services to other operators and end users. (<strong>b</strong>) Moreover, operators will not be allowed to offer electronic communications services to other operators who have not updated their infrastructure.</li>
<li>Any authorized operator failing to fulfill TIB requests, orders, and warnings will be subject to an administrative fine of up to 3% of its annual turnover, and/or revocation of its authorization.</li>
<li>Additionally, if the operator is sanctioned for these violations, other legal entities related to this operator, executive board members or other directors could be deemed ineligible to offer electronic communications services.</li>
</ol><p>The amended Authorization Regulation will become effective on February 28, 2015, to give operators time to update their infrastructure.</p>
<p>Additional information on the new ITC Authority's Regulations can be found <a href=""http://www.lexology.com/library/detail.aspx?g=1b4498b5-5470-462e-888c-e51bc03d70c2"">here</a>. </p>
<p>Finally, according to a new omnibus bill recently submitted to the Turkish Parliament, the prime minister and any ministries may soon be given the power to request TIB to block websites within four hours. Upon governmental request, TIB will be able to take urgent measures to block access to website or remove online content for “protecting the right to life, protecting people’s life and property, national security, public order, preventing crime, or protecting general health.” Websites must be blocked by service providers within four hours from TIB's communication of the Government's request and will remain blocked until the content is removed. On October 2, 2014, the Turkish Constitutional Court already ruled unconstitutional a similar regulation empowering TIB to block website within four hours without court order. However, the willingness of the Turkish Government to censor the Internet and control tightly online intermediaries' activities appear to be relentless. </p>
<p> </p>
",Intermediary Liability,2015-01-28 1:28,505,Giancarlo Frosio,News
12773,,Spain,0,0,Spanish Court Criminalizes Linking to Copyright Infringing Materials and Reverses Consolidated Case Law,Copyright,"<p>As we <a href=""https://cyberlaw.stanford.edu/blog/2015/01/spanish-copyright-reform-enters-force-special-focus-online-intermediaries"">reported </a>a few days ago, the recent Spanish copyright reform granted enhanced powers to the Spanish Copyright Commission to target websites providing links to infringing works in a purposeful and massive way. Recently, the Criminal Court of Appeal of Castellón has given a first judicial implementation to this principle and departed from a long-standing judicial tradition. The Court of Appeal upheld a previous decision charging the webmaster of the website Bajatetodo.com with a eighteen-month prison term under Article 270 of the Spanish Criminal Code. The website used to provide links to a miscellaneous array of infinging materials available online.</p>
<p>The Court of Appeal applied the language of the new copyright reform by stressing that the webmaster went well beyond a mere passive neutral intermediary role by selecting, ordering and indexing the online resources to access the infringing materials. For this reason, the webmaster could not benefit of the linking safe harbour, specifically provided by the <a href=""https://cyberlaw.stanford.edu/page/wilmap-spain"">Spanish implementation of the eCommerce Directive</a>. So far, Spanish courts had been extremely careful in construing linking as copyright infringment. They recurrently ruled that webmasters arranging and indexing links to infringing materials still maintained a passive intermediary role that merely facilitated the download of unlawful content, thus this activity was sheltered by the linking exemptions provided by Spanish law.</p>
<p>Additionally, the Court of Appeal of Castellón made specific reference to the <a href=""http://the1709blog.blogspot.co.uk/2015/02/active-provider-criminal-sanctions.html"" style=""font-size: 13.0080003738403px; line-height: 20.0063037872314px;"">Svensson case</a> decided by the European Court of Justice. The Court rejected the earlier assumption by Spanish courts that operators of websites linking to infringing contents online cannot be held criminally liable because they do not engage in acts of communication to the public. According to <em style=""font-size: 13.0080003738403px; line-height: 20.0063037872314px;"">Svensson</em>, the Spanish Court argued, linking to infringing contents constitutes unauthorized communication to the public, and therefore copyright infringment, which triggers the website operators' criminal liability.  As we argued <a href=""https://cyberlaw.stanford.edu/blog/2014/03/freedom-linking-europe"" style=""font-size: 13.0080003738403px; line-height: 20.0063037872314px;"">elsewhere</a>, Svensson may prove to be a powerful precendent for criminalizing linking activities that were earlier viewed by courts as passive neutral acts protected by intermediary liability safe harbours. </p>
<p>Addition information regarding this case may be also found <a href=""http://the1709blog.blogspot.co.uk/2015/02/active-provider-criminal-sanctions.html"" style=""font-size: 13.0080003738403px; line-height: 20.0063037872314px;"">here</a>.</p>
",Intermediary Liability,2015-02-03 7:20,505,Giancarlo Frosio,News
12817,,United States,0,0,The emperor still doesn't have new clothes.,Other,"<p>Recently, a jury found Mr. Ross Ulbricht guilty of running the black market website Silk Road. Many observers claim that the government's theory expanded liability for third parties like Mr. Ulbricht online. As I mention in a recent GizMoto interview, the government's theory of liability wasn't new, but <a href=""http://gizmodo.com/how-the-silk-road-trial-set-a-dangerous-legal-precedent-1684208875"" target=""_blank"">""whether the government obtained the evidence that they wish to use to prove this narrative . . . in a lawful way consistent with the Fourth Amendment""</a> is still up for debate.</p>
<hr id=""system-readmore"" /><p>On Silk Road, you could buy everything from cyanide, to marijuana, to, yes, some say hit men. The site was dubbed the Amazon of the black market. While diary entries from Mr. Ulbricht showed that he initially intended to launch the site so that he could sell mushrooms, the factual issue in the trial was whether he was the infamous Dread Pirate Roberts who continued to captain the site after it got up and running -- and after Mr. Ulbricht supposedly bailed out.</p>
<p><span style=""line-height: 1.3em;"">Some have claimed that the government's theory of liability </span><a href=""http://www.nbcnews.com/tech/internet/why-silk-road-trial-should-matter-non-criminals-n285296"" style=""font-size: 13px; line-height: 1.3em;"" target=""_blank"">""would expand legal liability for commerce in contraband online,""</a><span style=""line-height: 1.3em;""> and that the outcome of the trial shows that </span><a href=""http://www.engadget.com/2015/02/08/silk-road-trial-lessons/"" style=""font-size: 13px; line-height: 1.3em;"" target=""_blank"">""anonymity is dead.""</a><span style=""line-height: 1.3em;""> Under this view, it is a slippery slope to hold Mr. Ulbricht liable for the conduct of people on Silk Road. That means all folks running websites have to be nannies who oversee all that is done on the site or risk criminal prosecution. </span></p>
<p>Maybe so. The Silk Road verdict makes it tougher to be a libertarian provider of a virtual platform where people can freely -- and anonymously -- transact. The freewheeling atmosphere on Silk Road was facilitated via the use of Bitcoin as the medium of payment. Some in the financial industry have sought similar anonymity with their ""dark pool"" methods of trading, where ""the trading volume created by institutional orders . . . are unavailable to the public."" Dark pools, too, <a href=""http://www.wsj.com/articles/dark-pools-face-new-sec-probe-1402356915"" target=""_blank"">have come under legal scrutiny</a>. </p>
<p>Contributory liability under copyright makes a third party -- here Mr. Ulbricht -- liable for infringements that occur under their control that they are aware of, or should be aware of. There is no intentional ostrich defense -- ""I chose not see or hear criminality!"" -- to such liability, nor is there such a defense to aiding and abetting violations of federal law. If Mr. Ulbricht was, in fact, Dread Pirate Roberts, then he intentionally facilitated the illegal transactions. In this respect, the case did not ""expand legal liability for commerce in contraband online,"" and so the emperor still has no clothes, contrary to what others say.</p>
<p>However, Silk Road did suggest new methods of potential government overreaching in the digital age. According to some pundits, the F.B.I. was mysteriously able to uncover the Silk Road servers supposedly via a software flaw on a site's login page that, in turn, revealed an IP address. Supposedly, the IP address led the feds to an Iceland location where the server for Silk Road was located. Whether this cookie crumb trail created by the feds violated the Fourth Amendment is an issue that will likely be raised on appeal. </p>
<p>Regardless of the outcome of that appeal, Silk Road illustrates the tension between being able to conduct business in private online without the government unlawfully snooping, and society's interest in regulating virtual transactions that have negative externalities -- nasty effects -- on all but the transacting parties.</p>
","Copyright and Fair Use, Intermediary Liability, Privacy",2015-02-11 14:10,1047,Ryan E. Long,News
12819,,International,1,1,The Mutual Legal Assistance Problem explained,Other,"<p class=""p1""><span class=""s1"">Following Edward Snowden revelations, it’s an understatement to say that governments were unhappy with their citizens' data being managed solely under US laws. This frustration is brought into sharp contrast when you examine the elongated system which other states have to use to obtain the same data for criminal investigation into serious, but sadly every day offences, such as murder, rape, cybercrime and increasingly cyber bullying or stalking - Mutual Legal Assistance. </span></p>
<p class=""p1""><span class=""s1"">The integration of the internet into most aspects of our daily lives has wrought similarly profound changes in crime and criminal justice, from the rise of purely online criminality (c</span><span class=""s2"">ybercrime), to the use of internet communications technology in the commission of real-world crimes, to the use of internet records to investigate, identify and convict. </span></p>
<p class=""p2""><span class=""s1"">As I wrote in my last <a href=""https://cyberlaw.stanford.edu/blog/2014/07/reflections-uks-drip-act""><span class=""s3"">blog</span></a>, it is quite possible that the location of the companies providing a communication platform, the location of data, and the location of perpetrators are all in different parts of the world.</span></p>
<p class=""p2""><span class=""s1"">Internationally, my colleagues in the law enforcement community lament what they perceive as less than straightforward access to user data from online providers based (for them) overseas. Facebook, Microsoft, Yahoo and Google - all based in the US - are the most commonly cited providers, but providers can and are increasingly based anywhere in the world.</span></p>
<p class=""p2""><span class=""s1"">This is often described as ‘the Mutual Legal Assistance Treaty (MLAT) problem’, after the existing international frameworks used to obtain evidence - including communications data - across borders. There are, however, alternatives to MLAT available in differing circumstances, and this in itself adds to the problem.</span></p>
<p class=""p1""><span class=""s1"">For examples, whilst <a href=""http://ECPA""><span class=""s4"">US legislation</span></a> precludes the sharing of content with non-US requesters, except in cases of “danger of death or serious physical injury to any person”, it is absent on the sharing of less sensitive information, such as subscriber data. This leads the US providers deciding in certain circumstances to share data directly with non-US law enforcement requesters. This is the data that most transparency reports provide. Favourable circumstances always include a proven adherence to a national legal process, and are also likely to relate to a serious offence, where no human rights violations are likely and where the user of the data is based in the requestors jurisdiction. Another option is to focus on joint investigations with the US where there is a clear US dimension to the crime, for example where victims or perpetrators are located in the US. </span></p>
<p class=""p1""><span class=""s1"">The options would be the same if the data was held elsewhere in the world, with the joint investigation being with the relevant local agency - these issues are not limited to the US.</span></p>
<p class=""p3""><span class=""s2"">The most resilient way of obtaining data is, however, by invoking MLAT. </span><span class=""s1"">Despite MLAT regularly touted as the solution to obtaining data internationally, it is not well understood. </span><span class=""s2"">Mutual Legal Assistance (MLA) is an agreement, usually by treaty (T), between two or more countries to provide assistance to each other on criminal legal matters. T</span><span class=""s1"">he types of assistance that can be provided through MLATs traditionally include: service of documents; search and seizure; restraint and confiscation of proceeds of crime; provision of telephone intercept material; and the facilitation of taking of evidence from witnesses.</span><span class=""s2""> </span><span class=""s1"">The agreements themselves, whilst indicating the points of contact in both countries, do not specify the end-to-end process. This is governed by a mixture of national laws: laws covering international co-operation and laws relating what is being requested. The MLA process is therefore determined by a combination of domestic law and bilateral and multilateral treaties on international crime.  MLA is resilient because it is the only process that ties together the laws of both receiving and requesting country, making it legally robust at all stages.</span></p>
<p class=""p4""><span class=""s1"">However, the MLA process is long. It requires an administrative legal process in each countries and </span><span class=""s5"">duplicate checking of paperwork</span><span class=""s1"">.  In the UK to US process it involves the law enforcement requestor  working with the Crown Prosecution Service to write a letter of request under the US-UK MLAT, which then is forwarded to the UK’s Central Authority in the Home Office. The Central Authority checks that the request complies with the Treaty regulations, including whether it </span><span class=""s6"">“would be contrary to important public policy” or if the request relates to an “offense of political character.”</span><span class=""s1""> The UK central Authority will then forward the letter of request to the US Central Authority, at the US Department of Justice’s Office of International Affairs (OIA)</span><span class=""s7""> </span><span class=""s5"">in Washington DC</span><span class=""s1"">. The OIA will then review the letter for compliance with the treaty, before forwarding it to the US Attorney’s Office in the District where the provider is incorporated, which is often the Northern District of California, where Silicon Valley is located. The US Attorney will then translate the letter of request into a US legal document, usually a court order, which is then served on the recipient </span><span class=""s5"">company.</span><span class=""s1""> Following the company’s response to the legal order, the response will then go back through US law enforcement office for ‘minimization’, where an interpretation is placed on the data required for the foreign investigation and any data exceeding this interpretation is removed. The response is then sent back via both Central Authorities, again for verification, to the original Crown Prosecutor and the law enforcement requester.</span></p>
<p class=""p4""><span class=""s1"">The length of this country-to-country process can be compounded by legislation requiring that communication should be via the traditional postal service. </span></p>
<p class=""p4""><span class=""s1"">In the UK, requests for communications data through MLA can take up to 13 months. Despite this frustration, the UK is most likely in a privileged position in terms of MLA, speaking the same language. <a href=""http://www.unodc.org/documents/organized-crime/unodc_ccpcj_eg.4_2013/cybercrime_study_210213.pdf""><span class=""s8"">The UN Cybercrime Study</span></a> of 2013 indicates that most countries </span><span class=""s5"">‘reported median response times of ... 150 days for mutual legal assistance requests, received and sent.... It is clear that the use of formal cooperation mechanisms occurs on a timescale of months, rather than days’. </span></p>
<p class=""p1""><span class=""s1"">But it’s not just law enforcement that is frustrated by the MLAT problem. Governments have additional frustrations: </span></p>
<p class=""p1""><span class=""s1"">there is frustration at an inability to get all communications data relating to nationals, including content, under their own national laws, especially where these laws have proven robust human rights safeguards not enhanced by duplicate processes. In many cases double checking does no more to protect the privacy of the user, instead frustrating the investigative or judicial process in the country requiring the information. There is also the flip side of an inability by foreign citizens or governments to challenge the way in which data has been handled. This is strongly articulated in the EU-US <a href=""http://ec.europa.eu/commission_2010-2014/reding/multimedia/news/2013/11/20131118_en.htm""><span class=""s4"">debate on data protection</span></a>.</span></p>
<p class=""p1""><span class=""s1"">an increasing burden, as the number of requests for international communications data goes up, on government’s<i> Central Authorities</i>, who are responsible for processing both incoming and outgoing requests. Few countries, including the US, have increased the resources provided to Central Authorities. Recommendation 34 of the December 2013 <a href=""http://www.whitehouse.gov/sites/default/files/docs/2013-12-12_rg_final_report.pdf""><span class=""s4"">Report</span></a> and Recommendations of The President’s Review Group on Intelligence and Communications Technologies is to “increase resources to the office in the Department of Justice that handles MLAT requests, [given that] the Office of International Affairs (OIA) in the Department of Justice has had flat or reduced funding over time, despite the large increase in the international electronic communications that are the subject of most MLAT requests.”</span></p>
<p class=""p1""><span class=""s1"">when a crime is not a crime in both countries, a response that the request requires MLAT is often (mis)interpreted</span><span class=""s7""> </span><span class=""s1"">as a refusal to produce information. For example, in December 2012 a prosecutor in India was advised to consider using Mutual Legal Assistance to obtain information from overseas providers and referred to the Treaty between the US and India. Instead the <a href=""http://zeenews.india.com/news/dehli/center-not-co-operating-in-complaint-against-websites-court_814836.html""><span class=""s4"">court issued</span></a> service of summons to bring Facebook, Orkut, YouTube, Yahoo, Blogspot, Google and Microsoft to court for allegedly committing offenses, including those of selling obscene materials to youths and hatching criminal conspiracy. Sometime in these cases MLAT will result in a negative response, especially when the request relates to freedom of speech or hate crime issues, even where these are within a clear national qualified human rights framework.</span></p>
<p class=""p1""><span class=""s1"">Finally, governments, including the US, also wish to ensure that companies which are incorporated in their jurisdiction maintain the laws of their jurisdiction. This includes laws relating to sharing communication data, but also more fundamental laws, such as those governing human rights.</span></p>
<p class=""p4""><span class=""s1"">Governments are not alone in their frustrations. US providers as recipients want a legal underpinning for providing data that fits with their business model. In light of Snowden’s revelations they are particularly sensitive to voluntary schemes for content and would like to show consistency to their users by only acceding to requests with an explicit legal underpinning. They want this to be in the jurisdiction in which they are incorporated for cultural, human rights and possibly economic reasons. Where there is clashing legislation - such as the US Electronic Communications Privacy Act preventing the release of content requested under another state’s laws - it is understandable that the provider will want to opt to comply with the legislation in the country in which it is incorporated.</span></p>
<p class=""p4""><span class=""s1"">Another significant concern to US providers is when countries dispute the need to use formal channels, such as MLAT or a request under their own legislation, and instead threaten legal action against a company’s officials based in-country. In 2012 and 2013 we have seen this in <a href=""http://www.nytimes.com/2013/07/13/technology/twitter-yields-to-pressure-in-hate-case-in-france.html?_r=0""><span class=""s8"">France</span></a> with Twitter, in <a href=""http://zeenews.india.com/news/dehli/center-not-co-operating-in-complaint-against-websites-court_814836.html""><span class=""s8"">India</span></a> with several providers and in <a href=""http://www.theguardian.com/world/2012/sep/26/brazil-google-executive-arrest-video""><span class=""s8"">Brazil</span></a> for Google. </span></p>
<p class=""p3""><span class=""s2"">US providers are also fearful of the ‘balkanization’ of the internet. Instead they, like the US government believe that</span><span class=""s1""> <a href=""http://www.whitehouse.gov/sites/default/files/docs/2013-12-12_rg_final_report.pdf""><span class=""s4"">“non-US governments seeking such records [via MLAT] can face a frustrating delay in conducting legitimate investigations. These delays provide a rationale for new laws that require e-mail and other records to be held in the other country, thus contributing to the harmful trend of localization laws.”</span></a></span></p>
<p class=""p4""><span class=""s1"">Non Governmental Organisations who focus on representing the privacy rights of the users are frustrated by the lack of transparency in the current systems.  Despite increased transparency reporting by many providers, it is often unclear under what circumstances and which laws data is or is not shared with law enforcement agencies in different jurisdictions. There is no transparency in MLAT.</span><span class=""s5""> They are also concerned with the balkanisation of the internet, and the likely global impact on freedom of expression and access to information. </span></p>
<p class=""p4""><span class=""s5"">Finally, in the context of NGOs, I think it is important to note that </span><span class=""s1"">victims of crime which could be better investigated with better access to data, whilst clearly stakeholders, are not currently vocally represented. My feeling is that it is these victims of often serious crimes who are really facing the MLAT problem.</span></p>
","Architecture and Public Policy, Privacy",2015-02-23 13:06,740,Gail Kent,News
12827,,Brazil,0,0,Whatsapp at Risk of Suspension of Services in Brazil,Other,"<div>A few weeks ago, a judge of the state of Piauí, in Brazil, ordered Whatsapp to suspend its activities in the country. The judge has also issued orders for the suspension of the service to all telecommunication service providers, compelling them to enforce the measure, considering the service has no representation in Brazil. As the case pertains to the sharing of child pornography through the network, its details are classified.</div>
<div> </div>
<div>The order became known only last Wednesday, when its content was leaked to the media. Since it became public, it has caused an uproar in social network services. Telegram Messenger, a competitor of Whatsapp, stated through twitter in the day of the disclosure of the order that they had completed ""2 million new signups from Brazil in the last 20 hours"", and were then ""signing up 100 new users per second.""</div>
<div> </div>
<div>On the day following its disclosure to the public, Thursday, the decision was reversed by the judge of the Court of Appeals of the State of Piauí in charge of the appeal. This decision can be challenged.</div>
<div> </div>
<div>The services have not been interrupted at any point.</div>
<p><em><a href=""https://br.linkedin.com/in/felipebusnello/en"" target=""_blank"">Felipe Octaviano Delgado Busnello</a> is a qualified Brazilian attorney active in the field of internet and intellectual property law. He can be reached at felipe.busnello at gmail.com.</em></p>
",Intermediary Liability,2015-03-02 12:59,1134,Felipe Busnello,News
12835,,Spain,0,0,Spain: The Right to Be Forgotten Does Not Apply to Blogger,Privacy or Data Protection+Right to Be Forgotten+Freedom of Expression,"<p>In a recently <a href=""http://www.poderjudicial.es/search/doAction?action=contentpdf&databasematch=AN&reference=7309398&links=28079230012014100466&optimize=20150302&publicinterface=true"">reported ruling</a>, the Spanish National High Court held that Google is not responsible for the processing of personal data on blog hosted on Google’s owned Blogger, and therefore, that the so called “right to be forgotten” established by the Court of Justice of the European Union (CJEU) in the <a href=""http://curia.europa.eu/juris/document/document.jsf?text=&docid=152065&pageIndex=0&doclang=EN&mode=lst&dir=&occ=first&part=1&cid=264144"">Google Spain</a> case does not extend to a blogging platform.</p>
<p>The ruling reverses a <a href=""http://www.agpd.es/portalwebAGPD/resoluciones/tutela_derechos/tutela_derechos_2010/common/pdfs/TD-00412-2010_Resolucion-de-fecha-16-07-2010_Art-ii-culo-16-LOPD_Recurrida.pdf"">decision</a> issued by the Spanish Data Protection Authority (DPA) which had ordered Google to remove personally identifiable information from a blog hosted on Blogger. The claimant was a Spanish citizen who found that when typing his name on Google Search, the results included a link to a blog with information about a crime he had committed many years ago. While the official criminal records had already been cancelled, the information was thus still findable on the internet.</p>
<p>On the one hand, the DPA ordered Google to remove the information from its search engine. This was upheld by the National High Court, albeit ordering more precisely that Google remove the link from the search results – thus applying the criteria set out by the CJEU in <a href=""http://curia.europa.eu/juris/document/document.jsf?text=&docid=152065&pageIndex=0&doclang=es&mode=lst&dir=&occ=first&part=1&cid=264144"">Google Spain</a>.</p>
<p>On the other hand, the DPA considered Google, as the owner of the blogging platform, to be the “controller” of the processing. Interestingly, the DPA found that while Google was not liable for the content of the blog, as it was shielded by the hosting safe harbor, the DPA has the power to order Google to remove the information from the blog.</p>
<p>The National High Court reversed that and held that the responsible for the processing is not Google but the blog owner. It further held that the DPA cannot order Google to remove the content within a procedure for the protection of the data subject’s right to erasure and to object.</p>
<p>Arguably, under the rationale that the platform is not the controller of the processing, other user generated content sites such as YouTube or social networking sites might also fall outside the scope of the right to be forgotten.</p>
","Intermediary Liability, Privacy",2015-03-04 9:01,678,Miquel Peguera,News
12958,,India,0,0,Landmark Intermediary Liability Decision from the Indian Supreme Court,Defamation or Personality Rights+Freedom of Expression,"<p>Recently, the Supreme Court of India issued a landmark decision regarding the constitutionality of several provisions included in the Indian Information Technology Act (""IT Act""). The provisions dealt with content removal online and blocking orders. According to the Supreme Court, vague standards for blocking and removing content online are unconstitutional. Additionally, content blocking must be mandated only by a reasoned order from a judicial, administrative or governmental body and must be transparent.</p>
<p>The case was brought before the Supreme Court by two young ladies arrested by the police for posting on a social networking site critical comments about a city shutdown. Actually, one of these two young women just reinforced the original comment by ""liking"" it.</p>
<p>First, the Indian Supreme Court struck down provisions heavily censoring online speech through the implementation of amorphous and overbroad standards. Specifically, the Court declared Section 66A of the Information Technology Act as unconstitutional. Section 66A allowed both criminal charges against users and the removal of content by intermediaries based on allegations that the content was “grossly offensive or has menacing character”, or that false information was posted “for the purpose of causing annoyance, inconvenience, danger, obstruction, insult, injury, criminal intimidation, enmity, hatred or ill will."" The Court noted that Section 66A did not qualify as a reasonable restriction on freedom of expression by being vaguely worded and allowing misuse by the police.</p>
<p>Second, the Supreme Court construed Section 79 of the IT Act in such a manner that removal of content online may only occur if an adjudicatory body issues an order compelling intermediaries to remove the content. Section 79 of the IT Act provided that safe harbors from liability for online intermediaries could be suspended if the intermediary fails to take down content upon “receiving actual knowledge, or on being notified by the appropriate Government or its agency that any information, data or communication link residing in or connected to a computer resource controlled by the intermediary is being used to commit [an] unlawful act”. The recent Indian Supreme Court interpretation of Section 79 shields intermediaries from liability unless they fail to comply with an order directing them to remove the illegal content, rather than merely a private party request. According to the <a href=""https://cyberlaw.stanford.edu/blog/2015/03/welcome-manila-intermediary-liability-principles"">Manila Principles</a>, this may still be a very unsatisfactory arrangement as ""content must not be required to be restricted without an order from a judicial authority."" In particular, the judgment still maintains in place Section 69A of the IT act that provides the government with the ""power to issue directions for blocking for public access of any information through any computer resource [ . . . ] [w]here the Central Government or any of its officers specially authorised by it in this behalf is satisfied that it is necessary or expedient so to do, in the interest of sovereignty and integrity of India, defence of India, security of the State, friendly relations with foreign States or public order or for preventing incitement to the commission of any cognizable offence relating to above."" However, this is still a victory for online freedom of expression as the Indian Supreme Court clarifies that private parties should not be able to force content offline just by sending a notice to online intermediaries. </p>
<p>Finally, the court stated that transparency standards should apply to blocking orders and all website blocking orders should be made public.</p>
<p>The full text of the Indian Supreme court judgment can be found <a href=""http://supremecourtofindia.nic.in/FileServer/2015-03-24_1427183283.pdf"">here</a>.</p>
",Intermediary Liability,2015-03-27 12:04,505,Giancarlo Frosio,News
12959,,International,1,1,Welcome to the Manila Intermediary Liability Principles!,General,"<p>A few days ago, digital rights advocates and civil society groups gathered together in Manila and approved the Intermediary Liability Principles. The principles were officially launched at the Rightscon Southeast Asia in Manila.</p>
<p>The document sets out safeguards for content restriction on the Internet with the goal of protecting users' rights, including ""freedom of expression, freedom of association and the right to privacy."" A set of general principles is accompanied by sub-principles and a background paper qualifying some of the terminology and statements included in the principles. The six main principles are summarized below:</p>
<ol><li>Intermediaries should be shielded by law from liability for third-party content.</li>
<li>Content must not be required to be restricted without an order by a judicial authority.</li>
<li>Requests for restrictions of content must be clear, be unambiguous, and follow due process.</li>
<li>Laws and content restriction orders and practices must comply with the tests of necessity and proportionality.</li>
<li>Laws and content restriction policies and practices must respect due process.</li>
<li>Transparency and accountability must be built in to laws and content restriction policies and practices.</li>
</ol><p>The principles aim at creating a digital environment where intermediaries are in the best position for protecting human rights. They set high goals in order to minimize any ""invisible handshake"" between corporate and governmental power. Principle No. 2, especially, takes an extreme position in this direction, opposing the increasing emergence of administrative schemes for enforcing intermediary liability online. As also the UN Special Rapporteur on Freedom of Expression <a href=""https://cyberlaw.stanford.edu/blog/2013/12/italian-communication-authority-brushes-growing-discontent-its-proposal-administrative"">highlighted</a> multiple times, the Manila Principles recognize that only courts of law should be entitled to come up with that delicate ballancing of rights that online content removal entails.</p>
<p>The text of the principles, subprinciples and background paper is available on a dedicated website <a href=""https://www.manilaprinciples.org/"">here</a>. The Manila Principles are open to endorsement.</p>
",Intermediary Liability,2015-03-27 4:20,505,Giancarlo Frosio,News
12961,,Belgium,0,0,Belgian Court Says That ISPs Must Not Pay a Copyright Levy to Collective Societies,Copyright,"<div>
<div>
<div> </div>
<div>On March 13, 2015, the Distric Court of Brussels decided that Internet Service Providers (ISPs) should not pay a copyright levy for communicating to the public the repertoire of SABAM, the Belgian association of authors, composers and publishers and the largest Belgian collective management organisation (CMO).</div>
<div> </div>
<div>In 2011, SABAM sought to obtain the payment of a copyright levy from Belgian ISPs, including Belgacom, Telenet and Voo, for communicating to the public its repertoire. SABAM claimed that ISPs communicate to the public its repertoire without authorisation. SABAM demanded 3.4 percent of the ISPs' annual user subscription fees as a compensation for piracy committed by the ISPs' users. </div>
<div> </div>
<div>As requested by law, SABAM informed the Economic Federal Public Service (SPF Economie), the administrative authority in charge of overseeing CMOs' activities, about its request to the ISPs. The SPF Economie issued a negative opinion regarding SABAM's proposed levy. After some inconclusive negotiations and an initial action started by SABAM against the ISPs but rejected on procedural grounds, the Belgian Administration brought an action against SABAM before the Court of Brussels for obtaining a judgment declaring the proposed levy illegal. Brutele, Belgacom and Telenet joined the litigation as voluntary intervenors.</div>
<div> </div>
<div>The District Court of Brussels ruled that the demand of SABAM was contrary to the present legislation. The Court noted that ISPs are neutral internet intermediaries with a passive and technical role and do not communicate to the public SABAM's repertoire. According to the EU e-Commerce Directive, ISPs are classified as mere conduits that are not liable for the information they transmit.</div>
<div> </div>
<div>SABAM is considering whether to appeal this decision. According to SABAM, the European Court of Justice frequently “stressed that the economic benefit that someone has from relaying works, is often crucial for the decision if this is an act of communication to the public that falls within the exclusive right of the author.”</div>
<div> </div>
</div>
</div>
<div>The decision No. 13/12839/A of the Disctrict Court of Brussels is available <a href=""http://www.ipnews.be/wp-content/uploads/2014/04/20150313-Etat-belge-contre-Sabam.pdf"">here </a>(French only).</div>
<div> </div>
<div><em>The author would like to thank Axel Beelen for some of the background information included in this blog post. Mr. Beelen is a Belgian lawyer and blogger and can be reached <a href=""http://www.ipnews.be/en/about-us/contact/"">here</a>.</em></div>
",Intermediary Liability,2015-03-30 5:45,505,Giancarlo Frosio,News
12973,European Union,,0,0,(C) More Entertainment for Broadcasters: The European Court of Justice on Linking to Live Streams of Sport Events,Copyright+Other IP Rights,"<div> </div>
<div>A few days ago, the European Court of Justice (ECJ) decided <em>C More Entertainment AB v Linus Sandberg</em>. This is the last episode of the linking saga, previously discussed by the ECJ in <em><a href=""https://cyberlaw.stanford.edu/blog/2014/03/freedom-linking-europe"">Svensson </a></em>and <em><a href=""https://cyberlaw.stanford.edu/page/wilmap-european-union"">Bestwater</a></em>. This time, the ECJ had to decide whether linking to live internet streams of sport events infringed on the exclusive related rights of broadcasting organizations. The ECJ concluded that national legislation may extend the exclusive right of the broadcasting organisations to acts of communication to the public encompassing broadcasts of sporting fixtures made live on internet.</div>
<div> </div>
<div>
<div>The request for a preliminary ruling came from the Supreme Court of Sweden. The online broadcaster C More Entertainment challenged the legality of Mr. Sandberg’s website hosting links enabling users to circumvent a paywall to watch its live streams of hockey matches. </div>
<div> </div>
<div>Finally, the Swedish Court decided to drop a number of questions, initially referred to the ECJ, concerning whether placing clickable links on a website may be classified as an act of communication to the public. The ECJ already answered those questions in <em><a href=""http://cyberlaw.stanford.edu/blog/2014/03/freedom-linking-europe"">Svensson</a></em>, noting that links communicate works to the public, but they are not infringing unless they make the work available to a new public. Therefore, links to authorized works freely available online do not infringe the right of communication to the public. In contrast, a link enabling users to circumvent a paywall would communicate the work to a new public and would be infringing.</div>
<div> </div>
<div>In this case, however, C More Entertainment does not own a copyright in the underlying sport event, which, as we have discussed <a href=""https://cyberlaw.stanford.edu/blog/2013/09/alalalai-rojadirecta-battle-again-italy"">here</a>, does not reach the level of originality required for copyright protection. Instead, C More Entertainment enjoys a related right in the broadcasting of the sport event.</div>
<div> </div>
<div>According to Article 3(2)(d) of Directive 2001/29, Member States must provide broadcasting organisations with  “the exclusive right to authorise or prohibit the making available” of fixations of their broadcasts to the public, “in such a way that members of the public may access them from a place and at a time individually chosen by them.” According to the ECJ, this ""right of making available to the public"" forms part of the wider ""right of communication to the public,"" which Article 3(1) grants to authors. Referring to the explanatory memorandum to the Commission Proposal to Directive 2001/29, the ECJ confirmed that “making available to the public” is intended to refer to ‘interactive on-demand transmissions’ characterized by the fact that members of the public may access them from a place and at a time individually chosen by them.</div>
<div> </div>
<div>As the ECJ noted, “that is not the case of transmissions broadcast live on internet.” C More Entertainment’s live streams of hockey matches would fall out of the scope of the rights granted by EU law to broadcasting organizations.</div>
<div> </div>
<div>Against this factual and legal background, the Swedish Supreme Court maintained only one question for the <span style=""font-size: 13.0080003738403px; line-height: 1.538em;"">ECJ:</span></div>
<p style=""margin-left:.5in;"">May the Member States give wider protection to the exclusive right of authors by enabling “communication to the public” to cover a greater range of acts than provided for in Article 3(2) of [Directive 2001/29]?</p>
<div>In practice, should Article 3(2) of Directive 2001/29 be interpreted as precluding national legislation from extending the exclusive right of the broadcasting organisations to acts of communication to the public encompassing broadcasts of sporting fixtures made live on internet? Does EU law preclude Member States to extend the exclusive rights of the broadcasters to those acts which could be classified as ""acts of communication to the public"" but which do not constitute ""acts of making available to the public the fixations of their broadcasts in such a way that members of the public may access them from a place and at a time individually chosen by them""?</div>
<div> </div>
<div>The ECJ answered to this question in the negative and held that “<a href=""http://eur-lex.europa.eu/legal-content/EN/ALL/?uri=CELEX:32006L0115"">Directive 2006/115</a> [on Rental Right and Lending Right and on Certain Rights related to Copyright in the Field of Intellectual Property] gives the Member States the option of providing for more protective provisions with regard to the broadcasting and communication to the public of transmissions made by broadcasting organisations than those which must be instituted in accordance with Article 8(3) of that directive.” Therefore, the ECJ concluded, Article 3(2) of Directive 2001/29 must be interpreted as not precluding national legislation from extending the exclusive broadcasting organisations' right of making available to the public referred to in Article 3(2)(d) to acts of communication to the public including live internet streams of sport events.</div>
<div> </div>
</div>
<div>The full text of case C‑279/13 is available <a href=""http://curia.europa.eu/juris/document/document.jsf?text=&docid=163250&pageIndex=0&doclang=EN&mode=lst&dir=&occ=first&part=1&cid=114017"">here</a>.</div>
<div> </div>
",Intermediary Liability,2015-03-31 7:03,505,Giancarlo Frosio,News
12985,,Italy,0,0,"Right to be Forgotten Must be Balanced with Freedom of the Press, Italian Privacy Authority Says",Privacy or Data Protection+Right to Be Forgotten+Freedom of Expression,"<p>On March 31, 2015, the Italian Privacy Authority (""Authority"") issued a decision stating that users cannot obtain the delisting of search results of recent news with a relevant public interest. However, search engines must delete or edit automatically generated snippets accompanying the search results if they are misleading. </p>
<p>The claimant contested Google's decision not to delist a news article referring to a judicial inquiry in which the claimant was involved. The claimant argued that the news article was ""extremely misleading and strongly detrimental."" Therefore, he asked to delist the search results associating his name with that news article.</p>
<p>The Authority denied the delisting request upon the finding that the news was extremely recent. Additionally, the Authority highlighted the relevant public interest of the news, which referred to an important judicial inquiry with the involvement of a large number of people at the local level. For all these reasons, the Authority found that the freedom of the press should prevail on the right to be forgotten under the present circumstances. Also, the Authority noted, if the interested party deems the news to be false, he may ask the publisher to update, rectify or integrate the article.</p>
<p>However, the Authority also concluded that search engines must delete or modify the automatically generated snippets summarizing the information included in the search results if they are misleading. In this case, the Authority found that the summary did not match the facts described in the news article and associated the claimant to more serious crimes than those for which he was under investigation. Actually, Google complied immediatelly with this request and deleted the inaccurate snippet prior to the Authority's decision.</p>
<p>In line with <a href=""https://cyberlaw.stanford.edu/blog/2014/11/eu-data-protection-authority-adopts-guidelines-implementation-right-be-forgotten"">Article 29 Working Party Guidelines</a> and other national decisions, the national application of the right to be forgotten in Europe moves forward by implementing strong safeguards for freedom of expression.</p>
<p>The decision of the Authority can be found <a href=""http://www.gpdp.it/web/guest/home/docweb/-/docweb-display/docweb/3822823"">here</a>. </p>
","Intermediary Liability, Privacy",2015-04-02 13:47,505,Giancarlo Frosio,News
13007,,Turkey,0,0,"Turkey Blocks Facebook, Twitter and YouTube over Images of Public Prosecutor Held Hostage",Dangerous Speech/Violent Extremism+Freedom of Expression,"<p>Today, a court in Istanbul ordered the ban of Twitter, Facebook and YouTube over the publication of the <a href=""http://prod.static9.net.au/~/media/images/2015/march/31/3103_istanbul_hostage_a.ashx?w=718"">picture</a> of a public prosecutor held hostage by extreme-Left militants. The blocking order on Twitter and Facebook was lifted after the social media sites complied with the request of removal. The ban of YouTube is still in place.</p>
<p>The 1st Criminal Court of Peace in Istanbul issued the blocking order against the social media platforms according to a request of the Chief Public Prosecutor of the Terror and Organized Crime Investigation Bureau. The Prosecutor Office demanded that the images of the public prosecutor Mehmet Selim Kiraz held hostage at gunpoint will not be used anywhere on electronic platforms. Mr. Mehmet Selim Kiraz later died of the injuries he suffered during an attempt of the Turkish special forces to rescue him from the kidnappers. Possibly, 166 website may be affected by the court order, including international newspaper websites such as The Independent, The Mirror, and Tgcom24 and major Turkish news channels and newspapers. The decision demanded the removal of the content and ordered the website blocking if the online platforms did not comply with the request. After the initial refusal to remove the content, the leading Turkish Internet Service providers implemented the ban on Twitter and YouTube. </p>
<p>Facebook complied immediately with the request of removal and was not reached by the implementation of the blocking order. According to a spokesman of the company, Facebook will appeal the decision, despite momentarily complying with the court order.</p>
<p>Later, Twitter complied with the court's request and removed from their platforms the links listed in the court order. Access to the social media platform appears to be restored in Turkey by now. </p>
<p>At the moment, Turkish authorities still maintain the block on YouTube, although Google is working to restore access to the video sharing platform as soon as possible. However, according to <a href=""http://national.bgnnews.com/turkey-to-ban-google-if-it-doesnt-remove-content-of-slain-prosecutor-haberi/4906"">Al Jazeera Turk</a>, Turkish authorities will ban access to the entire Google site and its services unless Google removes for Turkey all search results referring to the images of Mehmet Selim Kiraz's kidnapping by April 6, 11.30 pm GMT. (UPDATE: the ban on Youtube was lifted shortly after that on Twitter, upon removal of the allegedly infringing links, and Google services were finally never disrupted).</p>
<p>Despite the intense social outrage that the killing of a civil servant by a terrorist organization may provoke, banning entire web platforms used by millions of people and accusing them of sharing terrorist propaganda for publishing news including sensitive images does not seem to be the correct answer for a democratic society.</p>
<p>A copy of the court decision is available <a href=""http://www.cnnturk.com/haber/sosyal-medya/youtube-ve-twittera-erisilemiyor?utm_content=buffer5e347&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer"">here</a> (Turkish only). </p>
",Intermediary Liability,2015-04-06 16:11,505,Giancarlo Frosio,News
13019,,United States,0,0,Daphne Keller to Direct Intermediary Liability Project at Stanford Center for Internet and Society,General,"<div>Stanford Law School today announced the appointment of <a href=""http://cyberlaw.stanford.edu/about/people/daphne-keller"">Daphne Keller</a> as Director of Intermediary Liability at The Center for Internet and Society (CIS). Starting in September 2015, Keller will lead the Center’s work at the intersection of online technologies, liability and corporate responsibility, and civil liberties, with a particular focus on global liability regimes that impact free expression and innovation. </div>
<div> </div>
<div>CIS’ two-year-old initiative on intermediary liability explores the impact of global intermediary liability regimes on freedom of expression and innovation. Intermediary liability law can create incentives for platforms like Facebook or YouTube to police the online expression and conduct of their users – including artists, journalists and political activists. Without careful consideration, the rules can stifle legitimate expression and political activities, and can constrain providers’ ability to provide innovative new services.  </div>
<div> </div>
<div>The Director of Intermediary Liability is responsible for conducting and supervising policy analysis and advocacy efforts regarding intermediary liability regimes and their effect on free expression and innovation worldwide, and for managing and developing the Center’s innovative and influential work in this focus area. </div>
<div> </div>
<div>Keller is a renowned expert in intermediary liability, privacy and copyright law. As Associate General Counsel for Intermediary Liability and Free Speech issues at Google, Keller has been on the front lines of the intermediary liability issue – including resolving legal content removal requests – for 10 years. Keller’s experience is global, working primarily on legal and policy issues outside the U.S., including the European Union’s evolving “Right to Be Forgotten.” Daphne has also taught Internet law as a Lecturer at U.C. Berkeley School of Law and has taught courses at U.C. Berkeley School of Information and at Duke University School of Law. </div>
<div> </div>
<div>“International Intermediary liability regimes are developing quickly and impacting user rights online,” said CIS Faculty Director and Professor of Law Barbara van Schewick. “We believe that governments can address unwanted behavior on the Internet in ways that preserve civil liberties. I’m delighted that Daphne Keller has agreed to lead our efforts in this area. With her expertise and her enthusiasm for user rights, I can’t think of a better person to help us figure out what the role of intermediaries in an open and free society should be.” </div>
<div> </div>
<div>“I am excited to shift into a more public interest-oriented advocacy and research role, addressing the same fascinating topics I navigated at Google through a new lens and with new tools,” said Daphne Keller. “I am also eager to use my expertise to help educate students and to find new, civil liberties-enhancing solutions to thorny problems.” </div>
<div> </div>
<div>“We are thrilled to have Daphne Keller at The Center for Internet and Society,” said Dean M. Elizabeth Magill, the Richard E. Lang Professor of Law and Dean of Stanford Law School. “The Center for Internet and Society has led the way in navigating unchartered waters where new technology meets the law, and Daphne expands the Center’s capacity to work with students, lawyers and policy makers.”</div>
<div> </div>
<div>As Associate General Counsel for Intermediary Liability and Free Expression at Google, Keller focused primarily on legal and policy issues outside the U.S. Prior to that role, her roles at Google included leading the core legal teams for web search, copyright and open source software. Throughout her career, Keller has maintained strong ties to academia, teaching courses on Internet intermediaries, cyber law and intellectual property, the First Amendment and emerging technologies. Before joining Google in 2004, Keller practiced in the Litigation group at Munger, Tolles & Olson. </div>
<div> </div>
<div>Keller earned her law degree from Yale Law School and her undergraduate degree from Brown University. She has been a panelist, speaker and educator at numerous policy and professional events, including the U.K. Parliament Joint Committee on Privacy and Injunctions and Leveson Inquiry regarding intermediary liability issues for web search and other Google services in 2012, where she served as a witness; the Fordham IP Law and Policy Conference; the Stanford E-Commerce Best Practices Conference; and the USC School of Law Intellectual Property Institute. </div>
<div> </div>
<div>About The Center for Internet and Society</div>
<div>Led by faculty director Barbara van Schewick, The Center for Internet and Society (CIS) is a public interest technology law and policy program at Stanford Law School that supports the study of the interaction of new technologies and the law and is a part of the Law, Science and Technology Program at Stanford Law School. CIS strives to improve both technology and law, encouraging decision makers to design both as a means to further democratic values. Along with conducting research and policy analysis, the Center sponsors legal fellowships, organizes events to foster discussion of critical policy issues, and provides educational opportunities for law students to conduct applicable research and policy analysis in this field. </div>
<div> </div>
<div><a href=""http://www.law.stanford.edu"" target=""_blank"">About Stanford Law School </a></div>
<div>Stanford Law School is one of the nation’s leading institutions for legal scholarship and education. Its alumni are among the most influential decision makers in law, politics, business and high technology. Faculty members argue before the Supreme Court, testify before Congress, produce outstanding legal scholarship and empirical analysis, and contribute regularly to the nation's press as legal and policy experts. Stanford Law School has established a new model for legal education that provides rigorous interdisciplinary training, hands-on experience, global perspective and focus on public service, spearheading a movement for change.</div>
",Intermediary Liability,2015-04-13 6:40,396,Center for Internet and Society,News
13064,,United States,0,0,Targeting Safe Harbors to Solve the Music Industry’s YouTube Problem,Copyright,"<p>Last week, the International Federation of the Phonographic Industry (IFPI) released its <a href=""http://www.ifpi.org/digital-music-report.php"">2015 Digital Music Report</a>—an annual state of the industry update for digital recorded music. Included in the report, along with year-over-year information about industry initiatives, revenue sources, and consumer preferences, is a policy agenda that highlights where the IFPI will be concentrating its lobbying efforts. This year, the IFPI is gunning for safe harbors like the one in the Digital Millennium Copyright Act (DMCA) that insulates user-generated content sharing sites from claims of copyright infringement. The IFPI is demanding that policy makers internationally “[make] clear that any liability exemptions can only apply to genuinely neutral and passive online service providers, and not to services that play an active role in distributing, promoting and monetising content.” The Report expressly names YouTube as a service that should not qualify for safe harbor, and it argues that YouTube is hiding in the DMCA safe harbor to avoid paying its fair share of music licensing fees.</p>
<p>It’s no secret that the motion picture and recording industries are unhappy with the current state of U.S. law on the scope of safe harbors for online intermediaries—most notably the safe harbor in section 512(c) for service providers that provide “storage at the direction of…user[s].” In two big cases, <em>UMG Recordings v. Shelter Capital Partners</em> (2013) in the Ninth Circuit and <em>Viacom v. YouTube</em> (2012) in the Second Circuit, rights owners urged the courts to interpret the safe harbor narrowly by holding that the automatic processes that video-sharing sites engage in to enable public access to user-uploaded videos fall outside the safe harbor. On that narrow reading of the statute, any UGC site that allows users to stream or view content rather than simply parking it on a server would be ineligible for safe harbor. In other words, all content-sharing sites would effectively be disqualified.</p>
<p>In both <em>UMG v. Shelter Capital</em> and <em>Viacom v. YouTube</em>, the court rejected that narrow reading of the safe harbor and adopted a broader interpretation that includes ancillary activities necessary to provide users with access to their stored material. One of the reasons why the courts were not persuaded by the argument that “storage” means only passive hosting is that Congress defined “service provider” broadly in the DMCA and required strictly passive handling of user content only for a separately defined subset of service providers seeking safe harbor for routing functions under section 512(a). If Congress had intended to do so, the Ninth Circuit said, it could have expressly required storage service providers to have the same passive relationship to user content that it required of routing service providers (e.g., broadband Internet access providers). The fact that it didn’t do so signaled to the court that Congress intended the section 512(c) storage safe harbor to protect functions beyond the passive hosting of user content.</p>
<p>In seeking to narrow the scope of storage safe harbors to strictly passive hosts, the IFPI is seeking to push YouTube, a UGC site, into a licensing deal like the ones the recording labels have with on-demand streaming services like Spotify. That would, the IFPI asserts, close an unfair “value gap” between streaming services, which pay market rates for content, and the safe-harbored YouTube, which offers copyright owners the option to take down their infringing content or to monetize it (on YouTube’s terms) through participation in ContentID. What the IFPI ignores in its proposal to amend or narrow intermediary safe harbors is the immense collateral damage to all UGC-sharing services that would occur if storage safe harbors like the one in section 512(c) of the DMCA were restricted to cover only passive hosting sites. Sites where millions and millions of people share huge amounts of <em>their own</em> copyrighted content—photos, videos, and music—can exist only because they are covered by statutory safe harbors. Much, if not most, of the content on YouTube is purely amateur. To restrict the scope of the storage safe harbor primarily to secure increased rents from YouTube for user uploads that include copyrighted sound recordings would benefit one industry at the expense of all online content-sharing services and their users. There has to be a better, more surgical way for the music industry to solve its YouTube problem.</p>
",Intermediary Liability,2015-04-20 19:11,1046,Annemarie Bridy,News
13065,,International,1,1,March 2015 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>March 2015 in Retrospect is available here:</p>
<p><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2015-march/"">http://www.internetjurisdiction.net/observatory/retrospect/2015-march/</a></p>
<p>Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
",Intermediary Liability,2015-04-21 8:16,505,Giancarlo Frosio,News
13109,European Union,Spain,0,0,A Right To Be Forgotten for Hosting Services?,Privacy or Data Protection+Right to Be Forgotten,"<p>European courts are beginning to sort through one of the most important follow-up questions to last spring’s “Right To Be Forgotten” ruling in <em><a href=""http://curia.europa.eu/juris/document/document_print.jsf?doclang=EN&docid=152065"">Google v. Costeja</a></em>: what does the case mean for hosting services? The answer matters for the Twitters, Facebooks and YouTubes of the world – not to mention European hosting services like DailyMotion, local political discussion forums, and blogs or newspapers with user comment sections. And it matters to Internet users, because the way the “Right To Be Forgotten” plays out for these services will have a very real effect on our ability to speak freely and find information online. Courts should protect users’ rights by declining to apply <em>Costeja</em> to hosting services.</p>
<p><span style=""line-height: 1.3em;"">Although the </span><em style=""line-height: 1.3em;"">Costeja</em><span style=""line-height: 1.3em;""> ruling from the Court of Justice of the European Union involved what is popularly called the “Right to Be Forgotten,” it actually established a relatively narrow and concrete right: to stop particular links from appearing in Google’s web search results when users query for a person by name. The CJEU did not go into the philosophical quagmire suggested by the “Right To Be Forgotten” moniker; and it did not address removal rights against platforms that host information posted by users. But of course the same people who want to limit what can be found about them in search results will likely care about sites hosting blog posts or video with the same information. So cases asking hosts to also take down information are inevitable. (In full disclosure, I worked on this issue for web search in my previous role at Google.)</span></p>
<p>One recent Spanish ruling wrangled with this question and reached the right outcome, declining to extend <em>Costeja</em> to require removal of a user’s blog posts from Google’s Blogger service. Plaintiff and the Spanish Data Protection Agency had argued that the hosting platform must remove users’ blog posts, following the loose new standards established for search engines in <em>Costeja.</em> The Appeals court disagreed – for now, at least. As Miquel Peguera explains in his <a href=""http://cyberlaw.stanford.edu/blog/2015/03/spain-right-be-forgotten-does-not-apply-blogger"">post</a> about the case, the Court grounded its decision in Data Protection law, holding that Blogger – unlike Google’s web search engine – did not act as the data controller for content posted by third parties. Because the court’s analysis stopped there, it didn’t reach thorny questions about what it would mean for users’ speech and information rights if Internet hosts had to follow <em>Costeja.</em></p>
<p> </p>
<p><strong>A Recipe for Deleting Users’ Lawful Speech</strong></p>
<p>Compelling hosts to follow <em>Costeja</em> would make it dangerously easy to silence amateur journalists, video-makers, bloggers and others who rely on hosting platforms to reach an audience. Notice-and-takedown systems <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2038214"">already</a> create a risk of over-removal by Internet platforms adopting an “if in doubt, take it down” standard – appeasing the person who demands content removal is easy; leaving content up is risky; analyzing the law to make the right call is expensive. Combine this existing dynamic with <em>Costeja’s</em> new and notoriously hard-to-understand removal guidance, and you have a recipe for easy removal of legal content.</p>
<p>An intermediary operating under <em>Costeja</em> is in a whole new world compared to the known system of notice and takedown for hosting platforms under Europe’s <a href=""http://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32000L0031&from=EN"">E-Commerce Directive</a>. A conventional removal claim – say, for copyright infringement or defamation – can be assessed in light of well-developed national law, including defenses and exceptions developed by courts or legislatures to protect free expression rights. Getting the “right” answer can still be a bit of a crapshoot – a tech company is a poor stand-in for a national court in assessing complex claims – but at least there is law to follow. </p>
<p>By contrast, <em>Costeja</em>’s removal guidance is conveyed in a few short phrases. The CJEU tells us that content should be removed if it is “inadequate, irrelevant or no longer relevant, or excessive in relation to the purposes of the processing” by the intermediary. (Par. 94) But the content should be left up if, “for particular reasons, such as the role played by the data subject in public life … the interference with his fundamental rights is justified by the preponderant interest of the general public” in accessing the content. (Par. 99) European legal experts disagree wildly on what this means in practice; it is unrealistic to expect operators of a broad array of hosting platforms to do any better when faced with difficult real-world removal requests. Courts, like the one that heard the Blogger case in Spain, will be wise not to add hosting companies to the list of entities compelled to stand in judgment over Internet users’ speech under this untested standard.</p>
<p> </p>
<p><strong>Removing Content at Its Source</strong></p>
<p>Another important free expression angle arises from the very different roles played by search engines and hosts in disseminating information online. Removing content from search results is a form of de-indexing. Removing from a host is, effectively, deletion.</p>
<p>Removing web search results makes information harder to find online. That matters a lot if the information concerns the criminal convictions of your babysitter or the malfeasance of your mayor – most users who don’t find out about those in search results will look no further. But at least the information is still out there. People who really want to know can hope to track it down. This seems to have been the CJEU’s goal – to add friction to the system, or as Viktor Mayer-Schönberger <a href=""http://www.newyorker.com/magazine/2014/09/29/solace-oblivion"">says</a>, to create a speed bump on the road to other people’s personal information.</p>
<p><span style=""line-height: 1.3em;"">Applied to Internet hosts, though, </span><em style=""line-height: 1.3em;"">Costeja</em><span style=""line-height: 1.3em;""> wouldn’t put a speed bump in the road – it would be more like a concrete barricade. User-created content that exists on only one site would, once removed, become effectively impossible to find online. In the not uncommon case where an Internet host holds the creator’s only copy, the content could be gone for good. (Of course, sometimes this kind of removal at the hosting source is exactly what courts or legislators intend – the U.S. DMCA and E.U. ECommerce Directive both include removals from hosting sites. But those removals depend on well-established underlying law, and can include procedural protections to correct erroneous removals.) </span><em style=""line-height: 1.3em;"">Costeja</em><span style=""line-height: 1.3em;""> removals from hosted sites would apply the broad standard the court crafted for “speed bump” removals to a whole different class of removals: the ones that can silence speakers completely.</span></p>
<p>As careful readers of <em>Costeja</em> know, the opinion itself supports the idea that it was never intended to reach hosts. For one thing, the Court explicitly says that Google’s search removal obligation sometimes exists even when the underlying indexed site has the right to publish the content. So a motivated and well-lawyered hosting service that received a content removal request under <em>Costeja</em> could point to a lot of reasons not to comply. But Internet users who rely on hosting platforms to express themselves and learn new information deserve better protection than that. They deserve a bright-line rule from European courts that <em>Costeja</em> does not apply to hosting services at all.</p>
<p> </p>
<p> </p>
","Intermediary Liability, Privacy",2015-04-30 7:17,1188,Daphne Keller,News
13159,,International,1,1,April 2015 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>April 2015 in Retrospect is available here:</p>
<p><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2015-april/"">http://www.internetjurisdiction.net/observatory/retrospect/2015-april/</a></p>
<p>Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
",Intermediary Liability,2015-05-13 13:44,505,Giancarlo Frosio,News
13172,,United States,0,0,453 days later...,Copyright+Freedom of Expression,"<p><span style=""line-height: 1.3em;"">Welcome news today from the U.S. Court of Appeals for the 9</span><sup>th</sup><span style=""line-height: 1.3em;""> Circuit. By a vote of 11 to 1, the court </span><a href=""http://cdn.ca9.uscourts.gov/datastore/general/2015/05/18/12-57302%20EB%20opinion.pdf"" style=""font-size: 13px; line-height: 1.3em;"">overturned</a><span style=""line-height: 1.3em;""> its injunction against the controversial video called </span><em style=""line-height: 1.3em;"">Innocence of Muslims</em><span style=""line-height: 1.3em;""> that it had ordered off YouTube back in February 2014.</span></p>
<p>Here's the background. Actress Cindy Lee Garcia was cast in that video in a cameo role and paid $500 to deliver two lines: “Is George crazy? Our daughter is but a child?” The video’s writer/director had a covert plan and instead dubbed over Garcia’s lines and replaced them with: “Is your Mohammed a child molester?” Although her appearance lasted just five seconds, Garcia understandably wanted to be disassociated from the video altogether.</p>
<p>The problem is the legal vehicle her lawyers chose to do so, namely copyright law. Garcia’s copyright theory was both novel and misguided: she claimed to own a copyright in her acting performance and therefore to have the right to stop the video’s distribution. No such copyright exists, the court ruled today, so the video could not be enjoined.</p>
<p>As offensive as the video is (and it certainly is), and as sympathetic as the plaintiff is (and she certainly is), Garcia used the wrong law to address the wrong. She would have been better off pressing her claims of fraud or breach of contract against the writer/director instead of asserting a copyright interest in her fleeting performance.</p>
<p>Today’s opinion thoroughly analyzed the weaknesses in Garcia’s copyright claim and the very high bar that must be cleared before an injunction can issue, given the First Amendment. Yet the opinion is relatively circumspect in recounting the history of how the case reached this point at all – a history about which the court itself cannot be proud.</p>
<p>An earlier panel of the 9<sup>th</sup> Circuit overturned a district court judge and issued that YouTube injunction in the first place, back on February 19, 2014. And not only did it issue the injunction, it initially issued it in secret accompanied by an unprecedented order barring Google from even mentioning its existence. Google admirably <a href=""http://www.scribd.com/doc/209491860/Emergency-stay-Google"">fought</a> against that secret order, and lost.</p>
<p>In addition to the 9<sup>th</sup> Circuit’s opinion today, Judge Stephen Reinhardt <a href=""https://www.citizen.org/documents/RheinhardtEarlyHint.pdf"">wrote</a> separately to focus on the court’s own complicity in the case (though he does not mention the secret order). As he begins that opinion: “This is a case in which our court not only tolerated the infringement of fundamental First Amendment rights but was the architect of that infringement.” Judge Reinhardt then reaffirms the position he advocated from the beginning: that the prior restraint issued by the earlier panel of the court under the guise of copyright infringement should have been subject to emergency and expedited review by the full en banc court. As he writes: “By refusing to immediately rehear this case en banc, we condoned censorship of political speech of the highest First Amendment magnitude.”</p>
<p>Having clerked and practiced in the federal courts for many years, I have immense respect for the court and for the judicial process. Yet I cannot help but think about those 453 days that the injunction remained in effect. Winter turned to spring, which turned to summer, which turned to fall, which turned back to winter, and now it’s spring again. All the while the injunction remained in place, and YouTube was forced to proactively search for and remove what the court has found, by an overwhelming vote, to be Constitutionally protected speech.</p>
<p>It’s now 15 months later, and the 9<sup>th</sup> Circuit has finally issued its decision – a ruling that experts had been anticipating from day one. The court may have reversed its injunction, but at this late date it cannot undo the damage that was done to our Constitution. The First Amendment was left to atrophy while the clock ticked away.</p>
<p>Judge Reinhardt calls his court’s lack of urgency “violence done to the First Amendment.” As he notes, “the exercise of freedom that was lost pending en banc proceedings cannot be recovered.” That loss is ours.</p>
","Copyright and Fair Use, Intermediary Liability",2015-05-18 16:37,265,Tom Rubin,News
13198,,International,1,1,May 2015 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>May 2015 in Retrospect is available here:</p>
<p><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2015-may/"">http://www.internetjurisdiction.net/observatory/retrospect/2015-may/</a></p>
<p>Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
",Intermediary Liability,2015-06-02 15:52,505,Giancarlo Frosio,News
13204,,Mexico,0,0,Debate over the Right to be Forgotten Heats up in Mexico,Right to Be Forgotten+Freedom of Expression,"<p>The controversy over the so called “right to be forgotten” recently surfaced in Mexico. A few months ago, the <a href=""http://inicio.ifai.org.mx/SitePages/ifai.aspx"">Mexican National Institute for the Access to Information</a> (INAI) ordered Google Mexico to remove embarrassing—but true—search results about a prominent businessman. Free speech advocates expressed their concern about the censorial effect of the decision and sided with Google, which is now appealing the decision before the ordinary courts.</p>
<p>The INAI ruled in favor of a transportation magnate, Carlos Sánchez de la Peña, who wanted three links removed from Google search results. The links contained negative comments about the business dealings of Mr. Sánchez’s family—including a government bailout of bad loans. The INAI heard the case after Google Mexico rejected a petition from Mr. Sánchez de la Peña to have the links removed.</p>
<p>In his request to the INAI, Mr. Sánchez claimed that the three Google links distorted and decontextualized information about his activities as an entrepreneur. Mr. Sánchez de la Peña’s family has owned “Estrella Blanca” bus lines for generations. <a href=""https://www.google.com/search?q=S%C3%A1nchez+de+la+Pe%C3%B1a&oq=S%C3%A1nchez+de+la+Pe%C3%B1a&aqs=chrome..69i57.1563j0j8&sourceid=chrome&es_sm=122&ie=UTF-8#q=Carlos+S%C3%A1nchez+de+la+Pe%C3%B1a"">One of the links</a> directed to an article about a lawsuit against Mr. Sánchez’s father, Salvador Sánchez Alcántara, by shareholders in the bus company. Mr. Sánchez de la Peña is named in the story and the <a href=""https://www.google.com/search?q=S%C3%A1nchez+de+la+Pe%C3%B1a&oq=S%C3%A1nchez+de+la+Pe%C3%B1a&aqs=chrome..69i57.1563j0j8&sourceid=chrome&es_sm=122&ie=UTF-8#q=Carlos+S%C3%A1nchez+de+la+Pe%C3%B1a"">snippet accompanying the link</a>. The article also discusses how the company received millions of dollars in loans from Mexican banks that collapsed during the country’s financial crisis in the mid-1990s. The loans, most of them past-due, were absorbed by Mexico’s bank-bailout fund known as IPAB.</p>
<p>The <a href=""https://privacyassociation.org/media/pdf/knowledge_center/Mexico_Federal_Data_Protection_Act_July2010.pdf"">Federal Law on Protection of Personal Data Held by Private Parties</a> [“DP Law”], provides a set of rights called “ARCO rights”, that refer to the rights of Access, Rectification, Cancellation and Objection, that data owners can exercise against the processing of their personal data by private parties. The Regulations to the Federal Law on the Protection of Personal Data [“DP Regulations”] further qualify those rights. However, the principle according to which a person can request the cancellation of his personal data is very vague. Also, limitations to said cancellation right seem highly discretionary and vaguely defined under <a href=""https://cyberlaw.stanford.edu/page/wilmap-mexico"">Article 26</a> of the DP Law as well as under <a href=""https://cyberlaw.stanford.edu/page/wilmap-mexico"">Article 88</a> of the DP Regulations. The INAI commissioners considered that Mr. Sánchez met the privacy-law requirements that allow for the removal of information when its “persistence causes injury” even if the information was lawfully published.</p>
<p>Mexico’s data privacy law contains exceptions to Internet privacy rules if the information is in the public interest. The INAI, however, did not apply the exception, arguing that Google didn’t claim those exceptions when making its case.</p>
<p>The INAI ordered the removal only from google.com.mx. Mexico’s data privacy law only requires the removal of links from local search engines.</p>
<p>Google will be challenging the INAI ruling before the ordinary courts. Google Mexico considers that the INAI decision infringes on the right to access to information and freedom of speech. Free-speech advocates sided with Google Mexico by noting that the INAI ruling would allow politicians and business tycoons to abuse the so-called right to be forgotten by wiping out Internet links that cast them in a negative light. Activists and advocates are warning society about the negative effects of this type of rulings, especially in countries like Mexico, where the independent press and media are still fighting against censorship. The INAI ruling removes pieces of information that are essential for academics, think tanks and critical journalists in their work to hold elusive and criminal government officials accountable for their deeds before Mexican society.</p>
<p><em><a href=""https://www.linkedin.com/pub/jose-francisco-camarena/7/40b/b48"">José Camarena</a> is a Mexican attorney and can be reached at <a href=""mailto:pepecl2003@gmail.com"">pepecl2003@gmail.com</a></em>.</p>
",Intermediary Liability,2015-06-03 6:57,505,Giancarlo Frosio,News
13221,,International,1,1,Global Content Regulation and Jurisdiction: Who Decides?,Privacy or Data Protection+Other IP,"<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:6pt;text-align: justify;""><span id=""docs-internal-guid-fb815870-f64c-4b65-ad45-8f3328a99501""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;"">Policymakers around the world are showing renewed interest in the rules that govern Internet information flow across national borders. New regulation may not sound like good news to those concerned about online information access and free expression, but it’s worth a hard look at what will happen without it: national courts will decide how to regulate content outside their borders. Courts aren’t well-equipped to shape national policy that touches not only on free expression rights but on foreign relations and national IT infrastructure. But that is effectively what they are being forced to do in cases about online content that violates national law. If we believe in democratic process, we should welcome a change of forum for these issues – toward non-judicial branches of government, and ideally toward serious discussion within transnational institutions to set well-considered, rights-based guidelines for these difficult cases.</span></span></p>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:6pt;text-align: justify;""><span id=""docs-internal-guid-fb815870-f64c-4b65-ad45-8f3328a99501""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;"">Courts around the world, hearing claims ranging from privacy to trade secret infringement, are being asked to make meaningful changes to the way Internet users access information. In the most extreme cases, plaintiffs want content removed globally. A </span><a href=""http://www.michaelgeist.ca/2015/06/b-c-court-of-appeal-upholds-global-deletion-order-against-google/""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(17, 85, 204); text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;"">Canadian court</span></a><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;""> affirmed a global removal order of this sort last week, saying that BC courts have jurisdiction to require Google to remove search results from its services for every country in the world. The </span><a href=""http://www.cnil.fr/english/news-and-events/news/article/cnil-orders-google-to-apply-delisting-on-all-domain-names-of-the-search-engine/""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(17, 85, 204); text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;"">French Data Protection Authority</span></a><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;""> is now asserting similar power. Global removal orders raise a lot of hard questions – some familiar to courts from other jurisdiction cases, but many quite novel. When should the forum country’s law regulate information access for the rest of the world? Is the forum country’s foreign policy a factor when a court ruling undermines the sovereignty of lawmakers and courts in other countries? If the forum country asserts this power over other countries, does it concede that other countries’ courts can regulate content access in the forum country? Should the court stay its hand out of concern about creating a “lowest common denominator” Internet, subject to the sum of all countries’ content laws?*</span></span></p>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:6pt;text-align: justify;""><span id=""docs-internal-guid-fb815870-f64c-4b65-ad45-8f3328a99501""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;"">Other cases ask courts to compel foreign Internet defendants to use geotargeting or IP address blocking, so users in the forum country can’t see particular content. That’s what some people thought the </span><a href=""http://ec.europa.eu/justice/data-protection/article-29/documentation/opinion-recommendation/files/2014/wp225_en.pdf""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(17, 85, 204); text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;"">Article 29</span></a><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;""> group was asking Google to do for Right To Be Forgotten removals: just make sure that Europeans could not access the unexpurgated (or less expurgated) versions of search results. IP blocking orders avoid the global censorship questions, but raise thorny new ones. Does the harm averted by the forum country’s IP blocking order in one case offset long-term harm from further balkanizing the Internet? Is blocking Internet access to foreign businesses consistent with the forum country’s trade policies? What are the costs to online speech and innovation as the web becomes gradually less world-wide in nature? If the forum country can re-architect the Internet to isolate its citizens from banned content, is it so wrong for </span><a href=""https://en.wikipedia.org/wiki/Internet_censorship_in_China#Technical_implementation""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(17, 85, 204); text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;"">China</span></a><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;""> or </span><a href=""http://www.washingtonpost.com/blogs/the-switch/wp/2013/08/15/heres-how-iran-censors-the-internet/""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(17, 85, 204); text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;"">Iran</span></a><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;""> to do the same? Would architectural barriers to online “travel” take us back to a world where only the wealthy can experience other legal content regimes, by physically traveling to them – and do we want that?</span></span></p>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:6pt;text-align: justify;""><span id=""docs-internal-guid-fb815870-f64c-4b65-ad45-8f3328a99501""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;"">These are hard questions. Without a clearer shared policy framework, a courtroom is not the right place to ask them. Judges are understandably reluctant to be guided by “pure policy” considerations, which can leave them looking to black-letter jurisprudence developed largely in a pre-Internet age. Courts also often have before them a sympathetic local plaintiff with a legitimate grievance and a difficult path to relief; and a defendant who is either a remote wrongdoer or a technical Internet intermediary, lacking relevant information and perhaps even incentive to defend content created by a user. It should not come as a surprise when many courts in this situation conclude that they have jurisdiction to grant relief by ordering global removal or IP blocking. And every assertion of jurisdiction makes it easier for the next court to do the same.</span></span></p>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:6pt;text-align: justify;""><span id=""docs-internal-guid-fb815870-f64c-4b65-ad45-8f3328a99501""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;"">It is time to move these conversations to the right forums. The recent statement on cross-border data flows from the </span><a href=""https://wcd.coe.int/ViewDoc.jsp?Ref=CM/Rec(2015)6&Language=lanEnglish&Ver=original&Site=CM&BackColorInternet=DBDCF2&BackColorIntranet=FDC864&BackColorLogged=FDC864""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(17, 85, 204); text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;"">Council of Europe</span></a><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;""> is an important start. The European Commission’s prominent inclusion of this issue in the </span><a href=""http://europa.eu/rapid/press-release_IP-15-4653_en.htm""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(17, 85, 204); text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;"">Digital Single Market</span></a><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;""> strategy is another. These questions should not be answered in the context of a single case before a judge, without considered input from other branches of government. Nor should they be answered by national institutions – such as DPAs -- specialized in just some of the many issues in play. Governments with strong national interests in content restriction – </span><a href=""https://en.wikipedia.org/wiki/Internet_censorship_and_surveillance_by_country#.C2.A0China""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(17, 85, 204); text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;"">China</span></a><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;"">, </span><a href=""https://en.wikipedia.org/wiki/Internet_censorship_and_surveillance_by_country#.C2.A0Iran""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(17, 85, 204); text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;"">Iran</span></a><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;"">, </span><a href=""https://en.wikipedia.org/wiki/Internet_censorship_and_surveillance_by_country#.C2.A0Saudi_Arabia""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(17, 85, 204); text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;"">Saudi Arabia</span></a><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;""> – have been crafting policy in this area for a long time, with </span><a href=""http://www.reuters.com/article/2015/05/21/us-russia-internet-idUSKBN0O62H220150521""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(17, 85, 204); text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;"">Russia</span></a><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;""> and </span><a href=""https://edri.org/yet-another-internet-blocking-law-turkey/""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(17, 85, 204); text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;"">Turkey</span></a><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;""> not far behind. Countries and institutions with strong commitments to speech and information rights for citizens need to catch up, and engage policymakers with real expertise to identify national priorities and guide courts. Leaving this question to case-by-case analysis without such a framework is the wrong approach. </span></span></p>
<p></p>
<p><span style=""color: rgb(0, 0, 0); font-family: Arial; font-size: 14.6666666666667px; white-space: pre-wrap; line-height: 1.38; text-align: justify;"">-------------- </span></p>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:6pt;text-align: justify;""> </p>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:6pt;text-align: justify;""><span id=""docs-internal-guid-fb815870-f64c-4b65-ad45-8f3328a99501""><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;"">* </span><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); font-style: italic; vertical-align: baseline; white-space: pre-wrap;"">Bonus questions for all you jurisdiction nerds: </span><span style=""font-size: 14.6666666666667px; font-family: Arial; color: rgb(0, 0, 0); vertical-align: baseline; white-space: pre-wrap;"">Does it matter if the law at issue is relatively consistent across national borders (counterfeiting, say) or relatively diverse (privacy, election campaigning)? Does it matter if the disputed content is illegal in the “site of harm” country but legal in the “site of publication” country? What if defendant did not intentionally target the forum country? Does it matter if the forum country’s law creates only a “soft conflict” by removing more content than a foreign country’s law would require, versus a “hard conflict,” by actually violating rights protected by that country’s law? Does it matter if a defendant Internet company complies with forum country’s law on a nationally targeted version of the service, but follows other countries’ laws on other versions? Where defendant is an intermediary, does it matter if relief might be available against the actual content creator? Does the answer depend at all on that intermediary’s willingness to hand over, to plaintiff or prosecutors, private user data about the content creator?</span></span></p>
<p> </p>
","Architecture and Public Policy, Intermediary Liability",2015-06-15 1:19,1188,Daphne Keller,News
13240,Council of Europe,Estonia,0,0,Delfi Reloaded: The ECHR Confirms that Internet News Portals Are Liable for User-Generated Defamatory Comments,Defamation or Personality Rights,"<p>Today, the Grand Chamber of the European Court of Human Rights (ECHR) delivered a long-awaited decision in Delphi AS v. Estonia. Confirming an <a href=""http://hudoc.echr.coe.int/sites/eng/pages/search.aspx?i=001-126635"">earlier judgment</a> rendered on October 10, 2013 by the Fifth Section of the ECHR, the Grand Chamber held that finding Delfi liable for comments posted by third parties had not been in breach of its freedom to impart information. Please refer to our <a href=""https://cyberlaw.stanford.edu/blog/2013/10/european-court-human-rights-holds-delfiee-liable-anonymous-defamation"">previous blog post</a> for a report on the October 2013 decision and the facts of the case.</p>
<p>The ECHR had been called upon to review the validity of a number of judgments form Estonian courts against Delfi according to the principles of the <a href=""http://conventions.coe.int/treaty/en/Treaties/Html/005.htm"">European Convention on Human Rights</a>. For the first time, the ECHR had to consider whether an Internet news portal should be liable for user-generated comments. In particular,</p>
<p style=""margin-left:.5in;"">the case concerned the duties and responsibilities of Internet news portals which provided on a commercial basis a platform for user-generated comments on previously published content and some users – whether identified or anonymous – engaged in clearly unlawful hate speech which infringed the personality rights of others.</p>
<p>The Grand Chamber found in favor of Estonia by 15 votes to 2 and largely confirmed the conclusions reached by the smaller chamber in October 2013. In sum, the Grand Chamber found that</p>
<p style=""margin-left:.5in;"">the Estonian courts’ finding of liability against Delfi had been a justified and proportionate restriction on the portal’s freedom of expression, in particular, because: the comments in question had been extreme and had been posted in reaction to an article published by Delfi on its professionally managed news portal run on a commercial basis; the steps taken by Delfi to remove the offensive comments without delay after their publication had been insufficient; and the 320 euro fine had by no means been excessive for Delfi, one of the largest Internet portals in Estonia.</p>
<p>The decision of the ECHR was a blow to freedom of expression advocates, who submitted briefs in support of Delfi warning about the implications of the case for freedom of expression, anonymity online and innovation.</p>
<p>The full decision is available <a href=""http://hudoc.echr.coe.int/sites/eng/pages/search.aspx?i=001-155105"">here</a>. The press release can be found <a href=""http://hudoc.echr.coe.int/sites/eng-press/pages/search.aspx?i=003-5110487-6300958"">here</a>.</p>
",Intermediary Liability,2015-06-16 19:58,505,Giancarlo Frosio,News
13254,,France,0,0,French Privacy Authority Orders Google to Delist RTBF Infringing Results Worldwide,Right to Be Forgotten+Privacy or Data Protection+Freedom of Expression,"<p>A few days ago, the <em>Commission nationale de l'informatique et des libertés</em> (CNiL), the French data protection authority, ordered Google to apply the <a href=""https://cyberlaw.stanford.edu/blog/2014/05/internet-search-engines-are-liable-processing-personal-data-says-ecj"">right to be forgotten (RTBF)</a> on all domain names of Google's search engine, including the .com domain.</p>
<p>As many other national data protection authorities in Europe, the CNil supervises the application of the European Court of Justice (ECJ)'s judgment on the RTBF in case of refusal by the search engines to carry out the the requested delisting. In response to hundreds of individual complaints since the May 2014 decision by the ECJ, the CNil requested Google to delist search results in multiple occasions. In all those instances, the CNiL expressly requested that the delisting had to be effective across the whole search engine, regardless of the domain extension through which the users access the information.</p>
<p>However, so far, Google applied the delisting only to European extensions of its search engine. RTBF infringing search results still remained accessible in the French territory from google.com and other non-European extensions.  </p>
<p>With its latest decision, the CNiL puts now Google on formal public notice to delist search results from all the search engine's extensions, which are accessible from the French territory, within 15 days. If Google will not act promptly, the CNiL Select Committee will suggest a sanction to be imposed on the company.  </p>
<p>The CNiL's decision is in accordance with the <a href=""https://cyberlaw.stanford.edu/blog/2014/11/eu-data-protection-authority-adopts-guidelines-implementation-right-be-forgotten"">Article 29 Working Party's Guidelines</a> (Guidelines) on the implementation of the ECJ judgment on the RTBF. In its November 2014 Guidelines, the European data protection authority noted that limiting de-listing to EU domains cannot be considered a sufficient means to satisfactorily guarantee the rights of data subjects according to the ruling. In practice, the Guidelines stated, ""this means that in any case de-listing should also be effective on all relevant .com domains."" </p>
<p><span style=""font-size: 13.0080003738403px; line-height: 20.0063037872314px;"">A press release in English commenting on the </span>CNiL's decision is available <a href=""http://www.cnil.fr/english/news-and-events/news/article/cnil-orders-google-to-apply-delisting-on-all-domain-names-of-the-search-engine/"">here</a>.</p>
<p> </p>
",Intermediary Liability,2015-06-23 0:36,505,Giancarlo Frosio,News
13255,,Brazil,0,0,Brazilian Supreme Court Adopts Common Law Tests for Intermediary Liability in Copyright Case,Copyright,"<div>Last month, the <em>Superior Tribunal de Justiça</em> (STJ), the highest appellate court in Brazil for non-constitutional questions of federal law, awarded a landmark decision in a case discussing the liability of the social networking site Orkut for copyright infringing user-generated content on its site. The Court ruled that content providers cannot be held liable for copyright violations committed by third parties if they do not profit from copyright infringement on the part of its users. The Court also ruled that Orkut could not be held responsible for links that users post to external pages containing copyright infringing material. </div>
<div> </div>
<div>The STJ upheld the judgement passed by the appellate court. The Court mentioned that copyright infringement is excluded from the limitations on intermediary liability contained in the <a href=""https://cyberlaw.stanford.edu/page/wilmap-brazil""><em>Marco Civil da Internet </em>Act</a>. Moreover, as in other cases, the court maintained its understanding that the <em>Marco Civil da Internet </em>would nevertheless not be applicable to the facts, as they have occurred prior to its enactment. Thus, the judges agreed that only the general principles included in the Brazilian Civil Code were applicable to this case.</div>
<div> </div>
<div>In its reasoning, the judge cited the <em>Betamax </em>case and the <em>Napster </em>case, and thereby applied to the case a standard resembling the <em>Betamax</em>'s ""capable of substantial non-infringing uses"" defense for the first time in Brazil.  The court adopted two criteria to deny the claims on contributory infringement: “1 – [t]he structure and posture of the provider have not contributed to the copyright violation; and 2 – [n]o material damages arose from the inertia of the provider.” By the first consideration, the Court effectively applied the doctrine of contributory infringement, and subsequently ruled that the provider has not incurred in it. The terminology, “structure” and “posture”, is very similar to the tests set by the Napster and Grokster cases, respectively. Moreover, by the second criterion, the court applied the vicarious liability doctrine a la Napster. Although similar doctrines exist in Brazil, the STJ never applied this Common Law counterpart. The following passage of the opinion specifically spelled out the two criteria: </div>
<div> </div>
<div style=""margin-left:.5in;"">Orkut did not have [file] sharing as an objective. It was not possible to download [files] from the webpages of the social network. The architecture of the social network did not substantially provide to its users the necessary means to the violation of rights. In the present case, the social network does not provide a technological instrument for file sharing. To hold the provider liable would be as holding the post office liable for crimes perpetrated in private written correspondences.</div>
<div> </div>
<div>Finally, the STJ ruled, in consonance with previous judgements, that linking to infringing material does not constitute per se contributory infringement.</div>
<div> </div>
<div>The ruling is not yet publicly available.</div>
<div> </div>
<div><em><a href=""https://br.linkedin.com/in/felipebusnello/en"" target=""_blank"">Felipe Octaviano Delgado Busnello</a> is a qualified Brazilian attorney active in the field of internet and intellectual property law. He can be reached at felipe.busnello at gmail.com.</em></div>
<div> </div>
",Intermediary Liability,2015-06-24 2:28,1134,Felipe Busnello,News
13258,,Netherlands,0,0,"Facebook Has to Identify Uploader of Revenge Porn, Says Dutch Court",Revenge Porn,"<p>A Dutch Court today <a href=""http://uitspraken.rechtspraak.nl/inziendocument?id=ECLI:NL:RBAMS:2015:3984"">ruled</a> that Facebook has a duty to identify a person who has uploaded a revenge porn video on its social network. In this case, the video displays a woman, Chantal, performing oral sex on her now ex-boyfriend. A fake account bearing Chantal’s name was created and used to share the private video with her friends and others. Chantal’s ex-boyfriend, who recorded the video, has always denied uploading the video. Although Facebook removed the video within one hour, the video had already found its way online and is still being shared. Chantal went to court and claimed release of information identifying the person who created the fake account and uploaded the video.</p>
<p>The type of nonconsensual pornography Chantal was confronted with is commonly referred to as ‘revenge porn’ since it is often posted online by ex-partners. Unlike in <a href=""http://www.loc.gov/lawweb/servlet/lloc_news?disp3_l205404206_text"">Japan</a> or <a href=""http://www.independent.co.uk/news/uk/home-news/revenge-porn-illegal-in-england-and-wales-under-new-law-bringing-in-twoyear-prison-terms-10173524.html"">England</a>, there are no specific legal rules regarding revenge porn in the Netherlands. In December 2014, former Minister of Security and Justice Ivo Opstelten, <a href=""http://www.rijksoverheid.nl/documenten-en-publicaties/kamerstukken/2014/12/20/antwoorden-kamervragen-over-het-strafbaar-stellen-van-wraakporno.html"">argued</a> that there is no lacuna in Dutch criminal law as far as nonconsensual pornography is concerned. According to the Minister, provisions in Dutch criminal law on insult and defamation can be used to prosecute revenge porn. Also the current Minister of Security and Justice, Ard van der Steur, <a href=""http://www.rijksoverheid.nl/bestanden/documenten-en-publicaties/kamerstukken/2015/06/13/tk-verzoek-vkc-reactie-rtl-nieuwsuitzending-over-wraakporno/lp-v-j-0000008372.pdf"">believes</a> that the current legal regime suffices to combat revenge porn. Meanwhile, the Dutch police <a href=""https://www.google.nl/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0CCIQFjAA&url=http%3A%2F%2Fwww.nrc.nl%2Fhandelsblad%2Fvan%2F2014%2Fnovember%2F21%2Fblote-fotos-plus-afpersing-daar-doet-de-politie-1442790&ei=fB2LVZnfHoHMsgGUiYnIAQ&usg=AFQjCNHZ5y1mFJyWexT9N3gU7PXxHtfN1Q&sig2=jlsvXhFVFS_5i_Kj4dUTvw"">seems</a> to prioritize cases of revenge porn where these are combined with elements of stalking or extortion, leaving ‘ordinary’ cases of revenge porn relatively uninvestigated.</p>
<p>A <a href=""https://www.youtube.com/watch?v=ONVz3JCi4xQ"">TV report</a> by crime reporter Peter R. de Vries on Chantal’s case has shown a somewhat lax attitude of the police towards her case. Chantal reported the crime to the Dutch police one day after the video was published on Facebook. The police requested information about the fake-account from Facebook, but did so only after the <a href=""https://www.facebook.com/help/224562897555674?sr=14&query=how%20long%20delete&sid=1BeoaC7xmVf7PKHB5"">90-day period</a> during which Facebook may still store information about a deleted account. Facebook had thus already <a href=""http://www.parool.nl/parool/nl/4/AMSTERDAM/article/detail/4067941/2015/06/10/Facebook-heeft-gegevens-wraakporno-gewist.dhtml"">deleted</a> the information about the account, leaving both the police and Chantal with little hope of finding the person who uploaded the revenge porn.</p>
<p>As a civil law procedure seemed the only option left, Chantal started a case against Facebook to uncover the identity of the perpetrator. The Lower Court of Amsterdam today <a href=""http://uitspraken.rechtspraak.nl/inziendocument?id=ECLI:NL:RBAMS:2015:3984"">ruled</a> against Facebook. According to the Court, Facebook acted unlawfully by not releasing the information. A duty to release such information exists if someone can only stop unlawful actions of another through the release of personal data by the provider. Although Facebook argued that it no longer possesses the requested information, the Court has doubts whether that actually is the case. The Court therefore ordered Facebook to release any information relating to the owner of the fake account. In case Facebook is unable to release such information, the company should allow an independent third-party to investigate whether Facebook had or still has the information, and what that information entailed or entails.</p>
<p>A huge victory for Chantal and other victims of revenge porn.</p>
<p><em><a href=""http://www.stefankulk.nl/"">Stefan Kulk</a> is a researcher at the Centre for Intellectual Property Law (CIER) of Utrecht University. He can be reached at S.Kulk at uu.nl</em></p>
",Intermediary Liability,2015-06-25 11:03,1261,Stefan Kulk,News
13284,,International,1,1,June 2015 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>June 2015 in Retrospect is available here:</p>
<p><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2015-june/"">http://www.internetjurisdiction.net/observatory/retrospect/2015-june/</a></p>
<p>Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
",Intermediary Liability,2015-07-02 4:29,505,Giancarlo Frosio,News
13322,,International,1,1,July 2015 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>July 2015 in Retrospect is available here:</p>
<p><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2015-july/"">http://www.internetjurisdiction.net/observatory/retrospect/2015-july/</a></p>
<p>Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
",Intermediary Liability,2015-07-31 15:30,505,Giancarlo Frosio,News
13355,European Union,,0,0,New paper: The Shaky Ground of the Right to Be Delisted,Right to Be Forgotten+Privacy or Data Protection+Freedom of Expression,"<p>I’ve just posted a new paper titled <a href=""http://ssrn.com/abstract=2641876"">“The Shaky Ground of the Right to Be Delisted”</a> to the ssrn website, which deals with the so called “right to be forgotten” as it was crafted by the Court of Justice of the European Union in its landmark <a href=""http://curia.europa.eu/juris/document/document.jsf?text=&docid=152065&doclang=EN""><em>Google Spain</em> ruling</a>.</p>
<p>Here is the abstract:</p>
<p>It has long been discussed whether individuals should have a “right to be forgotten” online to suppress old information that could seriously interfere with their privacy and data protection rights. In the landmark case of Google Spain v AEPD, the Court of Justice of the European Union addressed the particular question of whether, under EU Data Protection Law, individuals have a right to have links delisted from the list of search results, in searches made on the basis of their name. It found that they do have this right – which can be best described as a “right to be delisted” – when some conditions are met.</p>
<p>The ruling, which imposes on search engines the duty to assess and accommodate delisting requests, has proven to be highly controversial. Strong feelings have been expressed either in favor or against it, in what may be seen as a clash between the values of personal data protection and freedom of expression.</p>
<p>This article does not delve into this underlying debate. Instead, it aims to explore the solidness of the ground on which the right is based. It begins by providing an overview of the relevant elements of EU data protection law so as to allow readers not familiar with its nuances to properly follow the discussion. After presenting the facts of Google Spain, both at national and EU level, the article discusses how the ‘right to be delisted’ was crafted by the CJEU. It argues that it is based on shaky ground, as it is premised on the characterization of search engines as “data controllers,” which is arguably at odds with their intermediary role and – in the absence of specific safeguards – makes their activity largely incompatible with the data protection legal framework. Moreover, the article discusses how the Court failed to devise a proper balance of the different rights at stake, particularly that of freedom of expression and information. It suggests that the intermediary role of generalist search engines should be adequately protected, both under the data protection legal framework as well as under the liability limitation scheme established by the E-Commerce Directive. This, however, is not likely to be achieved in the near future. A careful approach by national courts and data protection authorities is thus suggested as a way to fix some of the shortcomings identified in the ruling.</p>
<p> </p>
","Intermediary Liability, Privacy",2015-08-17 11:46,678,Miquel Peguera,News
13415,,International,1,1,August 2015 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>August 2015 in Retrospect is available here:</p>
<p><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2015-august/"">http://www.internetjurisdiction.net/observatory/retrospect/2015-august/</a></p>
<p>Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
",Intermediary Liability,2015-09-08 3:14,505,Giancarlo Frosio,News
13437,,France,0,0,"The ‘Right to Be Forgotten’, the right to be included, and global content regulation",Right to Be Forgotten,"<p>Today the French Data Protection regulator, CNIL, <a href=""http://www.theguardian.com/technology/2015/sep/21/french-google-right-to-be-forgotten-appeal"">reaffirmed its position</a> that Google must apply European “Right to Be Forgotten” (RTBF) law globally, by removing content from its services in all countries.  Europe’s RTBF laws are rooted in citizens' rights to data protection and privacy.  They are inconsistent with U.S. and other countries’ free expression laws, because they require suppression of information even if that information is true and not causing harm. In the U.S., the First Amendment would not allow a court to force a search engine to delist this kind of data.   (Europe has its own version of this issue: European law protects speech that must be removed under Russian law, probably including Russia’s version of RTBF.  It’s not clear how CNIL or France would react if Russia applied that law to restrict content for French Internet users.)</p>
<p>As many commentators have pointed out, CNIL’s position creates a conflict between the rights of European citizens to privacy and data protection, and the rights of people in other countries to access information.   Perhaps ironically, European law typically does a much better job than US law at defining and protecting “access to information” as a right distinct from the right to free expression. France is one of several countries where citizens have asserted a legal right to prevent Internet intermediaries from voluntarily removing content.  In a case working its way through court in Paris, a French schoolteacher is <a href=""https://www.washingtonpost.com/news/the-intersect/wp/2015/03/09/facebook-censored-a-nude-painting-and-it-could-change-the-site-forever/"">suing Facebook</a> for removing his post of a Gustave Courbet painting under its nudity policy.  His claim would never survive in an American court: U.S. law could not require Facebook to host nude content posted by users if it didn’t want to. The U.S. approach suggests a greater fear of government censorship, while the EU approach suggests fear and distrust of discretionary private decision-making, perhaps especially on the part of U.S. based companies.</p>
<p>How to reconcile France’s Facebook Courbet case and its Google CNIL case?  Are intermediaries subject to compulsory inclusion of content, as well as compulsory removal? In fairness, one case is much more advanced than the other – we don’t yet know if the court will agree that the Facebook plaintiff has a cause of action, though we know it has taken jurisdiction.   But they reflect profoundly different approaches to speech on the Internet, and to the power of one country’s law to regulate. If the French court did decide that Facebook must reinstate the plaintiff’s post, would it order reinstatement globally?  Or does French privacy/data protection law have different global reach from French free expression/access to information law?</p>
<p>At front and center of both these cases is the question of who decides what information the public can see – and what parts of the world must abide by their decision.  This is a <a href=""http://cyberlaw.stanford.edu/blog/2015/06/global-content-regulation-and-jurisdiction-who-decides-0"">hard issue</a>.  Lawmakers, courts and companies will all make mistakes.  Those mistakes will be much more consequential – we will all bear the consequences – if regulators succeed in compelling Internet companies to remove controversial content globally.  </p>
","Architecture and Public Policy, Intermediary Liability, Privacy",2015-09-21 16:00,1188,Daphne Keller,News
13464,,European Union,0,0,Intermediary Liability and User Content under Europe’s New Data Protection Law,Right to Be Forgotten+Privacy or Data Protection+Freedom of Expression,"<p><em>Cross-posted to the <a href=""http://policyreview.info/articles/news"">Internet Policy Review News & Comments</a> </em><em style=""font-size: 13.008px; line-height: 1.538em;"">and <a href=""https://inforrm.wordpress.com/tag/daphne-keller/"">Inforrm</a> blogs.</em></p>
<p>A big new law is coming, and a lot of companies doing business online aren’t going to like it.  Neither will many advocates of civil liberties for Internet users. Europe’s pending <a href=""http://www.twobirds.com/en/practice-areas/privacy-and-data-protection/eu-framework-revision"">General Data Protection Regulation</a> (GDPR) updates and overhauls EU data protection law – the law that produced this week’s <a href=""http://curia.europa.eu/juris/documents.jsf?num=C-362/14"">Schrems</a> case and last year’s “Right to Be Forgotten” <a href=""http://curia.europa.eu/juris/document/document_print.jsf?doclang=EN&docid=152065"">ruling</a> in the EU. Data protection has long been a field considered arcane and impenetrable by many US lawyers.  Most businesses and other entities outside Europe have rightly paid little attention in the past because the law seemingly did not apply to them.  But if draft GDPR provisions circulating at this near-final stage in the lawmaking process are enacted into law, that’s about to change.  Companies that previously fell outside data protection jurisdiction, including those with minimal ties to Europe, are being brought within its scope.  For many, compliance will entail meaningful costs in money and engineering time.  And online companies that deal in content – whether as creators and online publishers or as technical intermediaries – may find themselves receiving unprecedented erasure demands from European citizens or regulators.  Going forward, if users around the world find their Facebook reminiscences about European acquaintances disappearing – or can’t find tweets about individuals who <a href=""http://www.nytimes.com/2014/10/04/business/media/times-articles-removed-from-google-results-in-europe.html"" target=""_blank"">settled fraud allegations with the FTC</a> – this law will likely be the reason.</p>
<p>The GDPR is in many other respects a very good law. Europe already provides more robust legal privacy protections than many countries, including the US; this will make those protections even stronger and advance global norms around the privacy rights of Internet users.<a href=""#_edn1"" name=""_ednref1"" title="""" id=""_ednref1""><sup><sup>[1]</sup></sup></a>  And it should surprise no one that European lawmakers, angered by the <a href=""https://www.google.com/search?q=snowden+europe+anger&oq=snowden+europe+anger&aqs=chrome..69i57.3926j1j7&sourceid=chrome&es_sm=91&ie=UTF-8"">Snowden revelations</a> and the US government’s lackadaisical response, want more control over what personal data leaves Europe and how it is protected and safeguarded.  But the GDPR has many other consequences, intended or unintended, for free expression, innovation, and the cost of doing business on the Internet.  Those deserve much more public discussion than they are currently getting.</p>
<p>Over the coming months, I will be unpacking these elements of the GDPR in a series of blog posts.<a href=""#_edn2"" name=""_ednref2"" title="""" id=""_ednref2""><sup><sup>[2]</sup></sup></a>  My focus will mostly be on how the law affects Internet intermediaries – and through them, users’ ability to receive and impart information using the Internet.  Some aspects I discuss, like jurisdiction and the “Right to Be Forgotten,” will be important for other kinds of online entities as well. The series isn’t about privacy under the GDPR, and it won’t focus on data protection law governing collection and use of user data in logs or other back-end storage systems.  Great coverage of privacy aspects is available from <a href=""https://edri.org/gdpr-document-pool/"">public interest groups</a>, <a href=""https://www.huntonprivacyblog.com/2015/05/05/hunton-releases-guide-proposed-eu-general-data-protection-regulation/"">law firms</a>, and other sources.</p>
<p>A major goal of this series is to foster better conversation between data protection experts and practitioners focused on other parts of Internet law -- particularly intermediary liability and free expression.  My own background is in Internet law.  I am not a data protection lawyer.  In my previous role as Associate General Counsel for Google, I had an immersive real-world education in data protection, most recently in relation to the CJEU’s “Right to Be Forgotten” ruling in <a href=""http://curia.europa.eu/juris/document/document_print.jsf?doclang=EN&docid=152065""><em>Costeja</em></a>.  But there are other areas of data protection law where I am a relative novice.  My hope is that data protection practitioners, as well as other Internet law mavens, will leave comments here or otherwise reach out with feedback, including criticism.  These posts will later be aggregated in a single publication, which will be greatly improved by your comments.</p>
<p><strong>A brief background on data protection law, intermediary liability, and the GDPR</strong></p>
<p>The law of data protection is generally very foreign to US lawyers.  But some version of it exists in many countries around the world, not just in Europe,<a href=""#_edn3"" name=""_ednref3"" title="""" id=""_ednref3""><sup><sup>[3]</sup></sup></a> and provides important rights to citizens.  Data protection is enshrined in the EU <a href=""http://www.europarl.europa.eu/charter/pdf/text_en.pdf"">Charter</a> of Fundamental Rights as a right distinct from privacy: a broad right to limit processing of all information relating to oneself, not just information that invades personal privacy.   Where it conflicts with other fundamental rights, including rights to receive and impart information, the rights at issue must be balanced.  The 1995 <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:31995L0046:en:HTML"">Data Protection Directive</a> sets out a detailed framework for the data protection right, including specific legal grounds for entities to process personal data.  It also establishes regulatory bodies for enforcement.  National and sub-national Data Protection Agencies (DPAs) are the primary enforcers, and have ongoing relationships with many regulated entities.  For most Internet companies, the foremost data protection issue has been, and will continue to be, the backend processing of data about users – maintaining account information, for example, or tracking behavior on a site.</p>
<p>The law of intermediary liability limits and defines the legal responsibility of technical intermediaries for content posted online by third parties.  In the US, key intermediary liability laws are the <a href=""https://www.law.cornell.edu/uscode/text/17/512"">DMCA</a> for copyright and <a href=""https://www.law.cornell.edu/uscode/text/47/230"">CDA 230</a> for defamation, invasion of privacy, and most other concerns.  In the EU, intermediary liability is governed by Articles 12-15 of the <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:32000L0031:en:HTML"">eCommerce Directive</a>, as implemented in the national laws of Member States.  Protected intermediaries generally have no obligations to police, and no liability for unlawful user content until they know about it.<a href=""#_edn4"" name=""_ednref4"" title="""" id=""_ednref4""><sup><sup>[4]</sup></sup></a>   To comply with these laws, intermediaries operate <a href=""https://en.wikipedia.org/wiki/Notice_and_take_down"">notice and takedown</a> systems to remove content when notified that it violates the law.  In theory intermediaries should only remove user content if the notice is correct and the content actually is illegal – but intermediaries often delete content based on inaccurate or bad faith accusations, leading to over-removal of Internet users’ lawful speech.<sup><sup><a href=""#_edn5"" name=""_ednref5"" title="""" id=""_ednref5"">[5]</a></sup></sup></p>
<p>Historically, many lawyers have not drawn a connection between data protection and the law of intermediary liability.  The two fields use very different vocabularies, and are for the most part interpreted, enforced and litigated by different practitioners.  A lawyer who views an issue through the lens of intermediary liability and one who views the same issue through the lens of data protection may have trouble even understanding each other’s concerns. </p>
<p>But if the two fields were ever really separate, the CJEU’s 2014 “Right to Be Forgotten” ruling in the <a href=""http://curia.europa.eu/juris/document/document_print.jsf?doclang=EN&docid=152065""><em>Costeja</em></a> case changed that.  The court ruled that Google had to de-list certain search results when users searched for the plaintiff’s name.  It prescribed what is effectively a notice and takedown system to remove search results, but arrived at this remedy through the language and logic of data protection – with no reference to Europe’s intermediary liability rules.<a href=""#_edn6"" name=""_ednref6"" title="""" id=""_ednref6""><sup><sup>[6]</sup></sup></a>  <em>Costeja</em> follow-on cases will likely force lower courts to grapple more directly with questions about how the two areas of law fit together.  Even as those cases progress, however, EU legislators are overhauling the governing law by replacing the Data Protection Directive with the pending GDPR.</p>
<p><strong>Legislative Process for the GDPR</strong></p>
<p>The GDPR has been in the works since January 2012, when the European Commission proposed a comprehensive update and reform of the 1995 Data Protection Directive.  A number of drafts from different EU governance bodies have been released since.<a href=""#_edn7"" name=""_ednref7"" title="""" id=""_ednref7""><sup><sup>[7]</sup></sup></a>  (This discussion does not distinguish between drafts except where differences are relevant.)   The GDPR is now in a final “trilogue” process, in which remaining differences will be resolved.  One announced timeline put finalization as early as <a href=""http://www.eppgroup.eu/news/Data-protection-reform-timetable"">December</a>, though such deadlines often slip.  The law will come into force two years after its publication date.  Because it is a Regulation rather than a Directive, it will not have to be implemented as separate legislation in each member state of the EU.  Rather, it will automatically go into effect.  The GDPR covers a lot of ground, with provisions addressing everything from data portability, to coordination between national DPAs, to company codes of conduct and appointment of data protection officers.  A good summary of the process and overall issues as of June is <a href=""http://www.dataprotectionreport.com/2015/06/european-council-approves-eu-general-data-protection-regulation-draft-final-approval-may-come-by-end-of-2015/"">here</a>, and a substantive Q&A from the European Parliament is <a href=""http://www.europarl.europa.eu/news/en/news-room/content/20130502BKG07917/html/QA-on-EU-data-protection-reform"">here</a>.</p>
<p>There is a chance that some of the sound and fury around the GDPR will come to nothing, if provisions of the GDPR are obviated by other sources of law – such as one of the pending <a href=""http://arstechnica.com/tech-policy/2015/06/wikileaks-releases-secret-tisa-docs-the-more-evil-sibling-of-ttip-and-tpp/"">trade agreements</a> with the US, or laws arising from the EU’s new <a href=""http://ec.europa.eu/priorities/digital-single-market/"">Digital Single Market (DSM) initiative</a>.  This possibility of preemption could explain why trade and business groups have been relatively unengaged with the GDPR.  But the DSM process is in its infancy, and trumping the GDPR through a trade agreement seems like a long shot.  European lawmakers do not seem disposed to make major concessions to the US <a href=""http://www.channelregister.co.uk/2015/10/06/silicon_valley_after_max_schrems_safe_harbour_facebook_google_analysis/"">right now</a> on issues of privacy and data protection.  And to the extent that US trade negotiators are seeking such concessions, their priorities may not lie with the issues I identify here.</p>
<p>Final passage of the GDPR will not necessarily answer the questions raised in this series about intermediaries and user access to information.  Practitioners have significant unresolved differences about how certain points in the 1995 Directive should be interpreted; the GDPR probably won’t change that.  Existing drafts are unclear on some key points, and seem likely to remain so – there can be good reasons for negotiators to choose constructive ambiguity, leaving room for DPA or court interpretation after the law is enacted.  The upshot is that we will not necessarily see expert consensus on everything the GDPR means, and what parts of the law it has changed, even once its language is finalized.</p>
<p>Ambiguous drafting, intentional or not, will likely leave room for litigation and policy battles about the GDPR’s impact on Internet intermediaries and user free expression.  But it is clear that overall the Regulation moves the needle in a troubling direction for online innovation and civil liberties.  It extends jurisdiction to a vast new group of Internet companies, imposing burdensome regulatory obligations on companies that have never heard of this law.  It extends “Right to Be Forgotten” content erasure requirements, applying European legal standards to require deletion of content that is legal in other places.  By the same token, it puts decisions balancing European users’ speech and privacy rights into the hands of foreign technology companies, instead of national courts.  And it tilts the playing field for the people whose rights are affected: it expands rules and institutions to vindicate privacy rights, but has no countervailing increase in resources or legal channels to protect speech and information rights.  These issues merit much closer consideration before the GDPR is finalized and brought into effect.</p>
<p> </p>
<p align=""center""><strong>Frequently Asked Questions and Rough Answers</strong></p>
<p> </p>
<p><strong>1. Core Questions About the GDPR and Intermediary Liability</strong></p>
<p>Later blog posts will address these topics in more depth.</p>
<p><a name=""Jurisdiction"" id=""Jurisdiction""></a></p>
<p style=""margin-left:.5in;""><em>Q: What entities outside Europe will fall under GDPR jurisdiction?</em></p>
<p style=""margin-left:.5in;"">A:  A lot.  The GDPR asserts jurisdiction over entities that offer services to or “monitor” EU users.  “Monitoring” seems to be defined broadly enough to include fairly standard web and app customization features, so the law reaches many online companies outside of the EU.  In practice, regulators presumably will not prioritize or dedicate limited resources to policing small and distant companies.  But the GDPR will be an issue for companies with growing EU user bases and presence in Europe; and regulators can choose to enforce the law against many more entities around the world.</p>
<p style=""margin-left:.5in;""><em>Q: What’s this about Controllers and Processors?</em></p>
<p style=""margin-left:.5in;"">A: These are key terms under existing data protection law and in the GDPR.  Regulated entities are generally classified as either Controllers or Processors.  Distinct legal obligations flow from that classification.  Controllers are, roughly speaking, entities that hold personal data and decide what to do with it.  Because they are the decision-makers, they have more obligations under the law – including compliance with erasure or “Right to Be Forgotten” requirements.  Processors hold personal data, but follow instructions from a controller about what to do with it.  Their legal duties are correspondingly fewer.  In a simple example, a firm that holds records about its employees is a controller of their personal information; if it outsources payroll operations under contract with a payroll company, that company is a processor.  The CJEU’s determination that Google acted as a controller in operating web search was a key holding of <em>Costeja</em>.  More on the controller/processor distinction is <a href=""https://www.dataprotection.ie/docs/Are-you-a-Data-Controller-/43.htm"">here</a>.</p>
<p style=""margin-left:.5in;""><em>Q: What about the “Right to Be Forgotten”?</em></p>
<p style=""margin-left:.5in;"">A: It’s not going away.  In the GDPR, it is currently enumerated as a right to “Erasure.”  In recent drafts it has been a right exercisable only against data controllers, not data processors.  That would mean Google web search still has to do these removals.  There is room for debate about the obligations of other Internet intermediaries, such as Twitter.  Content providers can also be required to honor “Right to Be Forgotten” removal requests, but under different substantive standards for determining what to remove.</p>
<p style=""margin-left:.5in;""><em>Q: Does the GDPR clear up whether intermediaries can rely on intermediary liability “safe harbors” or notice and takedown systems under the eCommerce Directive when they receive an erasure request?</em></p>
<p style=""margin-left:.5in;"">A:  I don’t think so.  But there will be disagreement on this.</p>
<p style=""margin-left:.5in;""><em>Q: How does the GDPR directly address free expression?</em></p>
<p style=""margin-left:.5in;"">A: Article 80, which in most drafts is titled “Processing of personal information and freedom of expression,” requires Member States’ laws to include exemptions and derogations protecting speech and information rights.  That’s a lot of pressure to put on national law, which historically has varied widely in its protection of such rights.<a href=""#_edn8"" name=""_ednref8"" title="""" id=""_ednref8"">[8]</a>  More troublingly, some drafts would offer exceptions only for the “processing of personal data carried out solely for journalistic purposes or the purpose of artistic or literary expression.”  (EDPS Art. 80)  In other words, if the work is for some other purpose, or if it has a mixed purpose, the exceptions would not apply.  </p>
<p style=""margin-left:.5in;"">For intermediaries processing third-party data, free expression is also relevant, though in ways that can be hard to pin down in practice.  The legal basis for intermediaries’ processing in the first place is often that the processing serves “legitimate purposes.” (Art 5.1(b)) When an intermediary declines to honor a removal request on free expression grounds, the GDPR provision invoked is one that references only “legitimate interests.” (Art 6.1(f)) While undefined, such legitimate purposes and interests clearly include expression and information rights.  But the GDPR and existing law provide scant detail on how to assess these interests – this was one common critique of the <em>Costeja</em> ruling.  And important questions about <em>whose</em> interests may be considered – which come up in litigation about content removal – are not always addressed well in GDPR drafts.  For example, one draft provision allows controllers to decline to remove content based on “legitimate interests pursued by the controller, or by the third party or parties to whom the data are disclosed[.]” (6.1(f) EDPS)  Under this formulation, the interests of the speaker – the user whose content is indexed, transmitted, or hosted – fall out of the analysis.  Data protection law’s lack of detailed provisions for free expression made more sense in an era when regulated entities were assumed to be banks, employers, medical offices, and the like.  Today, inattention to the unique role of Internet intermediaries in GDPR drafting will likely lead to more removals of lawful expression – and more litigation.</p>
<p style=""margin-left:.5in;""><em>Q: If parts of this law are unclear, who decides what it means?</em></p>
<p style=""margin-left:.5in;"">A: It will take a while.  Initial layers of review will typically come from data protection regulators, rather than courts.  In the first instance, DPAs – largely staffed by career civil servants specialized in data protection law – will answer most questions.  Issues that affect more than one country will be resolved via important and hotly contested new “One Stop Shop” and Cooperation Procedure provisions.  Difficult questions or disagreements among national DPAs will be addressed by a new European Data Protection Board created by the GDPR, which effectively replaces the existing EU-wide Article 29 Working Party.  Entities which disagree with regulators’ interpretation of the law can eventually go to court (or the complainant can go directly to court instead of the DPA), so in the long term we will see court opinions on the hard issues.  But they may vary from country to country and even from case to case within a country – particularly in civil law countries.  The really hard and consequential questions should eventually bubble up to the Court of Justice of the EU (CJEU) or possibly the European Court of Human Rights (ECHR).</p>
<p> </p>
<p><strong>2. Important and Complex Questions from Experts</strong></p>
<p>These are all hard questions I have heard from experts in Brussels.  They will not get extensive treatment in this series, but they matter a lot in the long term. Feedback regarding these questions is especially welcome; there is more to be said about all of them.</p>
<p style=""margin-left:.5in;""><em>Q: Aren’t the eCommerce Directive and GDPR already aligned, because any intermediary that is passive enough to qualify for eCommerce protection will also qualify as a Processor for data protection purposes?</em></p>
<p style=""margin-left:.5in;"">A: This question comes up because of some approximate parallels between the eCommerce and Data Protection directives.  Intermediaries lose protection under the eCommerce Directive if they are too “active” in handling user-generated content, as opposed to being “passive” and “neutral.”  Similarly, under data protection law, an entity that determines for itself how to process personal data is deemed a “controller” with significant legal obligations including data erasure; while an entity merely following a controller’s instructions about how to process data is a “processor” with fewer obligations.   There are parallels between the two classification systems: the more discretion you exercise in managing third party data or content, the more responsibility you have.  So it would be theoretically possible that the only entities that have content erasure obligations as controllers under the GDPR are ones that fall outside eCommerce Directive protections anyway – in other words, that all data protection processors are passive intermediaries protected by the eCommerce Directive, and all controllers aren’t. </p>
<p style=""margin-left:.5in;"">But the law doesn’t say that now, and there’s good reason it shouldn’t in the future.  There are already instances where an intermediary has been deemed a controller in data protection cases, but found to be protected by the eCommerce Directive in content removal cases. More broadly, law about “passive” and “active” eCommerce intermediaries is a moving target.  Court rulings provide widely diverging interpretations in different cases and in different countries.  More fundamentally, the animating policy goals of data protection law and intermediary liability law are sufficiently different – and the scope of unrelated issues each much address sufficiently broad – that it seems unlikely the two would ultimately arrive at identical classification regimes.</p>
<p style=""margin-left:.5in;""><em>Q: What does the GDPR have to do with freedom of expression?</em></p>
<p style=""margin-left:.5in;"">A: Some thoughtful data protection experts honestly see no free expression concerns with the law, despite its strong new language requiring erasure of information.  Erasure is only required after consideration of relevant legitimate interests, including interests in free expression and access to information, so – one could reason – protection of free expression is built in. </p>
<p style=""margin-left:.5in;"">One problem with this analysis is the documented tendency of intermediaries to avoid risk and transaction costs by simply removing any challenged content.<a href=""#_edn9"" name=""_ednref9"" title="""" id=""_ednref9""><sup><sup>[9]</sup></sup></a>  Putting removal decisions in the hands of technology companies – as opposed to, say, content creators or national courts – is a recipe for over-removal of lawful expression.  Another is that procedural details in the GDPR’s removal and review process tilt the playing field in favor of privacy rights, and make users’ free expression rights harder to vindicate.  A final problem is that different countries have very different laws balancing free expression against other rights, including privacy or data protection.  Content that self-evidently should be removed in Europe may be protected and lawful speech in the US and other countries.  Applying EU removal standards to content in those countries creates a free expression issue for Internet speakers and readers there.</p>
<p style=""margin-left:.5in;""><em>Q:  The erasure provisions of the GDPR aren’t about liability, so how can they affect intermediary liability?</em></p>
<p style=""margin-left:.5in;"">A: I’ve heard this question a couple of times from smart data protection lawyers, and I’m not sure I quite understand it.  But here’s a shot.  I think the point may be that the erasure requirements function like injunctive relief, they don’t create liability in the sense of exposure to monetary damages. Assuming that is the argument, there are several possible responses.  One is about terminology.  The term “intermediary liability” is used by practitioners as shorthand for an array of obligations intermediaries have toward third party content, including notice and takedown.  So any law creating a removal obligation for intermediaries falls in the category of “intermediary liability” law.  (We could really use better terminology.)  Another answer is that given the new, high financial penalties for GDPR noncompliance, an intermediary risks serious financial consequences for not taking content down – even if the intermediary believes the law does not require removal.  The same may be true under current law, according to the <em><a href=""http://eulawanalysis.blogspot.com/2015/04/vidal-hall-v-google-strengthening-eu.html"">Vidal-Hall</a></em> ruling.  A third answer is that parts of the GDPR seemingly create liability for intermediaries even when they are unaware that they are processing content unlawfully. <a href=""#_edn10"" name=""_ednref10"" title="""" id=""_ednref10""><sup><sup>[10]</sup></sup></a>  Such a departure from the eCommerce Directive’s knowledge standard would be a sea change for intermediary liability, and make the operation of open platforms for users to receive and impart information a much riskier business.  </p>
<p> </p>
<p><strong>3. One Question I Hope Other People Are Asking About Free Expression and The GDPR</strong></p>
<p><a name=""Archives"" id=""Archives""></a></p>
<p>I have not seen much evidence of librarians and archivists following the GDPR, and provisions affecting them are outside the scope of this series.  I would be interested in seeing any analysis others have on this issue.</p>
<p style=""margin-left:.5in;""><em>Q: Does the GDPR have other consequences for free expression and information access, aside from the Internet issues discussed here?</em></p>
<p style=""margin-left:.5in;"">A: Yes.  The stand-out issue to me is the GDPR’s treatment of archives and research.  I am not expert in this field, but I hope those who are have been tracking the GDPR and communicating with decision-makers in Brussels.  The GDPR appears to whittle away at archival uses in a number of ways.  For example, Article 83 in most drafts permits use of personal data for “historical, statistical or scientific research” only if it is impossible to conduct the research using non-identifying information.  Given the expansive definition of “personal data,” and the cost for libraries or researchers to strip out anything that meets the definition, this would appear to impose significant costs on normal and valuable research.  Many exceptions and derogations permit archival “public interest” uses only if they are specifically listed in national law.  For example, one draft says Member State law must ensure that archival data “cannot be used in support of measures or decisions affecting specific individuals, except for those measures or decisions that are specifically foreseen in Member State law.”  (EDPS draft Art. 83a) It is easy to imagine scenarios where a use unanticipated by the State has real societal value: aggregation of third party personal data to decide if a specific individual should be charged with professional negligence, for instance, or receive extra educational support, be protected from certain allergens in the workplace, etc.  Unless all these scenarios are foreseen and enumerated by every national legislature in the EU, the outcome appears troubling for researchers – and the people whose lives are made better by their work. </p>
<p style=""margin-left:.5in;"">Another possible threat to archives comes from provisions about “further processing” and the purpose limitation for data processing.  (Art. 5 and elsewhere.) Different drafts take notably distinct approaches to the situation in which personal data that was collected for one purpose is later used for a new purpose.  The issue is rightly important and contentious because of concerns about companies getting user permission for one purpose, and then using the data for other things.  Without careful drafting, though, this could also affect archives and research institutions, where information collected for one purpose can often be a treasure trove for researchers pursuing new questions.  It is not clear if this concern is fully represented in GDPR discussion.</p>
<div>------<br clear=""all"" /><hr align=""left"" size=""1"" width=""33%"" /><div id=""edn1"">
<p><a href=""#_ednref1"" name=""_edn1"" title="""" id=""_edn1""><sup><sup>[1]</sup></sup></a> One important new provision of the GDPR establishes user rights to data portability, for example. (Art. 18)</p>
</div>
<div id=""edn2"">
<p><a href=""#_ednref2"" name=""_edn2"" title="""" id=""_edn2""><sup><sup>[2]</sup></sup></a> Many thanks to Neal Cohen, who reviewed this work with a data protection practitioner’s keen eye.  Remaining mistakes are my own.</p>
</div>
<div id=""edn3"">
<p><a href=""#_ednref3"" name=""_edn3"" title="""" id=""_edn3""><sup><sup>[3]</sup></sup></a> The title of Professor Graham Greenleaf’s article on point is telling:  <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2000034"">Global Data Privacy Laws: 89 Countries, and Accelerating</a>.</p>
</div>
<div id=""edn4"">
<p><a href=""#_ednref4"" name=""_edn4"" title="""" id=""_edn4""><sup><sup>[4]</sup></sup></a> Protection varies with the nature of the service.  Providers in the “mere conduit” category do not have knowledge-based removal obligations; and all intermediaries can lose legal protection if they are too actively involved in managing content.</p>
</div>
<div id=""edn5"">
<p><a href=""#_ednref5"" name=""_edn5"" title="""" id=""_edn5""><sup><sup>[5]</sup></sup></a> See, e.g., Jennifer Urban and Laura Quilter’s <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2210935"">2006 review</a> of DMCA removals and Daniel Seng’s <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2411915"">more recent work</a> in the same area; Bits of Freedom’s study of <a href=""http://www.theregister.co.uk/2004/10/14/isp_takedown_study/"">Dutch intermediaries</a> and Oxford PCMLP’s study on <a href=""http://pcmlp.socleg.ox.ac.uk/wp-content/uploads/2014/12/liberty.pdf"">UK and US intermediaries</a>; and Rishabh Dara’s detailed study of over-removals by <a href=""http://cis-india.org/internet-governance/intermediary-liability-in-india.pdf"">Indian intermediaries</a>.</p>
</div>
<div id=""edn6"">
<p><a href=""#_ednref6"" name=""_edn6"" title="""" id=""_edn6""><sup><sup>[6]</sup></sup></a> Some argue that <em>Costeja</em> de-indexing should not be called “removal,” because it leaves the same results available for different queries. In intermediary liability parlance, this kind of partial suppression of content would still be called a “removal.”  Search engines are not expressly covered by the eCommerce Directive intermediary liability provisions, but many national courts or laws have protected them as intermediaries.  The protection of any intermediaries with respect to data protection-based content removal requests is further complicated by eCommerce Directive Article 1.5(b), which some","Intermediary Liability, Privacy",2015-10-08 6:00,1188,Daphne Keller,News
13478,,International,1,1,Empirical Evidence of “Over-Removal” by Internet Companies under Intermediary Liability Laws,General+Freedom of Expression,"<p><strong>The ""Over-Removal"" Issue</strong></p>
<p>Most intermediaries offer legal “Notice and Takedown” systems – tools for people to alert the company if user-generated content violates the law, and for the company to remove that content if necessary.  Twitter does this for tweets, Facebook for posts, YouTube for videos, Google for search results, local news sites for user comments, etc.  National law varies in terms of what content must be removed, but some version of Notice and Takedown exists in every major market.  Companies receive a remarkable mix of requests – from those identifying serious and urgent problems, to those attempting to game the Notice and Takedown system as a means to silence speech they disagree with, to those stating wildly imaginative claims under nonexistent laws.</p>
<p>What do companies do with these removal requests?  Many of the larger companies make a real effort to identify bad faith or erroneous requests, in order to avoid removing legal user content.  (I worked on removals issues for Google for years, and can attest to the level of effort there.)  But mistakes are inevitable given the sheer volume of requests – and the fact that tech companies simply don’t know the context and underlying facts for most real-world disputes that surface as removal requests.</p>
<p>And of course, the easiest, cheapest, and most risk-avoidant path for any technical intermediary is simply to process a removal request and not question its validity.  A company that takes an “if in doubt, take it down” approach to requests may simply be a rational economic actor.  Small companies without the budget to hire lawyers, or those operating in legal systems with unclear protections, may be particularly likely to take this route.</p>
<p>Much of the publically available information about over-removal by intermediaries is anecdotal.  But empirical evidence of over-removal – through error or otherwise – keeps trickling in from academic studies.  This data is important to help policy-makers understand what intermediary liability rules work best to protect the free expression rights of Internet users, as well of the rights of people with valid claims to removal.  This post lists the studies I have seen. </p>
<p>These studies were mostly conducted by academics or advocates with a particular interest in protecting user free expression and ensuring that legal content remains available online.  One day I hope we will see more data from the other side – advocates for rightsholders, defamation plaintiffs, or other groups harmed by online content that violates their legal rights.  That could help build a more complete picture of the over-removal issue as well as any related under-removal problem – intermediaries failing to remove content when notified, even though applicable law requires removal.   </p>
<p> </p>
<p><strong>The Studies</strong></p>
<ul><li><u>Urban et al's new 2016 research, ""<a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2755628"">Notice and Takedown in Everyday Practice</a>."":</u> This report is a treasure trove of qualitative and quantitative info on DMCA operations. A key finding is the divergence, documented and quantified in the study, between ""classic"" DMCA practice and new tools like robonotices and ContentID. The new tools are used by major players and dominate public discussion, but manual DMCA processing by small rightsholders and OSPs didn't go away. The report is long and well worth reading, my summary of key findings is <a href=""http://cyberlaw.stanford.edu/blog/2016/04/dmca-classic-dmca-turbo-major-new-empirical-research-notice-and-takedown-operations"">here</a>. </li>
<li><u>Jennifer Urban and Laura Quilter’s <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2210935"">2006 review</a> of copyright-based removals from Google’s services under the US Digital Millennium Copyright Act (DMCA)</u>:  Relying on information released to the <a href=""https://chillingeffects.org/"">Chilling Effects</a> (now called Lumen) database by the company about processed removals (i.e. the ones where the company agreed to remove, not the ones it declined), the authors found that 55% of notices involved disputes between competitors, and 31% presented significant issues regarding the validity of the copyright infringement claim.  (Daniel Seng’s <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2563202"">more recent work</a> with a similar but much larger data set has great detailed statistics on DMCA removal trends, but his published conclusions do not include analysis of the validity of the claims processed.)</li>
<li><u>The 2004 <a href=""http://www.fepproject.org/policyreports/WillFairUseSurvive.pdf"">Brennan Center study</a> on removals and free expression</u>:  Reviewing a data set of 320 copyright and trademark-based removal requests, the authors concluded that 47% stated weak claims or involved speech with important fair use or free expression legal defenses.</li>
<li><u>Rishabh Dara’s detailed experiment and study of over-removals by <a href=""http://cis-india.org/internet-governance/intermediary-liability-in-india.pdf"">Indian intermediaries</a></u>: Dara submitted increasingly unreasonable removal requests to various intermediaries, and carefully documented the responses.  His results show considerable over-removal, including removal based on clearly invalid legal claims and removal of content not targeted by the requests.</li>
<li><u>The 2004 Bits of Freedom study of <a href=""http://www.theregister.co.uk/2004/10/14/isp_takedown_study/"">Dutch ISPs</a></u>:  The group created accounts with ten Dutch ISPs and used them to post copies of a famous, public domain, 19<sup>th</sup> century political essay.  It then used different contact information to send copyright “infringement notices” to the ISPs, under Dutch law implementing the eCommerce Directive.  Of the ten ISPs, seven removed the content despite its age and public domain status.</li>
<li><u>Oxford Program in Comparative Media Law and Policy’s smaller experiment with </u><a href=""http://pcmlp.socleg.ox.ac.uk/wp-content/uploads/2014/12/liberty.pdf"">UK and US ISPs</a><span>: Researchers posted John Stuart Mill’s 1859 discussion of media freedom from “On Liberty” – which is in the public domain.  They then used different accounts to request its removal via UK and US ISPs.  The UK ISP removed the essay without question, while the US ISP responded by requiring the requester to comply with the more formal requirements of the US DMCA, including “good faith belief” and “penalty of perjury” attestations.</span></li>
<li><u>Company transparency reports:</u> Transparency reports from <a href=""https://transparency.twitter.com/removal-requests/2014/jul-dec"">Twitter</a>, <a href=""https://www.google.com/transparencyreport/"">Google</a>, <a href=""https://transparency.yahoo.com/government-removal-requests/index.htm"">Yahoo</a>, <a href=""https://govtrequests.facebook.com/"">Facebook</a>, <a href=""https://www.microsoft.com/about/business-corporate-responsibility/transparencyhub/crrr/"">Microsoft</a> and others offer some data about removal requests. The data is valuable for other purposes, but usually not great for sussing out the validity or even volume of complaints. Most reports list only requests from government sources, which represent a small minority of legally-based content removals. Some show the overall percentage of requests accepted and rejected; or include anecdotal examples.  In some cases, particularly for Google’s “Right to Be Forgotten” (RTBF) removals, this data is supplemented by news reports. For example, <a href=""http://www.theguardian.com/technology/2015/jul/14/google-accidentally-reveals-right-to-be-forgotten-requests"">coverage</a><span> last summer suggested that most RTBF claims come from non-public figure requestors. It is also <a href=""https://euobserver.com/investigations/130590"">reported</a> that relatively few requesters take their claims to Data Protection Agencies</span><span> when Google rejects their removal requests; and that when they do the Agencies often agree with Google's decision. </span></li>
<li><u>The Lumen <a href=""https://lumendatabase.org/"">database</a> and other research drawing on it</u>: Lumen, formerly known as Chilling Effects, maintains a remarkable database containing millions of removal requests made public by companies and other contributors.  Significant academic research has been carried out using the database, much of it relevant for over-removal questions.  An overview of this literature as of 2010 is in Chilling Effects <a href=""https://www.eff.org/node/58197"">amicus brief</a><span> from Perfect 10 v. Google.</span></li>
<li><span><u>Judith Townsend's <a href=""http://policyreview.info/articles/analysis/online-chilling-effects-england-and-wales"">research</a> on removals by journalists and bloggers</u>: This survey concerns removals by publishers rather than intermediaries, but contains interesting data on the frequency of requests and compliance, as well as availability of legal counsel to those receiving removal requests.</span></li>
</ul><p>More studies and data sources surely exist, or will exist.  I have heard in particular of one from Pakistan, but have not found it so far.  If you know of other sources, please let me know or post them in the Comments section so this page can become a more useful resource for people seeking this information.</p>
<p>NOTE: I periodically update this post.  Last update was April 21, 2016. </p>
","Copyright and Fair Use, Intermediary Liability",2015-10-12 8:23,1188,Daphne Keller,News
13497,,International,1,1,September 2015 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>September 2015 in Retrospect is available here:</p>
<p><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2015-september/"">http://www.internetjurisdiction.net/observatory/retrospect/2015-september/</a></p>
<p>Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
",Intermediary Liability,2015-10-22 17:26,505,Giancarlo Frosio,News
13505,,European Union,0,0,"The GDPR’s Notice and Takedown Rules: Bad News for Free Expression, But Not Beyond Repair",Right to Be Forgotten+Privacy or Data Protection+Freedom of Expression,"<p><em style=""color: rgb(51, 51, 51); font-family: 'Helvetica Neue', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; line-height: 18.2px;"">Cross-posted to the <a href=""http://policyreview.info/articles/news"" style=""color: rgb(128, 0, 0); transition: all 0.3s; outline: none; background: transparent;"">Internet Policy Review News & Comments</a> </em><em style=""font-size: 13.008px; line-height: 1.538em;"">and <a href=""https://inforrm.wordpress.com/tag/daphne-keller/"">Inforrm</a> blogs.</em></p>
<p><em>This is one of a series of posts about the pending EU General Data Protection Regulation (GDPR), and its consequences for intermediaries and user speech online.  In an earlier </em><a href=""http://cyberlaw.stanford.edu/blog/2015/10/intermediary-liability-and-user-content-under-europe%E2%80%99s-new-data-protection-law""><em>introduction and FAQ</em></a><em>, I discuss the GDPR’s impact on both data protection law and Internet intermediary liability law.  Developments culminating in the GDPR have put these two very different fields on a collision course -- but they lack a common vocabulary and are in many cases animated by different goals.  Laws addressing concerns in either field without consideration for the concerns of the other can do real harm to users’ rights to privacy, freedom of expression, and freedom to access information online.</em></p>
<p><em>Disclosure: I previously worked on ""Right to Be Forgotten"" issues as Associate General Counsel at Google. </em></p>
<p><strong>-----</strong></p>
<p>The pending EU <a href=""http://www.twobirds.com/en/practice-areas/privacy-and-data-protection/eu-framework-revision"">General Data Protection Regulation</a> (GDPR) changes the processes companies use to handle legal complaints about content online.  These procedural changes have a very substantive impact, undermining safeguards for free expression and increasing the likelihood that lawful online content will be erased. </p>
<p>Internet intermediaries such as Facebook or Google look to processes created under intermediary liability law to tell them what to do when someone alleges that content put online by their users is illegal.  These laws -- like national laws implementing the <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:32000L0031:en:HTML"">eCommerce Directive</a> in the EU, or the copyright-specific <a href=""https://www.law.cornell.edu/uscode/text/17/512"">DMCA</a> in the US -- are the basis for existing notice and takedown processes used by Internet companies.  As protections for online expression and information, existing rules and processes are far from perfect.  But they are vastly better than the processes the GDPR will impose.  Most existing rules permit -- or require -- procedural checks and balances to protect rights of both the accused who put the content online, and the accuser who believes that the content violates her legal rights.</p>
<p>The GDPR changes that.  It legislates a broad basis for content erasure under the “Right to Be Forgotten,” and tells intermediaries to follow a novel process to carry out removals.<a href=""#_ftn1"" name=""_ftnref1"" title="""" id=""_ftnref1""><sup><sup>[1]</sup></sup></a>  As this post will detail, the new process is highly problematic for Internet users’ rights of free expression and access to information.  And because the GDPR imposes extremely high fines on intermediaries who fail to erase content when they should have -- draft figures range from up to .5% to up to 5% of annual global turnover -- the intermediary has every incentive to assume requests are valid, even when they challenge potentially important and legal content. (Art. 79)</p>
<p>It doesn’t have to be this way.  The GDPR could easily incorporate widely-used notice and takedown principles and procedures, designed to balance rights of both the person posting content online, and the person who wants it taken down.  Importantly, it could do so without weakening the other core privacy rights created by the GDPR.   The GDPR’s notice and takedown problems arise because, in Articles 17 and 19, the Regulation treats two very different situations as if they were the same.  By separating them and handling them differently, the Regulation could improve protections for free expression rights as well as privacy rights.</p>
<p>The first situation addressed in the GDPR's erasure provisions occurs when an Internet user seeks to delete data collected by companies about her online behavior -- data typically held in back-end storage systems such as logs, and used for profiling or similar activity by the company. When a user wants to erase this kind of data, two sets of rights are implicated: those of the requesting data subject, and those of the company. Presumably the requester’s rights will usually prevail. The GDPR’s erasure provisions seem broadly reasonable for this two-party situation.  </p>
<p>The second situation is the one I am concerned with here: when the requester asks the intermediary to erase <em>another person’s</em> online expression.  This request is very different, because it affects at least four parties: the requesting data subject; the intermediary; the person who posted the content online; and other Internet users who want to view the content.  Procedures designed for back-end data deletion and a two-party interaction are not adequate to protect and balance the rights of these four very different parties.  Unsurprisingly, when rules designed for the two-party scenario are applied to this more complex situation, the rightsholders left out in the cold are the ones exercising free expression rights by posting content, or exercising information access rights by seeking and viewing it. </p>
<p>By effectively leaving the free expression and information-access rights of Internet users out of the equation, the GDPR creates a badly flawed notice and takedown process.  It’s a process that will likely have consequences far beyond data protection law.  The GDPR’s new, low bar for protection of free expression on the Internet will shape future cases before DPAs and courts, and will likely also affect legislation in other areas.  If the EU’s current <a href=""http://ec.europa.eu/priorities/digital-single-market/"">Digital Single Market</a> initiative leads to reconsideration of intermediary liability laws, the GDPR’s new notice and takedown process will be seen as a model to be emulated for copyright, defamation, and other removal claims. </p>
<p>GDPR drafters should incorporate procedures to protect expression and information access now, to ensure that processes designed to streamline removals for data subjects with genuine claims do not also become tools for targeting and deleting lawful information online. </p>
<p>A <a href=""https://cyberlaw.stanford.edu/blog/2015/10/notice-and-takedown-under-gdpr-operational-overview"">separate post</a> walking through the GDPR’s removal process in detail and parsing Regulation language is <a href=""https://cyberlaw.stanford.edu/blog/2015/10/notice-and-takedown-under-gdpr-operational-overview"">here</a>. More analysis of the GDPR’s removal process, including its relation to other EU laws and legal issues, will appear in my next post.</p>
<p><strong>Why Notice and Takedown Rules Matter</strong></p>
<p>A good notice and takedown process does two things. It takes unlawful content down, and it keeps lawful content up.  Procedural checks are critical for the second goal, to limit what legal scholars call “collateral censorship.”  As Yale Law School professor Jack Balkin <a href=""http://cdn.harvardlawreview.org/wp-content/uploads/2014/06/vol127_balkin.pdf"">explains</a>, relying on intermediaries to enforce laws about expression creates a structural problem:</p>
<p style=""margin-left:.5in;"">Collateral censorship occurs when the state holds one private party A liable for the speech of another private party B, and A has the power to block, censor, or otherwise control access to B’s speech.  This will lead A to block B’s speech or withdraw infrastructural support from B.  In fact, because A’s own speech is not involved, A has incentives to err on the side of caution and restrict even fully protected speech in order to avoid any chance of liability. (P. 2309)</p>
<p>This is a real issue, not a theoretical one.  Notice and takedown processes are widely misused to target lawful content, even when they do incorporate procedural checks against abuse.  And, as multiple <a href=""http://cyberlaw.stanford.edu/blog/2015/10/empirical-evidence-over-removal-internet-companies-under-intermediary-liability-laws"">studies</a> confirm, intermediaries often take the path of least resistance by simply acquiescing to removal requests, even when they are improper.  Some companies do put real effort and resources into identifying and rejecting unfounded removal requests.  I am proud to say that I was part of this effort during my own time at Google.  But both anecdotal and statistical evidence tell us that such efforts, alone, are often not enough to avoid removal of legal and valuable content.</p>
<p>It’s important to appreciate the numbers behind this issue.  Intermediaries receive a <em>lot</em> of groundless removal requests.  In the ""Right to Be Forgotten"" context, Google says that currently <a href=""https://www.google.com/transparencyreport/removals/europeprivacy/"">59%</a> of incoming requests fail to state valid legal claims.  Privacy regulators seem to agree: the Article 29 Working Party, reviewing cases brought to DPAs, <a href=""http://ec.europa.eu/justice/data-protection/article-29/press-material/press-release/art29_press_material/2015/20150618_wp29_press_release_on_delisting.pdf"">concluded</a> that “in the great majority of cases the refusal by a search engine to accede to the request is justified.”  Empirical data about copyright removals shows a similar pattern of requests targeting legal content.<a href=""#_ftn2"" name=""_ftnref2"" title="""" id=""_ftnref2""><sup><sup>[2]</sup></sup></a> Scholars reviewing copyright-based removals from Google web search in 2006 <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2210935"">found</a> that almost a third of successful requests raised questionable legal claims.  If unsuccessful requests were included, that number would be much larger. </p>
<p>Notice and takedown laws also exist to protect people who are harmed by online content.  But protecting those people does not require laws to prioritize removal with little concern for the rights of online speakers and publishers.  A good notice and takedown process can help people with legitimate grievances while incorporating procedural checks to avoid disproportionate impact on expression and information rights.  Valuable information that would be gone under existing laws but for these checks -- importantly including transparency about what content has been removed -- spans <a href=""https://www.eff.org/deeplinks/2008/09/massive-takedown-anti-scientology-videos-youtube"">religious</a>, <a href=""http://www.ibtimes.com/russia-turkey-asked-twitter-remove-hundreds-tweets-government-censorship-attempts-1810234"">political</a>, and <a href=""http://arstechnica.com/science/2013/02/site-plagiarizes-blog-posts-then-files-dmca-takedown-on-originals/"">scientific</a> content, along with <a href=""http://arstechnica.com/tech-policy/2011/06/criticism-and-takedown-how-review-sites-can-defend-free-speech/"">consumer reviews</a>. Crafting the law to better protect this kind of content from improper removal is both important and possible.</p>
<p><a name=""Process"" id=""Process""></a></p>
<p><strong>What’s Wrong with the GDPR’s Notice and Takedown Process</strong></p>
<p>The GDPR content removal process doesn’t track legal requirements established under the eCommerce Directive.   And it bears almost no relation to the gold standard for notice and takedown, developed by civil society groups and published in the <a href=""https://www.manilaprinciples.org/"">Manila Principles</a>.  Instead, it creates a new, untested system in which it is very easy to get content taken down, and very hard to identify or correct wrongful removals.  In a <a href=""https://cyberlaw.stanford.edu/blog/2015/10/notice-and-takedown-under-gdpr-operational-overview"">separate post</a> I walk through the GDPR’s exact requirements in much more detail.  They are very convoluted and hard to piece together,<a href=""#_ftn3"" name=""_ftnref3"" title="""" id=""_ftnref3""><sup><sup>[3]</sup></sup></a> but appear to work as follows.  All citations to draft GDPR provisions refer to versions available in this comparative <a href=""https://secure.edps.europa.eu/EDPSWEB/webdav/site/mySite/shared/Documents/Consultation/Opinions/2015/15-07-27_GDPR_Recommendations_Annex_EN.pdf"">table</a>.</p>
<p style=""margin-left:.5in;"">1.      An individual submits a removal request, and perhaps communicates further with the intermediary to clarify what she is asking for.</p>
<p style=""margin-left:.5in;"">2.      In most cases, <em>prior to assessing the request’s legal validity, the intermediary temporarily suspends or “restricts” the content</em> so it is no longer publicly available.<a href=""#_ftn4"" name=""_ftnref4"" title="""" id=""_ftnref4""><sup><sup>[4]</sup></sup></a></p>
<p style=""margin-left:.5in;"">3.      The intermediary reviews the legal claim made by the requester to decide if it is valid.  For difficult questions, the intermediary may be allowed to consult with the user who posted the content.<a href=""#_ftn5"" name=""_ftnref5"" title="""" id=""_ftnref5""><sup><sup>[5]</sup></sup></a></p>
<p style=""margin-left:.5in;"">4.      For valid claims, the intermediary proceeds to fully erase the content.  (Or probably, in the case of search engines, de-link it following guidelines of the <a href=""http://curia.europa.eu/juris/document/document_print.jsf?doclang=EN&docid=152065""><em>Costeja</em></a> “Right to Be Forgotten” ruling.)  For invalid claims, the intermediary is supposed to bring the content out of “restriction” and reinstate it to public view -- though it’s not clear what happens if it doesn’t bother to do so.</p>
<p style=""margin-left:.5in;"">5.      The intermediary informs the requester of the outcome, and communicates the removal request to any “downstream” recipients who got the same data from the controller.</p>
<p style=""margin-left:.5in;"">6.       <em>If the intermediary has additional contact details or identifying information about the user who posted the now-removed content, it may have to disclose them to the individual who asked for the removal, </em>subject to possible but unclearly drafted exceptions<em>.</em> (Council draft, Art. 14a)</p>
<p style=""margin-left:.5in;"">7.       In most cases, <em>the accused publisher receives no notice that her content has been removed, and no opportunity to object.  </em>The GDPR text does not spell out this prohibition, but does nothing to change the legal basis for the Article 29 Working Party’s conclusions on this point. </p>
<p>The deviation from standard notice and takedown processes here is significant.  I’ve flagged in italics the most extreme examples, with the greatest adverse effects on online expression and information-access rights.  </p>
<p><a name=""Restriction"" id=""Restriction""></a></p>
<p>            <strong>Temporary, Pre-Review Content Restriction</strong></p>
<p>One of the biggest issues with the GDPR process is the immediate, temporary removal of content from public view, “pending the verification whether” the removal request states a legitimate basis for permanent removal.  The GDPR calls this “restriction.”  Although intermediaries can in theory skip this step in special cases, the GDPR provides no clear guidance on what those cases are, and levies debilitating fines for failure to restrict content when appropriate.  The restriction provisions shift an important default: from a presumption that online expression is permitted until proven otherwise, to a presumption that its challenger is right.  This is dangerous because intermediaries receive many, many groundless requests -- recall the 59% figure for Google. Rather than leave that lawful content up, the GDPR would take it down.</p>
<p>As a matter of fair process even in run-of-the-mill cases, this automatic restriction right is troubling.  An allegation made in secret to a private company should not have such drastic consequences.  In other, less common -- but all too real -- scenarios, it is flatly dangerous.  Instant, temporary removal of internet content is a tool begging for use by bad actors with short-term issues: the disreputable politician on the eve of election; the embezzler meeting a new client; the convicted abuser looking for a date. Mandating it by law is a big mistake.</p>
<p>Automatic restriction is also inconsistent with the eCommerce Directive.  Neither it nor any other intermediary liability law I’ve seen makes intermediaries remove content they have not even seen or assessed.  The Directive requires an intermediary to remove when it has “knowledge” of unlawful content.  At a bare minimum, that means the intermediary has no removal obligation until it knows what content is at issue and why it violates the law.  Some European courts have held that the “knowledge” standard can set a much higher bar for removal.  For difficult removal questions, these courts say, intermediaries can’t know whether content is illegal, and therefore are not obliged to remove it, until the matter has been adjudicated in court.<a href=""#_ftn6"" name=""_ftnref6"" title="""" id=""_ftnref6""><sup><sup>[6]</sup></sup></a>  Courts in other parts of the world -- including the Supreme Courts of both <a href=""http://supremecourtofindia.nic.in/FileServer/2015-03-24_1427183283.pdf"">India</a> and <a href=""https://cyberlaw.stanford.edu/blog/2014/11/argentine-supreme-court-decides-landmark-intermediary-liability-case"">Argentina</a> --  have reached similar conclusions.  Courts arrived at these rulings, and erected high procedural barriers to wrongful content removal, in order to protect fundamental rights of Internet users to seek and impart information.  Where the GDPR’s removal process applies to expression posted by Internet users -- as opposed to data only stored and used by companies -- should do a much better job factoring in those same rights.</p>
<p><a name=""Disclose"" id=""Disclose""></a></p>
<p>            <strong>Disclosure of Publisher’s Personal Information</strong></p>
<p>A second glaring problem with the GDPR process is its requirement that companies disclose the identity of the person who posted the content, without any specified legal process or protection.<a href=""#_ftn7"" name=""_ftnref7"" title="""" id=""_ftnref7""><sup><sup>[7]</sup></sup></a>  This is completely out of line with existing intermediary liability laws. Some have provisions for disclosing user identity, but not without a prescribed legal process, and not as a tool available to anyone who merely alleges that an online speaker has violated the law.  It’s also out of line with the general pro-privacy goals of the GDPR, and its specific articles governing disclosure of <em>anyone’s</em> personal information -- including that of people who put content on the Internet. </p>
<p>The GDPR provision requiring disclosure does make confusing reference to other laws on point, which may be intended to incorporate protections against improper disclosure of the publisher’s information.  If so, the GDPR should express that protection much more clearly to avoid wreaking havoc with rights to anonymous speech.  Hopefully revision in this section is politically feasible -- the disclosure requirement is so obliquely phrased, and so bizarre in a pro-privacy regulation, that I can only assume it is unintentional.  If it is not remedied, the provision creates yet another incentive for the GDPR take down process to be abused, and puts yet another very serious burden on rights to free expression online. (<em>See new footnote<a href=""#_ftn8"" name=""_ftnref8"" title="""" id=""_ftnref8""><sup><sup>[8]</sup></sup></a> for updated analysis as of <span data-term=""goog_1103820861"" tabindex=""0"">Nov. 17 2015</span></em>.)</p>
<p><a name=""NoNotice"" id=""NoNotice""></a></p>
<p>            <strong>No St</strong><strong>andard Notice or Opportunity for the Publisher to Contest Removal</strong></p>
<p>Finally, the GDPR creates considerable procedural unfairness for the user who posted the disputed content, in most cases excluding her from the entire process.  The GDPR does not spell out when an intermediary may tell an online publisher about legal challenges to her material.  But it does nothing to change the <a href=""http://ec.europa.eu/justice/data-protection/article-29/documentation/opinion-recommendation/files/2014/wp225_en.pdf"">conclusion</a> reached by the Article 29 Working Party for Google’s ""Right to Be Forgotten"" delistings, that Google may not routinely tell webmasters when their content has been delisted.  In special cases, the Working Party conceded, Google may communicate with the webmaster before removing. </p>
<p>That exception will do very little to deter over-removal in the GDPR context, however.  One of the main purposes of providing broad notice to users whose content has been removed is to let affected parties correct the <em>intermediary’s</em> errors.  Intermediaries already over-remove legal content, because assessing claims is time-consuming and expensive, and standing up for user content exposes companies to legal risk. The GDPR’s vague rules and high fines make incentives to remove all challenged content even stronger.  This problem cannot be cured by asking already risk-averse companies to take on the costly task of identifying difficult cases and re-routing them for special internal processing. Routinized notice puts the opportunity for error-correction in the hands of the person best motivated and equipped to use it: the content’s publisher.  Leaving the determination entirely in the hands of a technology company simply cannot substitute for involving the publisher as a mechanism to reduce improper removals.</p>
<p>From a pure data protection perspective, leaving the accused publisher out of the loop makes a sort of sense: if an individual has the right to make the company stop processing data about her, that should also preclude their processing it even further by talking to the publisher about it.  This “when I say stop, I mean stop” reasoning may be sensible in the traditional data protection context, where an individual wants stored, back-end data such as logs or accounts deleted.   But when the free expression rights of another individual are at stake, systematically depriving that individual of any opportunity to defend herself is a serious denial of fairness and proportionality.  In this respect, too, the GDPR departs from intermediary liability laws and model rules, which in many cases provide for notice to the publisher and an opportunity for objection via “counternotice.”  Legal systems without this formal process would still generally consider the publisher’s defenses relevant to the “knowledge” that triggers removal. None systematically preclude knowledge or input by the person whose free expression rights are at stake.</p>
<p><strong>Conclusion</strong></p>
<p>The point of intermediary liability law and notice and takedown processes is to take illegal content down and keep lawful expression up.  It is to protect the rights of <em>all</em> parties involved -- including the person asserting a removal right, the person whose expression is being challenged, and the person seeking information online.  The GDPR process falls far short of this goal and will lead to the wrong outcomes, potentially in the majority of complaints.  It can be greatly improved by incorporating procedural checks in cases where one person’s request for an intermediary to erase content affects a third party’s right to seek or impart information online.</p>
<p align=""center"">-----</p>
<p><strong>References</strong></p>
<p>The introduction to this series and an FAQ about the GDPR and intermediary liability are <a href=""http://cyberlaw.stanford.edu/blog/2015/10/intermediary-liability-and-user-content-under-europe%E2%80%99s-new-data-protection-law"">here</a>.  A detailed walk-through of the GDPR notice and takedown process is <a href=""https://cyberlaw.stanford.edu/blog/2015/10/notice-and-takedown-under-gdpr-operational-overview"">here</a>.  In my next post, I will discuss how the GDPR relates to other laws and how it got to this point, as a matter of political process and legal evolution.</p>
<div>
<hr align=""left"" size=""1"" width=""33%"" /><div id=""ftn1"">
<p><a href=""#_ftnref1"" name=""_ftn1"" title="""" id=""_ftn1""><sup><sup>[1]</sup></sup></a> As discussed in the Introduction to this series, there is an <a href=""http://cyberlaw.stanford.edu/blog/2015/04/right-be-forgotten-hosting-services"">argument</a> that hosts like Twitter or YouTube are not covered by “Right to Be Forgotten” removal obligations because they are data processors rather than controllers.   This series assumes that hosts will be covered.  The law on point is open to interpretation; but I doubt that DPAs and courts will ultimately choose to exempt such important Internet actors.</p>
</div>
<div id=""ftn2"">
<p><a href=""#_ftnref2"" name=""_ftn2"" title="""" id=""_ftn2""><sup><sup>[2]</sup></sup></a> Most data and anecdotal evidence of over-removal comes from the copyright field, because it generates a high volume of removals and has been subject to considerable transparency for many years. The “Right to Be Forgotten” in Europe is poised to become what copyright is in the US: an important claim to enforce legitimate rights, but also the tool of choice for people who don’t have a valid legal claim and want online content suppressed anyway.</p>
</div>
<div id=""ftn3"">
<p><a href=""#_ftnref3"" name=""_ftn3"" title="""" id=""_ftn3""><sup><sup>[3]</sup></sup></a> In the <a href=""http://cyberlaw.stanford.edu/blog/2015/10/intermediary-liability-and-user-content-under-europe%E2%80%99s-new-data-protection-law"">introductory post</a> to this series, I asked for comments and criticism from others reviewing this material. That request is especially relevant for interpretations of the GDPR’s requirements. If you think I got something wrong, please <a href=""https://twitter.com/daphnehk"">tell</a> me.</p>
</div>
<div id=""ftn4"">
<p><a href=""#_ftnref4"" name=""_ftn4"" title="""" id=""_ftn4""><sup><sup>[4]</sup></sup></a> Provisions covering this have moved and been redrafted quite a bit, but are mostly at Articles 4(3a), 17, 17a, and 19a.</p>
</div>
<div id=""ftn5"">
<p><a href=""#_ftnref5"" name=""_ftn5"" title="""" id=""_ftn5""><sup><sup>[5]</sup></sup></a> Pursuant to Article 29 Working Party’s <a href=""http://ec.europa.eu/justice/data-protection/article-29/documentation/opinion-recommendation/files/2014/wp225_en.pdf"">guidelines</a>.  The GDPR itself does not specify.</p>
</div>
<div id=""ftn6"">
<p><a href=""#_ftnref6"" name=""_ftn6"" title="""" id=""_ftn6""><sup><sup>[6]</sup></sup></a> <a href=""http://www.remarksblog.com/uk-high-court-rules-that-google-is-not-liable-in-blog-defamation-case/"">Davison</a> case in the UK;  <em>Royo v Google</em> in Spain (Barcelona appellate court judgment 76/2013 of 13 February 2013, holding that knowledge requires court order unless validity of claim is manifest). </p>
</div>
<div id=""ftn7"">
<p><a href=""#_ftnref7"" name=""_ftn7"" title="""" id=""_ftn7""><sup><sup>[7]</sup></sup></a> This provision appears in Council draft Article 14a.  Possibly relevant exceptions are set forth at sections 4(c) and (d) of that Article. This provision seems clearly designed for a different situation, in which one company gets data from another company - an insurance company and a data broker, for example.  But since the individual putting content online is probably a controller for that data, it’s her information that would be disclosed.  CJEU case law and Article 29 opinions suggest that in most cases, an individual in this situation could not escape controller status by claiming a household use exemption.  See <a href=""http://curia.europa.eu/juris/liste.jsf?num=C-212/13"">Ryneš</a> and <a href=""http://curia.europa.eu/juris/liste.jsf?num=C-101/01"">Lindqvist</a> cases, and discussion in Bezzi et al, <em>Privacy and Data Management for Life</em>, p. <a href=""https://books.google.com/books?id=peEsGDHxPKwC&pg=PA70&dq=%224.2+users+of+social+networking+sites+as+data+controllers%22&hl=en&sa=X&ved=0CDAQ6AEwAGoVChMIp9_dzszlyAIVED6ICh2R1QE3#v=onepage&q=%224.2%20users%20of%20social%20networking%20sites%20as%20data%20controllers%22&f=false"">70-71</a>.</p>
<div id=""ftn8"">
<p><sup><sup><a href=""#_ftnref8"" name=""_ftn8"" title="""" id=""_ftn8"">[8]</a> </sup></sup><em><span data-term=""goog_1103820863"" tabindex=""0"">November 17, 2015</span> update: </em>Miquel Peguera has pointed out that 14a(1) appears to require the intermediary controller to disclose its <em>own</em> contact information.  He is right, as usual.  Language I should have cited instead appears at 14a(g) and 15(1)(g) of the Council draft. </p>
<p>14a(2)(g) requires the intermediary to disclose “from which source the personal data originate, unless the data originate from publicly accessible sources.” Language at 14a(2) may limit this disclosure based on “circumstances and context,” but does not clearly address the privacy concerns of the Internet user whose information would be disclosed.</p>
<p>15(1)(g) additionally provides the data subject with the right to obtain information, including “where the personal data are not collected from the data subject, any available information as to their source.”</p>
</div>
</div>
<div> </div>
<p> </p>
</div>
<p> </p>
","Intermediary Liability, Privacy",2015-10-29 3:00,1188,Daphne Keller,News
13506,,European Union,0,0,Notice and Takedown Under the GDPR: an Operational Overview,Right to Be Forgotten+Privacy or Data Protection+Freedom of Expression,"<p dir=""ltr""><em style=""font-size: 13.008px; line-height: 1.538em;""><span id=""docs-internal-guid-6c3665a5-b15c-6f1a-f46e-5bbb5dcf9998"">This is one of a series of posts about the pending EU General Data Protection Regulation (GDPR), and its consequences for intermediaries and user speech online.  In an </span></em><em style=""font-size: 13.008px; line-height: 1.538em;"">earlier <a href=""http://cyberlaw.stanford.edu/blog/2015/10/intermediary-liability-and-user-content-under-europe%E2%80%99s-new-data-protection-law"">introduction and FAQ</a>, I discuss the GDPR’s impact on both data protection law and Internet intermediary liability law.  Developments culminating in the GDPR have put these two very different fields on a collision course -- but they lack a common vocabulary and are in many cases animated by different goals.  Laws addressing concerns in either field without consideration for the concerns of the other can do real harm to users’ rights to privacy, freedom of expression, and freedom to access information online.</em></p>
<p><em><span id=""docs-internal-guid-6c3665a5-b15c-6f1a-f46e-5bbb5dcf9998"">Disclosure: I previously worked on Right to Be Forgotten issues as Associate General Counsel at Google.  </span></em></p>
<p><em style=""font-size: 13.008px; line-height: 1.538em; color: rgb(51, 51, 51); font-family: 'Helvetica Neue', 'Helvetica Neue', Helvetica, Arial, sans-serif;"">Cross-posted to the </em><em style=""font-size: 13.008px; line-height: 1.538em; color: rgb(51, 51, 51); font-family: 'Helvetica Neue', 'Helvetica Neue', Helvetica, Arial, sans-serif;""><a href=""http://policyreview.info/articles/news"" style=""font-size: 13.008px; color: rgb(128, 0, 0); transition: all 0.3s; outline: none; line-height: 1.538em; background: transparent;"">Internet Policy Review News & Comments</a> </em><em style=""font-size: 13.008px; line-height: 1.538em;"">and <a href=""https://inforrm.wordpress.com/tag/daphne-keller/"">Inforrm</a> blogs.</em></p>
<p> </p>
<p>-----</p>
<p>This is the third post in a series analyzing the EU’s pending General Data Protection Regulation (GDPR).  The <a href=""https://cyberlaw.stanford.edu/blog/2015/10/gdpr%E2%80%99s-notice-and-takedown-rules-bad-news-free-expression-not-beyond-repair"">previous post</a> reviewed high-level problems with the GDPR’s process for erasing content posted online by Internet users.  The process disproportionately burdens the rights of Internet users to seek and impart information online.  Those rights could be much better protected, without sacrificing remedies for people whose privacy has been violated, if the GDPR treated erasure of user-generated content separately from erasure of data collected directly by companies based on user behavior and used for back-end processes such as profiling.  The GDPR could then apply standard, well-tested procedural checks to limit erroneous or bad faith removals of lawful user-generated content. </p>
<p>This post goes into more detail about the Regulation’s exact language and the removal process.  It will walk through each step an intermediary would follow to erase user-generated content based on the GDPR’s Right to Be Forgotten provisions. </p>
<p>For the person requesting content removal on the basis of privacy or data protection rights, the removal process will be something of a black box – though increasing <a href=""http://www.theguardian.com/technology/2015/may/14/dear-google-open-letter-from-80-academics-on-right-to-be-forgotten"">calls for transparency</a> could change that somewhat in practice.  From the perspective of the person whose speech rights are affected, it’s an even blacker box.  In many cases, the speakers may not know that their content has been challenged and taken down; if they notice that it’s gone, they won’t know why.  From the perspective of the people seeking information online, the process is entirely opaque.   They’ll never know what they’re missing.  </p>
<p>From the intermediary’s perspective, the process is an operational challenge, requiring an ongoing investment of time, personnel, legal analysis and engineering work.  Not all intermediaries will choose to make that investment, or to go through the process described here. Financial incentives for companies to simply honor all removal requests, or to err on the side of removal in case of doubt, are extremely strong.   An intermediary risks sanctions of up to 0.5% -- or 2%, or even 5%, depending which draft provision you read -- of its annual global turnover every time it chooses to keep user content online.  (Art 79)  Those are dangerously high figures for any company, and particularly for intermediaries handling multiple takedown requests.  As a result, the GDPR will likely lead to the frequent erasure of lawful, free expression by Internet users.</p>
<p>The GDPR draft provisions cited here all appear in the European Data Supervisor’s comparison <a href=""https://secure.edps.europa.eu/EDPSWEB/webdav/site/mySite/shared/Documents/Consultation/Opinions/2015/15-07-27_GDPR_Recommendations_Annex_EN.pdf"">document</a>.</p>
<p><strong>            1.  The Removal Request Comes In</strong></p>
<p>In practice and under many intermediary liability laws or model rules, an intermediary may receive an initial removal request but not have enough information to evaluate it until later, when the requester sends more information.  The GDPR does not clearly distinguish between those two stages, which creates problems I describe below.</p>
<p style=""margin-left:1in;""><strong>a.   The Initial Communication Arrives</strong></p>
<p>The first thing that happens is that the intermediary gets a removal request, asserting that content put online by another Internet user violates the requester’s rights.  If it does not have a well-designed intake form for requests (because it’s a small company, for example), or if the requester did not use the form, further communication will often be necessary for clarification.  Such back and forth is common, because removal requests often inadvertently omit key information like the location of the offending content or the legal right it is said to violate. </p>
<p>This part of the process would be greatly improved for both the requester and the intermediary if they could rely on existing intermediary liability law or best practices regarding the information that must be included in removal requests. Those rules tell intermediaries, as a procedural matter, when to proceed to the request evaluation stage; and they ensure the intermediary has the information it needs when that stage comes.  For people requesting removal, clear rules help them submit an actionable request on the first try, and tell them when the ball is in the intermediary’s court to respond.</p>
<p>The GDPR could help requesters and companies by implementing form-of-request requirements modeled on the DMCA, the <a href=""https://www.manilaprinciples.org/"">Manila Principles</a>, or even existing national-law guidelines for complaints to DPAs. <a href=""https://www.manilaprinciples.org/"">These need</a> not be onerous.  Guidelines commonly call for the requester to provide things like her contact information, the exact location of the content, and the legal basis for removal.  For Right to Be Forgotten requests, Microsoft’s Bing <a href=""https://www.bing.com/webmaster/tools/eu-privacy-request"">removal request form</a> suggests a useful additional element: the requester must explain any public role she has in her community.</p>
<p>The GDPR allows the intermediary to ask the requester for ID at this stage, if there is a reasonable doubt as to her identity.  (Art 10.2, 12.4a, Council draft).   Intermediaries can also reject requests that are “manifestly unfounded or excessive”; by doing so they assume the burden of proof for that conclusion.  (Art. 12.4, Council draft) </p>
<p style=""margin-left:1in;""><strong>b.   The Requester Provides Any Additional Information Needed for the Intermediary to Evaluate Her Claim</strong></p>
<p>At some point, with or without further communication with the requester, the intermediary acquires enough information to make a judgment about honoring the removal request.  (Or, is presumed by law to have enough information.)  You could think of this as the point when the request becomes procedurally ripe or valid, in the same way that a court pleading becomes procedurally valid by meeting legal filing formalities.  Once it is reached, the intermediary can turn to the substantive legal claim being asserted.</p>
<p>The GDPR requires a one-month turnaround time for most removal requests.  Hopefully this only begins once the request is procedurally ripe, and evaluation is possible.  The GDPR could be clear though – the one-month clock should not start ticking from the minute the first communication comes through the door, unless it provides necessary, specified information.  (Art. 12.2)</p>
<p><strong>            2.  The Intermediary Restricts Public Access to the Disputed Content</strong></p>
<p>Now, the first really unusual thing happens: in most cases, the intermediary must take the challenged content offline immediately, <em>before</em> weighing the public interest and perhaps before even looking at the content.   The GDPR calls this “restriction” of processing.  The restriction provisions have changed language and location from draft to draft, and are difficult to parse. But they appear to mean that intermediaries take challenged content offline first, and ask questions later , subject to some unclear exceptions.  They may even mean that the intermediary must temporarily remove content as soon as the initial complaint identifies the content’s location, even before the requester clarifies the basis for the legal claim.  To my knowledge, this is unprecedented.  No other intermediary liability system gives one user this kind of instantaneous veto power over another user’s expression.<sup><sup><a href=""#_ftn1"" name=""_ftnref1"" title="""" id=""_ftnref1"">[1]</a></sup></sup></p>
<p>The rest of this subsection will parse the GDPR’s dense legislative language about restriction of content.  Readers who don’t like that kind of thing should probably skip ahead to Step 3.  The basic overview is this:  (a) most provisions clearly say that “restricted” content must be rendered publicly inaccessible; (b) almost any removal request to an intermediary can trigger the restriction obligation; and (c) exceptions to automatic takedown exist, but they aren’t very clear or meaningful.  Minor amendments could, and should, clarify these exceptions to solve the problem I identify here.</p>
<p style=""margin-left:1in;""><strong>a.       What does it mean to restrict content?</strong></p>
<p>The GDPR says that restricting content means making it inaccessible to the public.  As the Parliament draft explains, restricted data is no longer “subject to the normal data access and processing operations and cannot be changed anymore” -- including, presumably, by the person who uploaded it.  (Parl. Art. 17(4))  The Council draft provides that restricted data:</p>
<p style=""margin-left:.5in;"">may, with the exception of storage, only be processed with the data subject consent or for the establishment, exercise or defence of legal claims or for the protection of the rights of another natural or legal person or for reasons of important public interest. (Art. 17a(3), <em>see also </em>EDPS draft Art. 19a)</p>
<p>In other words, restricted data is kept in storage and not otherwise processed unless an exception applies.</p>
<p>The Council draft definition of “restriction of processing” introduces the only ambiguous note.  It says restriction is “the marking of stored personal data with the aim of limiting their processing in the future.”  (Art. 4(3a))  For intermediaries, arguably this could mean “marking” back-end copies of user-generated content, but not restricting normal public access.  That’d be odd and inefficient as a technical matter, but at least it wouldn’t burden anyone’s speech and information rights in advance of knowing whether the takedown request is valid.  It’s not likely to be what is meant, though, because the same draft, from the Council, includes the language I quoted above about suspending “normal data access.” </p>
<p>More likely, this anomalous definition just reflects the GDPR drafters’ focus on back-end stored user data, rather than on public-facing online content.  A good revision to the GDPR could track exactly this distinction.  By expressly excluding user-generated content from the restriction provisions, drafters could avoid significant problems that the restriction provisions create for online expression and information rights.</p>
<p style=""margin-left:1in;""><strong>b.  What kinds of requests trigger content restriction?</strong></p>
<p>In theory, not all requests should trigger content restriction.  The GDPR says restriction is only for processing and requests that are predicated on specific, enumerated legal grounds.  (Parl. Art. 17a(3); Art. 6)  Those grounds may effectively cover all processing of user-generated content by Intermediaries, though.</p>
<p>One listed basis for restriction is when content’s “accuracy is contested by the data subject, for a period enabling the controller to verify the accuracy of the data.”  (Council 17a(1)(a)); Parl. Art 17.4(a))  In other words, claims that would once have sounded in defamation, and been subject to well-developed defenses, now lead to immediate suspension of content.  The content can be reinstated when the controller “verif[ies] the accuracy of the data” -- generally meaning never, because finding the truth behind real-world disputes is not what intermediaries do well.  Interestingly, the problems with asking anyone but courts to adjudicate questions of accuracy were flagged by the Article 29 Working Party in its <em>Costeja</em> <a href=""http://ec.europa.eu/justice/data-protection/article-29/documentation/opinion-recommendation/files/2014/wp225_en.pdf"">recommendations</a>, saying that DPAs await should judicial determinations in cases of ongoing dispute about accuracy.  The GDPR nonetheless puts this responsibility in the hands of intermediaries.</p>
<p>The other basis for restriction is even broader, but harder to piece together from the GDPR text.  It arises when an intermediary’s initial processing of user-generated content took place on the basis of “legitimate interests” that outweighed the privacy rights of people mentioned or depicted in that content.  (Art. 6.1.(f)) Under data protection law, this is the legal basis for most, possibly all processing of such data by intermediaries.  So this basis for restriction seems to apply generally to intermediaries facing content removal requests.</p>
<p>To figure out whether to restrict in response to such a request, an intermediary must perform a multi-step, circular analysis, which hinges almost entirely on balancing poorly defined “legitimate interests.”<a href=""#_ftn2"" name=""_ftnref2"" title="""" id=""_ftnref2""><sup><sup>[2]</sup></sup></a>  This “legitimate interests” analysis is very similar to the analysis the intermediary is supposed to perform later, to decide whether to permanently erase the content.  The “legitimate interests” basis for temporary restriction should be different from the “legitimate interests” basis for permanent erasure, though.  The two analyses happen at different times, and an intermediary is supposed to restrict “pending the verification whether the legitimate grounds of the [intermediary] controller override those of the data subject,” i.e. restriction is provisional until the erasure decision is made.   (Council 17a(1)(c)).   But given the confusing similarity of the standards, and the clear intention that some content be restricted from public access right away, we should not be surprised to see quick and sloppy -- and permanent -- removal decisions being made immediately upon receipt of challenges to online expression.</p>
<p>Similar GDPR language in another draft, which may or may not mean the same thing, says restriction lasts until “the controller demonstrates compelling legitimate grounds for the processing which override the interests, fundamental rights and freedoms of the data subject.” (Parliament Art 19(1)).<a href=""#_ftn3"" name=""_ftnref3"" title="""" id=""_ftnref3""><sup><sup>[3]</sup></sup></a>  Here again, the standard for ending restriction is unclear.  It might boil down to the same vague, widely criticized standard set by the Court of Justice of the European Union (CJEU) in the <a href=""http://curia.europa.eu/juris/document/document_print.jsf?doclang=EN&docid=152065""><em>Costeja</em></a> “Right to Be Forgotten” case -- but expressed in a lot more words.</p>
<p style=""margin-left:1in;""><strong>c.  Exceptions to the restriction requirement</strong></p>
<p>Intermediaries can decline to restrict content “for reasons of important public interest” or to protect “the rights of another natural or legal person.”<a href=""#_ftn4"" name=""_ftnref4"" title="""" id=""_ftnref4""><sup><sup>[4]</sup></sup></a>  (Council 17a(3))  It’s unclear if these exceptions set a higher or lower bar than the “legitimate interests” standard intermediaries are supposed to apply at other points in their analysis of removal requests.   Arguably, these exceptions protect even less content than the CJEU’s <em>Costeja</em> standard: <em>Costeja</em> lets Google reject de-indexing requests based on the “<em>preponderant</em> interest of the general public,”  while the GDPR lets intermediaries leave content up, during the time it takes to evaluate a removal request, based on an  “<em>important</em> public interest.”  (Costeja Par. 97)   Intermediaries willing to bet real money that they know the difference between “preponderant” and “important” can choose their actions accordingly.  Intermediaries flummoxed by these standards will simply take the content offline without additional review.</p>
<p>Another exception permits content to remain publicly available at this stage “in order to protect the rights of another natural or legal person”. This seems more promising.  Content removal requests, almost by definition, affect the rights of another person -- the content’s publisher.  Intermediaries or publishers could even argue that <em>every</em> request to remove public content (as opposed to every request to erase user data in back-end storage) qualifies for this exception.   It is unrealistic to expect intermediaries broadly to take this position, of course, given uncertainty the about whether DPAs or courts would agree, and given that errors expose the company to fines heavy enough to sink a business.  But GDPR drafters could easily modify this part of the statute to protect online speakers from having legal content suppressed, by specifying that pre-review restriction is never appropriate in the case of user-generated content. </p>
<p><strong>            3. The Intermediary Decides Whether to Permanently Remove the Content</strong></p>
<p>The intermediary now comes to the crux of the issue:  Has the complainant made a claim strong enough to override the interests of the person who put the content online in the first place – as well as the interests of all the people who might want to see it, and the interests of the intermediary itself?  If so, the content gets erased.  I’ll write about how the GDPR shapes that substantive decision -- the merits of the “Right to Be Forgotten” claim -- later.  One interesting procedural wrinkle is that, according to the Article 29 Working <a href=""http://ec.europa.eu/justice/data-protection/article-29/documentation/opinion-recommendation/files/2014/wp225_en.pdf"">Party</a>, in difficult cases the intermediary may at this stage consult with the user who uploaded the information.  I’ll talk later about the limited practical value of this possibility.  For now, I assume that the intermediary agrees to remove the content.    </p>
<p><strong>            4. The Content is Removed</strong></p>
<p>For a search index, presumably what the GDPR calls “erasure” is meant to instead be the more limited de-linking mandated in the <em>Costeja</em> case.  (The GDPR does not actually say this.  But if the GDPR rendered <em>Costeja</em> obsolete, a more expert data protection lawyer than I would surely have pointed it out by now.)  Following the CJEU’s ruling, this means removing links, titles, snippets and cache copies of the webpage from only certain search results: those generated by searching on the requester’s name.</p>
<p>For hosting platforms, complying with a GDPR removal request has far greater impact on Internet users’ free expression and access to information.<a href=""#_ftn5"" name=""_ftnref5"" title="""" id=""_ftnref5""><sup><sup>[5]</sup></sup></a>   Deletion by a host often eliminates the only place on the Internet where particular material can be found.  In practice, for ephemeral content like social media posts, it is often the author’s only copy as well.  Content deleted by an Internet host may be well and truly gone from the world.  Given these dramatically greater consequences, the standards applied by hosts in making removal decisions should be very different than those applied by search engines – with much greater weight given to free expression concerns.  As a procedural matter, it also seems more than reasonable that a host should postpone final erasure until the speaker has an opportunity to defend her speech. But while the difference between de-indexing search results and deleting content at its source is widely commented upon in academic and policy discussions, I know of no written guidelines for hosts.  The GDPR provides none.<sup><sup><a href=""#_ftn6"" name=""_ftnref6"" title="""" id=""_ftnref6"">[6]</a></sup></sup></p>
<p><strong>            5. The Requester and Downstream Recipients Are Told About the Removal</strong></p>
<p>The primary person the intermediary must tell about removal is, of course, the requesting data subject. (Art. 12.2)  In addition, to help that person enforce his or her data protection rights, the intermediary must also pass information about the removal downstream, so that whoever received content from the intermediary can also delete it.<a href=""#_ftn7"" name=""_ftnref7"" title="""" id=""_ftnref7""><sup><sup>[7]</sup></sup></a>  (Art. 13)    If the intermediary has unlawfully made the data public, it must attempt to undo the damage by tracking down recipients and telling them to delete any copies or links.  (Art 17.2)</p>
<p>These pass-through provisions, while potentially valuable with respect to traditional data controllers -- a hospital that shared patient information with an insurer, for example -- are an odd fit for intermediaries.  The content they handle typically originates with a third party, and passes through the intermediary’s technical systems without human review.  If that content was “illegal” <em>ab initio</em> under the GDPR, perhaps because of special rules governing sensitive data, must the intermediary then ransack its logs to find and communicate deletion requests to other users who saw it?  Would the person requesting removal – say, someone who was the subject of an ugly Facebook post – even want to risk the potential <a href=""https://en.wikipedia.org/wiki/Streisand_effect"">Streisand Effect</a> from this publicity?  </p>
<p><strong>            6.  The Intermediary Discloses Identifying Information About the User Who Posted the Content</strong></p>
<p>The GDPR also creates a troubling disclosure obligation in cases where the intermediary got the disputed content from someone other than the person requesting removal -- which is the case in most notice and takedown situations.  The intermediary is supposed to tell the requester “the identity and the contact details of the controller” -- in other words, the Internet user -- who provided the content.  (Art. 14a Council)  While there are arguments that users posting on social media or other hosting platforms do not qualify as controllers, those arguments have fared poorly in court and in analysis from academics and the Article 29 Working Party.<a href=""#_ftn8"" name=""_ftnref8"" title="""" id=""_ftnref8""><sup><sup>[8]</sup></sup></a>  Users who post their expression online are probably controllers, and the GDPR disclosure requirement probably applies to their personal data held by an intermediary.  The intermediary can be compelled, based on an unverified complaint, to unmask anonymous speakers -- sharing <em>their</em> personal information without consent.</p>
<p>The disclosure requirement may be a sensible provision for traditional data controllers -- say, a lender that shared information with a credit reporting agency.   But it is dangerous for online platforms.  It provides a means for companies and individuals to identify and potentially retaliate against people who say things about them that they do not like. The GDPR specifies no legal process or protection for the rights of those users, but does provide exceptions for cases in which “disclosure is expressly laid down by Union or Member State law to which the controller is subject” (14a.4(c) Council, <em>sic</em>).  Presumably this section is intended to limit disclosure of user data to situations where there is valid legal process and the disclosure complies with the legal protections of the GDPR itself.  But this is far from clear, and badly in need of redrafting to clearly prohibit disclosure absent adequate legal protection for the speaker.<a href=""#_ftn9"" name=""_ftnref9"" title="""" id=""_ftnref9""><sup><sup>[9]</sup></sup></a>  </p>
<p>I can only assume that the drafters were not considering this situation, or its tremendous impact on anonymous online speech, given their keen interest in anonymity and pseudonymity in other parts of the GDPR.  Here again, viewing the issue through the lens of intermediaries’ Notice and Takedown process illuminates disturbing consequences for Internet users who seek and impart information on the Internet.  And, again, simply excluding online content providers from this provision of the GDPR would solve an important problem.</p>
<p><em>See new footnote<sup><sup><a href=""#_ftn10"" name=""_ftnref10"" title="""" id=""_ftnref10"">[10]</a></sup></sup> for updated analysis as of <span data-term=""goog_1103820865"" tabindex=""0"">Nov. 17 2015</span></em></p>
<p><strong><strong>            7. The Person Who Put Content Online Is Not Told of Its Erasure</strong></strong></p>
<p>Finally, there is the one person who is <em>not</em> supposed to be told about the removal: the person whose speech is being erased.  The GDPR leaves intact legal provisions that regulators have interpreted to prohibit notice to the content’s publisher under existing law.  In its <a href=""http://ec.europa.eu/justice/data-protection/article-29/documentation/opinion-recommendation/files/2014/wp225_en.pdf"">guidelines</a> for Google’s implementation of the <em>Costeja</em> decision, the Article 29 Working Party said that there is no legal basis for Google to routinely tell webmasters when their content is delisted.<sup><sup><a href=""#_ftn11"" name=""_ftnref11"" title="""" id=""_ftnref11"">[11]</a></sup></sup></p>
<p>The idea that the person who put content online should not know when it is erased or de-linked makes some sense from a pure data protection perspective. The idea is that the requester is exercising a legal right to make the company stop processing her information.  Talking to a publisher or webmaster about the request is just more unauthorized processing.  More pragmatically, a person whose privacy is violated by online content probably will not want the perpetrator to know of her efforts to remove it.</p>
<p>Viewed through the lens of intermediary liability, due process, or free expression rights, by contrast, this looks pretty outrageous.  It gives all procedural protections to the accuser, and none to the accused.  The resulting harms to individuals and companies are real: a small business can lose access to customers; a speaker can have her opinions silenced; all through a secret process which in most cases provides no notice or opportunity for defense.  There is a reason that intermediary liability model rules like the <a href=""https://www.manilaprinciples.org/"">Manila Principles</a>, and existing laws like the US <a href=""https://www.law.cornell.edu/uscode/text/17/512"">DMCA</a>, allow or even require companies to let users know when their content is deleted, and give users a chance to challenge removal decisions.  A response or “counternotice” from the content provider serves as an important check on both improper removal requests and intermediary error in processing them.  The risk of error -- or laziness, or risk-aversion -- by the intermediary is the reason why routine, pre- or post-removal notice to the accused Internet user is so important.  If notice only happens when the intermediary figures out that a removal request is problematic -- as Article 29 suggested in its <a href=""http://ec.europa.eu/justice/data-protection/article-29/documentation/opinion-recommendation/files/2014/wp225_en.pdf"">Guidelines</a> -- many improper deletions of legal content will go uncorrected.</p>
<p>Notice to the person who put the content online can lead to better decision-making, by bringing someone who knows the context and underlying facts -- and who is motivated to defend her own expression -- into the conversation.  Importantly, it also opens up possibilities for better, more proportionate, and well-tailored solutions.  While intermediaries have a binary<a href=""#_ftn12"" name=""_ftnref12"" title="""" id=""_ftnref12""><sup><sup>[12]</sup></sup></a> choice – take content down or leave it up – a content creator can do much better: she can reword a bad phrase, update or annotate a news story, take down a picture from a blog post while leaving lawful text intact. She can preserve the good parts of her online speech while removing the bad.  Removal or correction of content at its source can also provide a better outcome for a person whose rights it violated, since the infringing content is no longer out there for people to find on other sites or shared by other means. </p>
<p>A number of courts have looked to content creators to take measures like this in the “Right to Be Forgotten” context. A recent, post-Costeja data protection <a href=""http://iuscomparatum.info/colombia-constitutional-court-rules-on-the-right-to-be-forgotten/"">case</a> from the Constitutional Court of Colombia is an example.  After weighing the opposing fundamental rights at issue, the court ordered an online news source to (1) update its article about the plaintiff, and (2) use <a href=""http://www.robotstxt.org/robotstxt.html"">simple technical tools</a> to prevent search engines from listing the information in search results.  Jef Ausloos and Aleksandra Kuczerawy <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2669471"">report</a> a similar case in Belgium.  The idea of putting this decision and technical control in the hands of the publisher is not new -- well before <em>Costeja</em>, the Italian DPA did the same thing with archived news articles about old criminal convictions.<sup><sup><a href=""#_ftn13"" name=""_ftnref13"" title="""" id=""_ftnref13"">[13]</a></sup></sup></p>
<p>Giving publishers notice and opportunity to defend their online expression would make the GDPR’s removal process more fair; avoid unnecessary harm to free expression and information access online; and introduce better tools to redress privacy harms to the person requesting removal.  Right now, the GDPR is putting decisions about the publisher’s content in the hands of her accuser and a technology company, instead -- and giving both of those parties incentives to disregard her rights.</p>
<p>The GDPR creates a process that fails to protect Internet users’ rights to free expression and access to information.  Simple text changes could eliminate many of these shortcomings, while still providing relief for people harmed by content online.  Lawmakers can and should make those changes while there is still time.</p>
<div><br clear=""all"" /><hr align=""left"" size=""1"" width=""33%"" /><div id=""ftn1"">
<p><a href=""#_ftnref1"" name=""_ftn1"" title="""" id=""_ftn1""><sup><sup>[1]</sup></sup></a> Though most laws would not preclude removals outside the intermediary liability framework, such as voluntary removals and in some countries government requests, from working like this.</p>
</div>
<div id=""ftn2"">
<p><a href=""#_ftnref2"" name=""_ftn2"" title="""" id=""_ftn2""><sup><sup>[2]</sup></sup></a> Council Article 17a(1)(c) says a data subject has a right to restriction where “he or she has objected to processing pursuant to Article 19(1) pending the verification whe","Intermediary Liability, Privacy",2015-10-29 3:00,1188,Daphne Keller,News
13507,,International,1,1,October 2015 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>October 2015 in Retrospect is available here:</p>
<p><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2015-october/"">http://www.internetjurisdiction.net/observatory/retrospect/2015-october/</a></p>
<p>Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
","Architecture and Public Policy, Intermediary Liability, Privacy",2015-11-02 12:18,505,Giancarlo Frosio,News
13543,,Brazil,0,0,Intermediary Liability Implications of Proposed Brazilian Libel Law Reform,Defamation or Personality Rights,"<p>Several bills pending before the Brazilian Congress seek to institute harsher penalties for crimes against honor and reputation when perpetrated through social networks. Below, you find a summary of the proposed changes to the present Brazilian legal framework and how those changes may impact intermediary liability.</p>
<p><strong>1. The <em>status</em> of crimes against honour in Brazilian law</strong></p>
<p>The <a href=""https://cyberlaw.stanford.edu/page/wilmap-brazil"">Brazilian Criminal Code</a> regulates four conducts as crimes against the honor. They are slander (Article 138), defamation (Article 139), libel (Article 140), and disrespect (Article 331). The first of the three operate against any person, and the fourth, disrespect, must be necessarily perpetrated against a government authority with regards to their function.</p>
<p>The maximum base penalties for the crimes of slander, defamation and libel are up to two years, with the possibility of increase by one third in four special cases (Article 141). These crimes, moreover, have their corresponding penalty doubled if there is promise of payment, or actual payment, to the perpetrator. The penalties are calculated in years of “detention” (meaning that “semi-open” and “open” regimes are employed), rather than ""reclusion"" (implicating time served fully in a penitentiary). No crimes against the honor, currently, are punishable by “detention”. Only the hypothesis of recidivism, or crimes which result in a penalty superior to four years, are punishable by any of such regimes. Crimes with penalties shorter than four years, which also do not constitute recidivism, must be converted in alternative penalties, encompassing fines and mandatory social works.</p>
<p>Currently, Brazilian law does not considered any crimes against honour as “heinous crimes,” a special category of crimes punished by reclusion, with no possibility of progression to a more lenient regime, amnesty or bail, and not bound by the statute of limitations. Moreover, there is no criminal liability for Internet intermediaries in Brazilian law.</p>
<p><strong>2. The proposed reforms</strong></p>
<p>There are three bills regarding the matter, which have been consolidated and will be voted jointly by the Congress. Two of them, bills <a href=""http://www2.camara.leg.br/proposicoesWeb/fichadetramitacao?idProposicao=946034"">215/2015</a> and <a href=""http://www2.camara.leg.br/proposicoesWeb/fichadetramitacao?idProposicao=1278965"">1547/2015</a>, regard solely criminal liability for crimes against the honour of individuals. Through both of them the Congress seeks to institute harsher penalties for such crimes when perpetrated through the use of social networks.</p>
<p>The latest bill, number <a href=""http://www2.camara.leg.br/proposicoesWeb/fichadetramitacao?idProposicao=1279451"">1589/2015</a>, bears similar proposed changes to criminal law, although attributing harsher penalties than the other two. In addition to these changes, it also bears various proposed provisions to drastically change obligations of internet providers and their liabilities.</p>
<p><strong>2.1 Reforms regarding direct criminal liability</strong></p>
<p>Drafted in 2014, the Federal Bill 215/2015 was originally a proposed reform of <span style=""font-size: 13.008px; line-height: 20.0063px;"">Article 141 of the Brazilian Criminal Code. By the original text, a fifth hypothesis would be added: (V) “through the use of social networks”. Since its proposal, the bill has been amended by various congressmen, and absorbed two other similar, posterior, bills: 1547/2015 and 1589/2015.</span></p>
<p>Bill 1547/2015 had a similar provision to bill 215/2014. It incorporated a proposed text for the addition of a fifth hypothesis for the increase of penalty contained on Article 141, very similar to the amendment proposed in bill 215/2014, with a slightly different wording: “in sites or through means of electronic messaging spread through the Internet”. It also included a proposal for reform of the Criminal Procedure Code, to obligate the competent authorities to print the content which would constitute the crime in order to “safeguard copy of the offensive material to compose the future police investigation and possible criminal action.”</p>
<p>The third joined bill, 1589/2015, differs substantially from the previous two. It institutes two paragraphs in Article 141:</p>
<p style=""margin-left:1cm;"">“§2, if the crime is perpetrated through content made available on the Internet, the penalty shall be doubled”; and</p>
<p style=""margin-left:1cm;"">“§3, if the slander, defamation or libel cause acts that result in the death of the victim, the penalty shall be of reclusion and applied five-fold.”</p>
<p>A provision also exists to make the crimes under the new two paragraphs prosecutable by the public authorities, independently from charges being pressed by the offended party. Moreover, there also exists a provision to constitute heinous crimes those resulting in death of the victim, as well as a provision excluding the possibility of bail in the case of paragraph 3. Finally, the 1589/2015 bill also includes a general rule, applicable to every crime, that obligates judges to estipulate a minimum reparation of damages for civil liability in all sentences.</p>
<p><strong>2.2 Reforms regarding intermediary liability</strong></p>
<p>Of the three bills, only bill nº 1589/2015 addresses intermediary liability and includes provisions altering the recently enacted <em><a href=""https://cyberlaw.stanford.edu/page/wilmap-brazil"">Marco Civil da Internet</a> </em>(MCI). Some of such provisions address intermediary liability directly, and the remainder of them alter the obligations of online intermediaries, hence making them indirectly liable for offenses. Specifically, Articles 10, 13, 15, 19, 21 and 23 of the MCI are proposed to be changed or adapted. </p>
<ol><li>Proposed article 23-A institutes the possibility for law enforcement authorities to request sensitive data to their guardians, in order to enable them to initiate criminal investigations on crimes against the honor perpetrated through the Internet, when no other means are available for producing such proof, and subsequently to bring charges to individuals involved. In consonance to proposed Article 23-A, two paragraphs of Article 10 of the MCI, which deal with limitations to the making available of sensitive data by its guardians, are proposed to be changed. The current provision requires a judicial order for obtening the data. The proposed amendments would add the locution “or by request of the competent authority”, waiving the requirement of a judicial order for authorities to obtain them.</li>
<li>Complimentary to the changes to Article 23, the bill also alters the texts of paragraph 5 of Article 13 and paragraph 3 of Article 15, dealing with the responsibilities of Internet access and hosting providers over the safeguard of private data, as to make them coherent to the new form of requisition by “competent authorities.”</li>
<li>Proposed article 23-B defines as crime the act of unlawfully requesting or making available sensitive data, punishable by up to four years and fine.</li>
<li>Article 19 of the MCI<em>, </em>which deals with intermediary liability, is also proposed to be changed by instituting, at paragraph 3-A, a right to be forgotten, conditioned to specific judicial order: “The individual or his legal representative may require judicially, at any time, the <em>unavailability </em>of content that relates his name or image to crime of which he has been absolved, after due process, or to slanderous, defamatory or libellous fact.” Proposed paragraph 4-A complements proposed paragraph 3-A, and sets the possibility for preliminary injunctions over the matter.</li>
<li>In addition to the current intermediary liability of Internet hosting providers set by Article 21 of the<em> </em>MCI, proposed Article 21-A sets intermediary liability for Internet access providers who fail to comply with the order of making ""unavailable"" the content indicated in Article 19 of the MCI.<br /><p style=""margin-left: 1cm;"">“The Internet connexion provider that fails to take action to make <em>unavailable </em>the content to which art. 19 refers shall be liable to the payment of a fine of R$50.000,00 (fifty thousand reais), applied in double in case of recidivism, notwithstanding other civil or criminal sanctions applicable.”</p>
<p>Although the text of proposed Article 21-A specifically addresses Internet access providers, it makes reference to Article19, which specifies the liability of Internet hosting providers for failing to comply with a court order requiring to make content <em>unvailable</em>.</p>
</li>
</ol><p><strong>3. The legal implications of bill nº 1589/2015</strong></p>
<p>The proposed reform of Brazilian law would have a major impact on direct liability and intermediary liability for crimes against honor and reputation perpetrated through the Internet.</p>
<ol><li>The change in prescribed penalties would result in maximum penalties, for the crime of slander, of four or ten years if the crime is perpetrated through content made available on the Internet or results in death of the victim, respectively. If an hypothesis of increase of the penalty is applied, the sentences can result in penalties of 5 years and 73 days and 13 years, respectively.</li>
<li>Proposed paragraph 3 of Article 141 would make the crime punishable by “reclusion”, in lieu of “detention”. Combined with the proposed change to make such a “heinous crime”, the penalty would be served in a penitentiary for its first two fifths, or three fifths in case of recidivism. As such, the maximum penalty of 13 years would result in imprisonment for five years and 73 days, or for 7 years and 292 days in case of recidivism.</li>
<li>Proposed article 23-B, that defines as crime the act of unlawfully requesting or making available sensitive data, is the first hypothesis of direct criminal liability of an individual linked to an Internet provider. This represents the possibility of direct criminal liability of an individual acting as an intermediary on the Internet.</li>
<li>Internet hosting providers would theoretically maintain the same degree of liability currently attributed to them by the <em>Marco Civil da Internet</em>, as the text of proposed article 21-A specifies Internet access providers, in lieu of Internet hosting providers. Access providers, however, would be liable to paying fines for the omission in making content unavailable. Further alterations or corrections to this text may still be made, and the text of proposed article 21-A may change to include Internet hosting providers.</li>
</ol><p><em><a href=""https://br.linkedin.com/in/felipebusnello/en"">Felipe Octaviano Delgado Busnello</a> is a qualified Brazilian attorney active in the field of internet and intellectual property law. He can be reached at felipe.busnello at gmail.com.</em></p>
",Intermediary Liability,2015-11-30 6:30,505,Giancarlo Frosio,News
13639,,European Union,0,0,Solving Data Protection Problems with eCommerce Directive Tools,Right to Be Forgotten+Privacy or Data Protection+Freedom of Expression,"<p><em style=""font-size: 13.008px; line-height: 1.538em;"">Cross-posted to the </em><em style=""font-size: 13.008px; line-height: 1.538em;""><a href=""http://policyreview.info/articles/news"" style=""font-size: 13.008px; line-height: 1.538em;"">Internet Policy Review News & Comments</a> and <a href=""https://inforrm.wordpress.com/tag/daphne-keller/"">Inforrm</a> blogs.</em></p>
<p><em>This is one of a series of posts about the pending EU General Data Protection Regulation (GDPR), and its consequences for intermediaries and user speech online.  In an earlier </em><a href=""http://cyberlaw.stanford.edu/blog/2015/10/intermediary-liability-and-user-content-under-europe%E2%80%99s-new-data-protection-law""><em>introduction and FAQ</em></a><em>, I discuss the GDPR’s impact on both data protection law and Internet intermediary liability law.  Developments culminating in the GDPR have put these two very different fields on a collision course -- but they lack a common vocabulary and are in many cases animated by different goals.  Laws addressing concerns in either field without consideration for the concerns of the other can do real harm to users’ rights to privacy, freedom of expression, and freedom to access information online.</em></p>
<p><em>Disclosure: I previously worked on ""Right to Be Forgotten"" issues as Associate General Counsel at Google. </em></p>
<p>-----</p>
<p>In my previous two <a href=""http://cyberlaw.stanford.edu/blog/2015/10/gdpr%E2%80%99s-notice-and-takedown-rules-bad-news-free-expression-not-beyond-repair"">posts</a> about the GDPR, I identified serious problems with its notice and takedown process, and resulting threats to Internet users’ rights to free expression and access to information. The legal framework of intermediary liability provides a lens for identifying these problems.  It also offers a set of ready-made tools to address them.  Lawmakers could and should take advantage of these tools to improve the GDPR. </p>
<p>The cleanest and simplest solution to the GDPR’s notice-and-takedown problems comes from existing law under the EU’s eCommerce Directive.  That body of law could govern removal of user content by intermediaries, leaving intact the GDPR’s current provisions for deleting back-end data companies collect and store about user behavior. More ambitiously, GDPR drafters could craft a new and better process. European lawmakers could take either approach without undermining other important data protection goals or provisions of the Regulation.</p>
<p> </p>
<p><a name=""ExistingTools"" id=""ExistingTools""></a></p>
<p><strong>Existing EU legal and policy resources could vastly improve the GDPR’s notice-and-takedown process.</strong></p>
<p><strong style=""font-size: 13.008px; line-height: 1.538em;"">            1. Applying existing eCommerce Directive law directly to the GDPR</strong></p>
<p>Existing law under the eCommerce Directive provides the most obvious and simple way to sweep away the problems created by the GDPR’s current takedown process.  The GDPR could state clearly that its erasure obligations, for intermediaries processing third-party content, are subject to Articles 12-15 of the eCommerce Directive .<a href=""#_edn1"" name=""_ednref1"" title="""" id=""_ednref1"">[i]</a>  Those articles cover enumerated activities such as hosting or caching user-generated content.  Unlike the current GDPR, they protect online expression by only requiring  intermediaries to remove unlawful content once they know about it, typically following notice and takedown processes. </p>
<p>Internet content removal laws under Member State legislation or case law implementing the eCommerce Directive were designed for precisely the situation an Internet intermediary encounters when faced with a “Right to Be Forgotten” erasure request.  Their purpose is to balance rights of aggrieved parties seeking removal of online content or links on the one hand, and the rights of other Internet users to share or access information on the other.  Of course, existing laws are far from perfect.  The widespread over-removal <a href=""http://cyberlaw.stanford.edu/blog/2015/10/empirical-evidence-over-removal-internet-companies-under-intermediary-liability-laws"">documented</a> in academic studies illustrates the need for improvement in those laws as well.  But they are worlds better than the GDPR’s current provisions, and they bring to bear the right set of considerations about rights and responsibilities of multiple parties on the Internet.</p>
<p>Invoking the eCommerce Directive within the GDPR is also a clean solution as a drafting matter. With a few new sentences, the GDPR could eliminate the thicket of ill-suited rules for intermediaries, without changing removal processes that work for back-end content collected by Internet companies about users.<a href=""#_edn2"" name=""_ednref2"" title="""" id=""_ednref2"">[ii]</a> As I will discuss below, this can be done without any change to the substantive privacy protections defined by the GDPR in its “Right to Be Forgotten” provisions and elsewhere.</p>
<p> </p>
<p>            2. <strong>Crafting new GDPR removal processes consistent with intermediary liability principles</strong></p>
<p>Of course, another option is to craft a new process that incorporates proportional protections for online expression.  This would be challenging in the time remaining, but if GDPR experts wanted expert input about notice and takedown, they would not have to look far.   The European Commission has developed considerable internal expertise in precisely this area in recent years.  As part of the 2012 <a href=""http://ec.europa.eu/internal_market/e-commerce/notice-and-action/index_en.htm"">Notice and Action Initiative,</a> the Commission conducted a lengthy public consultation.  The resulting <a href=""http://ec.europa.eu/internal_market/e-commerce/docs/communication2012/SEC2011_1641_en.pdf"">staff working document</a> provides a thorough and nuanced review of notice and takedown law and practice in Europe, and discusses concerns raised by stakeholders including free expression advocates.  The Commission is delving into the topic again through the <a href=""http://ec.europa.eu/priorities/digital-single-market/"">Digital Single Market</a> project.  </p>
<p>Europe also has a number of well-established civil society organizations that have thought hard about the nuts-and-bolts procedural aspects of content removal.  Article 19 has a concrete and sophisticated <a href=""https://www.article19.org/resources.php/resource/37243/en/internet-intermediaries:-dilemma-of-liability-q-and-a"">model</a> for notice and takedown – which looks nothing like the GDPR.  La Quadrature du Net has also published extensive commentary and concrete <a href=""https://lqdn.co-ment.com/text/KALAphGyXcx/view/"">recommendations</a> for notice and takedown, and in its early <a href=""https://lqdn.co-ment.com/text/7tnxTdetcXD/view/"">responses</a> to the <em>Costeja</em> case called for regulatory limitations to protect free expression.  These groups and others could provide thoughtful input.</p>
<p> </p>
<p><a name=""KeepPrivacy"" id=""KeepPrivacy""></a></p>
<p><strong>Improving GDPR notice and takedown to protect online free expression would not harm the privacy rights protected by other parts of the GDPR.</strong></p>
<p>Either of these approaches –invoking the eCommerce Directive, or inventing a better removal process – could be carried out without undermining the GDPR’s other achievements for data protection and privacy.</p>
<p style=""margin-left:.5in;""> </p>
<p style=""margin-left:.5in;""><strong>1. Protecting users’ rights to delete data tracking their online behavior</strong></p>
<p>First, improved notice and takedown rules need not have any effect on rights or processes for deleting the other kinds of personal data held by Internet companies.  Much of the GDPR is designed for this important, separate purpose – giving data subjects legal erasure rights with respect to the stored, back-end data that companies hold about their online behavior.   The GDPR’s removal process seems designed for this pure user-to-business, two-party interaction.  Applying it to the very different situation that arises when one Internet user wants to delete content posted by another is dangerous to online expression, for the reasons I set out in my <a href=""http://cyberlaw.stanford.edu/blog/2015/10/gdpr%E2%80%99s-notice-and-takedown-rules-bad-news-free-expression-not-beyond-repair"">second post</a>.  But using this single set of rules for both situations is a drafting choice, not a necessity. Drafters could invoke eCommerce law or other improved provisions for content notice and takedown without changing provisions for back-end data erasure at all.</p>
<p> </p>
<p>            2. <strong>Protecting the “Right to Be Forgotten”</strong></p>
<p>Second, content removal process issues can be separated from the substantive scope of the “Right to Be Forgotten.”  European lawmakers could decide that this right is very broad, and most user erasure requests should be granted; or they could decide the opposite.  That decision should not affect, or be affected by, the procedural rules for implementing an erasure request.  Well-crafted processes remain important to protect whatever content does fall outside of the “Right to Be Forgotten,” and to prevent its being unfairly targeted and removed from the Internet.</p>
<p>Procedural protections are especially important because the rights and remedies created by the GDPR will be around for a long time, and affect a broad and evolving Internet ecosystem – not just the large and well-resourced companies that appear in current headlines. Some of those companies, including Google, allocate considerable resources in an effort to avoid over-removal of content under intermediary liability law.  Processing requests carefully and rejecting the ones they believe are legally unfounded is, in my opinion, an important service to users.  But it is not behavior that should be taken for granted in crafting laws of general application.  The law should not incorporate any assumptions that all intermediaries will put effort into avoiding over-removal, or even that the ones doing it now will do it forever.</p>
<p> </p>
<p>            3. <strong>Companies’ voluntary removals of lawful content</strong></p>
<p>Finally, processes for content removal under the law can, and in this case should, be considered separately from processes companies use for discretionary content removal under their own community guidelines or policies. The two kinds of content removals pose important and related questions – about rights, procedure, and transparency in particular.  Comparison may be fruitful in other contexts.  But only one kind of removal, the one compelled by law, is being decided in the next six weeks under the GDPR.   The tools to improve protections for lawful online expression are readily available, drawing on existing intermediary liability law and models put forth by civil society groups.  Lawmakers should use them.</p>
<p> </p>
<p> </p>
<p><strong>Conclusion</strong></p>
<p>Public discussion of the GDPR has understandably been dominated by topics more traditionally associated with data protection, such as the data transfer provisions thrown into the spotlight by the recent <a href=""http://cyberlaw.stanford.edu/publications/privacy-activist-has-just-won-enormous-victory-against-us-surveillance-here%E2%80%99s-how"">Schrems</a> case.  There has been very little public discussion of the Regulation’s notice and takedown provisions.   But principles for notice and takedown have been extensively discussed, debated, and passed into law in the field of intermediary liability.  By invoking the protections European laws create in that context, lawmakers can fix these serious problems with the GDPR while still achieving its data protection goals.</p>
<p> </p>
<div>
<hr align=""left"" size=""1"" width=""33%"" /><div id=""edn1"">
<p><a href=""#_ednref1"" name=""_edn1"" title="""" id=""_edn1"">[i]</a> A possible formulation would be, “where a data subject seeks erasure of personal data under Articles 17 and 19 from a controller that is processing data provided by a third party pursuant to its function as an intermediary protected by Articles 12-15 of the eCommerce Directive, procedures for requesting and carrying out the erasure shall be governed by Member State law implementing those Articles of the eCommerce Directive.”</p>
<p>A shortcoming of this formulation is that it leaves intact other nagging problems with treating internet intermediaries as controllers under data protection law. Certain existing data protection obligations, including limitations on the processing of “sensitive” data categories such as health information, would, if truly applied to intermediaries’ processing of user-generated content, effectively make normal operations impossible.  The GDPR maintains these, and adds more requirements that sit poorly with the function of Internet intermediaries.  For example, the requirement that companies notify data subjects at the time of collecting data about them from third parties (Art. 14.3) would be very difficult for intermediaries to comply with, since an intermediary does not know when user-posted content includes personal data about another individual.  Other revisions, invoking eCommerce law broadly for intermediaries with respect to their processing of user-generated content could solve this class of problems.</p>
</div>
<div id=""edn2"">
<p><a href=""#_ednref2"" name=""_edn2"" title="""" id=""_edn2"">[ii]</a> As Miquel Peguera discusses masterfully in a <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2641876"">forthcoming article</a>, data protection enforcers have themselves wrangled with the peculiarity of treating intermediaries as data controllers or processors under the law.  The Article 29 Working Party in 2008 <a href=""http://ec.europa.eu/justice/data-protection/article-29/documentation/opinion-recommendation/files/2008/wp148_en.pdf"">recommended</a> special treatment for search engines for this very reason.  It distinguished personal data that a search engine collects from users from personal data included in indexed, third-party content, and said that for the latter, the “formal, legal and practical control the search engine has over the personal data involved is usually limited to the possibility of removing data from its servers.”  The CJEU’s <em>Costeja</em> ruling, similarly, identified notice and takedown as the locus of Google’s obligations as an intermediary.</p>
</div>
</div>
<p> </p>
",Intermediary Liability,2015-11-11 19:00,1188,Daphne Keller,News
13659,,International,1,1,A User-Focused Commentary on the TPP’s ISP Safe Harbors,Copyright+Other IP,"<p>               <em>This article is part of an IP-Watch and Infojustice.org series analyzing the Trans Pacific Partnership intellectual property provisions by leading experts around the world.  The series will publish weekly on Infojustice.org through the first quarter of 2016.</em></p>
<p>             </p>
<p>Section J of the TPP’s IP chapter, on ISP safe harbors, looks a lot like Section 512 of the DMCA, but the two frameworks differ in some important respects that could negatively impact the global environment for user speech online. This post offers a comparison of Section J and Section 512 with a focus on the rights of users and the status of user expression in the TPP’s intermediary safe harbor provisions.</p>
<p>First, the similarities. The TPP, like the DMCA, provides for a safe harbor framework pursuant to which ISPs can escape liability for users’ infringements by promptly removing or disabling access to allegedly infringing material upon acquiring knowledge of the material’s existence on their systems (18-60). As under the DMCA, such knowledge under the TPP can come from a copyright owner’s notice of infringement or from another source, including “red flags” of infringement (18-60). The TPP’s broad, functionally-driven definition of “Internet Service Provider” (18-58) aligns with DMCA, as do the legal benefits of the safe harbor (non-liability for money damages) (18-59) and the covered technical functions (routing, caching, storage/hosting, linking) (18-59). Of tremendous importance to ISPs, the TPP, like the DMCA, contains a no-duty-to-monitor rule (18-60) that prohibits member states from conditioning safe harbor on an ISP’s affirmatively monitoring its service for infringement. And like the DMCA, the TPP requires member states to provide a judicial process by which a copyright owner can compel an ISP to identify an alleged infringer who is the ISP’s customer (18-61).</p>
<p>The TPP’s safe harbor provisions differ from the DMCA’s, however, in important ways that make the notice and takedown protocol it contemplates structurally less speech-protective and more prone to over-enforcement and abuse. Most notably, the TPP makes it optional for member states to include a counter-notice and put-back protocol in their safe harbor frameworks (18-60). ISPs under the TPP are required to notify users when material is taken down, but without a system of counter-notices, users are left without any mechanism for having wrongfully removed material restored. Under the DMCA, potential abuse of notice and takedown by copyright holders is structurally (even if not very effectively) checked and balanced by the possibility that users will send counter-notices demanding that their material be put back. If a user makes that demand, an ISP is required under the DMCA to restore the material unless the copyright owner elects to sue the user. If the ISP fails to restore the material in response to a counter-notice, the ISP is liable to the user. An ISP in the United States must maintain both notice and takedown and counter-notice and put-back protocols to completely avoid liability: Implementation of a notice and takedown protocol avoids liability to copyright owners for infringing material; implementation of a counter-notice and put-back protocol avoids liability to users for material wrongfully taken down. The same will not necessarily be true for ISPs based in TPP member states, because the TPP’s counter-notice protocol is an optional component of a TPP-compliant safe harbor framework.  </p>
<p>Another important difference between the TPP and the DMCA is that the TPP has more relaxed requirements for the contents of a takedown notice. Unlike the DMCA, the TPP does not require a notice sender to state his or her good faith belief that the material identified in the notice is being used unlawfully. The TPP requires that notices contain only the identity of the work allegedly infringed, the location of the allegedly infringing material on the ISP’s system, and “sufficient indicia of reliability with respect to the authority of the person sending the notice” (18-60 n. 156). The DMCA’s required statement of a good faith belief operates in tandem with its cause of action for knowing material misrepresentation to provide a safeguard against abusive takedown notices that wrongfully target non-infringing or fairly used material. The Ninth Circuit’s recent decision in <em>Lenz v. Universal</em> illustrates how the DMCA’s required statement of a good faith belief forces copyright owners to put a little skin in the game when they send takedown notices. In <em>Lenz</em>, the court interpreted the DMCA’s “good faith belief” language to mean that notice senders must consider fair use before demanding that copyrighted material be taken down. The court held that a notice sender cannot form and attest to having a good faith belief that material is infringing without having first considered whether unauthorized use of the material was lawful as fair use or under some other copyright limitation. The TPP exempts service providers from liability for wrongful removals if they act in good faith in response to notices (18-60), but it does not require copyright owners to affirm that they are sending notices in good faith.</p>
<p>In terms of the relief available for users in cases involving takedown abuse, the TPP does require that Parties make available monetary remedies for knowing material misrepresentation in takedown notices (18-60). Unlike the DMCA, though, the TPP doesn’t provide expressly for recovery of attorney’s fees and costs in such cases. Without provision for recovery of attorney’s fees and costs, the prospect of user litigation to combat abusive takedowns is, for all intents and purposes, foreclosed. And while the TPP requires Parties to make statutory or exemplary damages available for copyright plaintiffs (18-46), it has no corresponding requirement that such damages be made available to user plaintiffs in abusive takedown cases. With respect to the unavailability of enhanced damages to combat abusive takedown practices, the TPP mirrors a recognized deficiency in the DMCA. User litigation to push back on abusive notice-sending is exceedingly rare even under the more user-oriented provisions of the DMCA. It will be that much rarer in countries that go no further to discourage takedown abuse than the TPP minimally requires.</p>
<p>The final paragraph of Section J affirms “the importance…of taking into account the impacts on rights holders and Internet Service Providers” (18-61). Consideration of impacts on Internet users was apparently not a high priority for the TPP’s negotiators. There is, however, one respect in which the TPP is potentially more user-friendly and more speech-protective than the DMCA: it lacks a provision requiring member states to condition safe harbor on an ISP’s adoption and implementation of a policy to terminate the accounts so-called repeat infringers. Repeat infringer rules are especially problematic in notice-based enforcement regimes that lack a convenient means for users to contest notices that they believe are mistaken or abusive.</p>
","Copyright and Fair Use, Intermediary Liability",2015-11-23 7:40,1046,Annemarie Bridy,News
13660,,Germany,0,0,German Federal Supreme Court Accepts Website Blocking Injunctions,Other IP,"<div data-blogger-escaped-style=""text-align: justify;"" style=""text-align: justify;"">
<p><em>This article is cross-posted with <a href=""http://www.husovec.eu/2015/11/bgh-accepts-website-blocking-injunctions.html"">author's personal blog</a>.</em></p>
<p>On Thursday, the German Federal Supreme Court <a href=""http://juris.bundesgerichtshof.de/cgi-bin/rechtsprechung/document.py?Gericht=bgh&Art=pm&Datum=2015&Sort=3&nr=72928&pos=0&anz=195"">issued a press release </a>informing that it has decided two long-excepted website blocking cases (I ZR 3/14, I ZR 174/14). Although we still have to wait couple of months for the text of the decision, there are several interesting aspects that are clear already.</p>
<p>First, the Court accepted privately litigated IP website-blocking in Germany. Even more, the Court - similarly as the Austrian Supreme Court in <a href=""http://www.husovec.eu/2014/08/austrian-supreme-court-confirms-open.html""><i>UPC Telekabel</i></a> and the English High Court in <a href=""http://www.bailii.org/cgi-bin/markup.cgi?doc=/ew/cases/EWHC/Ch/2003/3354.html&query=Cartier&method=boolean""><i>Cartier v Sky</i></a> - recognized that the availability of this remedy is <i>compulsory</i> under Art. 8(3) InfoSoc Directive.</p>
<p>Second, the Court has effectively corrupted its own previous case-law on adequately-causal contribution to the infringements, since it seems to claim that even an access provider contributes to infringements of third parties. The German scholars who (for many good reasons) argued that <i>Stoererhaftung</i> converges with the tort-law might get unpleasantly surprised by this proposition. Just try to imagine that this broadly read adequate-causality is one day implemented in tort-law ..</p>
<p>Third, the Court seems to have decided that the injunction is only reasonable if the access provider is the last enforcement resort, i.e. the right holders tries to enforce his rights against the real infringers first (websites or its hosts) or if such direct enforcement seems without any success from the outset. For these purposes, the right holder should take all reasonable steps, including commissioning of the investigation by a specialized firm or instituting an investigation before the state authorities. Since this effort could not have been shown in these case, the Court eventually rejected the injunction.</p>
<p>Fourth, unlike the Dutch court(s), BGH seems to fully follow the CJEU on the low requirement for the effectiveness of the website blocking measures.</p>
<p>Above all, it remains to be seen how the Court will make this operational in the German context where claims for injunctions have their consequences even prior to a court decision, so the obligation of the access provider to block would be usually created prior to an order (upon a cease and desist letter). If this would be the case, huge potential issues with the freedom of expression of the users and website owners lie ahead.</p>
</div>
<p> </p>
",Intermediary Liability,2015-11-29 9:58,759,Martin Husovec,News
13662,,European Union,0,0,Free Expression Gaps in the General Data Protection Regulation,Freedom of Expression+Right to Be Forgotten+Privacy or Data Protection,"<p><em>This is one of a series of posts about the pending EU General Data Protection Regulation (GDPR), and its consequences for intermediaries and user speech online.  In an earlier</em> <a href=""http://cyberlaw.stanford.edu/blog/2015/10/intermediary-liability-and-user-content-under-europe%E2%80%99s-new-data-protection-law""><em>introduction and FAQ</em></a><em>, I discuss the GDPR’s impact on both data protection law and Internet intermediary liability law.  Developments culminating in the GDPR have put these two very different fields on a collision course -- but they lack a common vocabulary and are in many cases animated by different goals.  Laws addressing concerns in either field without consideration for the concerns of the other can do real harm to users’ rights to privacy, freedom of expression, and freedom to access information online.</em></p>
<p><em>Disclosure: I previously worked on ""Right to Be Forgotten"" issues as Associate General Counsel at Google.</em></p>
<p><em>Cross-posted to </em><em>the</em> <em><a href=""http://policyreview.info/articles/news"">Internet Policy Review News & Comments</a></em></p>
<p> </p>
<p>This series of blog posts has identified <a href=""http://cyberlaw.stanford.edu/blog/2015/10/gdpr%E2%80%99s-notice-and-takedown-rules-bad-news-free-expression-not-beyond-repair#_ftnref7"">problems</a> with the GDPR’s notice and takedown provisions for user-generated content processed by Internet intermediaries.  The unnecessary new burdens these provisions place on Internet users’ free expression rights could be avoided, without undermining protections for privacy, through <a href=""http://cyberlaw.stanford.edu/blog/2015/11/solving-data-protection-problems-ecommerce-directive-tools"">simple changes</a> to the Regulation.  But the GDPR’s procedural bias toward content deletion by private intermediaries is not the only threat to free expression under the new law.</p>
<p>Several other GDPR provisions give short shrift to speech and information rights.<a href=""#_edn1"" name=""_ednref1"" title="""" id=""_ednref1"">[1]</a> One is the GDPR’s specific provision covering freedom of expression, at Article 80. Another is the GDPR’s process for adjudicating disputes and balancing rights through Data Protection Agencies (DPAs), courts, and the newly created European Data Protection Board. </p>
<p>These parts of the law disadvantage expression and information rights in ways that would be relatively harmless if data protection law still primarily applied, as it once did, to data held and processed internally by companies.  They have far larger consequences now, given the law’s application to vast amounts of publicly available information and content.  Problems created by these provisions are compounded by the new obligations on Internet intermediaries to erase users’ online expression under the “Right to Be Forgotten.”</p>
<p>I will treat these problems in far less detail than I did the notice and takedown process.  Even this relatively simple overview, however, raises real concerns about whether the GDPR can really provide proportional protections for free expression as a right co-equal with privacy and data protection. </p>
<p> </p>
<p><strong>The GDPR’s Article 80 Free Expression Provisions</strong></p>
<p>Free expression rights under the GDPR are directly addressed in Article 80, which requires that “Member States shall provide for exemptions or derogations” to protect free expression. Draft Recitals discuss – quite reasonably – the need to balance fundamental rights, including privacy and information rights. (Council Recitals 3a, 38, 53 and 56) However, a closer look at the Regulation reveals numerous causes for concern about this balance. </p>
<p>One problem with Article 80 is that it relies on Member State law to define and enforce the free expression rights guaranteed by the European Charter. This is the same allocation of responsibility that exists under the current Data Protection Directive, and empirical research has revealed significant problems with it. Cambridge professor David Erdos has exhaustively reviewed and analyzed national implementation of the current free expression carve-outs from data protection, and <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2471531"">found</a> significant and troubling variation from one country to another.  Some countries have not even passed legislation to create the derogations that have been required for the past twenty years under the 1995 Directive.<a href=""#_edn2"" name=""_ednref2"" title="""" id=""_ednref2"">[2]</a> Others have enacted laws that fall far short of the goal of balancing expression and privacy rights.  Given this history, it is unreasonable to expect Member States to enact more balanced protections under the GDPR.  </p>
<p>A second cause for concern arises from the language of the GDPR’s free expression provision in Article 80.  In some drafts, this Article does not even require Member States to protect all forms of expression – only those “carried out <em>solely</em> for journalistic purposes or the purpose of artistic or literary expression.”  (Comm. Art. 80, emphasis added)  This restrictive language is not new, but it is newly troubling given data protection law’s greatly expanded application to online speech. Individuals posting information, opinions, and ideas online will often lack the credentials to claim protection under these limited exemptions. Their failure to fit into defined categories should not preclude legal protection for their fundamental rights.</p>
<p>The rules Member States enact under this flawed framework directly affect intermediaries when they are asked to delete users’ online expression.  “Right to Be Forgotten” requests under the GDPR can in theory be rejected if the content being challenged is necessary “for exercising the right of freedom of expression in accordance with Article 80.”  (Art. 17.3 Commission)  (This provision does not, however, affect the intermediary’s obligation to <a href=""http://cyberlaw.stanford.edu/blog/2015/10/gdpr%E2%80%99s-notice-and-takedown-rules-bad-news-free-expression-not-beyond-repair#Restriction"">immediately take the content offline</a> pending review.)  In practice, intermediaries will be far less likely to honor this exemption if the relevant Member State law is vague, inapplicable to ordinary Internet users, or significantly different from one country to another.</p>
<p>Another problem with this provision is the lack of clarity about <em>whose</em> free expression rights an intermediary may consider. The most obvious person should be the Internet user who posted the content.<a href=""#_edn3"" name=""_ednref3"" title="""" id=""_ednref3"">[3]</a>  But doctrinally and before courts, serious legal uncertainty can arise regarding an intermediary’s ability to act on the basis of that user’s rights -- as opposed to the company’s own, relatively paltry, free expression rights.  As a conspicuous example, the CJEU’s <em>Costeja</em> ruling itself did not identify the publisher’s expression rights as a balancing factor in determining what content must be removed.  The GDPR perpetuates this uncertainty, sometimes suggesting that relevant interests are only those pursued by “the controller, or by the third party or parties to whom the data are disclosed” – in other words, the intermediary and the users who read the content, but not the publisher.  (EDPS Art. 6.1(f))</p>
<p>Inadequacies in the GDPR’s provisions governing free expression are problematic on their own, but will ramify as that law is interpreted by risk-averse private companies under the GDPR’s notice and takedown framework.  </p>
<p> </p>
<p><strong>Process and Public Resources to Protect Fundamental Rights</strong></p>
<p>A second set of problems for free expression arise from the way the GDPR instructs courts and regulators to handle disputes involving both privacy and free expression rights.  At every step of the way, the person asserting a privacy right has government support and a clear avenue to enforce her rights.  The person asserting a free expression right does not.  The GDPR’s provisions for DPA and court enforcement replicate many of the problems of the notice and takedown process: responsibility for defending or assessing free expression rights rests with entities that lack the information or incentives to reach a fair outcome, while people who do have information and incentives to defend their expression are excluded from the process. </p>
<p>In brief overview, what happens is this. When an intermediary does not comply with a Right to Be Forgotten removal request, the requester can take her grievance to the regional or national Data Protection Agency.<a href=""#_edn4"" name=""_ednref4"" title="""" id=""_ednref4"">[4]</a>  The DPA then adjudicates the matter as a two-party dispute between the data subject and the intermediary, under strict rules of confidentiality. The person whose free expression rights are at stake is absent from the process.<a href=""#_edn5"" name=""_ednref5"" title="""" id=""_ednref5"">[5]</a>  Defense of her rights lies in the hands of an intermediary that likely doesn’t know the facts of the underlying dispute, and has little incentive to risk antagonizing an important regulator. </p>
<p>This institutional imbalance – the person asserting a data protection right has a presumptive ally and audience in the DPA, the person asserting a free expression right has neither – is compounded by the basic mission and function of most DPAs.  Their legal mandate is to “protect the fundamental rights and freedoms of natural persons in relation to the processing of their personal data.”  (Comm. Art 46).  They are staffed by privacy professionals, well-versed in their field but not necessarily expert in free expression law, or in relevant Internet law.  This is not to say that DPAs will always shortchange free expression – in many cases, including the Right to Be Forgotten <a href=""http://ec.europa.eu/justice/data-protection/article-29/documentation/opinion-recommendation/files/2014/wp225_en.pdf"">removals criteria</a> put forward by the Article 29 Working Party, they very thoughtfully balance competing rights.  That said, DPAs are in most cases bodies of privacy professionals whose job is to regulate the processing of personal data.  Absent a far stronger legal mandate for them to balance privacy with free expression, and without robust inclusion of internal free expression experts as part of the Agencies themselves, it is not reasonable to expect DPAs to be equally attuned to both sets of rights – particularly when the person asserting a privacy right is before them, while the person who might claim a free expression right is nowhere to be seen. </p>
<p>Under pre-GDPR data protection law, regulatory review of such a claim would typically end with the DPA, at which point either party (the data subject or the intermediary) could move the dispute to national court.  The GDPR changes this by adding another potential level of review within the privacy regulation system, under the new pan-European Data Protection Board.  (EDPB) The EDPB will review cases and issue opinions to harmonize differences between national DPAs – differences which, in the free expression context, may easily arise from divergent Member State law.  The EDPB’s conclusions do not appear to be reviewable by Member State courts. Its binding opinions can seemingly be reviewed only by the CJEU.  (Council Recital 113)  Since the CJEU does not accept amicus or intervener briefs, the online speaker or publisher has no say in that level of review, either.</p>
<p>By contrast to this robust system for review and enforcement for privacy rights, the legal avenues available to a publisher or online speaker asserting free expression rights are scant. No publicly funded, legally powerful “Free Expression Agency” has a mandate to protect her rights; no “General Free Expression Regulation” lays out detailed enforcement mechanisms.  In most cases, her only recourse is to courts of law, where she can attempt to sue either the intermediary or the data subject who requested removal.  Neither claim is likely to succeed – most countries have no clear cause of action against an individual whose false accusation led an intermediary to remove content, or against the intermediary for taking that accusation at face value.<a href=""#_edn6"" name=""_ednref6"" title="""" id=""_ednref6"">[6]</a>  For publishers, speakers, and Internet users deprived of access to information under the GDPR, no clear remedy exists.</p>
<p> </p>
<p><strong>Conclusion</strong></p>
<p>Privacy and free expression are in principle equally important rights, protected proportionally under EU law.  Nonetheless, the GDPR tilts the playing field powerfully in favor of privacy rights – and incentivizes widespread deletion of online expression even in cases where no privacy or data protection right is really infringed.   Fixing these problems the GDPR’s text at this late date is probably impossible.  Protection of free expression will fall to Member State lawmakers and privacy regulators, as they interpret and implement the law.  The best hope for more balanced protections lies in their hands.</p>
<p> </p>
<div><br clear=""all"" /><hr align=""left"" size=""1"" width=""33%"" /><div id=""edn1"">
<p><a href=""#_ednref1"" name=""_edn1"" title="""" id=""_edn1"">[1]</a> Another problem, outside the scope of this analysis, comes from the GDPR’s restrictive rules for preservation and use of material in <a href=""http://cyberlaw.stanford.edu/blog/2015/10/intermediary-liability-and-user-content-under-europe%E2%80%99s-new-data-protection-law#Archives"" style=""font-size: 13.008px; line-height: 1.538em;"">libraries and archives</a>.</p>
</div>
<div id=""edn2"">
<p><a href=""#_ednref2"" name=""_edn2"" title="""" id=""_edn2"">[2]</a> “The laws of three countries (*Croatia, *Czech Republic and *Spain) provide no media derogation at all from any part of the data protection scheme.”  Erdos at 11.</p>
</div>
<div id=""edn3"">
<p><a href=""#_ednref3"" name=""_edn3"" title="""" id=""_edn3"">[3]</a> Respect for the rights of online speakers and publishers permeates most practical assessments of the “Right to Be Forgotten” – including the <a href=""http://ec.europa.eu/justice/data-protection/article-29/documentation/opinion-recommendation/files/2014/wp225_en.pdf"">Article 29 Working Party’s</a>.  The GDPR should ensure that close legalistic readings do not abandon this concern.</p>
</div>
<div id=""edn4"">
<p><a href=""#_ednref4"" name=""_edn4"" title="""" id=""_edn4"">[4]</a> Or to court, but that is less common.</p>
</div>
<div id=""edn5"">
<p><a href=""#_ednref5"" name=""_edn5"" title="""" id=""_edn5"">[5]</a> There is an interesting question about what happens if an intermediary has accepted the Article 29 Working Party’s authorization to contact the affected speaker in particularly difficult removal cases.  Can that person then be included in any subsequent procedure before a DPA?</p>
</div>
<div id=""edn6"">
<p><a href=""#_ednref6"" name=""_edn6"" title="""" id=""_edn6"">[6]</a> The GDPR does interestingly provide that  “each natural or legal person shall have the right to an effective judicial remedy against a legally binding decision of a [DPA] concerning them.” (Art. 74, <em>see also</em> Council R 113).  Possibly this opens the door for an affected speaker to get into court once a DPA has already ruled against her, even though the “legally binding decision” is not against her personally but against an intermediary.  </p>
<p> </p>
</div>
</div>
<p> </p>
","Architecture and Public Policy, Intermediary Liability, Privacy",2015-11-30 6:06,1188,Daphne Keller,News
13667,,Germany,0,0,German Supreme Court: Booking Portals Not Liable for Bogus User Reviews,General,"<div>Recently, the Federal Court of Justice (<em>Bundesgerichtshof</em>), the highest court in the system of ordinary jurisdiction in Germany, found that booking portals are not liable for bogus users' reviews tarnishing the reputation of third party businesses they host.</div>
<div> </div>
<div>The <em>Bundesgerichtshof </em><a href=""http://juris.bundesgerichtshof.de/cgi-bin/rechtsprechung/document.py?Gericht=bgh&Art=en&az=I%20ZR%2094/13&nr=72269"">decided a case </a>in which an anonymous review on a booking portal claimed that an hotel was – <em>inter alia</em> – contaminated by bed bugs. In fact, there were none. Users' reviews have direct <a href=""http://www.tandfonline.com/doi/abs/10.1080/02642069.2010.529436"">influence on online sales and prices in the hotel industry</a>. Therefore, there are incentives for hoteliers to manipulate reviews to give themselves an edge. It is obvious that the author of bogus reviews is directly liable under criminal as well as civil law. However, in this case, since the review was written anonymously, the culprit could not be identified or traced. Therefore, the victim tried to hold the booking portal accountable.</div>
<div> </div>
<div>The <em>Bundesgerichtshof</em><em> </em>denied the plaintiff's claim. Although the intermediary profits financially from the existence of users' reviews, the Court ruled that online travel agencies are not liable for the accuracy of user-generated ratings on their web pages. First, anonymous remarks in a review cannot be ascribed to the travel agency, which does not endorse the users' comments. Any informed internet user would reject the idea that booking portals make all the comments their own. Second, there is no direct liability for hosting false comments due to the safeharbor for intermediaries provided by <a href=""http://www.gesetze-im-internet.de/tmg/__10.html"">§ 10 TMG</a>, which is based on Article 14 of the E-Commerce Directive. The “hosting provider” safeharbor applies because the online travel agency is a “neutral” platform that does not interfere with the user’s communication. Therefore, the Court noted, it is not obliged to fulfill “any unreasonable duties to review,” which could “challenge the entire business model” of the platform operator. If, however, the booking portal is informed of comments allegedly in violation of unfair competition law, it should promptly remove them to avoid liability.</div>
<div> </div>
<div>The German Supreme Court embraced similar principles as those adopted by US federal courts. In the United States, plaintiffs have attempted, so far unsuccessfully, a variety of legal theories to hold platforms, <a href=""http://www.forbes.com/sites/ericgoldman/2015/11/30/stockholders-cant-sue-yelp-because-of-fake-reviews/"">like Yelp for example</a>, responsible for bogus reviews. However, competing interests might be hard to balance in these cases. On the one hand, the court ruling strengthens freedom of expression online by protecting intermediaries. On the other hand, lack of legal tools to tackle effectively widespread bogus reviews will inevitably lead to losing trust in consumer ratings. Therefore, it remains to be seen whether the German courts will hold onto this guiding principle or take also other competing interests into consideration.</div>
<div> </div>
",Intermediary Liability,2015-12-03 4:21,505,Giancarlo Frosio,News
13683,European Union,,0,0,"Series Conclusion and Summary:  Intermediaries and Free Expression Under the GDPR, in Brief",Freedom of Expression+Right to Be Forgotten+Privacy or Data Protection,"<p>Europe’s pending General Data Protection Regulation (GDPR) threatens free expression and access to information on the Internet.  The threat comes from erasure requirements that work in ways the drafters may not have intended -- and that are <a href=""http://cyberlaw.stanford.edu/blog/2015/11/solving-data-protection-problems-ecommerce-directive-tools#KeepPrivacy"">not necessary</a> to achieve the Regulation’s data protection purposes. </p>
<p>The GDPR’s “Right to Be Forgotten” or “Erasure” provisions serve an important goal, establishing enforceable rights and procedures to delete personal data held in companies’ back-end storage systems and used for purposes such as profiling.  But the GDPR’s streamlined erasure process, which makes sense for this data, can also be used to erase other Internet users’ online expression. The process, and the threat of high penalties, encourage companies to comply with most or all requests -- erasing information that, under the law’s own terms, is legitimately processed and should not be deleted. Minor revisions or clarifications in the GDPR could protect Internet users’ online expression from being erased without good reason, and better serve the goal of proportionality under EU law.</p>
<p><strong>Improper removal requests are common.</strong></p>
<p>Protecting online expression from legally invalid removal requests is important, because erroneous or malicious requests to delete online content are very common.  Widely reported examples include attempts, using intermediaries’ legal notice and takedown systems, to suppress online information based on <a href=""https://www.eff.org/deeplinks/2008/09/massive-takedown-anti-scientology-videos-youtube"">religious</a> or <a href=""http://www.ibtimes.com/russia-turkey-asked-twitter-remove-hundreds-tweets-government-censorship-attempts-1810234"">political</a> disagreement, or to silence negative<a href=""http://arstechnica.com/tech-policy/2011/06/criticism-and-takedown-how-review-sites-can-defend-free-speech/""> consumer reviews</a>.</p>
<p>Data protection-based removal requests are no exception to this pattern of over-reaching claims.  According to Google, <a href=""https://www.google.com/transparencyreport/removals/europeprivacy/"">58%</a> of “Right to Be Forgotten” requests it receives do not actually state valid claims under EU law.  The 58% figure is presumably roughly accurate -- Data Protection Authorities reviewing these cases have generally <a href=""http://ec.europa.eu/justice/data-protection/article-29/press-material/press-release/art29_press_material/2015/20150618_wp29_press_release_on_delisting.pdf"">agreed</a> with the company’s legal assessment. The many additional intermediaries covered by the GDPR’s expanded “Right to Be Forgotten” will inevitably receive many invalid or abusive requests as well.</p>
<p><strong>Standard tools derived from intermediary liability law can protect online expression from improper removal requests.</strong></p>
<p>The EU already has laws and norms intended to solve the problem of invalid content removal requests. Intermediary liability rules under the <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:32000L0031:en:HTML"">eCommerce Directive</a> are designed to facilitate removals for people with legitimate grievances, while preventing abusive or over-reaching requests from succeeding. The most basic protection for Internet users’ rights comes from the eCommerce Directive’s “knowledge” standard for removal, which ensures that intermediaries need not comply with clearly groundless removal demands.  More detailed rules in Member State implementing law and in the civil-society-endorsed <a href=""https://www.manilaprinciples.org/"">Manila Principles</a> include penalties for bad-faith removal requests and opportunities for the accused online speaker to defend her rights. </p>
<p><strong>The GDPR encourages intermediaries to comply with legally invalid erasure requests.</strong></p>
<p>The GDPR does not apply established rules and norms from other notice and takedown systems. Instead, it tells intermediaries to follow a new process with minimal checks and balances to protect online expression against groundless accusations.  Among other things,</p>
<p style=""margin-left: 0.5in;"">●      Intermediaries must <a href=""https://cyberlaw.stanford.edu/blog/2015/10/gdpr%E2%80%99s-notice-and-takedown-rules-bad-news-free-expression-not-beyond-repair#Restriction"">take content offline immediately</a> upon receiving a removal request – before even assessing the legal claim asserted.</p>
<p style=""margin-left: 0.5in;"">●      Intermediaries are generally <a href=""https://cyberlaw.stanford.edu/blog/2015/10/gdpr%E2%80%99s-notice-and-takedown-rules-bad-news-free-expression-not-beyond-repair#NoNotice"">barred from notifying the accused speaker</a> or giving her a chance to defend her online expression before it is erased.</p>
<p style=""margin-left: 0.5in;"">●      Intermediaries may be compelled to <a href=""https://cyberlaw.stanford.edu/blog/2015/10/gdpr%E2%80%99s-notice-and-takedown-rules-bad-news-free-expression-not-beyond-repair#Disclose"">disclose the accused speaker’s personal information</a> to the person seeking removal – surely an unintended suggestion, given the law’s larger pro-privacy purpose.</p>
<p>Companies also have financial incentives to honor most or all removal requests: noncompliance with the GDPR can cost a company up to 5% of a its annual global turnover or €100 million per violation.  It is unreasonable to expect small companies -- or indeed, almost any companies -- to take on such risks to defend users’ rights. </p>
<p><strong>GDPR drafters can solve this problem by more clearly incorporating EU intermediary liability standards to balance Internet users’ fundamental rights. </strong></p>
<p>The GDPR’s erasure provisions are probably not intended to work this way, and they don’t have to.  Clearly invoking <a href=""http://cyberlaw.stanford.edu/blog/2015/11/solving-data-protection-problems-ecommerce-directive-tools"">standards</a> from existing European notice and takedown law would improve protections for expression, <a href=""http://cyberlaw.stanford.edu/blog/2015/11/solving-data-protection-problems-ecommerce-directive-tools#KeepPrivacy"">without undermining the GDPR’s privacy provisions</a> in the process -- and without taking a side in long-running debates about how other aspects of data protection and eCommerce law relate to one another. </p>
<p>Alternately, for erasure requests targeting online expression, lawmakers could eliminate the “restriction” requirement for controllers to temporarily take content offline before even assessing the legal claim against it.  This provision may be particularly harmful in practice, because it shifts intermediaries’ default behavior toward deletion and moves a large number of requests away from the “knowledge” standard for removal.</p>
<p>If adding other new amendments at this late date proves impossible, the best hope for at least some improvement will rest with DPAs, courts, and Member State legislatures as they interpret and implement the law. But it would be far better to fix it now.</p>
<p><strong>References</strong></p>
<p>Other posts in this series lay out the problems discussed here in greater detail.</p>
<p>1.<a href=""http://cyberlaw.stanford.edu/blog/2015/10/intermediary-liability-and-user-content-under-europe%E2%80%99s-new-data-protection-law""> Introduction</a>.  Discusses current convergence between legal frameworks of data protection and intermediary liability; includes FAQs covering more detailed concerns.</p>
<p>2. <a href=""http://cyberlaw.stanford.edu/blog/2015/10/gdpr%E2%80%99s-notice-and-takedown-rules-bad-news-free-expression-not-beyond-repair"">GDPR Notice and Takedown Overview</a>.  Briefly reviews the GDPR erasure process, and identifies tensions with intermediary liability and free expression principles.</p>
<p>3. <a href=""https://cyberlaw.stanford.edu/blog/2015/10/notice-and-takedown-under-gdpr-operational-overview"">GDPR Notice and Takedown Details</a>.  Provides a deeper dive into GDPR text and operational requirements.</p>
<p>4. <a href=""http://cyberlaw.stanford.edu/blog/2015/11/solving-data-protection-problems-ecommerce-directive-tools"">Drafting Solutions</a>.  Proposes drawing on principles of intermediary liability under the eCommerce Directive, without weakening privacy and data protection rights under the GDPR.</p>
<p>5. <a href=""https://cyberlaw.stanford.edu/blog/2015/11/free-expression-gaps-general-data-protection-regulation"">GDPR Free Expression Provisions</a>. Identifies weaknesses in Article 80 as a mechanism to prevent excessive content deletion; discusses disproportionate advantages for privacy/data protection rights, as compared to free expression/information rights, under the GDPR’s regulatory and judicial review processes.</p>
<p><em>Disclosure: I previously worked on ""Right to Be Forgotten"" issues as Associate General Counsel at Google.</em></p>
",Intermediary Liability,2015-12-01 14:23,1188,Daphne Keller,News
13687,,United States,0,0,BMG v. Cox: The High Cost of Losing Safe Harbor,Copyright,"<p>               On December 1, a federal court in Virginia entered partial summary judgment for music publisher BMG in <a href=""http://www.leagle.com/decision/In%20FDCO%2020151202F28/BMG%20RIGHTS%20MANAGEMENT%20%28US%29%20LLC%20v.%20COX%20COMMUNICATIONS,%20INC.#""><em>BMG Rights Management v. Cox Communications</em></a>, a closely watched case on the applicability of the DMCA safe harbors to a broadband Internet access provider. BMG sued Cox for contributory and vicarious infringement based on Cox users’ peer-to-peer file sharing activity. Cox asserted the DMCA safe harbors in its defense, and BMG argued that Cox should be ineligible for safe harbor for failing to comply with section 512(i) of the DMCA, which requires providers to adopt and reasonably implement a policy for terminating the accounts of repeat infringers in appropriate circumstances. </p>
<p>               The DMCA doesn’t define “repeat infringer” or “appropriate circumstances,” leading courts to conclude that Congress intended for providers to have broad discretion over the substance and implementation of their section 512(i) policies. The case law has never been clear on whether a provider may legitimately take the position that the only customers who should be treated as repeat infringers under the DMCA are those who have been adjudicated and found liable for infringement. In this case, Cox failed to persuade the court that it should be required to terminate user accounts only in cases involving adjudicated infringers:</p>
<p style=""margin-left:.5in;"">Cox did not have leeway to wait until an account holder was adjudicated as an infringer to find that circumstances were appropriate for termination.…[T]he Court disagrees that a repeat infringer policy applies only to those who have been held liable in a copyright suit. Rather, an account holder must be considered an infringer, at minimum, when the service provider has actual knowledge that the account holder is using its services for infringing purposes.</p>
<p>Cox also struck out with its argument that notices of infringement from copyright owners are insufficient to confer actual knowledge of a user’s infringement on a provider. The court acknowledged conflicting decisions on the point but quoted the Ninth Circuit’s decision in <a href=""https://scholar.google.com/scholar_case?case=11327801397939418854&q=umg+v.+shelter+capital&hl=en&as_sdt=200006&as_vis=1""><em>UMG Recordings v. Shelter Capital Partners</em></a> for the proposition that notices are “powerful evidence of a service provider’s knowledge,” whether or not they are sufficient on their own to establish that knowledge. The evidence of knowledge in Cox’s case was particularly strong, the court said, because Cox received not one or two but at least fourteen notices of infringement for multiple individual users over a six-month period. In addition, emails from customers who were the subjects of repeat notices and whose accounts were eligible for termination under Cox’s policy contained admissions from the customers themselves that they had been sharing copyrighted files. On the facts, this was not a good case for Cox; the record quite clearly showed that Cox was calculatedly lax in its enforcement of its repeat infringer policy, hanging on to violators for the stated purpose of preserving revenue.</p>
<p>               With Cox stripped of safe harbor protection, this case is set to go to trial on BMG’s secondary infringement claims. The court denied Cox’s motion for summary judgment on both contributory and vicarious infringement. Of particular concern for all broadband access providers should be the court’s reasoning with respect to BMG’s claim of vicarious infringement. To establish vicarious infringement, a plaintiff has to show that the defendant had the right and ability to control the direct infringer’s activities and derived a direct financial benefit from those activities. Under the court’s reasoning, which closely tracks Judge Kozinski’s dissents in the <a href=""https://scholar.google.com/scholar_case?case=15405734604218338562&q=perfect+10+v.+visa&hl=en&as_sdt=200006&as_vis=1""><em>Perfect 10</em></a> cases, any service provider with a contractual right to terminate a customer’s service has the right and ability to control that customer’s infringing activity on the service. This is a broad reading of the control element. The court rejected Cox’s argument that the right and ability to control should be read more narrowly to mean control over an individual customer’s infringing conduct, as opposed to control (writ large) over the means the customer uses to infringe.</p>
<p>               On the direct financial benefit element of vicarious infringement, the court said that a jury could conclude that Cox benefited financially from illegal file sharing because the availability of infringing material through its network was a draw to customers. BMG’s evidence on this point was a survey showing that 16% of respondents used Cox’s service to infringe, and 70% of that 16% said they subscribed to the service at least in part because they could use it to infringe. By this logic, any provider of access to the open Internet can be held to use infringement as a draw to sell service. For what access provider is it not true that a subset of a subset of its customers counts the ability to access infringing material as one reason among many—the vast majority of them perfectly legal—to subscribe?</p>
<p>               Considering the fact that the roots of vicarious liability are in the “thick” privity of the master-servant relationship, the application of the doctrine in the copyright context to cover the “thin” privity between Internet access providers and their millions of customers seems like a stretch. In the <em>Perfect 10</em> cases, the Ninth Circuit rejected claims of vicarious liability against search and payment intermediaries as a matter of law, but the court in this case held that Internet access providers are differently situated. Given the court’s broad interpretation of the scope of vicarious liability, the loss of the safe harbor for Cox is potentially crushing. Whatever revenue Cox preserved by stinting enforcement of its repeat infringer policy pales in comparison to the damages to which it is now exposed.</p>
","Copyright and Fair Use, Intermediary Liability",2015-12-05 16:30,1046,Annemarie Bridy,News
13689,,United States,0,0,Cyber Attacks and Civil Liability - Symposium and Call for Contributors,Other,"<div>From my students at the University of South Carolina:</div>
<div> </div>
<div><u><span style=""font-size: 13.008px; line-height: 1.538em;"">Cyber Attacks and Civil Liability</span></u></div>
<div><em>Call for Panelists and Papers</em></div>
<div> </div>
<div><span style=""font-size: 13.008px; line-height: 1.538em;"">Panelist Proposals Deadline:</span><span class=""Apple-tab-span"" style=""font-size: 13.008px; line-height: 1.538em; white-space: pre;""> </span><span style=""font-size: 13.008px; line-height: 1.538em;"">12/18/16</span></div>
<div>Abstract Deadline: 01/18/16</div>
<div>Event Date: 02/04/16 – 02/05/16</div>
<div>Location: University of South Carolina School of Law, 701 Main Street, Columbia, SC, 29204</div>
<div>Organization: The South Carolina Law Review</div>
<div> </div>
<div>The South Carolina Law Review (SCLR) proudly presents its annual Symposium, Cyber Attacks and Civil Liability. The event will take place at the University of South Carolina School of Law on February 4–5, 2016 in Columbia, South Carolina. The SCLR is now accepting extended essays or articles discussing issues that relate to cyber security and products liability. These submissions will be published in conjunction with the Symposium. Working drafts should be submitted as soon as possible, but no later than January 18, 2016. The SCLR welcomes submissions from legal scholars and practitioners, as well as experts in the fields of computer engineering, coding, and others closely related to cyber security or products liability.</div>
<div> </div>
<div>In addition to written works, the SCLR is accepting applications to participate as a panelist at the symposium. The symposium will consist of three panels discussing the following topics:</div>
<div>•<span class=""Apple-tab-span"" style=""white-space:pre""> </span>Panel 1 will examine the science behind cyber attacks. </div>
<div>•<span class=""Apple-tab-span"" style=""white-space:pre""> </span>Panel 2 will discuss the existing legal framework of products liability and its ability to provide a means of redress for injuries caused by cyber attacks. </div>
<div>•<span class=""Apple-tab-span"" style=""white-space:pre""> </span>Panel 3 will examine practice specific concerns that lawyers may face in the cyber attack arena. </div>
<div>Panelists that participate in the Symposium will have travel and lodging expenses covered. For speakers interested in participating on a panel, please submit an abstract of a proposed discussion no later than December 18, 2015. </div>
<div> </div>
<div>Please submit all materials to Drew Rawl, Editor in Chief, Vol. 67 of the South Carolina Law Review at <a href=""mailto:eic@sclawreview.org"">eic@sclawreview.org</a>.  For further information, please contact Alexandra Williams at <a href=""mailto:awillsc@gmail.com"">awillsc@gmail.com</a> or Wesley Moran at <a href=""mailto:wmoran@email.sc.edu"">wmoran@email.sc.edu</a>.</div>
<div> </div>
","Intermediary Liability, Robotics",2015-12-07 8:52,371,Bryant Walker Smith,News
13698,,Ireland,0,0,Irish High Court Ordered ISP to Implement Graduate Response Strategy,Copyright,"<div>In <a href=""http://www.bailii.org/ie/cases/IEHC/2015/H317.html"">Sony Music & Ors v UPC Communications</a>, the High Court of Ireland ordered <span style=""font-size: 13.008px; line-height: 20.0063px;"">the second largest Irish Internet access provider,</span><span style=""font-size: 13.008px; line-height: 20.0063px;""> UPC Communications, to implement a </span><span style=""font-size: 13.008px; line-height: 20.0063px;"">""Graduated Response Strategy"" (GRS)</span><span style=""font-size: 13.008px; line-height: 20.0063px;""> against subscribers allegedly infringing copyright.</span></div>
<div> </div>
<div>The plaintiffs, Sony, Universal and Warner Music, sought an injunction to impose upon UPC Communications, an obligation to implement a against UPC's subscribers allegedly infringing plaintiffs' copyrights online. The injunction sought was pursuant to <a href=""https://cyberlaw.stanford.edu/page/wilmap-ireland"">Section 40 (5A) of the Copyright and Related Rights Act, 2000 (as amended) </a>requiring that the defendant take reasonable steps to prevent its subscribers from using the defendant’s internet service for the purpose of breaching the plaintiffs’ copyright in the plaintiffs’ sound recordings</div>
<div> </div>
<div>According to the plaintiffs requests, the essential elements of a GRS were that ""(<strong>i</strong>) the owners of the copyright send to the ISP a list of infringements with reference to specific internet protocol addresses; (The copyright owners can only identify the specific IP address. They cannot identify the name and address of the subscriber). However when this information is sent to the defendant, the defendant as the ISP can, using the IP addresses, identify the name and address of its subscribers. (<strong>ii</strong>) It then writes to its subscribers informing them that these matters have come to its attention. (<strong>iii</strong>) The second letter is a second reminder or threat of further action. (<strong>iv</strong>) The third step would be the suspension of the account for a week. (<strong>v</strong>) The fourth step would be the termination of the account.""</div>
<div> </div>
<div>The Court granted an injunction as sought by the plaintiff imposing upon UPC an obligation to implement a GRS as the European ""<span style=""font-family: Verdana; font-size: small; line-height: normal;"">directives permit the courts of Member States to impose injunctions on internet service providers [, . . . ] even though ISPs are not regarded as liable in law for the actions of their subscribers,"" due the availability of a ""mere conduit"" defense. However, according to the injuction, the GRS cannot encompass any suspension or termination of users' accounts but only the disclosure of information to make a Norwich Pharmacal order to finally seek an accounts' suspension or termination. The GRS should encompass the following steps:</span></div>
<ol><li>Step 1 - That the plaintiffs would furnish all relevant infringement information to the defendant and that the plaintiffs would bear the cost of this process.</li>
<li>Step 2 - That the defendant, when it receives a first copyright infringement notification from the plaintiffs, would send its subscribers a letter setting out the infringement and requesting him/her to cease and desist.</li>
<li>Step 3 - That the defendant where it receives a second copyright infringement notification would send a second letter to its subscriber requesting him/her to cease and desist.</li>
<li>Step 4 - That the defendant, where it receives a third copyright infringement in respect of a subscriber from the plaintiffs, would send to the plaintiffs a notification that a subscriber account has been the subject matter of three such notifications.</li>
<li>Step 5 - The plaintiffs, having been informed of a third copyright infringement notification and having been informed of the relevant IP addresses etc, could make a Norwich Pharmacal type application to ascertain the subscriber’s identity and address and the plaintiffs could then seek an order under s.40 (5A) for the suspension and/or termination of the subscriber’s service. Such applications would not be opposed or consented to by the defendant and the defendant would not seek its costs.</li>
</ol><div>Finally, the Court noted, on the issue of allocation of costs, that ""because the defendant is the company which profits - albeit indirectly - because it derives revenue from its subscribers who are engaged in this practice, it is the defendant who should, in my view, be primarily liable for the costs."" Therefore, according to the Court, UPC should be required to bear 80% of the costs.]</div>
",Intermediary Liability,2015-12-14 20:52,505,Giancarlo Frosio,News
13726,European Union,,0,0,"The Final Draft of Europe's ""Right to Be Forgotten"" Law",Right to Be Forgotten+Privacy or Data Protection,"<p>The probably-really-almost-totally final 2016 General Data Protection Regulation (GDPR) is <a href=""http://static.ow.ly/docs/Regulation_consolidated_text_EN_47uW.pdf"">here</a>!  Lawyers around the world have been hunkered down, analyzing its 200-plus pages. In the “Right to Be Forgotten” (RTBF) provisions, not much has changed from prior drafts. The law still sets out a notice and takedown process that strongly encourages Internet intermediaries to delete challenged content, even if the challenge is legally groundless.  The problems I <a href=""http://cyberlaw.stanford.edu/blog/2015/12/series-conclusion-summary-intermediaries-and-free-expression-under-gdpr-brief"">identified in earlier drafts</a> could have been avoided with simple changes – putting procedural checks on invalid erasure requests, while giving effect to valid ones.  Those changes would not have diminished any gains for online privacy rights under the GDPR, or affected Internet users’ ability to delete data collected by companies and held in back-end logs, accounts, or profiling systems.  The opportunity to make those targeted changes has now passed.</p>
<p>The silver lining is that the final GDPR text is riddled with ambiguous passages on key points.  Happy holidays, data protection lawyers – it’s the gift of lifetime employment!  These ambiguities will move debates that should have been resolved in the lawmaking process into a new phase, centered on advocacy before regulators and courts.  For RTBF issues, there are enough important ambiguities to keep the public discussion going for a long time.  The right interpretations can help lawmakers protect online privacy and data protection rights without doing unnecessary and disproportionate harm to free expression and information access.</p>
<p>In overview, here is how the notice and takedown provisions landed in the final draft.   For the quick-and-dirty version, just read the underlined parts.</p>
<ul><li><u>Data controllers, including at least some Internet intermediaries, must erase content based on “right to be forgotten” (RTBF) requests.</u> This is the thrust of Articles 17 and 19.  The much-debated RTBF moniker is in the title of Article 17: ‘Right to erasure (“right to be forgotten”).’  The RTBF provision directly applies only to data controllers, meaning the entities that “determine the purposes and means” of processing personal data.  For hosts and other Internet intermediaries, the next big question will be whether they count as controllers, with RTBF removal obligations for content uploaded by their users.  (Example: If I post about my cousin on Facebook, can my cousin compel Facebook to take it down?)
<p><em>What changed in the final draft</em>: Mostly just the title, which had varied from draft to draft. (I have not run text comparisons on all drafts, this is based on memory and review yesterday.)</p>
<p> </p></li>
</ul><ul><li><u>The GDPR doesn’t tell us whether hosting platforms like Facebook or Twitter are controllers with RTBF erasure obligations.</u> We know that search engines are controllers and thus have RTBF obligations -- that was a key holding in the <a href=""http://curia.europa.eu/juris/document/document_print.jsf?doclang=EN&docid=152065"">Google Spain/Costeja</a> case.  The GDPR doesn’t tell us what other Internet intermediaries will fall in that category.  Realistically, I find it hard to imagine DPAs excusing major social networks from erasure obligations, in the long run.  But there will be a lot of arguing first. 
<p>There are some strong arguments against RTBF obligations for hosts – for example, that they cannot be controllers because they only <a href=""http://cyberlaw.stanford.edu/blog/2015/03/spain-right-be-forgotten-does-not-apply-blogger"">process</a> content at the direction of a user, who is herself the controller.  There are also some widely accepted legal arguments that will, if they prevail, lead to more complicated answers.  Following one of them, RTBF would apply to hosts that are too “active” in managing user content, but not to “passive” hosts.  Following another argument, hosts would have to erase some content, but not nearly as much as the content that search engines must de-index.   (Example: Google may have to remove search results pointing to the Facebook page where I posted about my cousin, but Facebook still won’t have to remove the post from its platform.)</p>
<p><em>What changed in the final draft</em>: Not much.  There is some inconclusive new language about social networking in Recital 15.</p>
<p> </p></li>
</ul><ul><li><u>Intermediaries that do not honor RTBF requests risk crippling fines.  There are no legal consequences for “over-removing” content targeted by invalid RTBF requests.</u> This part of the GDPR kept changing in drafts, but fines for RTBF violations are now set at the greater of “20 000 000 EUR, or in case of an undertaking, up to 4% of the total worlwide (sic) annual turnover.”  Art. 79.3a.  This boosts intermediaries’ <a href=""http://cyberlaw.stanford.edu/blog/2015/10/empirical-evidence-over-removal-internet-companies-under-intermediary-liability-laws"">well-documented</a> existing incentives to simply honor all removal requests.  Honoring most or all RTBF requests would be a problem, given that both <a href=""http://www.microsoft.com/about/corporatecitizenship/en-us/transparencyhub/crrr/"">Bing</a> and <a href=""https://www.google.com/transparencyreport/removals/europeprivacy/"">Google</a> report that at least 50% of RTBF requests they receive are invalid under EU law.
<p><em>What changed in the final draft</em>: These numbers are new. Fines varied a lot in early drafts, and reportedly were hotly debated and lobbied until the 11<sup>th</sup> hour.</p>
<p> </p></li>
</ul><ul><li>We still don’t know the answer to <u>the </u><u>€20 million question: Do intermediary liability laws under eCommerce Directive Articles 12-15 apply to RTBF erasure requests? </u>  Existing rules under the eCommerce Directive tell Internet companies how to handle removal requests for other legal claims, like defamation.  Those rules have real flaws, but they at least build in some protections against legally groundless or abusive attempts to silence online expression.  There is no reason to use a whole new process for RTBF claims, so the answer to the question should be yes: eCommerce procedural rules for notice and takedown apply to RTBF erasures.  That would mean, among other things, that intermediaries don’t have to take down content until they know the removal request states a valid claim.
<p>The GDPR’s plain language seems to support this answer, but has a loophole that will fuel argument for years.  Both GDPR Recital 17 and Article 2.3 say the GDPR is “without prejudice” to “the liability rules of intermediary service providers in Articles 12 to 15” – the eCommerce rules that govern notice and takedown. The problem is, many data protection experts say that the eCommerce “liability rules” are irrelevant, because the GDPR doesn’t technically hold intermediaries liable for the speech of a third party.   Following this argument, the “without prejudice” language has no practical consequence.  As long as this question is unresolved, intermediaries can’t be certain whether they can use existing eCommerce removal systems, or whether they must develop new tools to implement the troubling new removal process prescribed by the GDPR.  Putting faith in the simpler interpretation of Article 2.3, and assuming it excuses an intermediary from following the specific rules described in the GDPR, is an expensive gamble.</p>
<p> </p></li>
</ul><ul><li><u>If eCommerce rules do not apply, then RTBF removals must follow specified steps and processes, which encourage erasure without adequate protections for Internet users’ expression and information rights. </u>A controller that gets a RTBF erasure request must follow specific steps.  Some are enumerated in scattered GDPR sections.  Others are implicit, based on regulators’ interpretation of similar language in the old Directive.  Those interpretations warrant fresh consideration and debate, though, as the GDPR expands their impact on Internet information access.
<p><a name=""Restrict"" id=""Restrict""></a><br /></p>
<p>The GDPR’s erasure process generally makes sense for traditional, pre-<em>Costeja</em> erasure requests – like when a user wants to delete behavioral tracking or profiling information, or content that she herself uploaded.  But applying that same process to erase a third party’s online expression is a problem, because it has almost no effective checks on over-reaching or malicious removal requests.</p></li>
</ul><p style=""margin-left: 1in;"">o   Intermediaries must <u>immediately take content offline</u> when they receive an erasure request, and keep it offline until they figure out whether the request is legally valid.  (Art. 17a.1.a and c)  For example, if someone claims that online information is inaccurate, the intermediary must “restrict” the information by taking it offline “for a period enabling the controller to verify the accuracy of the data.” (Art. 17a.1.a)  That kind of factual investigation of user-generated content is not something intermediaries are likely to attempt.  Information restricted under this remove-then-verify standard is unlikely to ever be reinstated. There are powerful policy arguments, as well as legal arguments based on fundamental rights, against this presumption of guilt for online speakers.  Those arguments should prevail.  But Article 17a won’t make it easy.</p>
<p style=""margin-left: 1in;""><em>What changed</em>: Prior language on “restriction” was confusing and scattered.  The final text in 17a cleans it up in ways that eliminate arguable exceptions or defenses from older drafts, but those were never strong anyway.</p>
<p style=""margin-left: 1in;"">o   Intermediaries must <u>decide what to erase without any meaningful guidance</u> about how to weigh the rights at issue.  Hopefully regulators will consult with stakeholders, including civil society groups and experts on free expression and information, to develop concrete guidelines -- like the very <a href=""http://ec.europa.eu/justice/data-protection/article-29/documentation/opinion-recommendation/files/2014/wp225_en.pdf"">thoughtful ones</a> they previously published for search engines.</p>
<p style=""margin-left: 1in;"">o   <u>The person whose online expression is erased is not notified or given an opportunity for defense</u>.  The GDPR does not spell this out, but leaves intact the language that regulators already interpreted to preclude notice in the search engine context.  Under <a href=""http://ec.europa.eu/justice/data-protection/article-29/documentation/opinion-recommendation/files/2014/wp225_en.pdf"">that interpretation</a>, intermediaries can sometimes consult with the publisher before erasing the content, however.</p>
<p style=""margin-left: 1in;"">o   The intermediary seemingly must <u>disclose the online speaker’s identity to the person requesting erasure.</u>   I think DPAs or courts will find ways interpret this part out of existence.  It’s seriously inconsistent with the GDPR’s pro-privacy goals.  Applying it to RTBF content removals was probably a drafting mistake.  The GDPR language on this is fuzzy enough that smart data protection lawyers should find a way around it, if they want to.  It says that the “data subject shall have the right to obtain from the controller” certain information, including “where the personal data are not collected from the data subject, any available information as to their source.”  Art. 15.1(g).  There is similar language at Article 14a(2)(g).</p>
<p style=""margin-left: 1in;"">o   There is <u>no specified form for requesting erasure</u> or required information that data subjects must include to explain why erasure is justified.  This, too, can and hopefully will be remedied in guidance from regulators.</p>
<p style=""margin-left: 1in;"">o   Most removals are to be processed in a <u>one month turnaround time</u>.  (Art 12.2)  That seems reasonable in most cases.  For companies experiencing rapid growth who don’t yet have legal teams dedicated to such things, it may lead to rushed and inaccurate removals decisions.</p>
<ul><li><u>The GDPR says data protection must be balanced with free expression</u>, and that RTBF requests can be denied on free expression grounds.  (Art. 17.3, R. 3a)  But <u>provides no guidance on what those free expression grounds are</u>. Instead, it leaves Member States to enact specific free expression protections sometime in the future.  (At. 80)  There are a number of <a href=""http://cyberlaw.stanford.edu/blog/2015/12/series-conclusion-summary-intermediaries-and-free-expression-under-gdpr-brief"">problems</a> with this approach.  For one, some countries still haven’t put in place the free expressions protections they were supposed to enact twenty years ago under the last Directive. So, don’t expect them to create harmonized and adequate protection for Internet users’ speech anytime soon. 
<p><em>What changed in the final draft</em>: The core text in Article 80 has changed a little, not in ways relevant for intermediaries.  It appears to me that protections for research and archival uses have become more robust there and throughout the GDPR, though.  My hat is off to whoever got that done.</p>
<p> </p></li>
</ul><ul><li><u>GDPR obligations apply to a huge number of non-EU companies – even more than in some earlier drafts.</u>  The GDPR’s “territorial scope” section applies the GDPR to companies outside the EU if they process data about people within the EU in connection with “offering goods or services” or “monitoring” user behavior.  Art. 3.2.   Recitals to the GDPR put some useful limits on the scope of the “offering” basis for jurisdiction over foreign companies. (R. 20)  But “monitoring” appears to cover a broad swath of tracking, profiling, and customization commonly done by Internet companies around the world. (R. 21, Art. 4.3aa)  So unless they block or differentiate services for EU users, those companies need to think hard about their obligations under the Regulation overall – not just for RTBF.
<p><em>What has changed in the final draft: </em>A lot more companies are covered. Unlike some prior drafts of Article 3.2, the final language covers data <em>processors</em> outside the EU, not just controllers.  That extends the GDPR to a lot more companies.  The new ones – non-EU data processors – have fewer direct obligations under the law, but will probably need to change their contracts with controller companies, and assume new duties under those contracts.  This is above and beyond the changes already underway to address data transfer issues because of the Schrems case.  I have not tracked processor duties closely, but expect plenty of good analysis on this from corporate law firms with big data protection practices, like <a href=""https://www.huntonprivacyblog.com/"">Hunton & Williams</a> or <a href=""https://www.wsgr.com/eudataregulation/"">Wilson Sonsini</a>. </p>
<p>Recitals in the final draft also evince a real frustration with claims that EU law does not reach the foreign corporate parents of subsidiaries established in the EU, saying “legal form of such arrangements, whether through a branch or a subsidiary with a legal personality, is not the determining factor” for determining jurisdiction under Article 3.1. (R 19, 28)</p></li>
</ul>",Intermediary Liability,2015-12-17 12:00,1188,Daphne Keller,News
13728,,Brazil,0,0,WhatsApp in Brazil?,Other,"<div>
<div>A few days ago, a Brazilian judge ordered telecoms to block access to WhatsApp on the Brazilian territory for lack of cooperation in a criminal investigation. A few hours later, a superior tribunal invalidated the initial blocking order and reinstated access to Whatsapp. Since the contours of this <a href=""https://cyberlaw.stanford.edu/blog/2015/03/whatsapp-risk-suspension-services-brazil"">latest </a>Brazilian Whatsapp affair appeared quite blurry, you may find a full report of the case below.</div>
<div> </div>
<div>On December 17, a judge from the 1st criminal court of São Bernardo do Campo in the state of São Paulo <a href=""http://www.tjsp.jus.br/institucional/canaiscomunicacao/noticias/Noticia.aspx?Id=29056"">ordered all telecoms</a> to block access to Whatsapp, a platform used by more than 100 million Brazilians, on the Brazilian territory for 48 hours. This decision was taken as part of a criminal case that is under secrecy, which makes impossible to know exactly what legal reasoning the judge applied to issue the blocking order.  According to the scanty information available, on the day before the blocking, all mobile telecom companies and supposedly other telecoms received a cryptic judicial order to block all access to Whatsapp for 48 hours, counting from midnight. Apparently, there were no precise technical instructions. The blocking was based on the refusal of WhatsApp to provide data that was relevant to an ongoing criminal investigation. Apparently, Facebook, the parent company owning Whatsapp, claimed that Brazilian courts did not have jurisdiction for ordering any data disclosure, being Whatsapp's servers located elsewhere. Presumably, the court considered these arguments unsustainable, according to the most recent case law and, in particular, the <em><a href=""https://cyberlaw.stanford.edu/page/wilmap-brazil"">Marco Civil da Internet</a></em>, the most recent Brazilian Internet legislation, which reformed the legal framework governing intermediary liability. In fact, Brazilian courts rejected similar arguments since earlier 2007/2008 Internet cases. </div>
<div> </div>
<div>All telecoms complied effectively at midnight. Whatsapp went down. Quickly people began to download Telegram or VPN programs.</div>
<div> </div>
<div>In the morning of the following day <a href=""https://en.wikipedia.org/wiki/Oi_(telecommunications)"">OI</a>, the largest telecommunications company in Brazil and South America, issued a statement claiming it had filed an Habeas Corpus against the blocking order before the court of appeals of the state of São Paulo. Brazilian commentators speculated that the Habeas Corpus was chosen in lieu of a more specific writ because OI had no knowledge of the basis of the order. Shortly thereafter, the court of appeals issued a statement confirming that the order came from an action under secrecy dealing with organized crime criminal activities, equivalent to those pertaining to the RICO Act in the United States. The appellate court further indicated that a company - presumably Facebook or WhatsApp, although it was not nominally mentioned by the court - had been already ordered twice to give up information and failed to comply, once in July and once in August.</div>
<div> </div>
<div>Finally, early in the afternoon of December 17, the court of appeals <a href=""http://www.conjur.com.br/2015-dez-17/tj-sao-paulo-suspende-bloqueio-aplicativo-whatsapp"">lifted the blockage</a>. The court <a href=""http://cdn.jota.info/wp-content/uploads/2015/12/liminar.pdf"">decided on OI's Habeas Corpus</a>, confirming that OI did not have to comply with the pristine blocking order, and issued a <a href=""http://politica.estadao.com.br/blogs/fausto-macedo/wp-content/uploads/sites/41/2015/12/MS-2271462.pdf"">second decision</a> on a correct writ [<em>Mandado de Segurança</em>] with the same order, but with general effects. As the court noted, although, according to the <em>Marco Civil da Internet</em>, Brazilian courts do have jurisdiction to order data disclosure to companies operating in their territory, the Marco Civil needs to be applied following the Constitution and its own principles, not in a vacuum. Therefore, the Court invalidated the previous decision since it was disproportionate and unnecessary. In particular, it inflicted a considerable harm to users, rather than just the company. According to the appellate court, the inferior court should have applied alternative coercive measures to force the data disclosure, such as imposing fines or possibly jail time on the company's legal representatives for non-compliance, rather than shutting down the whole service.</div>
<div> </div>
<div>Brazilian commentators noted that Facebook's position was hardly helpful in fostering the discussion of internet rights in Brazil and belittled the debate that surrounded the <em>Marco Civil da Internet</em> and its perceived achievements.  According to Brazilian law, internet hosting providers in Brazil must give up information to judicial authorities, and there are instances in which blocking orders for not compliance might be legitimate. Claiming that national courts lack necessary jurisdiction to order data disclosure because Internet platforms' servers are located elsewhere will hardly convince those courts to surrender national sovereignty, especially if consistent caselaw and legislation state otherwise. Earlier this year, WhatsApp's blockage in the Brazilian territory <a href=""https://cyberlaw.stanford.edu/blog/2015/03/whatsapp-risk-suspension-services-brazil"">was already ordered </a>by a judge of the state of Piauí in a case pertaining to the sharing of child pornography but never implemented. Outdated arguments focusing on the servers' location, rather that the effects of the platform's activity on the national territory, seem to have lost their teeth with national courts. According to recent developments, global Internet platforms must necessarily realize that they should strictly abide to national law, if they want to operate in a certain jurisdiction. </div>
<div> </div>
<div><em><a href=""https://br.linkedin.com/in/felipebusnello/en"">Felipe Octaviano Delgado Busnello</a> is a qualified Brazilian attorney active in the field of internet and intellectual property law. He can be reached at felipe.busnello at gmail.com.</em></div>
</div>
<div> </div>
",Intermediary Liability,2015-12-28 6:54,505,Giancarlo Frosio,News
13735,,International,1,1,December 2015 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>December 2015 in Retrospect is available here:</p>
<p><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2015-december/"">http://www.internetjurisdiction.net/observatory/retrospect/2015-december/</a></p>
<p>Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
",Intermediary Liability,2016-01-07 2:29,505,Giancarlo Frosio,News
13811,,European Union,0,0,Comentario a la versión final de la legislación Europea de “Derecho al Olvido”,Right to Be Forgotten+Privacy or Data Protection,"<p dir=""ltr""><em>Este artículo apareció originalmente en inglés <a href=""http://cyberlaw.stanford.edu/blog/2015/12/final-draft-europes-right-be-forgotten-law"" target=""_blank"">aquí</a>. Traducido por <a href=""https://www.linkedin.com/in/paula-vargas-de-brea-cipm-1761b926"" target=""_blank"">Paula Vargas de Brea</a>. Reproducciones autorizados con enlace y atribución.</em></p>
<p dir=""ltr"">La versión casi-probablemente-con-seguridad final del Reglamento General de Protección de Datos (GDPR por sus siglas en inglés) ha llegado!. Alrededor del mundo, los abogados han estado absortos analizando sus mas de 200 páginas. Respecto de las normas referidas al llamado “Derecho al Olvido” (RTBF por sus siglas en inglés) no mucho ha variado en relación con las versiones anteriores. La norma continúa estableciendo un procedimiento de notificación y remoción con un fuerte incentivo para que los intermediarios de Internet eliminen el contenido cuestionado, aun si el cuestionamiento fuera legalmente infundado. Los problemas que ya identifiqué en versiones anteriores podrían haberse evitado con cambios simples –incluyendo algunos controles procedimentales ante requerimientos de eliminación inválidos, y dando trámite a los válidos. Estos cambios no habrían afectado el alcance de la protección del derecho a la privacidad bajo la GDPR, ni afectado la capacidad de los usuarios de Internet para borrar datos recolectados por las empresas y retenidos en registros de back-end, cuentas de usuarios, o sistemas de generación de perfiles. Ahora, la oportunidad para hacer esos cambios acotados ya ha pasado.</p>
<p dir=""ltr""><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">El lado positivo es que el texto final de la GDPR esta plagado de párrafos ambiguos en puntos críticos. Feliz año abogados de protección de datos – ¡es un regalo que ocurre una vez en la carrera! Estas ambigüedades trasladarán los debates que deberían haber sido resueltos en la etapa de redacción de la ley hacia una nueva fase, centrada en la argumentación ante los reguladores y los tribunales. En las cuestiones de “Derecho al Olvido”, existen suficientes ambigüedades en temas importantes como para mantener el debate público activo por un largo tiempo. Las interpretaciones correctas pueden ayudar a los legisladores a proteger la privacidad en línea y el derecho a la protección de datos sin causar un daño innecesario y desproporcionado a la libertad de expresión y el acceso a la información. </span></p>
<p dir=""ltr""><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">En términos generales, así es como las normas de notificación y remoción quedaron en la versión final. Para una perspectiva rápida, pueden leerse solo las partes subrayadas.</span></p>
<ul><li dir=""ltr"">
<p dir=""ltr""><u><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">Los Responsables del tratamiento de datos personales, incluyendo por lo menos algunos intermediarios de Internet, deberán borrar contenido ante una solicitud fundada en el “Derecho al Olvido”</span>.</u> Esta es la idea central de los Artículos 17 a 19. El alias del muy debatido “Derecho al Olvido” esta en el Artículo 17: ´Derecho al borrado (“Derecho al Olvido”)´. La norma del Derecho al Olvido se aplica directamente solo respecto de los responsables del tratamiento, es decir a aquellas entidades que “determinan el propósito y los fines” del procesamiento de datos. Para los proveedores del servicio de almacenamiento y otros intermediarios de Internet, la gran pregunta será si ellos son considerados como responsables, con la obligación de remover contenido generado por sus usuarios. (Por ejemplo: si yo realizo un post sobre mi primo en Facebook,¿ puede mi primo obligar a Facebook a removerlo?)</p>
</li>
</ul><p dir=""ltr""><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">¿Qué cambió en la versión final?: básicamente sólo el título, que fue variando de versión en versión (no realicé una comparación de todos las versiones, por lo cual me baso en mi memoria y en lo que revisé últimamente)</span></p>
<ul><li dir=""ltr"">
<p dir=""ltr""><u><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">La GDPR no nos dice si plataformas como Facebook o Twitter pueden ser calificadas como responsables del tratamiento a quienes les alcanzarían las obligaciones de borrado</span>.</u> Ya sabemos que los motores de búsqueda son responsables y tienen por tanto obligaciones de “Derecho al Olvido”, ello fue el objeto de una decisión clave en el caso Google España/ Costeja. La GDPR no indica que otros intermediarios caerían dentro de esta categoría. En verdad, encuentro difícil de imaginar a una Agencia de Protección de Datos Personales (DPA por sus siglas en inglés) excluyendo a las redes sociales más importantes de las obligaciones de borrado, ello en el largo plazo. Pero primero se dará un intenso debate. Existen algunos argumentos fuertes contra la aplicación del “Derecho al Olvido” a los proveedores de servicios de almacenamiento –por ejemplo, que éstos no pueden ser considerados como responsables del tratamiento porque solo procesan datos bajo la instrucción de un usuario, quien es realmente el responsable del tratamiento. Pero también existen otros argumentos legales, ampliamente aceptados, que conducirían a respuestas más complicadas. Siguiendo uno de dichos argumentos, el “Derecho al Olvido” se aplicaría a aquellos proveedores de servicios de almacenamiento que fueran demasiado “activos” en la gestión de los contenidos de sus usuarios, pero no a los que fueran “pasivos”. Siguiendo otro argumento, los proveedores de servicios de almacenamiento deberían borrar algún contenido, pero ni de cerca la cantidad de contenido que deberían des-indexar los motores de búsqueda. (Por ejemplo: Google debería remover los resultados de búsqueda que conducen al post que yo realicé sobre mi primo en Facebook, pero Facebook no estaría obligada a remover ese post de su plataforma).</p>
</li>
</ul><p dir=""ltr""><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">¿Qué cambió en la versión final?: no mucho. Se incluye un nuevo lenguaje, no muy concluyente, sobre el uso de redes sociales en el Antecedente 15.</span></p>
<ul><li dir=""ltr"">
<p dir=""ltr""><u><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">Los intermediarios que no cumplan con las solicitudes fundadas en el “Derecho al Olvido” se arriesgarán a ser objeto de devastadoras multas.</span></u> No genera ninguna consecuencia por “remover de más” el contenido objeto de solicitudes de “Derecho al Olvido” inválidas. Esta parte de la GDPR fue cambiando con las versiones, pero las multas por violación al “Derecho al Olvido” se han establecido ahora en un rango de “20.000.000 Euros, o en caso de una empresa, hasta el 4% del ingreso anual global (sic)” (Art. 79.3a). Esto dispara los incentivos de los intermediarios, ya existentes y suficientemente documentados, a simplemente honrar todas las solicitudes de remoción. Honrar la mayoría de los requerimientos de “Derecho al Olvido” sería un problema, dado que ambos, Bing y Google han reportado que por lo menos el 50% de las solicitudes de remoción fundadas en el “Derecho al Olvido” que reciben son inválidas de conformidad con la ley Europea.</p>
</li>
</ul><p dir=""ltr""><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">¿Qué cambió en la versión final?: Estos montos son nuevos. Las multas variaron mucho de las versiones anteriores y, según se ha reportado, fueron fuertemente debatidas y objeto de lobbies hasta última hora.</span></p>
<ul><li dir=""ltr"">
<p dir=""ltr""><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">Aun no conocemos la respuesta a la </span><u>pregunta de los 20 Millones de Euros: ¿se aplican las normas de responsabilidad de los intermediarios previstas en los Articulos 12-15 de la Directiva Europea de Comercio Electrónico a las solicitudes de borrado por “Derecho al Olvido”?.</u> Las reglas existentes en la Directiva Europea de Comercio Electrónico le indican a las empresas de Internet como ejecutar las solicitudes de remoción por otros reclamos legales, tales como difamación. Estas reglas tienen verdaderas fallas, pero al menos brindan ciertas protecciones contra intentos sin fundamento legal o abusivos de silenciar discurso en línea. No hay razón para utilizar un proceso totalmente nuevo para los reclamos por “Derecho al Olvido”, por lo que la respuesta para esta pregunta debería ser afirmativa: las  reglas procedimentales de Comercio Electrónico para la notificación y remoción son aplicables al borrado por “Derecho al Olvido”. Esto significaría, entre otras cosas, que los intermediarios no deberían remover contenido hasta saber que la solicitud contiene un reclamo válido.  </p>
</li>
</ul><p dir=""ltr"" style=""margin-left:18pt;""><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">El lenguaje literal de la GDPR parece apoyar esta respuesta, pero contiene un agujero que agitará debates por años. Tanto el Antecedente 17 como el Articulo 2.3 ambos dicen que la GDPR se aplica “sin perjuicio” de “las reglas sobre responsabilidad de intermediarios establecidas en los Artículos 12 a 15”-las reglas de Comercio Electrónico que regulan el procedimiento de notificación y remoción. El problema se presenta, dicen muchos de los expertos, en que las reglas de responsabilidad  de intermediarios de la Directiva de Comercio Electrónico son irrelevantes, ya que la GDPR, técnicamente no sanciona con responsabilidad civil al intermediario por el discurso de un tercero. Siguiendo este razonamiento, el “sin perjuicio” no tendría una consecuencia práctica. Mientras esta cuestión permanezca irresuelta, los intermediarios no tienen certeza sobre si pueden utilizar los sistemas de remoción ya existentes o si deben desarrollar nuevas herramientas para implementar los problemáticos nuevos procedimientos descriptos en la GDPR. Simplemente guiarse por la fe en la interpretación más simple del Artículo 2.3, y asumir que ella excusa a los intermediarios de cumplir con las reglas específicas previstas en la GDPR, es una apuesta que puede costar cara. </span></p>
<ul><li dir=""ltr"">
<p dir=""ltr""><u><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">Si las reglas de Comercio Electrónico no fueran aplicables, entonces las solicitudes de remoción por “Derecho al Olvido” deberían seguir pasos y procedimientos específicos, lo que promueve el borrado si no existe una protección adecuada para los derechos a la libertad de expresión y acceso a la información de los usuarios de Internet</span>.</u> Un responsable del tratamiento que recibe una solicitud de borrado por “Derecho al Olvido” debe seguir  pasos específicos. Algunos están enumerados en secciones dispersas de la GDPR. Otros son implícitos, surgidos de la interpretación de los reguladores de algún lenguaje similar de la vieja Directiva. Estas interpretaciones garantizan, no obstante, consideraciones y debates frescos, a medida que la GDPR expande su impacto en el acceso a la información en Internet.</p>
</li>
</ul><p dir=""ltr"" style=""margin-left:18pt;""><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">El procedimiento de borrado de la GDPR tiene sentido para las solicitudes tradicionales de borrado, pre-Costeja –como cuando un usuario quiere borrar el tracking de su comportamiento en línea o información de su perfil, o contenido que esa misma persona hubiera subido.  Pero aplicar las mismas reglas para borrar un discurso en lina de una tercera persona es un problema, porque no existe casi un control efectivo respecto de las solicitudes muy amplias o maliciosas</span></p>
<ul><li dir=""ltr"">
<p dir=""ltr""><u><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">Los intermediarios deben remover inmediatamente el contenido</span></u> cuando reciban una solicitud de remoción, y mantenerlo fuera de línea hasta que resuelvan si la solicitud es legalmente válida (Art. 17.a.1.a y c). Por ejemplo, si alguien reclama que la información en línea es incorrecta, el intermediario debe “restringir” la información, sacándola de circulación “por un período que permita al responsable del tratamiento verificar la corrección de los datos” (Art. 17ª.1.a). Esta clase de investigación fáctica del contenido generado por usuarios no es algo que los intermediarios vayan a intentar hacer. La información removida de acuerdo a este estándar de remuevo-luego-verifico difícilmente vuelva a ser publicada. Existen poderosos argumentos de política, así como argumentos legales basados en los Derechos Humanos, contra esta presunción de culpabilidad de quienes se expresan en línea. Estos argumentos deberían prevalecer. Pero el Articulo 17 no lo hará fácil.</p>
</li>
</ul><p dir=""ltr""><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">¿Que cambió?: El lenguaje anterior sobre “restricción” era confuso y estaba disperso. El texto final en el 17a es más limpio, en el sentido que elimina excepciones o defensas discutibles de las versiones anteriores, aunque igualmente éstas nunca fueron demasiado viables. </span></p>
<ul><li dir=""ltr"">
<p dir=""ltr""><u><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">Los intermediarios deben decidir que remover sin ninguna guía razonable</span></u> sobre como balancear los derechos en juego.  Con suerte, los reguladores consultaran con las partes interesadas, incluyendo los grupos de la sociedad civil y expertos en libertad de expresión y acceso a la información, para desarrollar guías concretas- como las publicadas previamente para los motores de búsqueda que fueron cuidadosamente pensadas</p>
</li>
</ul><ul><li dir=""ltr"">
<p dir=""ltr""><u><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">La persona cuyo discurso en línea es borrado no es notificada o no se le da oportunidad alguna para expresar una defensa</span>.</u> La GDPR no lo dice, pero mantiene intacto el lenguaje que los reguladores ya han interpretado como excluyente de la notificación, en el contexto de los motores de búsqueda. Bajo esta interpretación, no obstante, los intermediarios pueden algunas veces consultar con quien publicó originalmente el contenido.</p>
</li>
</ul><ul><li dir=""ltr"">
<p dir=""ltr""><u><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">El intermediario, aparentemente debe divulgar la identidad de quien expresó un discurso, a la persona que requiere su borrado</span>.</u> Considero que las DPA y los tribunales encontrarán la forma de interpretar esta parte como si no existiera. Es fuertemente inconsistente con el objetivo pro-privacidad de la GDPR. Su aplicación a los casos de remoción de contenido por “Derecho al Olvido” se debe, probablemente, a un error de redacción. Los términos de la GDPR en este tema son lo suficientemente difuso como para que los abogados de protección de datos personales  encuentren una salida inteligente, si es que quieren hacerlo. Dice que: “los titulares de datos tendrán el derecho a obtener de los responsables del tratamiento” cierta información, incluso “en el caso en que la información no sea recolectada del titular del dato, cualquier información disponible sobre su fuente” Art. 15.1 (g). El Artículo 14 a (2) (g) contiene un lenguaje similar</p>
</li>
</ul><ul><li dir=""ltr"">
<p dir=""ltr""><u><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">No se especifica un formato para solicitar el borrado</span></u> ni cual es la información que los titulares de datos deben incluir para explicar la razón por la cual el borrado estaría justificado. Esto también podría, y esperemos que suceda, ser remediado con alguna guía de los reguladores.</p>
</li>
</ul><ul><li dir=""ltr"">
<p dir=""ltr""><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">La mayoría de las solicitudes de remoción deben ser procesados en </span><u>un plazo máximo de un mes (Artículo 12.2).</u> Esto parece razonable en la mayoría de los casos. Para las empresas que se encuentren experimentando un crecimiento rápido y que aún no cuenten con equipos legales dedicados a estos temas, el plazo podría llevar a decisiones de remoción apresuradas e incorrectas.</p>
</li>
</ul><ul><li dir=""ltr"">
<p dir=""ltr""><u><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">La GDPR dice que la protección de datos debe ser balanceada con la libertad de expresión</span></u><span> </span>y que las solicitudes por Derecho al Olvido pueden ser negadas con fundamento en este derecho. (Art. 17.3, R.3 a). Sin embargo, <u>no provee ninguna guía sobre cuales son esos fundamentos de libertad de expresión.</u> En cambio, deja a los Estados Miembros la tarea de establecer los mecanismos de protección de la libertad de expresión en algún momento futuro (Art. 80). Esta aproximación genera una serie de problemas. Por un lado, algunos países aún no han establecido las protecciones para la libertad de expresión que se suponía debían dictar hace veinte años, bajo la última Directiva. Por lo tanto, no es esperable que elaboren una protección armónica y adecuada para el discurso de los usuarios de Internet en el corto plazo.</p>
</li>
</ul><p dir=""ltr""><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">¿Que cambión en la versión final?: el texto central del artículo 80 cambió un poco, pero no en una forma relevante para los intermediarios. Me parece, no obstante, que las protecciones para investigación y usos de archivo se han fortalecido allí y en el resto de la GDPR. Me saco el sombrero por quien sea que obtuvo ese logro.</span></p>
<ul><li dir=""ltr"">
<p dir=""ltr""><u><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">Las obligaciones de la GDPR se aplican a una enorme cantidad de empresas No Europeas –aún más que en versiones anteriores.</span></u><span> </span>La sección de “alcance territorial” aplica la GDPR a empresas fuera de la Unión Europea si éstas procesan datos sobre personas dentro de la Unión Europea en conexión con la “oferta de productos y servicios” o por “monitorear” el comportamiento de los usuarios. Art. 3.2. Los Antecedentes de la GDPR establecieron ciertos limites útiles en cuanto al alcance de “ofrecer” como base para determinar la jurisdicción sobre empresas extranjeras (Antecedente 20). Pero “monitoreo” parece alcanzar una amplia franja de tracking, elaboración de perfiles, y costumización que son usualmente realizadas por las empresas de Internet alrededor del mundo (Antecedentes 21,Art. 4.3aa). Por lo tanto, a menos que se bloqueen o se diferencien servicios para los usuarios Europeos, esas empresas necesitan pensar en profundidad sobre sus obligaciones bajo el Reglamento en general, no sólo respecto del “Derecho al Olvido”.</p>
</li>
</ul><p> </p>
<p dir=""ltr""><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">¿Que ha cambiado en la versión final?: muchas más empresas son alcanzadas. A diferencia de algunas versiones anteriores del Artículo 3.2, el lenguaje final alcanza a los encargados del tratamiento fuera de la Unión Europea, no solo a los responsables del tratamiento. Esto extiende la GDPR a muchas más empresas. Las nuevas –encargados del tratamiento no Europeos- tienen menos obligaciones legales directas, pero probablemente necesitarán modificar sus contratos con las empresas responsables del tratamiento, y asumir nuevos deberes bajo esos contratos. Estos es independiente de los cambios que ya están ocurriendo para abordar la transferencia internacional de datos como consecuencia del caso Schrems. No he seguido los deberes de los encargados muy de cerca, pero aguardo muchos buenos análisis sobre esto de los estudios jurídicos con prácticas en protección de Big Data, como Hunton & Williams o Wilson Sonsini. </span></p>
<p dir=""ltr""><span id=""docs-internal-guid-989d6d10-a32a-04ef-9bf3-b29dd149f913"">Los Antecedentes de la versión final también evidencian una frustración real con los reclamos de que la ley Europea no alcanza a las empresas extranjeras matrices de las subsidiarias establecidas en la Unión Europa, expresando que “el formato legal de esos arreglos, sea a través de una filial o una subsidiaria con personalidad jurídica propia, no es un factor determinante” para fijar la jurisdicción de acuerdo al Articulo 3.1. (Antecedentes 19,28)</span></p>
<p> </p>
",Intermediary Liability,2016-02-02 10:12,1188,Daphne Keller,News
13819,,United States,0,0,"New Berkman Center Report Assures Us That Law Enforcement Isn't ""Going Dark""",Other,"<p>The Berklett Cybersecurity Project of the Berkman Center for Internet and Society at Harvard University <a href=""https://cyber.law.harvard.edu/node/99280"">has just released a new report</a> on the so-called “going dark problem” that is fueling law enforcement demands for access to encrypted information. The report, “Don’t Panic: Making Progress on the ‘Going Dark’ Debate,” concludes that new consumer technologies will increasingly provide a wealth of data to governments about individual movements and activities. The full report is available in PDF form <a href=""https://cyber.law.harvard.edu/pubrelease/dont-panic/Dont_Panic_Making_Progress_on_Going_Dark_Debate.pdf"">here</a>.</p>
<p>The signatories to “Don’t Panic” comprise an all-star group of security and policy experts from civil society organizations, the U.S. intelligence community, and academia, reflecting diverse experience and viewpoints. The Berklett Cybersecurity Project seeks to “bring together people who come from very different starting points and roles, and who very rarely have a chance to speak frankly with one another,” according to Professor Jonathan Zittrain, the Berkman Center’s faculty chair and one of the report’s signatories. “We want to come away with some common insights that could help push the [‘going dark’] discussion into some new territory.”</p>
<p>The debate could use that push. For more than two decades, the U.S. law enforcement community has cautioned policymakers and the American public that it is in danger of <a href=""https://www.fbi.gov/about-us/otd/going-dark-issue"">“going dark”</a> if criminals and terrorists can take advantage of strong, commercially-available encryption technologies. Those warnings have <a href=""http://www.dailydot.com/politics/comey-say-apple-encryption-bad-bad/"">intensified</a> since the fall of 2014, when Apple announced that it would start encrypting its popular iPhones by default. But law enforcement’s proposed solution – weaker crypto for everyone, criminal or innocent – has never really changed.</p>
<p>The new Berkman report questions law enforcement’s forecast that it faces an ever-decreasing availability of data needed for criminal and national security investigations. According to “Don’t Panic,” rumors of crime-fighting’s imminent death due to crypto have been greatly exaggerated. While encryption may “dim” some communications from police view, said Berkman Center fellow and report signatory Bruce Schneier, there are “other areas where communications and information are actually becoming more illuminated, opening up more vectors for surveillance.”</p>
<p>In particular, the report predicts that the “<a href=""https://cyberlaw.stanford.edu/multimedia/internet-things-global-implications-merging-physical-and-digital-worlds"">Internet of Things</a>” – sensors and wireless connectivity in a range of appliances and products, “from televisions and toasters to bed sheets, light bulbs, cameras, toothbrushes, door locks, cars, watches and other wearables” – will increasingly be able to reveal otherwise private conduct to law enforcement. Indeed, Schneier has been saying for years that we live in “<a href=""https://www.schneier.com/blog/archives/2012/01/going_dark_vs_a.html"">the golden age of surveillance</a>.”</p>
<p>With numerous other tools and sources of information at its disposal, the Berkman report concludes, law enforcement has ample means of tracking suspects even as the use of encryption becomes more and more widespread. There is no need, in other words, for <a href=""http://www.csmonitor.com/World/Passcode/2015/1113/Opinion-Miscalculating-the-risk-of-crypto-backdoors"">backdoors</a> or <a href=""http://thehill.com/policy/cybersecurity/262658-feinstein-vows-to-offer-encryption-piercing-bill"">crypto-""piercing"" legislation</a>. As Professor Susan Landau of Worcester Polytechnic Institute declared in an individual signatory statement appending the report: “policy facilitating the ubiquitous use of uncompromised strong encryption is in our national security interest.”</p>
<p>For these reasons, some groups opposing the government’s push for crypto backdoors have lauded the report, even though it’s actually quite sobering from a civil liberties perspective. The proliferation of surveillance-friendly personal data may be good news for police investigations – but it’s worrisome for personal security, <a href=""http://www.theguardian.com/technology/2015/apr/07/how-can-privacy-survive-the-internet-of-things"">privacy</a>, <a href=""http://www.un.org/apps/news/story.asp?NewsID=45075"">freedom of expression</a>, and <a href=""https://cyberlaw.stanford.edu/press/experts-consumer-protections-vital-internet-things-expand"">consumer protection</a>, as <a href=""https://www.lawfareblog.com/security-or-surveillance"">Schneier</a> and <a href=""https://www.lawfareblog.com/good-news-and-troubling-news-were-not-going-dark"">Prof. Zittrain</a> commented in guest posts on <a href=""https://www.lawfareblog.com/"">Lawfare</a> earlier this week. The report acknowledges these tensions, calling it “vital” in light of the developing Internet of Things to “make thoughtful decisions about how pervasively open to surveillance we think our built environments should be.”</p>
<p>We hope that policymakers, consumers, and the companies that develop these products will heed that call. CIS congratulates our friends at Berkman on the release of this timely, balanced, and much-needed report.</p>
","Architecture and Public Policy, Privacy",2016-02-03 13:21,1371,Riana Pfefferkorn,News
13820,,International,1,1,2015 in RETROSPECT: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>The Internet & Jurisdiction Project released the <span style=""font-size: 13.008px; line-height: 20.0063px;"">fourth annual </span><span style=""font-size: 13.008px; line-height: 1.538em;"">RETROSPECT edition. The 2015 in RETROSPECT is available <a href=""http://www.internetjurisdiction.net/release-2015-retrospect/"">here</a>.</span></p>
<div>KEEPING TRACK OF GLOBAL TRENDS</div>
<div> </div>
<div>The Internet & Jurisdiction Project releases Volume 4 of its annual Retrospect report. ""2015 in Retrospect"" features a review of crucial dynamics to identify emerging norms, stimulate policy discussions and catalyze the development of cooperation mechanism to preserve the global character of the Internet.</div>
<div> </div>
<div>Retrospect is a flagship publication of the Internet & Jurisdiction Project. It provides since 2012 a unique source to study and understand emerging trends and high-level patterns regarding the tension between the cross-border nature of the Internet and the patchwork of geographically defined national jurisdictions. The I&J Retrospect was founded to enable evidence-based multi-stakeholder cooperation and inform participants engaged in the Internet & Jurisdiction process about relevant developments. Between January and December 2015, the Internet & Jurisdiction Project detected, curated and categorized over 350 high-level cases around the world in a dedicated database.</div>
<div> </div>
<div>THE I&J OBSERVATORY</div>
<div> </div>
<div>The Internet & Jurisdiction Observatory, composed of leading academic experts, supports the Internet & Jurisdiction Project in keeping track of the latest trends around the globe. This interdisciplinary network crowd-ranks every month all collected cases in the Internet & Jurisdiction database via a progressive filtering process. The 20 most important cases are showcased the monthly Internet & Jurisdiction Project newsletter Retrospect with concise summaries and links to relevant background information. The case collection ”2015 in Retrospect“ is a compilation of the 240 most important cases of 2015.</div>
<div> </div>
<div>ABOUT THE INTERNET & JURISDICTION PROCESS</div>
<div> </div>
<div>The Internet & Jurisdiction Project facilitates since 2012 a pioneering global multi-stakeholder process. It addresses the challenge of how to handle the digital coexistence of diverse national laws in shared cross-border online spaces and prevent a fragmentation of cyberspace. The Internet & Jurisdiction Project enables multi-stakeholder cooperation in order to develop new mechanisms that are as transnational as the Internet itself and guarantee due process across borders.</div>
<div> </div>
<div>The process has a high visibility in various global Internet Governance fora and actively engages over 100 key entities including states, Internet companies, technical Internet operators, civil society organizations, international organizations and leading universities around the world.</div>
",Intermediary Liability,2016-02-03 13:57,505,Giancarlo Frosio,News
13844,,International,1,1,January 2016 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>January 2016 in Retrospect is available here:</p>
<p><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2016-january/"">http://www.internetjurisdiction.net/observatory/retrospect/2016-january/</a></p>
<p>Retrospect is the monthly newsletter of the <a href=""http://www.internetjurisdiction.net/"">Internet & Jurisdiction Project</a> - a global multi-stakeholder dialogue process that explores the tension between the cross-border nature of the Internet and national jurisdictions. Every month, the members of the Internet & Jurisdiction Observatory expert network identify the 20 most relevant cases through a progressive filtering process to inform the participants of the Internet & Jurisdiction Project on emerging trends around the world.</p>
",Intermediary Liability,2016-02-05 5:09,505,Giancarlo Frosio,News
13867,,United States,0,0,A New Case (of Chilling Effects?) Against DMCA Counter-Notice Senders,Copyright,"<p>E. TV Networks has filed copyright infringement <a href=""http://digitalcommons.law.scu.edu/cgi/viewcontent.cgi?article=2154&context=historical"">claims</a> in federal district court against Google and sixteen YouTube users. The targeted users sent DMCA counter-notices to YouTube following E. TV’s requested takedowns of videos containing copyrighted material from performances by rapper Chief Keef. The users named in the case come from countries around the world, including the UK, Poland, and Mexico, in addition to the United States. The suit claims an astonishing $20M in monetary damages arising from just 39 uploads. Thirteen of the defendants are accused of uploading only a single infringing video; the remaining three are accused of uploading two, nine, and fifteen. The complaint asks for only injunctive relief against Google, which is safe harbored from claims for monetary damages through its compliance with the DMCA’s notice and takedown framework. The monetary damages are therefore all claimed against the named users.</p>
<p>This case was filed as Congress contemplates revisions to the safe harbors in Section 512, and as players on both sides of the copyright wars complain about chronic abuse in the notice and counter-notice system. The DMCA’s notice and takedown framework has long and fairly been faulted for stacking the deck in favor of takedown and against the filing of counter-notices. The imbalance comes in part from the fact that filing counter-notices exposes users like the ones now targeted by E. TV to litigation by deep-pocketed copyright owners seeking staggering statutory damages that bear no credible relationship to sustained losses. Just two weeks ago, the Department of Commerce’s <a href=""http://www.uspto.gov/learning-and-resources/ip-policy/copyright/white-paper-remixes-first-sale-and-statutory-damages"">Internet Policy Task Force</a> recommended changes to the Copyright Act’s statutory damages provisions to rein in excessive claims against individual users. Other efforts to correct the structural imbalance in the safe harbor framework are coming from the private sector and the courts. Last November, YouTube <a href=""http://googlepublicpolicy.blogspot.com/2015/11/a-step-toward-protecting-fair-use-on.html"">announced</a> that it would begin funding legal representation for an unspecified subset of its users to combat abusive DMCA takedown practices by copyright owners. While copyright owners have long maintained that <em>any</em> unauthorized use of their material, no matter how minimal or potentially fair, justifies removal under the DMCA, the Ninth Circuit recently rejected that position. In <a href=""http://cdn.ca9.uscourts.gov/datastore/opinions/2015/09/14/13-16106.pdf""><em>Lenz</em> <em>v. Universal</em></a>, the court held in September that copyright owners sending takedown notices must first consider whether the material they want removed has been fairly used.  </p>
<p>It’s not possible to assess the merits of E. TV’s copyright claims against the users in this case, because the videos in suit appear to be no longer available for viewing. The merits are really beside the point, however, for two reasons: (1) the defendants, even if they have legitimate fair use claims, will probably quickly conclude that the cost and the risk of litigating are way too high; and (2) the plaintiff’s broader goal of making users think twice and hard about filing counter-notices was achieved with the filing, at least to the extent that the case gets publicity among YouTube users. This is litigation for the sake of example, like the RIAA’s suits against P2P file sharers in the early 2000s. It's just unfortunately unknowable without more information what the users here are an example <em>of</em>. All we know is that they filed counter-notices. And then got sued. For crazy amounts of money.     </p>
","Copyright and Fair Use, Intermediary Liability",2016-02-09 13:26,1046,Annemarie Bridy,News
13889,,United States,0,0,Apple ordered to help FBI bypass iPhone security,Dangerous Speech/Violent Extremism,"<p>As I've said many times over the years, on matters of <a href=""https://en.wikipedia.org/wiki/Crypto_Wars"">technology policy</a> and <a href=""http://cyberlaw.stanford.edu/blog/2015/02/information-sharing-cyber-rescue-again"">Internet security</a>, sometimes I wonder if the US government ever left the 1990s. </p>
<p>Last evening a federal magistrate directed Apple to work with the FBI in facilitating their access to the seized iPhone of one of the San Bernadino attackers. But not content to remain in the 1990s, the judge invoked the <a href=""https://en.wikipedia.org/wiki/All_Writs_Act"">All Writs Act </a>-- first enacted in 1789, its amended version has become the seemingly de facto legal basis for US federal law enforcement to try and compel its way into, through, or around technology security controls.</p>
<p>The text of the court order is <a href=""https://assets.documentcloud.org/documents/2714001/SB-Shooter-Order-Compelling-Apple-Asst-iPhone.pdf"">here.</a>  Although it does not direct Apple to break the encryption per se, it asks the company to disable features that make it more difficult to brute force the device security capabilities --  such as the function that disables (er, self-destricts) the device after multiple attempts to enter a PIN number. </p>
<p>While that sounds innocuous enough, it is likely such access cannot be granted on a device-by-device basis upon demand by law enforcement, although some technologists believe it <a href=""http://blog.trailofbits.com/2016/02/17/apple-can-comply-with-the-fbi-court-order/"">possible</a>.  Rather, unless Apple demonstrates the technical, economical, or temporal infeasability of complying with the judge's order or gets the order lifted, the consequence may well be an update/patch to IOS that would implement that proverbial ""backdoor"" feature that certain law enforcement officials -- specifically, FBI Director James Comey -- allege is needed to protect the country, citizens, and (think of the) children from <a href=""http://cyberlaw.stanford.edu/blog/2015/11/blaming-cryptography-and-snowden-again"">Any Number of Evil-Sounding Things That May or May Not Be True</a>(tm).  By contrast, NSA Director Admiral Mike Rogers has already stated <a href=""https://theintercept.com/2016/01/21/nsa-chief-stakes-out-pro-encryption-position-in-contrast-to-fbi/"">publicly</a> there is no need for such backdoors or law enforcement access, and that strong Internet security features are more of a benefit than risk to society -- despite that perennial and selectively sensational <a href=""http://cyberlaw.stanford.edu/blog/2016/02/new-berkman-center-report-assures-us-law-enforcement-isnt-going-dark"">hand-wringing</a> by prominent law enforcement and/or intelligence officials. Meaning, we can't discount the notion that Comey's quest for such access is little more than a turf battle between the FBI and NSA over computing capabilities, something that surveillance maximalists in Congress are only too happy to <a href=""https://www.techdirt.com/articles/20151209/11244833035/james-comey-dianne-feinstein-team-up-to-mislead-about-encryption-promise-legislation-to-undermine-national-security.shtml"">support</a>.  Thankfully, some members of Congress -- namely Stanford CS graduate Ted Lieu -- already are speaking out and <a href=""http://www.dailydot.com/politics/apple-iphone-encryption-ted-lieu-fbi-court-order/"">sounding the warning</a> about the very slippery slope these actions may create over time.</p>
<p>Wired's Kim Zetter <a href=""http://www.wired.com/2016/02/magistrate-orders-apple-to-help-fbi-hack-phone-of-san-bernardino-shooter"">notes</a> that this request suggests the FBI is confident in its ability to brute-force passwords and PIN numbers. Perhaps that's true --- although I can't help wonder if the FBI would otherwise be forced to delegate such duties to more computer-savvy organizations such as the NSA, potentially under a secret cybersecurity cooperation agreement relying on the controversial practice of <a href=""http://www.reuters.com/article/us-dea-sod-idUSBRE97409R20130805"">parallel construction</a>.  Or maybe the FBI simply wants the ability to do this stuff on their own without any external assistance but with some legal precedent to help that process along?  (Conspiracy theories abound....)</p>
<p>Apple CEO Tim Cook has already <a href=""http://www.apple.com/customer-letter/"">responded</a> to the issue in an open letter to customers, vowing to fight the order, reiterating the company's defense of strong product security and condemning the government's renewed attempts to weaken encryption and/or mandate backdoors to customer data.</p>
","Architecture and Public Policy, Privacy",2016-02-17 6:59,416,Richard Forno,News
13941,,International,1,1,February 2016 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>February 2016 in Retrospect is available here:</p>
<p><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2016-february/"">http://www.internetjurisdiction.net/observatory/retrospect/2016-february/</a></p>
<div>Retrospect is a flagship publication of the <a href=""http://www.internetjurisdiction.net/"">Internet & Jurisdiction Project</a>. It provides since 2012 a unique source to study an understand emerging trends and high-level patterns regarding the tension between the cross-border nature of the Internet and the patchwork of geographically defined national jurisdictions.</div>
<div> </div>
<div>All cases are crowd-ranked by leading international experts of the I&J Observatory. The Internet & Jurisdiction Project facilities a global policy process. It enables multi-stakeholder cooperation in order to develop new mechanisms that are as transnational as the Internet itself and guarantee due process across borders.</div>
","Architecture and Public Policy, Intermediary Liability, Privacy",2016-02-29 10:38,505,Giancarlo Frosio,News
13943,,United States,0,0,FBI v. Apple -- Can doesn't mean should obey.,Dangerous Speech/Violent Extremism,"<p>The FBI investigates a grizzly murder. You are a bank president. The murderer stored his phone book in your bank's safety deposit box, the code for which is encrypted with copyrighted proprietary software, before he committed the murder. The FBI demands that you provide it with the master code for the box, which can be used to unlock other boxes, too. You can give the FBI the code, but should you? Apple CEO Tim Cook is asking himself the same question, his answer is rightly ""no.""</p>
<p><img style=""float: left;"" /><span style=""line-height: 1.3em;"">On February 14, 2016, United States Magistrate Judge Sheri Pym ordered Apple to provide the FBI the means to circumvent the iPhone 5c's encryption technology. That way, the FBI can obtain Mr. Syed Rizwan Farook's phone contacts to see who else, if anyone, conspired with him on the December 2, 2015 killings. So the FBI's endgame is understandable, justified, and a matter of public safety. At the same time, Judge Pym's February order is constitutionally questionable, for these reasons.</span></p>
<p>First, there are less invasive and more reasonable means of obtaining the evidence. While the February order is ostensibly based on the ""All Writs Act,"" it was issued to give effect to a warrant directing Apple to give the FBI ""reasonable technical assistance."" If the February order permits the FBI to unreasonably search and seize Apple's property, it is constitutionally defective under the Fourth Amendment. Whether the ordered search is unreasonable depends on if there are other less invasive means of gathering the evidence.</p>
<p>Here, there are at least three other less invasive methods. First - the FBI could back its way into Mr. Farook's contact list by getting from Verizon, his cell phone carrier, phone calls, texts, or e-mails to or from his phone. Second -- Apple can provide the FBI the desired information from the Mr. Farook's iPhone. This would be akin to you, as the bank president, copying the murderer's phone book and providing copies to the FBI. Third - have the court review Mr. Farook's phone information <em>in camera</em>, that is behind closed doors, and cross-reference that information with the phone records around the time of the killings to determine relevance. Once that is done, some or all of the phone's information can be produced to the FBI.       </p>
<p>Second, there is a strong presumption in federal copyright law against allowing circumvention of encrypted copyrighted software. The Digital Millennium Copyright Act (""DMCA"") forbids devices from being made, imported, or marketed to the public which are primarily designed to circumvent technology that controls access to copyrighted content, such as Apple's software. Because Apple manufactures the phone, and owns the copyrights to the software located within, Apple is free to circumvent it's own technology under the DMCA. But Apple shouldn't be forced to so by the FBI. That's because the DMCA shows how important copyright encryption is to content creators like Apple, to Congress, and the consuming public. As a result, Apple's interest in protecting the integrity of its iPhone 5c -- and potentially other generations of iPhone - isn't mere ""marketing strategy,"" as stated by the FBI.</p>
<p>Third, there is no telling how far the government will go if the February order stands without being overturned. According to Apple, the FBI has sought to access to 11 other iPhones since September, and states attorney generals are biting at the bit to do the same. Given this rising tide, the elephant in the room is a lack of trust in what the government will do with the new path it is foraging. While some 51% of Americans apparently side with the FBI on the unlocking of Mr. Farook's iPhone 5c, American trust in the federal government in general is at an historical low of 19%, according to NPR.</p>
<p>Seen more broadly, the magistrate judge's February order can be the first rock in an Orwellian rockslide where the government requires all phone makers to make such backdoors to the encrypted software as a matter of policy. The unstated and yet real concern with such a domino effect is that executive agencies will not only use this information for criminal investigation purposes, but to violate the Constitutional and privacy rights of Americans. These concerns aren't academic. Nor are they paranoid. President Richard Nixon used the Internal Revenue Service go after American citizens he deemed to be his enemies, which led to his articles of impeachment. There is no telling what another Nixon would do with such unfettered power. Thus, Mr. Cook's concern about the magistrate's order setting ""dangerous precedent"" should not be taken lightly.</p>
<p>In the end, it is a shame that Apple and the FBI didn't partner up outside of court to craft a mutually beneficial solution that would maintain the integrity of Apple's iPhone 5c and also give FBI the evidence it needs. But amicable solutions like this won't happen as long as executive agencies like the FBI downplay legitimate concerns of corporate citizens like Apple as ""marketing strategy,"" and then pursue heavy-handed discovery tactics not because they should and need to - but because they can. It is up the judiciary to stop them by ensuring that the government's right to know is balanced against citizens' legitimate intellectual property and Constitutional rights. In the meantime, just because Apple can obey the likely unconstitutional February order doesn't mean it should. Instead, Apple should get a higher court to overturn and limit it.</p>
","Copyright and Fair Use, Privacy",2016-02-29 14:39,1047,Ryan E. Long,News
13961,,Spain,0,0,Trademarks as Keywords: Spanish Supreme Court finds no infringement,Other IP,"<p>The Spanish Supreme Court (TS) has recently ruled on the legality of using someone else’s trademark as a keyword to trigger sponsored ads in Google Adwords. The case is Maherlo v Charlet (<a data-mce-="""" href=""http://www.poderjudicial.es/search/doAction?action=contentpdf&databasematch=TS&reference=7612467&links=charlet%20Y%20marca&optimize=20160303&publicinterface=true"" target=""_blank"">pdf, in Spanish</a>).</p>
<p>The claimant, Maherlo Ibérica S.L., <a data-mce-="""" href=""https://www.masaltos.com/en/"" target=""_blank"">commercializes elevator shoes</a> for men—shoes with raised insoles that make people look taller. It owns two EU Community Trademarks which bear the words “Masaltos” and “Masaltos.com.” The defendant, Charlet S.A.M., is also in the business of selling elevator shoes, under a different trademark—<a data-mce-="""" href=""https://www.bertulli.com/index.php?len=2"" target=""_blank"">Bertulli</a>. The defendant selected the trademarked words “Masaltos” and “Masaltos.com.” to trigger ads in Google Adwords. The text of the ads, however, did not include those words. The commercial link in the ads pointed to the <a data-mce-="""" href=""https://www.bertulli.com/index.php?len=2"" target=""_blank"">defendant’s website</a>, where the plaintiff’s trademarks where not used, either.</p>
<p>Both the first instance court and the court of appeals (<a data-mce-="""" href=""http://www.poderjudicial.es/search/doAction?action=contentpdf&databasematch=AN&reference=7104629&links=03014370082013100467&optimize=20140624&publicinterface=true"" target=""_blank"">pdf, in Spanish</a>) found that such a use was not a trademark infringement. In its ruling, the Supreme Court affirms.</p>
<p>Just like the court of appeals, the Supreme Court follows the case law from the EU Court of Justice (CJEU), particularly the well known cases <em><a data-mce-="""" href=""http://curia.europa.eu/juris/document/document.jsf?text=&docid=83961&pageIndex=0&doclang=en&mode=lst&dir=&occ=first&part=1&cid=124843"" target=""_blank"">Google France</a></em> (2010) and <em><a data-mce-="""" href=""http://curia.europa.eu/juris/document/document.jsf?text=&docid=109942&pageIndex=0&doclang=EN&mode=lst&dir=&occ=first&part=1&cid=124996"" target=""_blank"">Interflora</a></em> (2011). In <em>Interflora</em> the CJEU held that</p>
<blockquote><p>the proprietor of a trade mark is entitled to prevent a competitor from advertising – on the basis of a keyword which is identical with the trade mark and which has been selected in an internet referencing service by the competitor without the proprietor’s consent – goods or services identical with those for which that mark is registered, where that use is liable to have an adverse effect on one of the functions of the trade mark. Such use:</p>
<p>–      adversely affects the trade mark’s function of indicating origin where the advertising displayed on the basis of that keyword does not enable reasonably well-informed and reasonably observant internet users, or enables them only with difficulty, to ascertain whether the goods or services concerned by the advertisement originate from the proprietor of the trade mark or an undertaking economically linked to that proprietor or, on the contrary, originate from a third party;</p>
<p>–      does not adversely affect, in the context of an internet referencing service having the characteristics of the service at issue in the main proceedings, the trade mark’s advertising function; and</p>
<p>–      adversely affects the trade mark’s investment function if it substantially interferes with the proprietor’s use of its trade mark to acquire or preserve a reputation capable of attracting consumers and retaining their loyalty.</p>
</blockquote>
<p>The assessment of the facts corresponds to national courts. Therefore, the CJEU case law does not prevent the finding by a national court that, in a particular case, the challenged use of the trademark adversely affects a trademark function. In fact, the Inteflora case was <a data-mce-="""" href=""http://www.bailii.org/ew/cases/EWHC/Ch/2013/1291.html"" target=""_blank"">finally decided in favor of the plaintiff by the national UK judge</a>, finding that there was a <a data-mce-="""" href=""http://ipkitten.blogspot.com.es/2013/05/say-it-with-flowers-interflora-wins.html"" target=""_blank"">likelihood of confusion</a>.</p>
<p>In Maherlo v Charlet, the Spanish Supreme Court upholds the lower court’s ruling that the use at issue use was not liable to have an adverse effect on any of the functions of the trademark. In particular, the TS upholds the conclusion that there was no risk of confusion or association (and thus no adverse effect to the origin function) because the text of the ad did not include the claimant’s trademarks. The plaintiff had argued that 63 internet users, out of 5,051 who googled the trademarked words, eventually purchased goods from the defendant. According to the claimant, this would indicate that they were misled into thinking that they were buying the goods from the plaintiff. The court of appeals rejected that contention, and noted that the absence of the trademark in the text of the ads clearly showed to the users that the advertiser was in fact a competitor, and thus the origin function was not jeopardized.</p>
<p>While there have been <a data-mce-="""" href=""http://kluwertrademarkblog.com/2016/01/12/a-look-at-keyword-advertising-decisions-in-spain/"" target=""_blank"">a number of rulings</a> dealing with the use of trademarks as keywords by first instance courts and courts of appeals in Spain, this is the first time the Supreme Court tackles the issue. It must be noted that the same plaintiff has also sued other merchants on these issues, and lower courts have sometimes <a data-mce-="""" href=""https://ispliability.wordpress.com/2012/05/06/keywords-ads/"" target=""_blank"">granted its claims</a>, though on somewhat different factual situations.</p>
",Intermediary Liability,2016-03-07 1:11,678,Miquel Peguera,News
14080,,Germany,0,0,German Supreme Court Upholds Blocking Orders,General,"<div> </div>
<div>The Federal Court of Justice (Bundesgerichtshof), the highest court in the system of ordinary jurisdiction in Germany, <a href=""http://juris.bundesgerichtshof.de/cgi-bin/rechtsprechung/document.py?Gericht=bgh&Art=en&client=12&nr=73488&pos=0&anz=1&Blank=1.pdf"">decided on actions against internet service providers</a> over access to websites linking to copyright infringing material and ended a longstanding phase of uncertainty over the applicability of website blocking orders in Germany. Due to intense public protest a few years ago, the federal government discarded its plan to establish the so-called <em>Netzsperren </em>and brushed administration-ordered blocking orders off the table. In this decision, the German Supreme Court confirmed that the judiciary is competent to issue website blocking orders.</div>
<div> </div>
<div>The collecting rights society GEMA sought to enjoin Deutsche Telekom from providing access to the website ""3dl.am,"" hosting links to files in file repositories such as Netload, Uploaded or Rapidshare, which contain material for which GEMA members own the copyright.</div>
<div> </div>
<div>The court approved blocking orders enjoining telecoms from providing access to sites hosting or linking to copyright infringing material if they knowingly provided the means to allow the infringement, provided they failed to take reasonable care. Additionally, blocking injunctions were not only permissible when the blocked domain contained exclusively infringing material, but also when the legal material was insubstantial compared to the illegal material.</div>
<div> </div>
<div>The Federal Court of Justice extended the scope of the <em>Stoererhaftung </em>doctrine—literally the ""liability of the disquieter,"" a form of indirect liability which only allows injunction claims, not damages claims—onto access providers. The Court made clear that access providers can be liable as <em>stoerer</em>—because they do contribute to the copyright infringement—but only if certain duties of care are reasonable. As the Court pointed out, the legal basis for the duties of care can be found in Article 8(3) of the InfoSoc Directive as applied by the ECJ in UPC Telekabel.</div>
<div> </div>
<div>The Court balanced the access providers' freedom of speech and the copyright holder’s constitutionally protected property right. It drew the conclusion that duties of care can be reasonable within narrow boundaries. First, the access provider must have received a notification from the rightholder about suspected violations. Second, a blocking injunction against an access provider required that the rightholders had first taken steps against the primary infringer, such as the website operator or host provider, and failed to stop the infringement, or it was clear from the outset that there was no likelihood of success at all to prevent the primary infringement.  The rightholders had to take reasonable steps—for example by hiring a private investigator or involving criminal prosecution authorities—to determine the identity and location of the primary infringer.</div>
<div> </div>
<div>In the case against ""3dl.am"", GEMA obtained an <em>ex parte</em> injunction against the operator of the website which could not be served at the address listed with the domain name registrar. GEMA then sued the host provider, but withdrew the complaint after it became clear that the host provider's address was false, too. According to the Court, GEMA should have made further enquiries and could not go after the access provider merely because the listed addresses of the primary infringers were false. For all these reasons, in the given case, the access provider prevailed. However, once the copyrightholders will be able to fulfill the judicial requirements to take action against the primary infringer first, they will eventually be entitled to obtain court-ordered website blocking injunctions against access providers.</div>
<div> </div>
",Intermediary Liability,2016-03-24 16:54,505,Giancarlo Frosio,News
14090,,Germany,0,0,"Review Portals Have to Verify Anonymous User Reviews, Says the German Supreme Court",General,"<div>In a recent decision, the Federal Court of Justice (<em>Bundesgerichtshof</em>), the highest court in the system of ordinary jurisdiction in Germany, established a case of intermediary liability for anonymous reviews published in review portals, which are under the obligation to verify the accuracy of the review upon request. This case departs from previous case law, which has usually seen review portals prevailing in court.</div>
<div> </div>
<div>Review portals have been recently highly involved with the development of intermediary liability law in Germany. The numerous cases dealing with online rating services are due to the fact that—in application of the so called <a href=""https://cyberlaw.stanford.edu/blog/2016/03/german-supreme-court-upholds-blocking-orders""><em>Stoererhaftung </em></a>doctrine—the courts have to balance the provider’s freedom of speech and the affected person’s personal rights on a cases-by-case basis. <a href=""https://cyberlaw.stanford.edu/blog/2015/12/german-supreme-court-booking-portals-not-liable-bogus-user-reviews"">In the past</a>, review portals have been victorious in court. The <em>Bundesgerichtshof </em>has ruled that the online-evaluation of professionals, such as <a href=""http://juris.bundesgerichtshof.de/cgi-bin/rechtsprechung/document.py?Gericht=bgh&Art=en&Datum=Aktuell&nr=48373&linked=pm"">teachers</a> <a href=""http://juris.bundesgerichtshof.de/cgi-bin/rechtsprechung/document.py?Gericht=bgh&Art=en&sid=18e188ccd712bed4e8781314de1c4c63&anz=1&pos=0&nr=68915&linked=pm&Blank=1"">doctors</a>, or <a href=""http://juris.bundesgerichtshof.de/cgi-bin/rechtsprechung/document.py?Gericht=bgh&Art=en&az=I%20ZR%2094/13&nr=72269"">hoteliers</a>, is permissible. Furthermore, the portals do not have to check every review before publication because such unreasonable duty would challenge the entire business model of the platform operator. The legal situation after the person affected has notified the provider is, nevertheless, unclear. It is undisputed that the portal has to <a href=""http://cyberlaw.stanford.edu/blog/2015/12/german-supreme-court-booking-portals-not-liable-bogus-user-reviews"">take down bogus reviews</a>.  However, according to the <a href=""http://juris.bundesgerichtshof.de/cgi-bin/rechtsprechung/document.py?Gericht=bgh&Art=en&Datum=Aktuell&nr=68159&linked=pm""><em>Sanego </em></a>decision and the provider privilege of § 12 TMG, the provider is not obliged to disclose the reviewer’s personal information.</div>
<div> </div>
<div>In the given case, an anonymous internet user evaluated the plaintiff, a dentist, with the equivalent of a D minus on <a href=""http://www.jameda.de/"">Jameda.de</a>—a specialized physician rating portal. The court made clear that the provider is only liable if it breaches the duties of care of the <em>Stoererhaftung </em>doctrine. However, the Court noted that the ""operation of a review portal carries an increased risk of defamation compared to other portals"" and ""this risk is enhanced by the ability to add reviews on an anonymous or pseudonymous basis."" Therefore, a provider is obligated to verify the review if the anonymity of its portal makes it difficult for the person affected to directly address the reviewer. According to the Court, the portal should have requested the reviewed her treatment documentation, including medical records, prescriptions and other evidence. Moreover, the provider has to pass on that part of information which is not privileged under § 12 TMG to the person affected by the review.</div>
<div> </div>
<div>The <em>Jameda </em>decision is available <a href=""http://juris.bundesgerichtshof.de/cgi-bin/rechtsprechung/document.py?Gericht=bgh&Art=pm&Datum=2016&Sort=3&nr=73851&pos=0&anz=49"">here </a>(in German only).</div>
",Intermediary Liability,2016-03-24 21:37,505,Giancarlo Frosio,News
14100,Council of Europe,,0,0,New Intermediary Liability Cases from the European Court of Human Rights: What Will They Mean in the Real World?,Hate Speech+Freedom of Expression+Defamation or Personality Rights,"<p>Last summer, the Grand Chamber of the European Court of Human Rights (ECHR) delivered a serious setback to free expression on the Internet. The Court held, in <a href=""http://www.bailii.org/eu/cases/ECHR/2015/586.html""><em>Delfi v. Estonia</em></a><em>, </em>that a government could compel a news site to monitor its users’ online comments about articles.* This winter, the Court’s lower chamber ruled the other way in <a href=""http://www.bailii.org/eu/cases/ECHR/2016/135.html""><em>MTE v. Hungary</em></a> – holding that a very similar order violated the guarantee of free expression under the European Convention on Human Rights (the Convention). Did anything really change?</p>
<p>In a series of four posts this week, I will take a practical look at the cases and their real-world impact.  The posts will cover</p>
<p style=""margin-left:.5in;"">(1) What the cases say (that’s this post)</p>
<p style=""margin-left:.5in;"">(2) <a href=""https://cyberlaw.stanford.edu/blog/2016/04/policing-online-comments-europe-new-human-rights-case-law-real-world"">How the cases may affect intermediaries’ notice and takedown operations</a>,</p>
<p style=""margin-left:.5in;"">(3) <a href=""https://cyberlaw.stanford.edu/blog/2016/04/litigating-platform-liability-europe-new-human-rights-case-law-real-world"">How the cases may affect litigation in the EU</a>, and</p>
<p style=""margin-left:.5in;"">(4) <a href=""https://cyberlaw.stanford.edu/blog/2016/04/policy-debates-over-eu-platform-liability-laws-new-human-rights-case-law-real-world"">How the cases may affect policy debates about platform liability under the EU’s Digital Single Market initiative.</a></p>
<p>First, let’s look at the rough upshot of the two rulings: News portals can be compelled to monitor user comments for hate speech and direct threats, but not for less harmful tortious speech.</p>
<p>The first case, <em>Delfi v. Estonia</em>, involved threats and anti-Semitic slurs in the user comments section of Delfi, an Estonian online newspaper. Estonian courts held, and the ECHR in 2015 affirmed, that the platform could be liable for those comments – even though it knew nothing about them and had a solid record of removing unlawful comments as soon as it found out about them. The key question to the ECHR was whether this outcome violated fundamental rights under the Convention – the equivalent of a constitutional challenge to a ruling in the US.</p>
<p>The news site argued that strict liability for user comments, and the de facto monitoring obligation it created, violated the fundamental rights to seek and impart information under Article 10 of the Convention. The Court found no such violation. It rejected arguments that requiring news sites to continuously police and delete users’ comments would lead them to over-police or simply shut down user forums, with resulting harm to fundamental rights.</p>
<p>As the Court emphasized several times, its conclusion was specific to this particular defendant as a commercial news provider, and the law may be different for other Internet hosts. Notably, given the ECHR’s role as adjudicator of the Convention, it was not called on to interpret applicable EU or national law. That means the ruling does not rest on the EU’s <a href=""http://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32000L0031&from=EN"">eCommerce Directive</a>, which says that protected Internet hosts cannot be compelled to undertake “general” monitoring.</p>
<p>In the newer case, <em>MTE v. Hungary</em>, the Court’s lower chamber goes the other way on nearly identical facts. Defendants included a news portal that, like Delfi, honored removal notices but didn’t actively police all of its users’ comments. Hungarian courts held the portal liable for reputational harm to a business caused by “false and offensive” user statements. The ECHR disagreed. It said that compelling the platform to find and remove every unlawful user comment “<em>amounts to requiring excessive and impracticable forethought capable of undermining freedom of the right to impart information on the Internet</em>[.]” Accordingly, the Hungarian court’s ruling violated Article 10 of the Convention.</p>
<p><em>MTE</em> reached this conclusion after politely working through the rather indeterminate list of factors identified in <em>Delfi</em>: Context of Comments, User Liability, Measures Taken by the Platform, and Consequences of Ruling for the Platform. The real crux of the ruling, though, was that the user comments at issue in <em>MTE</em> were not as bad as the ones in <em>Delfi </em>– they were not hate speech or direct threats. (P. 91) Accordingly, they were not dangerous enough to justify the risks that a monitoring requirement would pose for free expression. The Hungarian court’s error, said the ECHR, was that it</p>
<p style=""margin-left:.5in;"">paid no heed to what was at stake for the applicants as protagonists of the free electronic media. They did not embark on any assessment of how the application of civil-law liability to a news portal operator will affect freedom of expression on the Internet.</p>
<p>Following <em>MTE</em>, a court that ignores these rights in an intermediary liability case may violate the Convention.</p>
<p>The <em>MTE</em> ruling is a huge step forward on a policy level. The Court explicitly recognizes that regulating expression and information <em>platforms</em> means regulating their <em>users’</em> expression and information access. The ruling’s core insight is that “intermediary liability” laws directly affect the rights of ordinary Internet users, and can make or break their ability to speak and find information online.</p>
<p>But the ruling’s value may lie entirely in the policy and litigation arena. It’s not clear what, if anything, it will do to protect users’ online expression as a practical matter.</p>
<p>Tomorrow's post will consider the ECHR cases’ practical impact for intermediaries operating in Europe.</p>
<p>- - - </p>
<p>* <span style=""font-size: 13.008px; line-height: 1.538em;"">I contributed to an </span><a href=""http://cdn.ccianet.org/wp-content/uploads/2014/06/CCIA-EDiMA-EuroISPA-submission-on-Delfi-case_June-2014.pdf"" style=""font-size: 13.008px; line-height: 1.538em;"">intervention</a><span style=""font-size: 13.008px; line-height: 1.538em;""> in the </span><em style=""font-size: 13.008px; line-height: 1.538em;"">Delfi</em><span style=""font-size: 13.008px; line-height: 1.538em;""> case in my previous position as an attorney for Google, and was involved in some of the Google cases discussed in these posts. </span></p>
<p> </p>
",Intermediary Liability,2016-04-11 5:00,1188,Daphne Keller,News
14101,Council of Europe,,0,0,Policing Online Comments in Europe: New Human Rights Case Law in the Real World,Hate Speech+Freedom of Expression,"<p>This is the second of four posts on real-world consequences of the European Court of Human Rights’ (ECHR) rulings in <em><a href=""http://www.bailii.org/eu/cases/ECHR/2015/586.html"">Delfi v. Estonia</a></em> and <a href=""http://www.bailii.org/eu/cases/ECHR/2016/135.html""><em>MTE v. Hungary</em></a>. Both cases arose from national court rulings that effectively required online news portals to monitor users’ speech in comment forums. The first case, <em>Delfi</em>, condoned a monitoring requirement in a case involving threats and hate speech. The second, <em>MTE</em> held that a nearly identical requirement in a trade defamation case violated free expression guarantees in the European Convention on Human Rights (Convention).</p>
<p>The two rulings are explained in more detail in <a href=""https://cyberlaw.stanford.edu/blog/2016/04/new-intermediary-liability-cases-european-court-human-rights-what-will-they-mean-ground"">Post 1</a>. This post considers how – or whether – the two cases will affect daily operations for Internet intermediaries.</p>
<p>The ECHR rulings do not consider every law governing the parties – only the fundamental rights guarantees of the Convention. Real world Internet platforms operate under a more complex set of rules, including national implementations of the <a href=""http://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32000L0031&from=EN"">eCommerce Directive</a> in the EU. For platforms secure in their existing national law protections, the ECHR rulings don’t change anything. Hosts that qualify for immunity under eCommerce Directive Article 14 still cannot be subject to general monitoring obligations, because of limitations in Article 15. All the <em>Delfi</em> and <em>MTE</em> rulings tell us is that countries <em>could</em> make news platforms liable for hate speech and threats in user comments, in circumstances like those in <em>Delfi</em>, without violating the European Convention on Human Rights.</p>
<p>But for a platform uncertain how it would fare under the eCommerce Directive, or operating in countries outside the EU without comparable black letter law, <em>Delfi </em>is bad news.  And, unfortunately, <em>MTE</em> doesn’t really change that. There is nothing in <em>MTE</em> to alter a hosting platform’s calculus in deciding whether to monitor user expression, and the ECHR’s new ruling won’t cause many platforms to leave controversial content online when they find it.</p>
<p>The first problem, as <a href=""https://inforrm.wordpress.com/2016/02/17/offensive-online-comments-delfi-confirmed-but-tempered-dirk-voorhoof-and-eva-lievens/"">several</a> <a href=""http://blogs.lse.ac.uk/mediapolicyproject/2016/02/19/delfi-revisited-the-mte-index-hu-v-hungary-case/"">commenters</a> have observed, is that monitoring is an all or nothing proposition. It doesn’t matter if only worst-of-the-worst content, like hate speech, can trigger a monitoring duty. Intermediaries by definition don’t know if they have hate speech on their sites, so that duty is always there for platforms in Delfi’s situation.</p>
<p>Second, employees looking for comments that constitute <em>Delfi-</em>level threats and hatred will inevitably come across other user expression that might be <em>MTE-</em>level defamation. The ECHR says intermediaries can’t be required to look for those.  But once employees see them, those comments will presumably be removed, too. That’s what the eCommerce Directive and many tort laws require when an intermediary gains “knowledge” of unlawful content, whether through notice or other means. Because platform employees can’t assess the truth of disputed facts, are hard pressed to make legal judgments that are difficult even for courts, and risk liability by leaving comments up, they have little incentive to stand up for speech that could potentially get them sued. <a href=""http://cyberlaw.stanford.edu/blog/2015/10/empirical-evidence-over-removal-internet-companies-under-intermediary-liability-laws"">Empirical studies</a> tell us that we should expect over-removal of “gray area” content in the face of such uncertainty.</p>
<p>Thus, even for the kinds of controversial speech at issue in the <em>MTE</em> case itself, the ruling does not get intermediaries out of the monitoring business. Under a <em>Delfi/MTE</em> rule, tech platforms would still go looking for hate speech, find other potentially unlawful content, and presumably remove it -- with precisely the “foreseeable negative consequences on the comment environment of an Internet portal” and “chilling effect on the freedom of expression on the Internet” that the Court identified and tried to avoid. (P. 86)</p>
<p>The <em>Delfi</em> ruling adds one other odd element for platforms trying to operationalize these rulings – and for practitioners trying to understand the Court’s logic. <em>Delfi</em> held that the news portal did not have to monitor user content <em>before</em> it appeared on their website, but instead must act “without delay <em>after</em> publication” to remove hate speech. This is a pretty meaningless distinction for anyone running a hosting service – a matter of deleting content the second after it flickers onto the screen, instead of the second before.</p>
<p>The Court thinks this sequencing matters for free expression. It says that “regard to the freedom to impart information as enshrined in Article 10” drives its conclusion that the Estonian ruling requires only post-publication removal, and that the Grand Chamber “[<em>c]onsequently</em>” finds no “disproportionate interference with its freedom of expression.” (My emphasis. You can try parsing this language for yourself in P. 153 of <em>Delfi</em>.) This may be about avoiding a nominal prior restraint. Or it may mean the Court thinks it would be technically difficult for platforms to hold comments for pre-publication review, and it wants to give at least some temporal window for compliance. For most platforms I expect the distinction doesn’t matter much. In either case, it adds a bottleneck of human review for every comment posted by users.</p>
<p align=""center"">* * *</p>
<p>Tomorrow's post will look at how <em>Delfi </em>and <em>MTE</em> may affect current and future litigation in cases involving platform liability.</p>
",Intermediary Liability,2016-04-12 5:00,1188,Daphne Keller,News
14102,,International,1,1,March 2016 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>March 2016 in Retrospect is available here:</p>
<p><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2016-march/"">http://www.internetjurisdiction.net/observatory/retrospect/2016-march/</a></p>
<div>Retrospect is a flagship publication of the <a href=""http://www.internetjurisdiction.net/"">Internet & Jurisdiction Project</a>. It provides since 2012 a unique source to study an understand emerging trends and high-level patterns regarding the tension between the cross-border nature of the Internet and the patchwork of geographically defined national jurisdictions.</div>
<div> </div>
<div>All cases are crowd-ranked by leading international experts of the I&J Observatory. The Internet & Jurisdiction Project facilities a global policy process. It enables multi-stakeholder cooperation in order to develop new mechanisms that are as transnational as the Internet itself and guarantee due process across borders.</div>
",Intermediary Liability,2016-04-06 10:46,505,Giancarlo Frosio,News
14103,Council of Europe,,0,0,Litigating Platform Liability in Europe: New Human Rights Case Law in the Real World,Hate Speech+Freedom of Expression,"<p>This is the third of four posts on the European Court of Human Rights’ (ECHR) rulings in <a href=""http://www.bailii.org/eu/cases/ECHR/2015/586.html""><em>Delfi v. Estonia</em></a> and <a href=""http://www.bailii.org/eu/cases/ECHR/2016/135.html""><em>MTE v. Hungary</em></a>. In both cases, national courts held online news portals liable for comments posted by their users – even though the platforms did not know about them. These rulings effectively required platforms to monitor and delete user comments in order to avoid liability. The first ruling, <em>Delfi</em>, condoned monitoring in a case involving threats and hate speech. The second, <em>MTE</em>, held that a nearly identical outcome in a case involving trade defamation violated free expression guarantees in the European Convention on Human Rights (Convention).</p>
<p>The two rulings are explained in more detail in <a href=""https://cyberlaw.stanford.edu/blog/2016/04/new-intermediary-liability-cases-european-court-human-rights-what-will-they-mean-ground"">Post 1</a>. <a href=""https://cyberlaw.stanford.edu/blog/2016/04/policing-online-comments-europe-new-human-rights-case-law-real-world"">Post 2</a> discusses their operational impact for intermediaries hosting user-generated content in Europe. This post considers how the two cases may affect current and future litigation.</p>
<p>The real world litigation impact of <em>Delfi</em> and <em>MTE</em> will depend in part on individual countries’ laws and attitudes toward the Human Rights Court. As discussed in Post 1, courts will be able to resolve some cases under national law, without reaching questions about Convention rights. When courts do recognize human rights issues, it’s not always clear how much they care what the ECHR says. (It’s even less clear whether other branches of government will care. Turkey, for example, has been hauled to the ECHR and lost twice on nearly identical claims about Internet content blocking.) But there is a paucity of high level case law on point, so defendant platforms and interested civil society groups will likely seize on the <em>MTE</em> ruling in response to monitoring demands by plaintiffs in European courts.</p>
<p><u>Cases about “sub-<em>Delfi</em>-level” expression<a name=""Cases-about-sub-Delfi-level-expression"" id=""Cases-about-sub-Delfi-level-expression""></a></u></p>
<p>The key distinction between <em>MTE</em> and <em>Delfi</em> was the kind of “bad” speech at issue: <em>Delfi</em> approved monitoring for hate speech and threats, <em>MTE</em> disapproved monitoring for defamation. Thus, for defendants in cases about sub-<em>Delfi</em>-level tortious expression, such as defamation, <em>MTE</em> should in principle be very helpful. It provides a structuring outer limit, based on fundamental rights, for courts applying vague or outdated laws to Internet services. Even for the stronger <em>Delfi</em>-level comments, the <em>MTE</em> analysis could – and I believe should -- carry the day and preclude monitoring requirements for platforms other than news portals.</p>
<p>Of course, this raises the question of which claims are more like <em>Delfi</em> – speech so bad, it justifies the free expression harms of monitoring orders – and which are more like <em>MTE</em>. Where does copyright infringement fall, for example? What about data protection violations? Both claims are rooted in rights that the ECHR has traditionally balanced carefully against free expression, so part of the answer may lie in that case law. Another consideration may be the nature of the lawful speech that will likely fall prey to over-zealous removal.  Are the kinds of expression that might be mistaken for defamation somehow different from, or more valuable than, the kinds that might be mistaken for copyright infringement?  To my mind, evaluating hypothetical, future speech and calculating whether to accept a high risk that it will be improperly deleted is a dangerous exercise.  But courts may see this differently.</p>
<p><u>News defendants versus other platform defendants<a name=""News-defendants-versus-other-platform-defendants"" id=""News-defendants-versus-other-platform-defendants""></a></u></p>
<p>There is some room for debate about how the identity of the <em>MTE</em> and <em>Delfi</em> defendants as journalists plays into the analysis. On its face, the law seems much better for non-news source intermediaries. The <em>Delfi</em> court focused on the defendant’s status as a “professional publisher,” its reasoning drew extensively on cases and considerations specific to journalism. (Par. 129-135). It expressly “emphasise[d] that the present case relates to a large professionally managed Internet news portal run on a commercial basis which published news articles of its own and invited its readers to comment on them,” and that it “does not concern other fora on the Internet where third-party comments can be disseminated, for example an Internet discussion forum or a bulletin board[.]” (Par. 115-117)</p>
<p>Since Delfi’s status as a professional publisher increased its responsibilities, more traditional Internet hosts should logically have fewer duties. <em>MTE</em>, however, suggests a possible counterargument – that defendants’ journalistic role actually helped their defense. The court there noted (as did the <em>Delfi</em> court) that “providing [a] platform for third-parties to exercise their freedom of expression by posting comments is a journalistic activity of a particular nature,” suggesting that the defendants benefitted from their role in journalism. This idea may be reinforced by <em>MTE</em>’s reliance on case law protecting journalists who disseminate statements made by sources. (79)</p>
<p><u>Northern Ireland’s Facebook/McCloskey case<a name=""Northern-Irelands-Facebook-McCloskey-case"" id=""Northern-Irelands-Facebook-McCloskey-case""></a></u></p>
<p>One place the <em>MTE </em>ruling could be relevant is in a case <a href=""https://inforrm.wordpress.com/2016/04/02/case-preview-northern-ireland-cg-v-facebook-ireland-facebook-appeals-damages-award-in-keeping-kids-safe-from-predators-case-aidan-wills/"">against Facebook</a>, currently before the Court of Appeal of Northern Ireland.  A lower court there held the platform liable for misuse of private information, based on content posted by a user. It considered a data protection claim, but rejected it on jurisdictional grounds. Facebook had not been notified about the particular posts at issue in the case, though it knew of similar content from the same user.</p>
<p>By holding Facebook responsible for content it didn’t know about, the Northern Irish court effectively imposed a monitoring requirement comparable to those in <em>Delfi</em> and <em>MTE</em>. In theory, the case could be resolved on the same fundamental rights reasoning the ECHR used. There are national and EU law issues to clear up first, though, including Facebook’s argument that the eCommerce Directive precludes such a monitoring requirement.</p>
<p>At least two interesting wrinkles could make the ECHR case law relevant to the case’s outcome, however.  First, the Northern Irish court reasoned that its conclusion was consistent with the eCommerce Directive, because Facebook’s knowledge of similar content in a related case meant it “knew” about these posts as well.  If that analysis were right, it would mean that claimants who tell an intermediary about one piece of tortious content could subsequently impose a monitoring duty, without violating eCommerce Directive Article 15. That in turn raises the question whether this novel legal path toward intermediary policing duties would still be barred by the Convention.  Are the Article 10 concerns of the <em>MTE </em>court somehow lessened if monitoring is prompted by a user complaint instead of background law?  Would the answer be different if, as seems possible in this case, Facebook were expected to monitor only this particular user’s account?</p>
<p>Another major wrinkle in the Facebook case could make <em>MTE </em>and <em>Delfi</em> more directly relevant.  The case includes a data protection claim against the platform based on content posted by a user.  The lower court rejected this claim, but the appellate court might not. If the data protection claim is valid, the next question is whether the eCommerce Directive, including Article 15’s prohibition on general monitoring, applies to that claim. Many practitioners believe that it does not: that data protection-based claims, including “Right to Be Forgotten” removal demands, are carved out of the eCommerce intermediary liability rules. That’s an alarming possibility – that plaintiffs can evade those rules simply by adding a data protection claim to their pleadings, even for cases that would ordinarily be resolved under defamation, traditional privacy tort law, or other areas that clearly fall within the eCommerce framework. If the court accepted this argument and declined to apply the eCommerce Directive, the case could turn on other legal constraints on intermediary liability –in particular, the Article 10 limits that the <em>MTE</em> court said are mandatory under the Convention.</p>
<p><u>Germany’s monitoring cases<a name=""Germanys-monitoring-cases"" id=""Germanys-monitoring-cases""></a></u></p>
<p>Another interesting place to look for post-<em>Delfi</em> litigation fallout will be Germany. Courts there have imposed take down/stay down obligations on a number of Internet intermediaries under the “Stoererhaftung” or “interferer liability” doctrine. In a case involving copyright claims against Rapidshare, the Federal Court of Justice said that such obligations do not conflict with the restriction on general monitoring under Article 15 of the EU’s eCommerce Directive, because Rapidshare only had to monitor for the specific copyrighted works identified by the rightsholder.</p>
<p>Defendants in new German Stoererhaftung cases may invoke <em>MTE</em> to oppose monitoring demands. In copyright or defamation cases, they may argue that the expression at issue is less damaging than the unprotected hate speech in <em>Delfi</em>, and therefore cannot justify the monitoring-based harms to Article 10 rights identified in <em>MTE</em>. Plaintiffs in turn may contend that orders to monitor for precisely specified items of content pose little risk to lawful expression, because a platform is not called on to assess the legality of user speech – only to identify duplicates. I suspect plaintiffs would win that one in Germany. Courts there may also see little connection between their cases and the new ECHR rulings, because they view Stoererhaftung monitoring injunctions as remedies rather than determinations of tort liability.</p>
<p>But the <em>MTE</em> case raises a new and interesting procedural angle for the defense. Stoererhaftung defendants have, so far, been unable to get Court of Justice of the European Union (CJEU) review in the Stoererhaftung cases. That’s because the power to refer cases to the CJEU rests with the national court, not the parties. But the ECHR doesn’t work that way. A party can take a claim based on fundamental rights to the ECHR without court permission, once it has exhausted domestic appeals for its claim. Encouraged by the <em>MTE</em> ruling, platforms may be likelier to try this avenue of review.</p>
<p><u>Standing to assert Internet users’ rights<a name=""Standing-to-assert-Internet-users-rights"" id=""Standing-to-assert-Internet-users-rights""></a></u></p>
<p>A final interesting litigation angle concerns the distinction between the platform’s own Article 10 rights, and those of its users. In intermediary liability litigation, arguments based on users’ rights are typically more compelling and important than those based on the platform’s own rights, including its right to conduct a business. But are platforms allowed to raise them? Do they have standing to assert rights on behalf of users?</p>
<p>Both the <em>Delfi</em> and <em>MTE</em> rulings fudge this distinction at times, mentioning both user and platform rights. But <em>MTE</em>’s analysis seems almost entirely driven by consideration of Internet users’ rights, and defendant platforms clearly emphasized those rights in their pleadings. (P. 36-39, 61, 82, 86, 88.) The defendant in <em>Delfi</em>, by contrast, appears to have raised only the platform’s <em>own</em> “freedom to impart information created and published by third parties.” (P. 61, 73) The Court in Delfi identified the question before it as “whether… holding the applicant company liable for these comments posted by third parties [breached] <em>its</em> freedom to impart information” and stated in its conclusion that strict liability “did not constitute a disproportionate restriction <em>on the applicant company’s right</em> to freedom of expression.” (P. 140, 162, emphasis added).</p>
<p>Setting aside procedural questions about standing, the substantive outcome of <em>MTE</em> means that platform defendants should be able to raise users’ rights in national courts. Otherwise the Article 10 rights identified by the Court would be effectively unprotectable in intermediary liability cases. An interesting twist on the question is whether the ruling affects individual users’ rights to sue for “wrongful removal.” At present, a user whose lawful speech is removed based on a false accusation of illegality would have a hard time getting into court to sue the accuser, unless a government actor instigated the removal. (As for suing the platform, we’ll see what the <a href=""https://www.washingtonpost.com/news/the-intersect/wp/2015/03/09/facebook-censored-a-nude-painting-and-it-could-change-the-site-forever/"">French Courbet case</a> says, but that seems a much harder claim.) But if users never have standing to sue, the Article 10 rights identified in <em>MTE </em>are truly a right without a remedy.</p>
<p><u>Up Next</u></p>
<p>The next and final post will look at how <em>Delfi </em>and <em>MTE</em> could affect policy discussions, in Brussels and elsewhere, regarding potential changes to the law of platform liability.</p>
",Intermediary Liability,2016-04-13 5:00,1188,Daphne Keller,News
14118,European Union,,0,0,Policy Debates over EU Platform Liability Laws: New Human Rights Case Law in the Real World,Hate Speech,"<p>This is the last of <a href=""https://cyberlaw.stanford.edu/blog/2016/04/new-intermediary-liability-cases-european-court-human-rights-what-will-they-mean-real"">four posts</a> on the European Court of Human Rights’ (ECHR) rulings in <a href=""http://www.bailii.org/eu/cases/ECHR/2015/586.html""><em>Delfi v. Estonia</em></a> and <a href=""http://www.bailii.org/eu/cases/ECHR/2016/135.html""><em>MTE v. Hungary</em></a>. In both cases, national courts held online news portals liable for comments posted by their users – even though the platforms did not know about the comments. Those rulings effectively required platforms to monitor and delete users’ online expression in order to avoid liability. The ECHR condoned this outcome in <em>Delfi</em>, which involved threats and hate speech. But in <em>MTE</em>, it held that a nearly identical ruling in a case involving trade defamation violated the European Convention on Human Rights (Convention).  The monitoring order in <em>MTE</em><span> harmed defendants’ ability to provide a “platform for third-parties to exercise their freedom of expression by posting comments” online, the Court said, and was therefore impermissible under Article 10 of the Convention.</span></p>
<p>The <em>MTE</em> and <em>Delfi</em> rulings are relevant for current policy discussions in the European Commission and elsewhere. The idea of requiring intermediaries to monitor user-generated content has come up repeatedly as part of the <a href=""http://ec.europa.eu/priorities/digital-single-market_en"">Digital Single Market</a> initiative, most recently in this winter’s <a href=""https://ec.europa.eu/digital-single-market/en/news/public-consultation-regulatory-environment-platforms-online-intermediaries-data-and-cloud"">“platform liability”</a> consultation. (I <a href=""http://cyberlaw.stanford.edu/publications/us-copyright-office-section-512-study-comments-response-notice-inquiry"">contributed</a> to that consultation from my current position at <a href=""http://cyberlaw.stanford.edu/about/people/daphne-keller"">Stanford CIS</a>, and was involved in the Commission’s previous <a href=""http://ec.europa.eu/internal_market/e-commerce/notice-and-action/index_en.htm"">Notice and Action</a> inquiry as an attorney for Google.)</p>
<p>As long as the eCommerce Directive remains intact, monitoring proposals like those being floated in Brussels should be largely hypothetical for protected Internet hosts. But if the eCommerce safe harbors were re-opened for debate, the Convention-based limits on monitoring that the ECHR identified could suddenly become very important.</p>
<p><u>Monitoring for content so bad that platforms “know it when they see it”</u></p>
<p>One key question, if lawmakers sought to alter current EU law and expand monitoring obligations, would be what kinds of legal violations intermediaries can actually identify. <em>Delfi</em> condoned a monitoring obligation for some fairly extreme content – hate speech and threats of violence – that the Court thought anyone should recognize as ""on their face manifestly unlawful."" (P. 117)  <em>MTE</em> held that a monitoring requirement violated expression and information rights under Article 10 of the European Convention, in a case involving more legally ambiguous statements defaming a business.</p>
<p>The Court’s Article 10 concerns – that intermediaries monitoring user comments would systematically remove protected expression – are particularly important for “gray area”  statements that cannot easily be identified as legal or illegal.  It is much easier to mistakenly remove lawful content if it falls in this grey area.  For example, an intermediary might err on the side of removal if making an accurate legal judgment required factual investigation or nuanced legal analysis. If lawmakers did consider requiring platforms to monitor content, they would need to think carefully about what kinds of content actually fall within the ""manifestly unlawful"" or “know it when you see it” category. </p>
<p>Assuming, as the <em>Delfi</em> court did, that there are kinds of illegal content that human reviewers can readily identify, the next question is: can software identify it, too? It is unrealistic to expect platforms operating at Internet scale to hire and train legions of employees to review every piece of user content.  If lawmakers really went forward with requiring platforms to monitor content, the monitoring would almost certainly be carried out by machines.  To pass scrutiny under <em>MTE</em>, then, would a law need to prescribe only monitoring that can reliably be automated without significant over-removal of lawful speech?  Does such a thing exist?</p>
<p>Suppose the law mandated monitoring that in theory could be carried out accurately, but intermediaries in reality fell short of that standard and used cheaper tools that frequently removed lawful speech.  Would that practical result mean the law itself violated Article 10? Does the answer depend on the foreseeability of flawed, real-world implementation by intermediaries?</p>
<p>If the European Commission and other policy makers are serious about the “take down, stay down” idea, they will quickly arrive at questions like these.  The <em>MTE</em> and <em>Delfi</em> rulings provide important parts of the answers.</p>
<p><u>Obligations for platforms that “already have monitoring tools”</u></p>
<p>Proponents of monitoring obligations often argue that if an intermediary <em>already</em> has tools to detect duplicate content (or to otherwise somehow detect unlawful content), it should have to use them.  Copyright holders make this claim about YouTube’s ContentID; <a href=""http://www.spiegel.de/international/zeitgeist/max-mosley-discusses-his-fight-against-google-a-946180.html"">Max Mosley</a> made this claim about the duplicate image detection Google uses to fight child abuse images; <a href=""https://edri.org/files/2016-UN-consultation.pdf"">law enforcement</a> has raised it with respect to pro-terrorist and hate speech content on numerous platforms.   This argument in favor of policing by intermediaries is variously framed: as a matter of practicality, economic efficiency, traditional “due diligence” doctrine, and more.   It also arises as an eCommerce Directive interpretation.  The eCommerce-based argument is that when intermediaries scan and recognize content for business purposes, they become too “active” to claim safe harbors under Articles 12-14.  Therefore, Article 15’s protections from monitoring obligations do not apply.</p>
<p>Those who oppose monitoring obligations, including myself, often respond that this line of thought creates perverse incentives: No platform will want to voluntarily build tools to fight bad content if doing so only increases its own obligations and potential liability.   Besides, existing tools can be imprecise and take down good content with the bad – as the CJEU has <a href=""http://kluwercopyrightblog.com/2012/02/20/sabam-v-netlog-cjeu-c-36010-as-expected/"">recognized</a> in overruling monitoring injunctions. The risk of over-removal is enough of a problem when intermediaries use the tools for narrow purposes like identifying child sexual abuse content.   If they are compelled by law to use existing tools on harder-to-identify content, the scope for error and removal of lawful speech increases.   Imposing a legal obligation to monitor would also raise more acute Article 10 implications than voluntary efforts, because it involves governments in compelling private actors to delete controversial expression.</p>
<p>The argument that intermediaries with existing monitoring tools can legally be compelled to monitor <em>more</em> fits strangely with the <em>Delfi</em> and <em>MTE </em>cases.  Some platforms, after all, may develop monitoring tools precisely because of the <em>Delfi</em> ruling. Can lawmakers bootstrap from there to say the platforms then must use those same tools to find other kinds of content – like the defamation at issue in <em>MTE</em>, for example? That would be a lot like Mosley’s argument: that because Google built tools to find and weed out child sex abuse imagery, it must use those same tools to find pictures that violated his privacy.</p>
<p><em>Delfi </em>and <em>MTE</em> highlight the perversity of this reasoning.  A platform that institutes monitoring – whether voluntarily or to comply with <em>Delfi</em> – should not for that reason be denied protection under <em>MTE</em>. That outcome would create the wrong incentives for platforms, do harm to Internet users’ Article 10 rights, and defeat the purpose of these ECHR rulings.</p>
<p><strong>Conclusion</strong></p>
<p>This story is far from over. For one thing, it is possible that the <em>MTE</em> case could be appealed to the ECHR’s Grand Chamber.  For another, the issues it raises about Internet monitoring and online free expression and information will recur in litigation and legislative battles in Europe and around the world.  But the reasoning and outcome of the <em>MTE </em>case is an important step forward, and one that should influence outcomes in other fora.</p>
<p> </p>
",Intermediary Liability,2016-04-14 5:00,1188,Daphne Keller,News
14157,,United States,0,0,"DMCA Classic, DMCA Turbo: Major new empirical research on notice and takedown operations",Copyright,"<p>Good <a href=""http://cyberlaw.stanford.edu/blog/2015/10/empirical-evidence-over-removal-internet-companies-under-intermediary-liability-laws"">data</a> about Notice and Takedown can be hard to find. Jennifer Urban and Laura Quilter’s seminal <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2210935"">2006 study</a> has long been the gold standard, combining rigorous number-crunching with what must have been incredibly tedious substantive review of the copyright claims in DMCA notices. Now Urban, along with Brianna Schofield and Joe Karaganis, is back with a new report covering more recent data. It’s called “<a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2755628"">Notice and Takedown in Everyday Practice</a>,” and it’s a treasure trove of information about current DMCA operations.</p>
<p>The team conducted one qualitative study, conducting extensive confidential interviews with key players in the DMCA ecosystem: rightsholders, vendors, and Online Service Providers (OSPs). They also did two quantitative studies, based on close analysis of some 4,000 real DMCA notices held in the <a href=""https://lumendatabase.org/"">Lumen Database</a>. The resulting report is long but fascinating. You should read it. Here are some highlights.</p>
<p><strong>Same Statute, Different Worlds</strong></p>
<p>The report illuminates a major divergence between two worlds of DMCA practice. One is what the authors call “DMCA Classic”: low-volume, high-touch notice and takedown operations, typically involving small OSPs or small rightsholders. In the second world, which I’ll call DMCA Turbo, are the souped-up DMCA processes we know from news and policy debates, often involving powerful commercial actors on both the OSP and rightsholder sides. This world includes highly automated, high volume “DMCA Auto” operations (think “robonotices” and Google Web Search). It also includes voluntary “DMCA Plus” measures, such as proactive content monitoring (think ContentID on YouTube, or Audible Magic on many other platforms).</p>
<p><strong>“Classic” DMCA Operations</strong></p>
<p>Researchers conducted confidential interviews with 29 OSPs, more than half of which fall in the “Classic” category. As the Report describes it, for these OSPs</p>
<p style=""margin-left:.5in;"">the traditional DMCA notice and takedown process, involving substantive human review of takedown notices, is still the norm. DMCA Classic OSPs commonly receive dozens or hundreds of notices annually, with minimal increases year-on-year, and tend to be operating outside of the areas where there has been heightened conflict over copyright (music, video, and web search). (29)</p>
<p>Most of these OSPs reported a conservative approach to removals, “opting to take down content even when they are uncertain about the strength of the underlying claim” in order to avoid exposure to liability. (41) OSPs that dedicated more resources or assumed more risk in order to combat abuse typically seemed to do so for cultural reasons rather than truly commercial ones. (43) Like most OSPs in the study, many “Classic” ones reported instances of “deliberate gaming of the DMCA takedown process, including to harass competitors, to resolve personal disputes, to silence a critic, or to threaten the OSP[.]” (40)</p>
<p>These OSPs “described being left aside in policy debates and news accounts skewed by attention to” high profile issues affecting large commercial players.” They expressed specific concern about harm to their own legal protections based on automation and filtering efforts of major commercial players. (31)</p>
<p>The researchers did not have access to meaningful sample sets of DMCA notices from these smaller operators, so the Report offers no quantitative analysis of their practices. Urban et al did, however, have rich sample data from Google’s Image Search service. This service receives far fewer DMCA notices than Web Search –about one three-thousandth as many. It is not generally in the cross-hairs of major commercial or policy disputes, and typically deals with complaints from small businesses or individuals. So, although it is clearly not a “DMCA Classic” provider, its data may be a crude proxy for the “DMCA Classic” operational experience. </p>
<p>Here are some numbers from the Image Search data set, contrasted with the Web Search data set.</p>
<ul><li>For the same six month period, Web Search had over 108 million notices and Image search had 33,409.</li>
<li>Image search notices mostly came from individuals and small businesses. Web search notices overwhelmingly came from commercial rightsholders or their agents, and many appeared to the product of automated notice generation.</li>
<li>The error or abuse rate in Image Search notices is high: 38% raised substantive issues about the validity of the copyright claim. (That’s excluding one serial notifier whose barrage of notices skewed the entire data set.  With her notices, the error rate rises to 70%.) (98-99) </li>
<li>Twenty percent of Image Search notices came from outside the US. (102) </li>
<li>Most Image Search notices target personal websites, blogs, or social media sites. (102)</li>
</ul><p>(As a side note: From my own experience, I would also say that the simpler and less professionalized operations described in the Report’s “DMCA Classic” section have much in common with Notice and Takedown for operations for non-copyright claims –defamation or hate speech, for example – in countries where law requires OSPs to remove content in response to those legal claims.)</p>
<p><strong>Turbo DMCA Operations</strong></p>
<p>The Report looks closely at two related developments. One, which it calls “DMCA Auto,” is the use of automation by both rightsholders generating DMCA notices and OSPs processing them. The second, termed “DMCA Plus,” is OSPs’ use of filtering tools to identify and remove infringing content. The legal distinction between these two is important: DMCA Auto uses technology to comply with the statute, DMCA Plus uses it to go beyond the law’s requirements. I’m clustering them for simplicity and to highlight the contrast with the experience of small “Classic” operators, described above.</p>
<p>These processes are fairly well discussed in existing literature, but the Report’s qualitative section adds important detail. For instance, the researchers interviewed vendors that generate “robonotice” DMCA notifications for rightsholders. Some of them discussed spot-checking and other processes they use in an effort to avoid accidentally targeting the wrong content. (34)</p>
<p>Quantitative data about this world of DMCA operations comes from a sample of about 2000 DMCA requests, mostly to Google Web Search. In this sample set,</p>
<ul><li>91.8% were sent by outsourced agents, rather than by copyright holders themselves. About half of the agents were vendors and a little under half were trade associations. (84)</li>
<li>Over 2/3 of requests targeted file-sharing sites. (86)</li>
<li>“One in twenty-five of the takedown requests (4.2%) were fundamentally flawed because they targeted content that clearly did not match the identified infringed work. This extrapolates to approximately 4.5 million requests suffering from this problem across the entire six-month dataset.” (88)</li>
<li>28.4% raised some question about validity, based on facial review of the notices and targeted content. 15.4% failed to comply with DMCA statutory requirements. 7.3% targeted content with potential fair use defenses. (88)</li>
<li>“In about one out of twenty-five (4.2%) takedown requests, the allegedly infringed work described in the request did not match the allegedly infringing material at all.” For example, rightsholders for the musician Usher targeted a site hosting “The Fall of the House of Usher.” (90-91, acronyms omitted)</li>
</ul><p>The contrast between these operations and “DMCA Classic” are striking. If rightsholders and OSPs sometimes seem to be describing Notice and Takedown experiences from different worlds, the study suggests, perhaps that’s because they are.</p>
<p><strong>Other Interesting Findings</strong></p>
<p>The report is a treasure trove of information. A few more things that jumped out at me:</p>
<ul><li>Sizes of teams handling notice and takedown within OSPs. (36)</li>
<li>Abuse of DMCA notices to shoehorn in other legal claims not covered by the statute. (12, 37, 108)</li>
<li>Rarity of Counternotice. Many OSPs in the survey received none at all. (44) </li>
<li>Counternotice abuse. It exists! One notice provider reported being counternoticed seven times: five times for errors, and twice by Russian or Ukrainian torrent sites that presumably felt themselves to be beyond the effective reach of US copyright law. (46)</li>
<li>Backdoors. Some OSPs “provide senders with access to backend systems that go beyond streamlining … by allowing senders to remove content directly. Some sites allow ‘trusted’ senders to remove content directly from their hosting services without formal notices, identification of the infringed work, user notifications, or review.” (55)</li>
<li>Competition issues. Interesting discussion of when and why OSPs adopt fingerprinting and filtering systems; available commercial options and their cost; and filtering requirements as barriers to market entry. (57, 64)</li>
</ul>","Copyright and Fair Use, Intermediary Liability",2016-04-20 16:17,1188,Daphne Keller,News
14174,,Argentina,0,0,Argentinian Telecoms (and Credit Cards) Ordered to Block UBER App,Other,"<div>Argentina is in the midst of an inflamed debate on the lawfulness of UBER services. The last stage of the UBER affair—previously visiting cities like Milan or Paris—occurred in Buenos Aires. Finally, a number of orders from different authorities led to the blockade of the UBER app. In addition, credit card services were enjoined from processing payments connected to the App. Multiple arguments served as a legal basis to the different orders, including the endangerment of passengers´ health and safety and tax collection.</div>
<div> </div>
<div>Several institutional powers got entangled in this debate, often in a disconnected manner, creating an unnecessary legal ordeal. The President expressed his support to cab drivers; the President of the Communications Commission at the House of Representatives introduced a Bill in order to ban UBER; and—of course—the City of Buenos Aires judiciary was asked to prevent UBER from offering its service.</div>
<div> </div>
<div>Initially, taxi drivers and owners’ unions filed a lawsuit against UBER and the City of Buenos Aires—which allegedly allowed the service. As a result a judge in Buenos Aires granted an <a href=""http://www.ditc.com.ar/wp-content/uploads/2016/04/cautelar_uber_130416.pdf"">injunction </a>ordering the City of Buenos Aires to take any necessary action to block the circulation of UBER´s cars. Apparently, the Judge did not considered whether UBER was actually a public transportation company—it assumed it was. Neither he considered whether the public utility regime that regulates taxi services was even applicable, disregarding that—under Argentinean law—public utility regimes are not applicable by analogy. However, the Buenos Aires Court rejected blocking the Uber App, considering such a measure as “unconducive, lacking of arguments and possibly invading other jurisdictional powers.”</div>
<div> </div>
<div>Shortly thereafter, a criminal prosecutor from the City of Buenos Aires issued an injunction ordering ENACOM (Argentina´s FCC) to block the UBER App. Apparently, ENACOM refused to comply with the injunction arguing that a local prosecutor was not a competent authority to order such a measure. On April 22, a criminal judge from the City of Buenos Aires <a href=""http://www.lanacion.com.ar/1891860-la-justicia-portena-ordeno-el-bloqueo-de-uber"">ordered </a>ENACOM to block UBER within the City of Buenos Aires jurisdictional limits. It is not clear whether ENACOM, a federal agency, will comply with a City of Buenos Aires order. Content circulation through communications networks is a federal matter in Argentina, which is supposedly beyond the reach of local government jurisdiction. </div>
<div> </div>
<div>Finally, the Consumers Protection Agency of the City of Buenos Aires—an administrative agency—issued an injunction ordering telecoms to block the App and credit card companies to block any transaction related to the App. The injunction was issued against telecoms and credit cards as “contributors” to an allegedly harmful activity. A few days later, also a judge in Buenos Aires ordered credit card companies to cease their operations with UBER.</div>
<div> </div>
<div>Besides the underlying discussion regrading the legality of UBER services under existing laws, the Consumer Protection agency decision—later reinforced by a narrower judicial order—is a surprising outcome under Argentinian law as contributory liability does not apparently exist in Argentina. According to civil law principles, a person or entity can be found liable for third-party activities under several legal theories, but not contributory infringement. Also, a local administrative agency ordering Internet content blocking might run counter the standards established by the IASHR Special Rapporteur on Freedom of Expression. The Special Rapporteur has clearly stated that online content blocking would require a judicial order or at least an agency with jurisdictional powers over the content. </div>
<div> </div>
",Intermediary Liability,2016-05-03 1:40,505,Giancarlo Frosio,News
14182,,International,1,1,April 2016 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>April 2016 in Retrospect is available here:</p>
<p><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2016-april/"">http://www.internetjurisdiction.net/observatory/retrospect/2016-april/</a></p>
<div>Retrospect is a flagship publication of the <a href=""http://www.internetjurisdiction.net/"">Internet & Jurisdiction Project</a>. It provides since 2012 a unique source to study an understand emerging trends and high-level patterns regarding the tension between the cross-border nature of the Internet and the patchwork of geographically defined national jurisdictions.</div>
<div> </div>
<div>All cases are crowd-ranked by leading international experts of the I&J Observatory. The Internet & Jurisdiction Project facilities a global policy process. It enables multi-stakeholder cooperation in order to develop new mechanisms that are as transnational as the Internet itself and guarantee due process across borders.</div>
",Intermediary Liability,2016-05-06 4:31,505,Giancarlo Frosio,News
14217,,United States,0,0,Taplin's False Choice Between Music and Technology,Copyright,"<p>Jonathan Taplin’s op-ed (<em><a href=""http://www.nytimes.com/2016/05/20/opinion/do-you-love-music-silicon-valley-doesnt.html?ref=opinion"">Do You Love Music? Silicon Valley Doesn’t</a></em>) in the May 20 edition of <em>The New York Times</em> perpetuates a powerful dichotomy that has come to dominate debates surrounding copyright reform, specifically with respect to the Digital Millennium Copyright Act (DMCA): you’re either for the ""creative"" types, or you’re for the ""technology"" types. Pick a side.</p>
<p>For those of us who would rather not play favorites, because we love both music and technology, the choice Taplin presents is Solomonic. Fortunately, however, it also happens to be false. We can have our music and our technology, too, thanks in large part to the DMCA—a copyright law foundational to the growth of the Internet and just about everything on it.       </p>
<p>It is true, as Taplin points out, that the Internet was a very different place when Congress enacted the DMCA in 1998. Indeed, the ink was barely dry on the DMCA when a college student in Boston who thought it would be cool to share music with his friends unleashed Napster on the world. But Napster and its successors in digital disruption haven’t made the DMCA irrelevant or ineffective any more than online copyright infringement has destroyed the music industry.</p>
<p>In the International Federation for the Phonographic Industry’s 2015 Digital Music Report, Sony Music Chairman Edgar Berger is quoted as saying that “the industry is performing remarkably well,” ably managing simultaneous transitions from physical to digital, download to streaming, and PC to mobile. The market for digital music remains incredibly dynamic, with consumer preferences continuing to morph as technology evolves. That dynamism is certainly challenging for the music industry from a business perspective, but it is hard to square Berger’s upbeat assessment of the industry’s adaptability with Taplin’s dire assertion that it is “choking on the dust” of tech companies.</p>
<p>As Congress considers changes to the DMCA, it is important to remember the twin policy objectives underlying the statute: to minimize obstacles to growth for both creative types, who would not expand online distribution of their works without assurances that they would be protected from massive piracy, and technology types, who would not expand their sites and networks without assurances that they would be protected from massive liability for copyright infringement.</p>
<p>In light of the DMCA’s focus on promoting growth in <em>both</em> creativity and technology, the statute can be understood as a mechanism for simultaneously scaling up online copyright enforcement and scaling back online copyright liability—a unified solution designed to give creators the security necessary to expand content distribution and technologists the security necessary to expand online platforms and infrastructure.</p>
<p>Under the DMCA, technologists building innovative online platforms have a clear and straightforward set of ground rules to follow, allowing them to conform their operations to the law and, thereby, avoid the specter of potentially crushing liability. At the same time, creators of new artistic works, through the notice-and-takedown process spelled out in the statute, have a simple and cost-effective means to curtail large numbers of infringing uses of their protected expression.</p>
<p>Because of the DMCA, which imposes costs and obligations on both creative types and technology types, lovers of music and lovers of new technologies have been able to enjoy the best of both worlds. Let’s not encourage Congress to make a false choice now.</p>
<p>          </p>
","Copyright and Fair Use, Intermediary Liability",2016-05-20 11:37,1046,Annemarie Bridy,News
14218,,United States,0,0,"Facebook, Congress and the First Amendment",Freedom of Expression,"<p>The Facebook Trending Topics controversy has been analyzed from many angles, but there's been virtually no attention paid to the single most troubling aspect of the story: a Senate inquiry into Facebook's editorial decision-making process. My Slate column on the issue is <a href=""http://www.slate.com/articles/news_and_politics/jurisprudence/2016/05/facebook_s_trending_topics_are_none_of_the_senate_s_business.html"">here</a>.</p>
","Architecture and Public Policy, Copyright and Fair Use, Intermediary Liability",2016-05-23 13:04,265,Tom Rubin,News
14220,,United States,0,0,Facebook Fourth Estate? Two Questions Lawyers Should Answer,General+Freedom of Expression,"<p><strong style=""font-size: 13.008px; line-height: 1.538em;""><em>In defending Facebook against government scrutiny by invoking First Amendment rights, we’ve overlooked the legal consequences for CDA 230 and risk constitutionalizing the web.  </em></strong></p>
<p>In the wake of recent reporting of Facebook’s <a href=""http://gizmodo.com/former-facebook-workers-we-routinely-suppressed-conser-1775461006"">alleged liberal curation</a> of its trending newsfeed and Sen. John Thune’s subsequent <a href=""http://www.commerce.senate.gov/public/_cache/files/fe5b7b75-8d53-44c3-8a20-6b2c12b0970d/C5CF587E2778E073A80A79E2A6F73705.fb-letter.pdf?version=meter+at+0&module=meter-Links&pgtype=article&contentId=&mediaId=&referrer=https%3A%2F%2Fwww.googl"">letter to CEO Mark Zuckerberg</a> seeking answers about these allegations and demanding a meeting, constitutional scholars, press advocates, and civil libertarians have mobilized the First Amendment in the company’s defense. <a href=""https://www.eff.org/deeplinks/2016/05/senators-inquiry-facebooks-editorial-decisions-runs-afoul-first-amendment"">The Electronic Frontier Foundation’s (EFF) Sophia Cope argued</a> that the letter constitutes “an improper intrusion into editorial freedom,” and <a href=""http://www.slate.com/articles/news_and_politics/jurisprudence/2016/05/facebook_s_trending_topics_are_none_of_the_senate_s_business.html"">Stanford Law lecturer Thomas Rubin wrote in Slate</a> that “we should be concerned about this federal intrusion into an independent organization’s editorial process.”</p>
<p>But in our rush to ensure the integrity of the First Amendment, especially important in the murky context of digital civil liberties, we’ve overlooked the consequences of deciding that Facebook and similarly situated social media platforms are speakers, and in particular press speakers. Here, I unpack two particularly important legal consequences: (1) what happens to CDA 230 when Internet intermediaries invoke First Amendment protections, and (2) what is the limit to expanding First Amendment rights to new types of press actors?</p>
<p><strong>1. Policing the Boundary Between the First Amendment and CDA 230.</strong></p>
<p>Those who are advocating for a First Amendment interest in Facebook’s editorial practices assume that courts will recognize the distinction between the company’s curation decisions in its trending news feed and the third-party content it serves up in that feed. In other words, that Facebook “speaks” or exercises “editorial control” when it chooses how to rank or display content, but is not adopting the content of the articles themselves as its speech. Given the massive efforts at <a href=""https://newrepublic.com/article/113294/how-corporations-hijacked-first-amendment-evade-regulation"">First Amendment expansionism</a> happening in other areas of the law (what scholars have called a neo or “<a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2652762"">new Lochner</a>” moment), I’m less sanguine. We must explicitly and vigilantly police the boundary between Internet companies’ ability to claim First Amendment protections in their editorial practices versus CDA 230 immunity in the third-party content that they host.</p>
<p>Policing this legal boundary matters because we risk cannibalizing <a href=""https://www.law.cornell.edu/uscode/text/47/230"">CDA 230</a>, which provides that intermediaries are not liable for the third-party content that they host. As <a href=""https://www.eff.org/issues/cda230"">EFF correctly explains</a>, this provision “is one of the most valuable tools for protecting freedom of expression and innovation on the Internet.” Fundamentally, CDA 230 creates the legal backbone that makes possible companies like Facebook and Twitter, which are built in large part on hosting or curating content. As a result, CDA 230 protects users’ expression, because companies don’t worry about being legally liable for the content that you and I post, and fosters innovation and economic growth in the digital economy. Without it, companies that host third-party content would have been sued out of existence in the first place. Here’s the key language from <a href=""http://www.law.cornell.edu/uscode/text/47/230"">47 U.S.C. § 230</a>: <span style=""line-height: 1.3em;"">""No provider or user of an interactive computer service shall be treated as the publisher or speaker of any information provided by another information content provider.""</span></p>
<p>Historically, ensuring the integrity of CDA 230 hasn’t been an issue because Internet companies like Facebook, Twitter, and others acted exclusively as intermediaries. But as these companies play the role not only of intermediary but also of content curator and producer, the inherent contradiction between CDA 230 and the First Amendment comes to the fore: the First Amendment protects you when you claim speech or press activity as your own, while CDA 230 immunizes you when you host the content of others.  </p>
<p>The bottom line is that to protect CDA 230 – the statue that undergirds the structure of third-party websites and ensures that they are not liable for the content that you and I post – it is essential that companies maintain clear lines between their editorial and intermediary functions. In other words, these companies can’t have it both ways: they cannot be both non-liable for third-party content and at the same time invoke the high bar of First Amendment protection for the very same third-party speech. Perhaps a solution for Facebook would be to formally silo groups like its team (presumably a hybrid product and editorial team?) running the trending news feed, whereas its other services, like ads, continue to represent the company’s work as an intermediary.</p>
<p><strong>2. We Need a Limiting Principle for “the Press” or We Risk Constitutionalizing the Web.</strong></p>
<p>The concern that CDA 230 could be cannibalized by First Amendment claims is exacerbated by the lack of a limiting principle as to who or what can claim the type of First Amendment press right that advocates have outlined. The First Amendment question here is narrow: does human content curation coupled with an algorithm qualify as an editorial judgment? Both EFF and Rubin argue that, per <a href=""https://scholar.google.com/scholar_case?case=3261378222094247847&hl=en&as_sdt=6&as_vis=1&oi=scholarr""><em>Miami Herald v. Tornillo</em></a>, it does. This analysis means that Facebook is acting not as a mere corporate speaker, but rather as the press.</p>
<p>Given the fluidity and instability within journalism these days, we should expect that the legal definition of who counts as the press for First Amendment purposes will change, too. But what’s the limiting principle? Are algorithms making editorial judgments? Is every search engine, in line with what <a href=""http://volokh.com/wp-content/uploads/2012/05/SearchEngineFirstAmendment.pdf"">Eugene Volokh has argued on behalf of Google</a>, an editor?</p>
<p>The Facebook trending newsfeed example could offer a very narrow definition and clear limiting principle. Its trending news algorithm functions, it appears, with lots of hands-on interaction from humans; <a href=""http://gizmodo.com/former-facebook-workers-we-routinely-suppressed-conser-1775461006"">that’s part of what started the brouhaha in the first place</a>. So the limiting principle for an algorithm to count as part of the press is that it has not simply been created by a human and unleashed into the wild, but rather that it is the result of consistent, perhaps daily human decisionmaking. I realize many will disagree with this proposition, and they have a good argument: because algorithms are written by people, the results that they generate reflect human biases and intentions; in other words, they are a way that editorial choices are produced. But if we understand algorithms that are highly attenuated from their human creators as invested with constitutional rights as “the press,” then we risk constitutionalizing the entire Internet. Not only would such First Amendment expansionism likely favor corporate speakers over individuals, but more problematic is that the press clause would be rendered meaningless. There are a multitude of algorithms at work, and if the press clause covers all of them, it will be inappropriately and dangerously diluted.</p>
<p>We can avoid that route by adopting the tight human-algorithm nexus I described as a limiting principle for when algorithms can be understood as warranting press protections. Moreover, Facebook’s trending newsfeed offers the opportunity to establish a second limiting principle: a functional definition of the press, as opposed to a legacy or institutional definition. This is a position that I’ve argued for in the past. In opposing the 2013 federal shield legislation (I was working as a summer intern at EFF), I argued that legal definitions of the press should turn on the <a href=""https://www.eff.org/deeplinks/2013/07/congress-and-justice-depts-dangerous-attempts-define-journalist-threaten-exclude"">practice and not the profession of journalism</a>. Since Facebook is a non-traditional news source, any press protections that it claims would necessarily be tied to an argument about its functional role curating content and making editorial decisions, not on its professional background or institutional claim to legitimacy. Such a move could be a benefit for all sorts of non-traditional, non-institutional journalists.</p>
",Architecture and Public Policy,2016-05-24 12:23,428,Morgan Weiland,News
14221,,European Union,0,0,Can a New Broadcasting Law in Europe Make Internet Hosts Monitor Their Users?,General,"<p>The European Commission is making major steps forward in its new <a href=""http://ec.europa.eu/priorities/digital-single-market_en"">Digital Single Market</a> strategy. One important part, the <a href=""https://ec.europa.eu/digital-single-market/en/news/public-consultation-regulatory-environment-platforms-online-intermediaries-data-and-cloud"">Platform Liability</a> consultation, pointedly asked whether Internet intermediaries should “do more” to weed out illegal or harmful content on their platforms – in other words, to proactively police the information posted by users. Last week the Commission delivered part of its answer. It proposed that an important set of platforms – video hosts like DailyMotion or YouTube – should monitor their users and proactively remove content. That's an alarming development. As courts around the world have recognized, laws like this threaten ordinary Internet users' rights, by giving private intermediaries incentives to delete perfectly lawful online expression. </p>
<p>The good news is that the Commission won’t revise the EU’s core intermediary liability law, the <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:32000L0031:en:HTML"">eCommerce Directive</a>. That Directive explicitly prohibits lawmakers from requiring protected platforms to generally monitor their users. The bad news is that proposals unveiled this week erode the no-general-monitoring rule anyway - or at least try to. They do so through a mix of changes to other laws; far-reaching interpretations of the eCommerce Directive; and bewildering ""co-regulation"" measures that, paradoxically, seem designed to legally compel voluntary action by platforms. </p>
<p>One important vehicle for this change is a <a href=""https://ec.europa.eu/digital-single-market/en/news/proposal-updated-audiovisual-media-services-directive"">draft revision</a> to the Audio Visual Media Services (AVMS) Directive. The draft AVMS Directive expands broadcast-style regulations to video hosting platforms. It gives them major, but ill-defined, new duties to prevent users from sharing videos that promote hate, violence, or material inappropriate for minors. Here's my take on the draft Directive and the problems with its monitoring provisions.</p>
<p> </p>
<p><strong>Can the AVSM Directive Make Hosts Monitor Without Amending the eCommerce Directive?</strong></p>
<p>Video platforms generally maintain that the “hosting” provisions at Article 14 of the eCommerce Directive protect them from liability for content uploaded by users. Plenty of courts have agreed with them. If they are right, then under another eCommerce provision -- Article 15 -- the law can’t compel the hosts to generally monitor information posted by their users.</p>
<p>But there is a lot of disagreement about which platforms qualify for the eCommerce immunities. Some people – and some courts – think hosts are not protected if they do things like make hosted content searchable, or organize it into categories, or run ads. The theory is that this makes the platforms too “active,” and that only more passive hosts qualify for eCommerce Directive protection.</p>
<p>The draft AVMS Directive adopts an extremely broad version of this “active hosting” analysis. It says any host that “organizes” videos posted by users loses important parts of its eCommerce immunities. Therefore, these platforms can be held responsible for finding and removing content.</p>
<p>This interpretation would effectively change the rules for Internet users and intermediaries without formally reopening the eCommerce Directive. If it is right, courts or national lawmakers could apply a similar strained interpretation of the eCommerce Directive to other Internet hosts – blogging platforms like <a href=""https://www.crunchbase.com/organization/overblog#/entity"">OverBlog</a> or <a href=""https://wordpress.com/"">WordPress</a>, news sites with user comment forums, and more – as long as those hosts somehow “organize” posted content. And nothing in this line of reasoning limits the new rules to hateful or violent content. On this theory, lawmakers could compel the same hosts to monitor for trademark infringement or defamation without running afoul of the eCommerce Directive. </p>
<p>Stripping eCommerce immunities from hosts that “organize” user content would have significant implications for the EU tech economy. It would make investing in normal, contemporary online services - the ones with search functionality, channels, related content links, and other “organizing” features - a risky proposition in the EU. Only obsolete, bare-bones hosts could count on legal protections. That’s an odd outcome from the Digital Single Market process, which was supposed to boost technical innovation and investment in the EU.</p>
<p>Such a change would also be deeply troubling for Internet users’ rights. As the <a href=""http://cyberlaw.stanford.edu/blog/2016/04/new-intermediary-liability-cases-european-court-human-rights-what-will-they-mean-real"">European Court of Human Rights has noted</a>, when platforms have to police content, users’ rights suffer. Risk-averse private companies will remove not only genuinely unlawful content, but also controversial expression and anything else with a whiff of legal risk. Laws that require monitoring give private platforms <a href=""http://cyberlaw.stanford.edu/blog/2015/10/empirical-evidence-over-removal-internet-companies-under-intermediary-liability-laws"">every reason</a> to take down users’ content, even if it is perfectly legal. In a society increasingly dependent on internet communications, deleting users’ online expression effectively curtails democratic participation and opportunities to seek and impart information online.</p>
<p> </p>
<p><strong>Why Extend the AVSM Directive?</strong></p>
<p>The first reason lawmakers want this change, obviously, is to fight dangerous content online. Given current concerns about terrorism, hate speech, and incitement to violence, few people question this goal. But giving tech companies a vague set of obligations and incentives to over-enforce isn’t the answer. It’s a recipe for deletion of legal and valuable expression – including counter-speech by moderate voices in communities affected by extremism.</p>
<p>The second reason is economic. The idea is that online video hosts and traditional broadcasters compete for the same audience, but that there isn’t a level playing field because broadcasters have to comply with AVSM Directive rules. The part about competing economically is true – if it weren’t for the Internet, more of us would resort to watching TV. There may be some real imbalances there, and grounds for other legal reforms to fix financial inequities. But as economies of expression and participation, TV and the Internet are wildly different. Open video hosting platforms on the Internet let anyone in the world “broadcast” to anyone else in the world. Can the AVSM “level the playing field” in the other direction, by making traditional broadcasters give <a href=""https://www.youtube.com/watch?v=y3yRv5Jg5TI"">Chewbacca-Mask Mom</a> instant access to millions of viewers, as video hosting platforms have done? Can they give any viewer – <a href=""http://metro.co.uk/2016/05/26/chewbacca-wore-a-chewbacca-mom-mask-and-its-just-as-hilarious-5906799/"">like Mom-Mask Chewbacca</a> - an instant means of reply? Of course not. That’s not how broadcasting works. But just because lawmakers can’t make TV more democratic, that doesn’t mean they should make the Internet less so. Imposing new rules that will effectively harm Internet users’ ability to participate online is not a solution.</p>
<p> </p>
<p><strong>Who Gets Regulated under the AVMS Directive?</strong></p>
<p>As the draft Directive explains,</p>
<p style=""margin-left:.5in;"">An important share of the content stored on video-sharing platforms is not under the editorial responsibility of the video-sharing platform provider. However, those providers typically determine the organisation of . . . user-generated videos, including by automatic means or algorithms. Therefore, those providers should be required to take appropriate measures to protect minors . . . and protect all citizens from incitement to violence or hatred[.]</p>
<p style=""margin-left:.5in;"">In light of the nature of the providers' involvement with the content stored on videosharing platforms, those appropriate measures should relate to the organisation of the content and not to the content as such. The requirements in this regard as set out in this Directive should therefore apply without prejudice to Article 14 of [the eCommerce Directive.] (R. 28-29)</p>
<p>Building on this aggressive eCommerce Directive work-around, the draft expands broadcast regulations to any “video-sharing platform service” in which “the organisation of the stored content is determined by the provider of the service including by automatic means or algorithms, in particular by hosting, displaying, tagging and sequencing.” (Art. 1aa) EU countries are required to maintain lists of covered AVMS services. (Art. 2.5a) Since this new regulation seems to reach any host that lets users find videos using search algorithms or tagging, it should cover pretty much any video platform you’ve heard of or used.</p>
<p> </p>
<p><strong>What Do Video Hosts Have to Do?</strong></p>
<p>The AVMS Directive says unequivocally, ""Member States <em>shall ensure</em> by appropriate means that audiovisual media services provided by media service providers under their jurisdiction <em>do not contain any incitement to violence or hatred</em>.” (Art. 6, emphasis added.) That’s a tall order. Later on, Article 28 spells out “what constitutes an appropriate measure” to achieve this end. Depending how it’s interpreted, the list could be relatively modest – or really alarming. Assuming that the appropriate <em>means</em> in Art. 6 and the appropriate <em>measures</em> in Art. 28 are the same thing, here is what video-sharing platforms must do:</p>
<p> </p>
<p style=""margin-left:.25in;"">·       Prohibit or restrict hateful, violent, and harmful-to-minors content in their Terms of Service (Art. 28a.2(a)). Adding this point to a TOS seems superfluous for content that is already illegal, since companies operating under the eCommerce Directive must take down illegal content when they find out about it anyway. However, if this requirement means hosts have to define and delete new kinds of “harmful” speech that are <em>not</em> already illegal, that is downright scary. (Drafters might want to check out India’s <a href=""http://judis.nic.in/supremecourt/imgst.aspx?filename=42510"">Shreya Singhal</a> case, which struck down a similar “it’s not illegal but intermediaries must prohibit it by TOS anyway” law, if that’s what they mean.)</p>
<p style=""margin-left:.25in;"">·       Let users “flag” and “rate” that content, and respond to user flagging. (Art. 28a.2(b), (d) and (f)). To the extent the AVMS Directive is talking is about illegal content, this looks a lot like what platforms should do under the eCommerce Directive anyway.</p>
<p style=""margin-left:.25in;"">·       Create “age verification systems” and “parental control systems” for content harmful to minors. (Art. 28a.2(c) and (e)). That one’s more troubling. If it means hosts must proactively identify content that can ham minors, then it really is a monitoring requirement, with all the problems discussed above. And age-verification systems can be a privacy nightmare, since they mean video hosts check users’ IDs at the door. For example, Korea has an age verification requirement, and as Professor KS Park points out, in practice it’s been a slippery slope toward requiring mobile users to register their SIM cards.</p>
<p>Other parts of the draft Directive, and many of the Commission’s public statements about the Platform Liability inquiry, emphasize “voluntary” measures. For example, Article 4.7 says that “Member States shall encourage co-regulation and self-regulation through codes of conduct. . . They shall provide for effective enforcement, including when appropriate effective and proportionate sanctions.” It is not clear what exactly these “voluntary” measures under threat of State sanction would look like, or exactly how they relate to the Directive’s other enumerated obligations.</p>
<p> </p>
<p><strong>Now What?</strong></p>
<p>Importantly, this is a first draft. It’s from just one branch of government. What happens next is a lot of politics, arguments, amendments, and so forth. The future is not written, thank goodness.</p>
<p>But what would happen in practice if the AVMS Directive went into effect as drafted? Member States would pass their own implementing laws, presumably with a lot of variation. Foreign companies without ties to one EU country in particular could forum-shop and establish themselves in a country with more favorable laws, much as they have done under the Data Protection Directive. (Art. 28b)</p>
<p>At any step in the process of interpreting the Directive – in national legislation, or in arguments accepted by courts in litigation – ambiguities about whether video platforms have to monitor user content could get resolved. Authorities may well say that platforms have to monitor users, and that they are in trouble if they aren’t doing it already. Or they could decide that actually, this is a dangerous direction for the Internet. They might conclude that compelling private companies to police online speech is inconsistent with the State's obligation to protect Internet users' fundamental rights to seek and impart information online. </p>
<p>Resolution of that sort is a long way off, though. In the meantime, fear of being held liable for failure to monitor will drive behavior by private actors, in ways that threaten both innovation and Internet users’ rights. Technical innovators and investors will factor in the risk of expensive future monitoring obligations as they decide where, and whether, to start new companies. Existing platforms may decide to play it safe and set up filtering or monitoring efforts, or turn open platforms into walled gardens. Those outcomes would be bad news for everyone.</p>
<p> </p>
<p> </p>
<p> </p>
","Architecture and Public Policy, Copyright and Fair Use, Intermediary Liability",2016-05-27 14:51,1188,Daphne Keller,News
14222,,International,1,1,May 2016 in Retrospect: Intermediary Liability News and More from the Internet and Jurisdiction Project,General,"<p>May 2016 in Retrospect is available here:</p>
<p><a href=""http://www.internetjurisdiction.net/observatory/retrospect/2016-may/"">http://www.internetjurisdiction.net/observatory/retrospect/2016-may/</a></p>
<div>Retrospect is a flagship publication of the <a href=""http://www.internetjurisdiction.net/"">Internet & Jurisdiction Project</a>. It provides since 2012 a unique source to study an understand emerging trends and high-level patterns regarding the tension between the cross-border nature of the Internet and the patchwork of geographically defined national jurisdictions.</div>
<div> </div>
<div>All cases are crowd-ranked by leading international experts of the I&J Observatory. The Internet & Jurisdiction Project facilities a global policy process. It enables multi-stakeholder cooperation in order to develop new mechanisms that are as transnational as the Internet itself and guarantee due process across borders.</div>
",Intermediary Liability,2016-06-01 11:05,505,Giancarlo Frosio,News
14250,,United States,0,0,Luiz Fernando Moncau Joins Stanford Center for Internet and Society as Intermediary Liability Fellow,General,"<p><img alt="""" src=""/files/people/portaits/FGV-67.jpg"" style=""width: 200px; height: 301px; float: right; margin: 5px;"" />The Center for Internet and Society (CIS) at Stanford Law School has appointed <a href=""https://cyberlaw.stanford.edu/about/people/luiz-fernando-marrey-moncau"">Luiz Fernando Marrey Moncau</a> as Intermediary Liability Fellow. In this role at CIS, Moncau will continue his longstanding work promoting strong and well-crafted intermediary liability laws that advance the rights and freedoms of Internet users.  He will start in July 2016, working with Intermediary Liability Director <a href=""http://cyberlaw.stanford.edu/about/people/daphne-keller"">Daphne Keller</a></p>
<p>CIS’s three-year-old initiative on intermediary liability explores the impact of global intermediary liability regimes on freedom of expression and innovation. Intermediary liability law can create incentives for platforms like Facebook or YouTube to police the online expression and conduct of their users – including artists, journalists and political activists. Without careful consideration, these rules can stifle legitimate expression and political activities, and can constrain providers’ ability to offer innovative new services.</p>
<p>As part of its intermediary liability work, CIS, in collaboration with a  team of contributors from around the world, built a detailed World Intermediary Liability Map (<a href=""http://cyberlaw.stanford.edu/our-work/projects/world-intermediary-liability-map-wilmap"">WILMap</a>). The WILMap is an online resource tracking Internet regulations affecting freedom of expression and user rights worldwide. CIS Director Daphne Keller also has written about emerging jurisprudence from the European Court of Human Rights and other sources identifying intermediary liability law as a key protection for Internet users’ rights to free expression and access to information. </p>
<p>As Intermediary Liability Fellow, Moncau will lead projects connecting intermediary liability legal regimes to the fundamental, constitutional and human rights of Internet users. He will study laws and policies regarding intermediary liability regimes and their effect on free expression and innovation worldwide, and support the Center’s innovative and influential work in this focus area. </p>
<p>Moncau is an expert on freedom of expression and telecommunications and copyright law. As head of the Center for Technology and Society at FGV Law School of Rio de Janeiro, a leading research institution for law and technology in Brazil, Moncau has been on the cutting edge of the intermediary liability debate in that country.  He was actively involved in the development of Brazil’s groundbreaking Civil Rights Framework for the Internet (the <em>Marco Civil da Internet</em>).</p>
<p>Moncau’s experience includes working on legal and policy issues, such as the reform of Brazilian copyright law, the ongoing debates about data protection in that country and the effects of international trade agreements on civil rights.  He is the author of the book <em>Freedom of Expression and Copyright</em> <em>(Liberdade de Expressão e Direitos Autorais),</em> published in 2015 by Elsevier, co-author of the study “The Brazilian State and Transparency: Evaluating Compliance with Freedom of Information,” and author of a chapter of the “Media Piracy in Emerging Economies” study that was organized by Joe Karaganis and published by Social Science Research Council (SSRC).</p>
<p>“Intermediary liability regimes directly affect user rights online,” said CIS Faculty Director and Professor of Law Barbara van Schewick. “The law in this area is developing rapidly, and crafting it to preserve civil liberties and opportunities for technical innovation is critical.  CIS is very fortunate to have Luiz Moncau contribute to our efforts in this area. His experience and expertise will be key in developing tools and networks to advance a human rights-based approach to platform liability laws.” </p>
<p>“I am extremely excited to work with the CIS’s team to address the emerging challenges brought by technology to online freedom of expression. I hope to contribute with my research, policymaking and advocacy experience to foster the adoption of balanced intermediary liability rules around the world,” said Moncau.</p>
<p>“Luiz Moncau’s experience working for Internet users’ rights makes him a perfect fit for the Center’s work on intermediary liability,” said Keller.</p>
<p>As the Head for the CTS/FGV, Moncau coordinated and conducted research on freedom of expression, intellectual property, Internet regulation, consumer rights and telecommunications regulation. Throughout his career, he has maintained strong public-interest ties, participating in national and international debates about online freedom of expression, cybercrimes, cybersecurity, and the protection of consumers of telecommunications services. Before joining CTS/FGV in 2008, Moncau worked as a lawyer and policy analyst in the Advocacy Department of the Brazilian Institute for Consumer Defense (IDEC), and as a consultant for the Brazilian Ministry of Justice on telecommunications and consumers’ rights.</p>
<p>Moncau earned a law degree at the Pontifícia Universidade Católica de São Paulo and a master’s degree in constitutional law at Pontifícia Universidade Católica of Rio de Janeiro, where he is a Ph.D. candidate. He has been a panelist and speaker at numberous academic and policy events, including public hearings before the Brazilian National Congress and international conferences. Moncau also has broad experience as a spokesperson addressing Brazilian and international press on emerging technology issues.</p>
<p><a href=""http://cyberlaw.stanford.edu/""><strong>About The Center for Internet and Society</strong></a></p>
<p>Led by faculty director Barbara van Schewick, the Center for Internet and Society (CIS) is a public interest technology law and policy program at Stanford Law School that supports the study of the interaction of new technologies and the law and is a part of the Law, Science and Technology Program at the law school. CIS strives to improve both technology and law, encouraging decision makers to design both as a means to further democratic values. Along with conducting research and policy analysis, the Center sponsors legal fellowships, organizes events to foster discussion of critical policy issues, and provides educational opportunities for law students to conduct applicable research and policy analysis in this field. </p>
",Intermediary Liability,2016-06-06 8:22,396,Center for Internet and Society,News
14326,,United States,0,0,D.C. Circuit’s Net Neutrality Ruling Rejects Corporate First Amendment Expansionism,Freedom of Expression,"<p>The D.C. Circuit today <a href=""https://www.cadc.uscourts.gov/internet/opinions.nsf/3F95E49183E6F8AF85257FD200505A3A/$file/15-1063-1619173.pdf"">upheld the Federal Communications Commission’s (FCC) 2015 network neutrality regulations</a>, vindicating the agency’s decision to reclassify internet service providers (ISPs) as common carriers under Title II of the Telecommunications Act of 1996. Equally as important – though potentially overshadowed by the opinion’s crucial reclassification component – is the court’s total rejection of the ISPs’ constitutional argument that network neutrality rules violate their First Amendment rights. Specifically, ISPs had argued that their transmission of data is speech and thus the regulation’s prohibition on blocking and discriminating amount to an unconstitutional violation of their speech rights as they might be compelled “to transmit speech with which they might disagree.”</p>
<p>The court disagreed and reaffirmed that, because ISPs are common carriers, they are not speakers or editors, but rather facilitate others’ ability to engage in expression. And because network neutrality regulations relate to ISPs’ common carrier role, “[t]hose obligations affect a common carrier’s neutral transmission of <em>others’</em> speech, not a carrier’s communication of its own message.”</p>
<p>This point is obvious to anyone who’s used the internet: the ISP, which provides the connection between you and the websites you want to access, is not speaking or exercising editorial control when it transmits data. Rather, when an ISP transmits data that you requested when you visit reddit.com, you and reddit.com have expressive interests in that content – <em>not </em>the ISP.</p>
<p>By rejecting the ISPs’ First Amendment claim, the court not only maintained the current state of First Amendment doctrine with respect to common carriers, but importantly held the line against corporate First Amendment expansionism. As many scholars have documented – including <a href=""http://digitalcommons.law.yale.edu/fss_papers/3128/"">Yochai Benkler</a>, <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=470842"">Jack Balkin</a>, and <a href=""http://harvardlawreview.org/2015/03/adam-smiths-first-amendment/"">Robert Post</a> and <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2652762"">Amanda Shanor</a> – corporations have sought to undermine publicly interested regulations as a violation of corporate First Amendment rights. The ISPs’ constitutional claim that the transmission of data constitutes their speech represented a new front in that corporate war on regulation, and fortunately for the public and their interests in free expression, the D.C. Circuit rejected it.</p>
<p>Let’s review the key First Amendment elements of the <a href=""https://www.cadc.uscourts.gov/internet/opinions.nsf/3F95E49183E6F8AF85257FD200505A3A/$file/15-1063-1619173.pdf"">opinion</a>, all of which are contained in Part VII of the majority opinion, starting on page 106. (Judge Williams’ partial concurrence and dissent doesn’t address the First Amendment questions.)</p>
<p><strong>Common Carriers Are Not First Amendment Speakers</strong></p>
<p>As Judges Tatel and Srinivasan explain, common carriers like “telephone companies, railroads, and postal services” have historically been required to satisfy “[e]qual access obligations” like network neutrality “without raising any First Amendment issue.” And they spell out the logic animating this fact: “The absence of any First Amendment concern in the context of common carriers rests on the understanding that such entities, insofar as they are subject to equal access mandates, merely facilitate the transmission of the speech of others rather than engage in speech in their own right.” Simply, ISPs don’t have any expressive interests at stake when they act like conduits.</p>
<p>Further, consumers don’t perceive ISPs to be speaking or endorsing the content that they transmit. Because ISPs act as common carriers and neutrally provide access to all legal content that a user might want, “when a subscriber uses her broadband service to access internet content of her own choosing, she does not understand the accessed content to reflect her broadband provider’s editorial judgment or viewpoint.”</p>
<p>The court’s reasoning follows the logic that First Amendment and cyberlaw scholars, including Center for Internet & Society Director and Stanford Law Professor Barbara van Schewick, as well as the Stanford Communication Department Professors Ted Glasser and Fred Turner, outlined in an <a href=""https://cyberlaw.stanford.edu/files/publication/files/First%20Amendment%20Scholars%20Amicus%20Brief%20final.pdf"">amicus brief supporting the FCC</a>. There, they explained that the rules “are not subject to scrutiny under the First Amendment because they do not regulate any person’s speech” but rather regulate ISPs’ “conduct” – the act of “transmit[ting] others’ speech through [a] conduit.” Transmission isn’t a speech act because ISPs “do not act as speakers when they transmit the speech of others.”</p>
<p><strong>ISPs Don’t Have Editorial Interests Like Newspapers or Cable Co’s</strong></p>
<p>Additionally, the court made clear that ISPs, when operating as common carriers, do not have an editorial interest at stake. Judges Tatel and Srinivasan explain the point by comparing ISPs to newspapers and cable companies, which courts have held “engage in editorial discretion,” to explain that, here, “the exercise of editorial discretion is entirely absent with respect to broadband providers subject to the Order.” They continue:</p>
<p style=""margin-left:.5in;"">Unlike with the printed page and cable technology, broadband providers face no such constraints limiting the range of potential content they can make available to subscribers. Broadband providers thus are not required to make, nor have they traditionally made, editorial decisions about which speech to transmit. <em>See</em> 2015 Open Internet Order, 30 FCC Rcd. at 5753 ¶ 347, 5756 ¶ 352, 5869–70 ¶ 549. In that regard, the role of broadband providers is analogous to that of telephone companies: they act as neutral, indiscriminate platforms for transmission of speech of any and all users.</p>
<p>Here too, the court echoes the arguments in the <a href=""https://cyberlaw.stanford.edu/files/publication/files/First%20Amendment%20Scholars%20Amicus%20Brief%20final.pdf"">First Amendment scholars’ amicus brief</a>:</p>
<p style=""margin-left:.5in;"">Unlike newspapers and cable companies, broadband providers do not and need not exercise editorial control in order to determine how to fill a limited number of newspaper column inches or television channels. There is no limit to the applications, content, and services available over the Internet, and no technological constraint that prevents broadband providers from offering their users access to the entire Internet. Broadband Internet access service, as described above, is not the provision of a curated body of the Internet’s “greatest hits,” nor is there any technological reason why it has to be. Instead, that service gives users a connection over which they select for themselves the content they want to send and receive. It is much more like traditional phone networks; there is no need to “edit” or “select” who can make or receive phone calls.</p>
<p><strong>Even If ISPs Eventually Provide Content, Their Common Carrier Status and Its Immunity From First Amendment Scrutiny Isn’t Undermined</strong></p>
<p>The court acknowledged that if ISPs decide to provide content – for example, writing a Comcast or Verizon blog – then that content would qualify for First Amendment protection. But it made clear that such First Amendment protected activity doesn’t transform the common carrier component of what ISPs do such that it, too, is vulnerable to a constitutional attack. </p>
<p>Here’s the relevant paragraph from the opinion, which puts this point in context:</p>
<p style=""margin-left:.5in;"">Because the rules impose on broadband providers the kind of nondiscrimination and equal access obligations that courts have never considered to raise a First Amendment concern—i.e., the rules require broadband providers to allow “all members of the public who choose to employ such facilities [to] communicate or transmit intelligence of their own design and choosing,” <em>Midwest Video</em>, 440 U.S. at 701 (internal quotation marks omitted)—they are permissible. Of course, insofar as a broadband provider might offer its own <em>content</em>—such as a news or weather site—separate from its internet access service, the provider would receive the same protection under the First Amendment as other producers of internet content. But the challenged rules apply only to the provision of internet access as common carriage, as to which equal access and nondiscrimination mandates present no First Amendment problem. (emphasis in original)</p>
<p><strong>But the Court Leaves the Door Open to First Amendment Claims If ISPs Develop “Curated Internet Experience[s]”</strong></p>
<p>However, the court explains, if ISPs “choose to exercise editorial discretion—for instance, by picking a limited set of websites to carry and offering that service as a curated internet experience—it might then qualify as a First Amendment speaker.” Though the court doesn’t develop the argument because the net neutrality Order doesn’t cover these types of providers, it leaves the door open to the possibility of ISPs having an editorial interest.</p>
<p>Notably, the court used the word “might” – curating an internet experience <em>might </em>implicate an editorial interest and trigger the First Amendment. And it’s tricky to judge hypothetical curated experiences without facts. But to the extent that corporations use First Amendment arguments to undercut the principles of a free and open internet, judges should be skeptical, and should remember that users, consumers, and citizens have First Amendment interests, too.</p>
",Architecture and Public Policy,2016-06-14 20:31,428,Morgan Weiland,News
14329,,United States,0,0,A Big Win in the Second Circuit for Vimeo and the DMCA Safe Harbors (Post 1 of 3),Copyright,"<p>            <strong><em>What follows is the first of three posts on today's long-awaited decision by the Second Circuit Court of Appeals in </em>Capitol Records v. Vimeo<em>.</em></strong></p>
<p>            Capitol’s lawsuit against Vimeo, running in federal court in New York since 2009, raised important and unsettled questions concerning the scope of safe harbors for online intermediaries under the Digital Millennium Copyright Act (17 U.S.C. § 512)—questions remaining in the wake of the same court’s landmark decision in <em>Viacom v. YouTube </em>(2012). Three issues were in play in this case: (1) whether the safe harbors—which are a creature of federal copyright law—may be raised as a defense to allegations of infringement involving pre-1972 sound recordings, which are not within the scope of federal copyright law; (2) whether a service provider can be charged with “red flag” knowledge of infringement if its employee views a video containing all or almost all of a popular sound recording; and (3) whether Vimeo showed “willful blindness” to its users’ infringements and was thereby disqualified from the safe harbors.</p>
<p><strong>(1) Applicability of the Safe Harbors for Infringements of Pre-1972 Sound Recordings</strong></p>
<p>            Sound recordings made prior to February 15, 1972 are protected by state, not federal copyright law. Capitol Records and its co-plaintiffs argued on that basis that federally created safe harbors from infringement liability should not apply to claims alleging infringement of the copyrights in those recordings. The district court accepted that argument “without discussion,” based on an analysis (from 2011, during the course of the litigation) by the U.S. Copyright Office. The Second Circuit today reversed that holding, criticizing the Copyright Office in exceedingly polite but strong terms for a wrong interpretation of the statute and a misapplication of canons of construction. The court acknowledged that it should give ""appropriate deference to [the Office's] reasonably persuasive interpretations of the Copyright Act,"" but it concluded that the Office's interpretation in this instance did not fall under that umbrella. </p>
<p>            Rejecting outright the Office’s interpretation of the statute, the Second Circuit began its analysis with the premise that the safe harbors provide a defense for claims of “infringement of copyright.” Whereas the Copyright Office maintained that the statute defines “infringement” exclusively as the infringement of federal copyright, the court pointed out that the Act contains no definition of “infringement” that is thus limited. In fact, the Act contains no definition of “infringement” at all. It provides a statutory remedy for the infringement of federally created copyrights, but that’s not the same as saying that it precludes a statutory defense for the infringement of state created copyrights. Moreover, the court said, if Congress had intended to limit the range of infringements covered by the safe harbors to those involving federal copyrights, it could have followed the words “infringement of copyright” in section 512 with the phrase “under this title,” which appears in many other places in the statute. It didn’t. And that, the court said, was no accident.</p>
<p>            Moving from the language of the statute to the underlying policies, the court concluded that Congress did not intend to limit the scope of the safe harbors to infringements of federal copyrights when it hammered out the compromise embodied in the DMCA. The purpose of the safe harbors was “to make economically feasible the provision of valuable Internet services while expanding protections of the interests of copyright owners through the new notice-and-takedown provision.” Had Congress left pre-1972 sound recordings out of the DMCA calculus, service providers would have remained exposed to a large swath of the potentially crippling liability from which the safe harbors were intended to insulate them. As a matter of policy, such a bifurcated (i.e., federal vs. state) and partial approach to limiting liability makes no sense. Thus, the court held, the DMCA must be read, as the statutory language dictates, to include safe harbor from damages for infringements of state copyrights, including those on pre-1972 sound recordings.           </p>
<p>            The court’s analysis of the pre-1972 issue in this case is perhaps most remarkable for its pointed critique of the Copyright Office’s interpretation of the scope of the safe harbors. Over the years, the Office has consistently taken official positions that favor corporate right holders, even in cases where the statute is readily or reasonably susceptible to readings that support other interests and outcomes. It is unusual, however, to see a court take so dim a view of the Copyright Office's input on a matter of substantive copyright law. This decision is also notable because it clears up some (though by no means most) of the current chaos confronting online services with respect to copyrights in pre-1972 sound recordings. </p>
","Copyright and Fair Use, Intermediary Liability",2016-06-16 15:05,1046,Annemarie Bridy,News
14330,,United States,0,0,A Big Win in the Second Circuit for Vimeo and the DMCA Safe Harbors (Post 2 of 3),Copyright,"<p><em><strong>What follows is the second of three posts on </strong></em><strong>Capitol Records v. Vimeo</strong><em><strong>. </strong></em><strong><em>The first post is <a href=""https://cyberlaw.stanford.edu/blog/2016/06/big-win-second-circuit-vimeo-and-dmca-safe-harbors-post-1-3"">here</a>.</em></strong></p>
<p>            Capitol Records' lawsuit against Vimeo, running in federal court since 2009, raised important and unsettled questions concerning the scope of safe harbors for online intermediaries under the Digital Millennium Copyright Act (17 U.S.C. § 512)—questions remaining in the wake of the Second Circuit's landmark decision in <em>Viacom v. YouTube </em>(2012). Three issues were in play in this case: (1) whether the safe harbors—which are a creature of federal copyright law—may be raised as a defense to allegations of infringement involving pre-1972 sound recordings, which are not within the scope of federal copyright law; (2) whether a service provider can be charged with “red flag” knowledge of infringement if its employee views a video containing all or almost all of a popular sound recording; and (3) whether Vimeo showed “willful blindness” to its users’ infringements and was thereby disqualified from the safe harbors.</p>
<p><strong>(2) Establishing Proof of “Red Flag” Knowledge</strong></p>
<p>            As a condition for eligibility, the safe harbors require service providers to remove material that they either actually know or should know from surrounding facts or circumstances (i.e., “red flags”) to be infringing. In <em>Viacom</em>, the Second Circuit interpreted red flag knowledge under the DMCA to mean a provider’s subjective awareness of facts or circumstances from which specific instances of infringement would be objectively obvious to a reasonable person. The standard is a mixed subjective/objective one that requires courts to wade into the swampy terrain of what a hypothetical reasonable person should be able to discern in light of the facts in front of her.</p>
<p>          District courts deciding safe harbor disputes have applied the standard for red flag knowledge in an unpredictable way. This is true in part because ""reasonableness"" in any area of the law is an elusive concept and in part because there has been (to my knowledge, anyway) no authoritative definition in the context of the DMCA of what a hypothetical “reasonable tech company employee"" should be expected to know concerning potential instances of infringement that she might run across at work. This case helps to fill that vacuum, sensibly establishing that a reasonable person for DMCA purposes is none other than copyright law’s “ordinary person”—more specifically, one who is “not endowed with specialized knowledge or expertise concerning music or the laws of copyright.”</p>
<p>            Considered from the perspective of an ordinary employee of a tech company, the court held, the act of viewing some part of a user-uploaded video that contains all or virtually all of a “recognizable” song does not necessarily give rise to red flag knowledge (i.e., does not make infringement objectively obvious). The court offered several reasons why this is true: (1) the employee might not have viewed the whole video (and therefore might not have known that it contained all or virtually all of a song); (2) the employee’s reason for viewing the video might have been wholly unrelated to copyright; (3) the employee might not actually have recognized the “recognizable” song in question for a variety of reasons, including the employee’s age and taste in music; and (4) the employee might have had no expertise in copyright and could therefore not have distinguished between infringing and non-infringing content. In light of these factors, the court said, a plaintiff must do more to prove a defendant's red flag knowledge than simply offer proof that an employee to some extent viewed a video that contained all or most of a popular copyrighted song.</p>
<p>            Capitol Records argued that requiring plaintiffs to show more to establish the objective obviousness of an infringement would collapse red flag knowledge into actual knowledge, effectively reading red flag knowledge out of the statute as a separate basis for disqualification from safe harbor. The court disagreed, writing that “[i]f the facts actually known by an employee of the service provider make infringement obvious, the service provider cannot escape liability…on the ground that the person with knowledge of those facts never thought of the obvious significance of what she knew in relation to infringement.” To put it another way, awareness of facts that would make an infringement obvious to a reasonable person can disqualify a provider without any proof that the particular employee in question put two and two together to reach a subjective conclusion that material was infringing. As long as a reasonable person would have done the math, the plaintiff's burden is met regardless of what the provider's employee believed. By contrast, for a provider to be disqualified based on an employee’s actual knowledge, the employee must be shown to have reached a subjective conclusion that the material was infringing. Actual knowledge and red flag knowledge are thus distinct and distinguishable, with a lower burden of proof for the latter. The math in this case was just not as easy as the plaintiffs made it out to be, for the reasons the court cited. [Editorial note: Copyright math in general is hard, especially for people ""not endowed with specialized knowledge"" of it.]</p>
<p>            Even as the court rejected the plaintiffs’ argument that a holding for Vimeo would gut red flag knowledge, it acknowledged that the scope of red flag knowledge under its application of the statute is narrow. Such knowledge, it recognized, is likely to be provable in only a small number of cases. “Assuming this is so,” the court wrote, “it is of no significance.” A narrow scope for red flag knowledge, the court explained, is consistent with Congress’ primary goals for the safe harbors, which were to be accomplished primarily through the operation of the notice-and-takedown framework. That framework, after all, requires no inferences or guessing and is the true engine of the DMCA when it comes to content removal.</p>
<p>            Commentators unhappy with the outcome of this case are <a href=""https://twitter.com/devlinhartline/status/743545039003987968"">lamenting</a> the “death of red flag knowledge,” but red flag knowledge is alive and well. It’s just not trivially easy to prove, and that’s as it should be given both the goals of the statute and the nasty consequences (i.e., potentially bankrupting statutory damages) for providers that don’t qualify for safe harbor. The Second Circuit appreciated in this case that a broad and uncertain scope for red flag knowledge would make asserting the safe harbors little more than a game of chance, which is definitely not what Congress intended.</p>
","Copyright and Fair Use, Intermediary Liability",2016-06-17 11:13,1046,Annemarie Bridy,News
14354,,United States,0,0,A Big Win in the Second Circuit for Vimeo and the DMCA Safe Harbors (Post 3 of 3),Copyright,"<p><strong><em>What follows is the last of three posts on </em>Capitol Records v. Vimeo<em>. The first and second posts are <a href=""https://cyberlaw.stanford.edu/blog/2016/06/big-win-second-circuit-vimeo-and-dmca-safe-harbors-post-1-3"">here </a>and <a href=""https://cyberlaw.stanford.edu/blog/2016/06/big-win-second-circuit-vimeo-and-dmca-safe-harbors-post-2-3"">here</a>.</em></strong></p>
<p>            Capitol Records' lawsuit against Vimeo, running in federal court since 2009, raised important and unsettled questions concerning the scope of safe harbors for online intermediaries under the Digital Millennium Copyright Act (17 U.S.C. § 512)—questions remaining in the wake of the Second Circuit's landmark decision in <em>Viacom v. YouTube </em>(2012). Three issues were in play in this case: (1) whether the safe harbors—which are a creature of federal copyright law—may be raised as a defense to allegations of infringement involving pre-1972 sound recordings, which are not within the scope of federal copyright law; (2) whether a service provider can be charged with “red flag” knowledge of infringement if its employee views a video containing all or almost all of a popular sound recording; and (3) whether Vimeo showed “willful blindness” to its users’ infringements and was thereby disqualified from the safe harbors.</p>
<p><strong>(3) Willful Blindness and the No-Duty-to-Monitor Rule</strong></p>
<p>            Appellate courts have considered the interaction between the DMCA safe harbors and the common law doctrine of willful blindness in two previous cases: <em>In re Aimster Copyright Litigation</em> (6th Circuit, 2003) and <em>Viacom</em>. Citing <em>In re Aimster</em>, the Second Circuit held in <em>Viacom</em> that a plaintiff may prove that a provider had potentially disqualifying knowledge of its users’ infringements through a showing that the provider was willfully blind to those infringements, meaning that the provider made a “deliberate effort to avoid guilty knowledge” of them.</p>
<p>            YouTube argued in <em>Viacom</em> that Congress abrogated the doctrine of willful blindness in the DMCA by including a provision—section 512(m)—that absolved service providers of any duty to affirmatively monitor their services for infringing activity. The court in <em>Viacom</em> was only partially sympathetic to YouTube's argument, holding that section 512(m) limits but does not completely abrogate the common law doctrine. It held that “the willful blindness doctrine may be applied, in appropriate circumstances, to demonstrate knowledge or awareness of specific instances of infringement under the DMCA.” The <em>Viacom </em>court did not have an opportunity, however, to consider what “appropriate circumstances” might be. This case gave the Second Circuit that opportunity.</p>
<p>            The tension between willful blindness doctrine and the no-duty-to-monitor rule in section 512(m) is quickly apparent. Resolving that tension necessitates tricky line drawing between an innocent lack of knowledge that is wholly permissible under the DMCA (because of section 512(m)) and a guilty lack of knowledge that can disqualify a provider from safe harbor. The salient question with respect to willful blindness under the DMCA is this: What is the difference between a provider's not knowing because it didn’t go out of its way to find out and not knowing because it did go out of its way not to find out? The court answered that question correctly in this case.</p>
<p>            Capitol Records made three arguments for Vimeo’s willful blindness: (1) Vimeo should be held willfully blind because it monitored for infringement of <em>visual</em> content of videos but not <em>audio</em> content; (2) Vimeo’s awareness of facts suggesting a likelihood of infringement gave rise to a duty to investigate further, which it failed to fulfill, thus demonstrating willful blindness; and (3) Vimeo encouraged users to post infringing material and then turned a blind eye to the subsequent presence of that infringing material on its system. Considering the limiting effect of section 512(m) on each of these arguments, the court rejected all of them.</p>
<p>            First, the court said, the no-duty-to-monitor rule would mean little if a provider’s voluntary decision to engage in <em>some</em> monitoring were held to trigger a mandatory commitment to engage in <em>wholesale</em> monitoring. As to the second argument, the court was not persuaded that facts suggesting a likelihood of infringement give rise to any investigative duty on the part of a service provider. The duty to remove material in instances involving less than actual knowledge is limited in the statute to the discovery of facts that make infringement objectively obvious (i.e., red flag knowledge); that duty does not arise in situations where facts do no more than raise a suspicion that infringing activity is occurring. The court reasoned that requiring service providers “constantly to take stock of all information their employees may have acquired that might suggest the presence of infringements in user postings, and to undertake monitoring whenever some level of suspicion was surpassed…would largely undo the value of [section] 512(m).” For that reason, willful blindness doctrine cannot be interpreted to create a more relaxed form of scienter than red flag knowledge. A whiff of suspicion is not enough.</p>
<p>            The court was more receptive to the plaintiffs’ third argument. It assumed <em>arguendo</em> that a provider could lose the protection of section 512(m) by adopting a general policy of encouraging users to infringe and then turning a blind eye to the resulting infringements; however, it doubted the plaintiffs’ claim that Vimeo had adopted any such policy. All the evidence showed was that Vimeo’s employees engaged in “a handful of sporadic instances (amongst the millions of posted videos)” in which they encouraged infringement. That alone could not give rise to some kind of blanket waiver of section 512(m).</p>
<p>            Moreover, the court said, the sporadic infringements that Vimeo’s employees encouraged were not infringements of the <em>plaintiffs’</em> copyrights. The court emphasized in <em>Viacom</em> that knowledge under the DMCA (whether actual or red flag) relates to specific instances of infringement at issue in a given case and not to infringement in a general sense. Because willful blindness operates as a proxy for knowledge, it also must be shown under <em>Viacom </em>to relate to specific instances of infringement at issue in the case. Applying that rule, a plaintiff cannot succeed in showing that a provider was willfully blind to infringement of <em>its</em> copyrights (or willfully blind in some general sense) simply by showing that the provider’s employees encouraged the infringement of <em>somebody’s</em> copyrights. Yet that was all the evidence the plaintiffs offered.</p>
<p>            In rejecting all of the plaintiffs' arguments for Vimeo's willful blindness, the court made clear in this case that there is a limited scope for the doctrine given the no-duty-to-monitor rule in section 512(m). It left open the question of whether a provider could incur a duty to monitor, despite section 512(m), by adopting a general policy of encouraging infringement. It extended <em>Viacom</em>’s rule concerning specific instances of infringement to claims alleging willful-blindness-as-knowledge under the DMCA. It also suggested that the outcome of its willful blindness analysis might have been different if the plaintiffs could have shown that Vimeo’s employees encouraged users to post infringing material in which the plaintiffs actually owned the copyrights.   </p>
","Copyright and Fair Use, Intermediary Liability",2016-06-20 14:01,1046,Annemarie Bridy,News
14375,,United States,0,0,CDA 230 Problems: Do Algorithms Threaten to Undermine Speech Protections?,Freedom of Expression,"<p>A few weeks ago, after I published a <a href=""https://cyberlaw.stanford.edu/blog/2016/05/facebook-fourth-estate-two-questions-lawyers-should-answer"">blog post</a> raising the question of what might happen to CDA 230 when internet intermediaries like Facebook invoke First Amendment protections – which civil liberties lawyers’ were calling on Facebook to do in the wake of the controversy over its trending newsfeed – I was fortunate enough to have a sustained email exchange with UCLA Law Professor <a href=""https://law.ucla.edu/faculty/faculty-profiles/eugene-volokh/"">Eugene Volokh</a>. There, he pushed back on my claim that there is a tension between the First Amendment and CDA 230, pointing to precedent about intermediaries – including bookstores (<em>Smith v. California</em>; <em>Fort Wayne Books, Inc. v. Indiana</em>), newspapers (<em>New York Times Co. v. Sullivan</em>), and movie theatres (<em>Freedman v. Maryland</em>; <em>Vance v. Universal Amusement Co.</em>) – that show an intermediary can claim both constitutional rights and statutory protections in the same piece of content (e.g. selling a book, running an ad, or screening a film). His reading of the law is correct, and can and indeed has been applied to the online context, including to website operators and bloggers. So within this framework – within the scope of what types of facts have been contemplated by precedent – his skepticism was valid.</p>
<p>Professor Volokh’s incisive questions pushed me to clarify the distinction between the world he described, where intermediaries could invoke both the First Amendment and CDA 230 (or similar statutory immunity) in the same piece of content, with the emerging world that I’m interested in, where precedent is limited when applied to new situations that are substantially different in kind such that analogic reasoning fails. From this perspective, we can see the impending clash between the First Amendment and CDA 230, and, as a result, can ask the normative question of when the First Amendment should – or should not – apply.</p>
<p><span style=""line-height: 1.3em;"">This blog post represents the arguments and thoughts developed through my email exchange with Professor Volokh, to whom I am indebted for his time and thoughtful questions. It proceeds in three parts.</span></p>
<p>First, I explain the functional transformation happening in online intermediaries that changes their relationship to third-party content, which results in an open legal question as to how and if both the constitutional rights and statutory protections apply.</p>
<p><span style=""line-height: 1.3em;"">Second, I discuss how this open legal question will result in a tension between the First Amendment and CDA 230, such that the former may cannibalize the latter. This outcome turns on two factors: technological, business, and legal dynamics pushing intermediaries to the boundaries of the functional spectrum so they act more like speakers and editors on the one hand, and courts that are primed to reject any expansion of CDA 230 on the other.</span></p>
<p><span style=""line-height: 1.3em;"">Third, I argue that, in this context where we’ve reached the limits of precedent – where it’s unclear how the First Amendment and CDA 230 relate to one another – ethical considerations and especially a concern with the public interest should drive how we think about how the law ought to apply. This methodology matters not only for tackling intermediary speech questions, but moreover offers an approach for academics thinking through questions of First Amendment coverage, or what </span><a href=""http://scholarship.law.wm.edu/cgi/viewcontent.cgi?article=3592&context=wmlr"" style=""font-size: 13px; line-height: 1.3em;"">Frederick Schauer</a><span style=""line-height: 1.3em;""> describes as the right’s “scope of application.”</span></p>
<p><strong style=""line-height: 1.3em;"">1.     </strong><strong style=""line-height: 1.3em;"">Changing Functions of Intermediaries</strong></p>
<p><span style=""line-height: 1.3em;"">As a preliminary matter, it’s helpful to understand how the function of intermediaries is changing such that it is no longer clear how they can claim both First Amendment rights and CDA 230 immunities in the same content, as they have been able to do. (The blogger who has a First Amendment right to host comments, but a CDA 230 immunity from the content of those comments is a quintessential example.) The key insight is that today there is a spectrum of functional roles for intermediaries, due largely to the affordances of digital media technologies, which enables them to play different roles than they could in the past. As a result, these functional changes distinguish emerging intermediaries from those contemplated by our First Amendment precedent.</span></p>
<p>The precedents that Professor Volokh cites about bookstores, movie theatres, and newspapers are useful to understand online intermediaries that perform similar functions to those brick-and-mortar intermediaries, like online newspapers and online bookstores. For First Amendment purposes, these intermediaries function like neutral hosts or conduits, making a basic editorial choice to either sell or not sell a book, run or not run an ad, or screen or not screen a film. (Of course, brick-and-mortar intermediaries could have transformed the content that they were selling, but they didn’t; it wasn’t common practice, for instance, for theatre owners to splice new images into a third party’s film.) But they can also operate non-neutrally; as Professor Volokh points out, newspapers are protected if they edit op-eds, excerpt letters to the editor, or impose editorial standards around advertisements. Further, intermediaries can seek First Amendment protection for exercising non-neutral editorial judgments, like choosing to exclude certain viewpoints with which they disagree (<em>Miami Herald v. Tornillo</em>; <em>Hurley v. Irish-American Gay, Lesbian and Bisexual Group of Boston</em>).  </p>
<p><span style=""line-height: 1.3em;"">But the functional role that intermediaries can play online is qualitatively different. Intermediaries can be more than neutral hosts or ideological content curators. They can be editors and speakers with respect to third-party content, and can engage in transforming that content in qualitative ways on a scope and scale unparalleled in the analog world. Consider, for example, if an online content aggregator deployed an algorithm that edited headlines of third-party content to generate more clicks, so that sometimes it changed nothing, sometimes it changed a word or punctuation mark, and other times it changed the headline completely.</span></p>
<p>This hypo, which illustrates the functional spectrum available for online intermediaries, complicates the application of precedent that finds a constitutional right and statutory immunity for neutral hosts and non-neutral content curators in the same piece of third-party content to situations where intermediaries are more robust editors or speakers with respect to that content. In other words, when the intermediary takes on a more robust function – editorial and speaker functions that are more available today due to the affordances of digital media technologies – it is unclear if both First Amendment rights and CDA 230 protections attach. Specifically, the expansion of the functional spectrum available to online intermediaries with respect to how they interact with third-party content simultaneously bolsters their First Amendment claim and weakens their CDA 230 immunity argument. As a result, how the First Amendment, CDA 230, or both apply to online intermediaries playing new functional roles is an open legal question.</p>
<p><strong style=""line-height: 1.3em;"">2.     </strong><strong style=""line-height: 1.3em;"">Resulting Tension Between the First Amendment & CDA 230</strong></p>
<p><span style=""line-height: 1.3em;"">This open legal question will only become more salient due to technological affordances, business imperatives, and legal ambiguity around the scope of CDA 230. And this change will take place in a context where courts have expressed their disdain for CDA 230, suggesting that the statutory claim will become vulnerable if courts are given an out via a constitutional argument. The result might be that the integrity of CDA 230 is undercut by First Amendment claims (a concern that prompted my </span><a href=""http://cyberlaw.stanford.edu/blog/2016/05/facebook-fourth-estate-two-questions-lawyers-should-answer"" style=""font-size: 13px; line-height: 1.3em;"">earlier blog post</a><span style=""line-height: 1.3em;"">).</span></p>
<p><strong><em>Technological, business, and legal forces push intermediaries in new functional directions.</em></strong></p>
<p>First, social media and technology companies likely will blur and push the boundaries of the ways that they transform, interact with, and curate third-party speech. Even if the Facebook curation example does not rise to this level – one could make an argument either way as to whether or not it’s functioning as an editor – one can imagine a variety of more aggressive actions that intermediaries could take (recall our example of an algorithm that substantively changes headlines of third-party content). The combination of algorithms, machine learning, and big data strongly suggest that companies will have the opportunity and the business incentive to transform third-party content in new ways (for instance, to transform headlines to get more clicks).</p>
<p>Second, these changes will take place in an ambiguous legal context. As <a href=""https://www.eff.org/issues/bloggers/legal/liability/230"">EFF correctly explains</a> in its legal guide for bloggers, “courts have not clarified the line between acceptable editing and the point at which you become the ‘information content provider.’” In other words, current law imagines either (1) an intermediary that doesn’t change content and so gets both CDA 230 and First Amendment protections (the blogger who hosts comments is the quintessential example) or (2) an intermediary that changes content so much that, while it retains First Amendment rights, it loses CDA 230 immunity because it acts like an information content provider.</p>
<p>What is interesting and new – and poses the risk to CDA 230 that motivated my <a href=""http://cyberlaw.stanford.edu/blog/2016/05/facebook-fourth-estate-two-questions-lawyers-should-answer"">earlier blog post</a> – is a qualitatively different type of online property that lives on the boundaries of CDA 230 and is able to play a variety of functional roles. Because these online properties will be poised to claim First Amendment protections and CDA 230 immunity, the statutory claim will wade into the uncharted legal waters between “acceptable editing” and total transformation of third-party content. Regardless of whether or not the current Facebook trending news example rises to the level of an intermediary playing a new functional role as editor or speaker, what matters is that it’s a harbinger of things to come; social media and technology companies will innovate and push the boundaries of how First Amendment precedent has imagined engagement with third-party content, either as a neutral host or ideological curator. (Again, think of the permutations of the algorithmically edited headline hypo.)</p>
<p><strong style=""line-height: 1.3em;""><em>Courts are primed to limit CDA 230’s application to intermediaries’ new functional roles.</em></strong></p>
<p>These changes put courts in a position to decide between constitutional and statutory claims. Specifically, they will have to decide whether or not the new activity in which these online properties are engaged amounts to that of an information content provider, a question at the boundaries of CDA 230. And because of courts’ explicit disdain for the statute, litigants presenting functionally contradictory arguments – a constitutional interest as editor or speaker of a potentially new kind, and a statutory interest as a host or conduit – give courts the perfect opportunity to limit the statute: reject an expansion of CDA 230 and rely on the First Amendment claim.</p>
<p>Consider the opening lines of a First Circuit case, <em><a href=""http://media.ca1.uscourts.gov/pdf.opinions/15-1724P-01A.pdf"">Doe v. Backpage.com</a></em>, decided earlier this year against the plaintiffs because of CDA 230: “This is a hard case—hard not in the sense that the legal issues defy resolution, but hard in the sense that the law requires that we, like the court below, deny relief to plaintiffs whose circumstances evoke outrage.” If intermediaries increasingly portray themselves as “creat[ing] or develop[ing] [] information provided through the Internet or any other interactive computer service” (i.e. as an “information content provider” per <a href=""https://www.law.cornell.edu/uscode/text/47/230"">CDA 230(f)(3)</a>) to claim First Amendment rights but simultaneously claim CDA 230 protections – in other words, if intermediaries perform contradictory functions for constitutional and statutory purposes – then courts might use the First Amendment as an out with which to reject CDA 230. The point is that the threat of First Amendment claims cannibalizing CDA 230 is not hypothetical; it’s quite real given where courts are likely going.</p>
<p>So for emerging legal claims to which the Facebook example points, courts may not find CDA 230 immunity exists at all. The result? At minimum, a hardening of the current boundary of the statute. And by not expanding CDA 230 to these new types of claims – which I think will be much more prevalent going forward than those by the blogger hosting comments or the online bookstore – then the overall scope of CDA 230’s application to online properties will be diminished. The point is that when these new types of online properties claim both First Amendment and CDA 230 protections for new types of activities, they may offer courts the opportunity to limit and effectively diminish CDA 230 by preferring the First Amendment claim. </p>
<p>Is this inevitable? No. What’s important is that we think through these very real possibilities – given the changing nature of technology, legal ambiguity, corporate interests, and courts’ motivations – when we argue that potentially new types of activities should be covered by the First Amendment, as lawyers are doing in the Facebook trending newsfeed controversy.  </p>
<p><strong>3.     </strong><strong>Ethics Should Inform How to Act at the Boundaries of Precedent </strong></p>
<p><span style=""line-height: 1.3em;"">When we reach the limits of precedent – here, of the dual application of First Amendment rights and CDA 230 immunity – academics and the public have an opportunity to make normative arguments about how the law ought to apply. To get a handle on the ethical questions at stake, let’s consider the consequences of the argument that intermediaries who push existing functional boundaries and perform contradictory roles for constitutional and statutory purposes – seeking to be speakers and not to be speakers, to be editors and not to be editors with respect to the same content – should be able to invoke both the First Amendment and CDA 230. This creates an ethical dilemma for the public. How can the public know what type of speaker they are dealing with if an individual or organization simultaneously claims two contradictory identities? More importantly, how can the public hold an individual or organization accountable if it’s unclear what role that individual or organization is playing in our democracy?</span></p>
<p>This question is most salient in the context of the press. Let’s consider the Facebook trending newsfeed example. If Facebook invokes editorial control in its trending newsfeed, then it understands its actions as similar to those of the press. While that is a perfectly coherent First Amendment position, it’s hotly contested. <a href=""https://medium.com/@BuzzFeed/a-first-amendment-for-social-platforms-202c0eab7054#.m6dy0qkml"">BuzzFeed’s Nabiha Syed and Ben Smith</a> suggest that platforms are not speakers or journalists, explaining that while “[t]hey power social connection, free expression, and the distribution of news and entertainment on an unprecedented scale,” they “largely don’t create speech themselves,”  and <a href=""http://www.aejmc.org/home/2016/06/pac-060316/"">The Association for Education in Journalism and Mass Communication</a> explicitly argues that Facebook “should be judged as a social media platform, not as a news media company.” Even if Facebook positions itself as the press, that’s a role to which a host of responsibilities attach, a point that has been variously made during the recent Facebook brouhaha by <a href=""http://www.huffingtonpost.com/danah-boyd/facebook-must-be-accountable-to-the-public_b_10024786.html"">danah boyd</a> (calling for public accountability) and <a href=""http://www.nytimes.com/2016/05/23/business/facebooks-troubling-one-way-mirror.html"">New York Times media columnist Jim Rutenberg</a> (calling for more transparency).</p>
<p><span style=""line-height: 1.3em;"">By positioning itself as part of the press, and claiming the rights that attach, the public will have an expectation that Facebook, or at least the trending newsfeed part of it, will also take up the attendant responsibilities of the press: that it adheres to certain ethical standards and can be held accountable as such. (Of course, this is an ideal to which the press strives and often fails to achieve, but strives nonetheless.) But if Facebook can in its next breath argue that it’s not a speaker or editor in the very same content for which it just claimed First Amendment protections, all bets are off: that move totally upends the public’s ability to know what role Facebook is playing and how to hold it accountable, and breaks the rights-responsibility nexus that the public expects in its Fourth Estate.</span></p>
<p>Of course, the question is much bigger than Facebook. What’s at stake is the legal and social identity of new types of actors – hybrid content curators and content creators – the public’s ability to understanding those actors’ identity, and the public’s ability to then hold them accountable. This normative inquiry should animate not only questions about online intermediaries and how constitutional rights and statutory protections apply to them, but also should inform the broader academic question of First Amendment coverage. When we evaluate the application of speech and press rights to new actors and new situations, we should not be guided merely by analogic thinking from precedent, but moreover by ethical considerations animated by the public interest.       </p>
<p><strong>P.S. </strong></p>
<p>Thanks also to CIS Director of Intermediary Liability <a href=""http://cyberlaw.stanford.edu/about/people/daphne-keller"">Daphne Keller</a> and rising Harvard Law School 3L <span style=""color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: normal; background-color: rgb(255, 255, 255);"">and Chair of the Harvard Law Review Forum</span><span style=""line-height: 1.3em;""> </span><a href=""https://cyber.law.harvard.edu/people/aliciasn"" style=""font-size: 13px; line-height: 1.3em;"">Alicia Solow-Niederman</a><span style=""line-height: 1.3em;""> for their insightful feedback and helpful comments as I thought through these questions. </span></p>
",Intermediary Liability,2016-06-22 21:59,428,Morgan Weiland,News
14484,European Union,,0,0,126 Leading Academics to Europe’s Telecom Regulators: Protect the Open Internet in Europe,Other,"<p>Today, 126 academics from Europe and around the world published an <a href=""https://cis-static.law.stanford.edu/cis/downloads/AcademicsLettertoBEREC20160719final.pdf"">open letter</a> to European telecom regulators urging them to protect the open Internet in Europe. Regulators are currently working on guidelines that will determine how Europe’s new net neutrality law will be applied in practice. The letter urges regulators to adopt three key changes to the guidelines to preserve meaningful net neutrality in Europe: (1) prevent fast lanes on the Internet; (2) provide certainty on zero-rating; and (3) limit discriminatory traffic management. The letter was submitted to the regulators on Monday, the last day of the public consultation on the topic.</p>
<p>You can read the full letter <a href=""https://cis-static.law.stanford.edu/cis/downloads/AcademicsLettertoBEREC20160719final.pdf"">here</a>.</p>
<p>The signatories include academics from a wide range of countries and subject areas, as well as academics specializing in fields relevant to the net neutrality debate. They come from universities such as the London School of Economics and Oxford University in the UK, the French National Centre for Scientific Research in France, the KTH Royal Institute of Technology in Sweden, the University of St. Gallen in Switzerland, the Humboldt Universität zu Berlin, the Technical University Berlin, Ludwig Maximilians-Universität in Munich, the RWTH Aachen in Germany, American top universities such as Harvard, Stanford, and Berkeley, the National Law University Delhi and the Indian Institute of Technology, Delhi, in India, and many more.</p>
<p>As academics, we need an open Internet: We use the Internet to publish and share our work with other academics and the public, teach students at our institutions and further afield, and collaborate with researchers around the world. The European net neutrality guidelines will either preserve or frustrate that ability.</p>
<p>But as we explain in the letter, an open Internet is critical for anybody:</p>
<p style=""margin-left:.5in;"">“Enshrining sound safeguards for net neutrality within the guidelines is critical for allowing people in Europe and around the world to enjoy the full benefits of competition and exercise their rights to privacy, freedom of expression, freedom of assembly, and freedom to conduct a business online.”</p>
<p style=""margin-left:.5in;"">“As professional seekers, imparters, and receivers of information and ideas, we understand the pivotal importance of freedom of expression and urge you to take all necessary measures to guarantee that all individuals have the right to freely communicate and innovate without permission, so that they can truly be active participants in the information society, rather than mere consumers.”</p>
<p>Indeed, we join a broad, diverse movement urging regulators to strengthen the guidelines to protect the open Internet in Europe. The movement includes entrepreneurs, investors, technology companies and start-up organizations, public broadcasters, German media regulators, journalists, newspaper organizations, public interest and consumer groups from <a href=""https://www.savetheinternet.eu/en/"">Europe</a> and <a href=""https://www.laquadrature.net/files/NN_letter_BEREC_20160502.pdf"">around the world</a>, consumer watchdogs, <a href=""https://medium.com/@ValarieKaur/5-reasons-why-net-neutrality-is-vital-for-the-future-of-faith-in-europe-c9e5716a35d7#.azdprbq3s"">faith</a> <a href=""http://waccglobal.org/articles/save-the-internet-in-europe"">groups</a> – and more than <a href=""https://www.savetheinternet.eu/en/"">500,000 concerned citizens</a> who participated in the public consultation asking for strong net neutrality rules.</p>
<p>Together, we are sending a clear, unified message to the EU: protect the free and open Internet.</p>
<p><strong>Why net neutrality is vital for academics</strong></p>
<p>Academics in Europe and around the world have a stake in preserving the open Internet. For example, consider the negative impact that fast lanes would have on our ability to research, collaborate, and educate. European telecom companies are pushing regulators to allow them to use a legitimate exception in the law to sidestep the law’s prohibition on fast lanes on the normal Internet. They want the power to offer fast lanes to any application or website that’s willing to pay an extra fee to reach people faster – not just to those that could not function without it. According to filings and public statements by major European telecom companies and equipment makers, this includes everyday services like online telephony, online video conferencing, or online video – services we use all the time for our work.</p>
<p>But if some companies can pay so that their content reaches people faster or works at a better quality, those who can’t pay don’t have a chance to compete and be heard. Most academics and academic institutions won’t be able to afford a fast lane. Wherever we are physically located, this will make it harder for us to collaborate and connect with people in Europe.</p>
<p><strong>What the letter urges regulators to do</strong></p>
<p>We urge the European regulators to adopt three changes to its guidelines to ensure meaningful net neutrality in Europe:</p>
<ol><li><em>Prevent fast lanes on the normal Internet:</em> Europe’s net neutrality law bans fast lanes on the normal Internet. ISPs want to use the law’s legitimate exception for specialized services to circumvent that ban. To prevent that from happening, the guidelines should clarify that ISPs cannot use the specialized services exception to offer fast lanes to Internet applications, content, and services that can function on the normal Internet.</li>
<li value=""3""><em>Provide certainty on zero-rating:</em> Zero-rating is the practice of exempting select apps from users’ monthly data caps. Instead of leaving the evaluation of zero-rating to later case-by-case evaluation by national regulators, “the guidelines should ban harmful forms of zero-rating (such as application-specific zero-rating and zero-rating for a fee), providing legal certainty and sustainable solutions that empower individuals, rather than relegate their Internet experience to a selection of sponsored services,” as we write in the letter.</li>
<li value=""3""><em>Limit discriminatory traffic management:</em> <em>Regulators need to prevent carriers from discriminating among classes of traffic to manage their networks, unless that is the only way to address the problem. </em>The guidelines should clarify that discriminatory forms of traffic management, including practices that differentiate among classes of traffic, can only be used if less discriminatory, application-agnostic forms of traffic management are not available.</li>
</ol><p><strong>You can read the full letter <a href=""https://cis-static.law.stanford.edu/cis/downloads/AcademicsLettertoBEREC20160719final.pdf"">here</a>.</strong></p>
<p><strong>Read more</strong></p>
<p>You can read more about the problems with the guidelines in an open letter that web inventor Sir Tim Berners-Lee, Harvard Professor and leading Internet scholar Larry Lessig, and me published last week: <a href=""http://webfoundation.org/2016/07/four-days-to-save-the-open-internet-in-europe-an-open-letter/"">http://webfoundation.org/2016/07/four-days-to-save-the-open-internet-in-europe-an-open-letter/</a> (in English) and <a href=""https://netzpolitik.org/2016/offener-brief-vier-tage-bleiben-noch-um-das-offene-internet-in-europa-zu-retten/"">https://netzpolitik.org/2016/offener-brief-vier-tage-bleiben-noch-um-das-offene-internet-in-europa-zu-retten/</a> (in German).</p>
<p> </p>
<p> </p>
",Architecture and Public Policy,2016-07-21 2:35,267,Barbara van Schewick,News
14485,,Brazil,0,0,Network Neutrality in Brazil: the recently enacted Presidential Decree consolidates meaningful rules,Other,"<p>Amidst an economic and political turmoil, Brazil gave a significant step towards protection of network neutrality – the principle that keeps the Internet an open space, free from undue control by Internet service providers (ISPs). A Presidential Decree issued right before Dilma Rousseff was temporarily removed from power on May 10 consolidates the regime established by the Marco Civil – a Federal Statute known as the “Internet Bill of Rights” in Brazil - and brings clarity to the application of meaningful rules that may effectively preserve network neutrality.</p>
<p><span style=""line-height: 1.3em;"">The Internet was designed as an open platform for communication and innovation. These design principles made the network infrastructure neutral – meaning that all applications, services or content should be treated equally and the network owner had no interference over them. This design has fostered unparalleled innovation, because anyone can build applications online without intervention by network providers. As a result, entrepreneurs with few resources can launch their ideas online without paying for a faster connection to audiences or seeking permission from network providers to enter. Some of the world’s most important online innovations would not exist today without this open online environment, including Amazon, Facebook, Google, and Netflix.</span></p>
<p><span style=""line-height: 1.3em;"">However, network providers have overcome those design principles and currently have the power to treat information packets differently, i.e. to block, slow down or prioritize websites. There are many examples of these initiatives in several countries, and Brazil is not different. Skype and other phone applications have been subject to blocking practices, and there are many instances of traffic throttling against bit torrent applications. Also, prioritization through zero-rating plans has become widespread in the mobile sphere and now threatens the broadband environment with ISPs’ announced plans to significantly reduced bandwidth caps.</span></p>
<p><span style=""line-height: 1.3em;"">While some speculate that some of the practices may allow ISPs to grow their revenues and then invest more in developing networks, the discrimination of applications (either to degrade or prioritize) puts at risk the open Internet as we know it. These practices would eliminate the neutral character of the network infrastructure, creating the potential for anticompetitive conducts (when the ISP favors its own content or application) while also undermining innovation in the edges and consumer choice.</span></p>
<p><span style=""line-height: 1.3em;"">That’s why academics, regulators, and industry observers have called for regulation to codify net neutrality into law. Many countries like the US, Netherlands and Chile have established rules to preserve network neutrality. Brazil took a vital step through adopting the Marco Civil in 2014 and now takes another relevant step by issuing a Decree that consolidates the net neutrality regime.</span></p>
<p><span style=""line-height: 1.3em;"">The Marco Civil clearly establishes a statutory regime that aims at protecting network neutrality. The Statue elects several principles and targets for Internet regulation in Brazil that must be properly weighed in the interpretation of specific rules in further sections of the Statute. Notably, many of these principles are not only consistent with a meaningful network neutrality regime - they actually demand it. Article 2 expressly provides that free speech, diversity, openness, free competition, among others, are the foundations of the regulation in Brazil. Similarly, article 3 establishes the principles of the regulation of the Internet, including (i) free speech; (ii) preservation and guarantee of network neutrality, (ii) preservation of the stability and safety of the network, (iii) preservation of the participative nature of the network, and (iv) respect to different business promoted through the Internet. Finally, article 4 provides that Internet regulation must promote, among other things, (i) the access to information and the participation in culture and public matters and (ii) innovation and the diffusion of new technologies and models of use and access.</span></p>
<p><span style=""line-height: 1.3em;"">Therefore, the Marco Civil elected several principles that orbit the notion of network neutrality (free speech, openness, etc) as the basis of Internet regulation in Brazil and expressly turned the preservation and guarantee of network neutrality itself and the participative nature of the network into guiding principles for Internet regulation in Brazil. These general provisions constitute a powerful set of tools that must directly influence the interpretation of the specific rules disciplining Internet Service Providers (ISPs) behavior.</span></p>
<p><span style=""line-height: 1.3em;"">In line with those principles, article 9 sets forth a few rules that have the potential to put into force a strong neutrality regime. It provides that ISPs must treat all data packages equally and bans all forms of discrimination, but for two narrowly-defined exceptions. First, providers may prioritize emergency services, such as emergency calls to police. Second, providers can discriminate to meet “technical requirements essential to the adequate provision of services and applications.” These exceptions should be further disciplined by a much expected Presidential Decree.</span></p>
<p><span style=""line-height: 1.3em;"">While the “technical requirements” exception could eventually be subject of attempts by ISPs to “force” interpretations that would allow harmful discrimination, the Presidential Decree recently enacted (and two years after the Marco Civil came into force) consolidates a neutrality regime in Brazil by reinforcing that discrimination of traffic must be extremely exceptional. The Decree clearly limits the “technical requirements” that can justify some degree of discrimination to reasonable network management measures that are indispensable for an “adequate” provision of the services and aim at preserving the network’s “stability, safety, integrity and functionality”. According to the Decree, ISPs can only adopt traffic management practices to deal with safety threats and exceptional congestion situations; while doing that, they must not differentiate applications or classes of applications unless an application specific measure is indispensable. Also, all management techniques must be properly disclosed to consumers, that should have access to clear explanations about the measures and their impacts on traffic.</span></p>
<p><span style=""line-height: 1.3em;"">Importantly, the Decree expressly bans agreements or unilateral conducts by ISPs that (i) could violate the public and unlimited nature of access to the Internet and the principles and goals of the regulation of the Internet cited above; (ii) prioritize data packages based on commercial arrangements; and (iii) prioritize ISPs’ own applications. As a result, ISPs cannot offer fast lanes for applications that pay more or decide to give preferential treatment for their own content.</span></p>
<p><span style=""line-height: 1.3em;"">To be sure, there are points in the Decree that warrant careful consideration. One of them is the definition of “specialized services”, that should be narrowly interpreted so as to avoid the fragmentation of the Internet. This provision must serve as an exception to contemplate the provision of ordinary pay-TV and phone services using the same infrastructure network, and not result in a free pass for ISPs to circumvent network neutrality principles.</span></p>
<p>Also, the ban on prioritization cannot be interpreted as merely forbidding “fast lanes”. If the rule against paid prioritization only forbids payment for “fast lanes”, it would allow broadband providers to negotiate any other forms of preferential treatment, including zero-rates, guaranteed delivery in times of congestion or application-specific pricing.  Nevertheless, similar to fast-lanes, these forms of differential treatment are actual prioritization and may distort the nature of the Internet as an open space where any application can be successful and consumers may freely elect winners.</p>
<p><span style=""line-height: 1.3em;"">Protecting the open Internet is essential for the future of Brazil. Internet freedom has the potential to resolve long-standing inequalities, strengthen democratic institutions, and empower people that would not have voice in traditional media channels. The Presidential Decree is an important step towards meaningful network neutrality rules in Brazil. Going forward, the interpretation of the rules in individual cases will determine whether the protection of network neutrality in Brazil will be effective. Future enforcement by ANATEL and Courts must vigorously enforce the ban on blocking and discrimination established by the statute. The good news is that the institutional framework is well set to allow a meaningful neutrality regime.</span></p>
",Architecture and Public Policy,2016-07-21 10:32,1597,Ademir Pereira,News
14508,,United States,0,0,Whose Copyright Office?,Copyright,"<p>            In 2013, in a lecture at Columbia University, Register of Copyrights Maria Pallante <a href=""http://www.copyright.gov/docs/next_great_copyright_act.pdf"">announced</a> an ambitious vision for the “Next Great Copyright Act.” That vision appropriately included a prominent role for the Copyright Office in helping policy makers work through some difficult issues relating to copyright and evolving technologies. The Register closed her lecture by stating that a revised Copyright Act “[m]ost importantly…would serve the public interest.” For those of us in the copyright world who believe that balance in the system between the interests of right holders and the interests of the public is structurally and substantively critical to good copyright policy, the Register’s words were greatly reassuring. Some recent developments raise questions, however, about the extent to which the Copyright Office is demonstrating genuine commitment to balanced copyright policy in the public’s interest.</p>
<p>            One such development came last month, when the Second Circuit Court of Appeals in <em><a href=""https://www.eff.org/document/capitol-v-vimeo-2nd-circuit-opinion"">Capitol Records v. Vimeo</a></em> sharply criticized a Copyright Office report which concluded that the DMCA safe harbors do not apply to infringement claims involving pre-1972 sound recordings. The Office’s report supported the record label plaintiffs’ position in the litigation. In its opinion, the court engaged in an extended deconstruction of the Office’s argument, concluding that it was “flawed in several respects” and that it “substantially overstated, and misapplied, what the Supreme Court said.” In a <a href=""https://cyberlaw.stanford.edu/blog/2016/06/big-win-second-circuit-vimeo-and-dmca-safe-harbors-post-1-3"">blog post</a> at the time, I pointed out how unusual it is for a court to speak in such strong terms about shortcomings in the legal analysis of an expert government agency on a matter within its domain of expertise. Had the court accepted what it concluded was the Office’s highly problematic analysis of the safe harbor eligibility question, the recording labels would have been handed a significant windfall, and Vimeo (and similarly situated online service providers) would have suffered a commensurate loss.</p>
<p>            This month, the Office has become involved in an FCC rulemaking proceeding that proposes to open up the cable set-top box market to competition from non-cable equipment providers. (For some background on the rulemaking, see <a href=""https://apps.fcc.gov/edocs_public/attachmatch/FCC-16-18A1.pdf"">here</a> and—less wonky—<a href=""http://www.cnbc.com/2016/02/18/fcc-approves-new-set-top-box-rule.html"">here</a>.) The position the Office appears to be taking on the copyright implications of the FCC’s proposal aligns with that of the cable and motion picture industries, which flatly oppose the proposal. In connection with the rulemaking, I joined the EFF and some academic colleagues—Peter Jaszi, Pam Samuelson, Betsy Rosenblatt, and Rebecca Tushnet—in submitting <a href=""https://cyberlaw.stanford.edu/files/blogs/Copyright%20Scholars%20and%20Electronic%20Frontier%20Foundation%20Reply%20Comments_0.pdf"">comments </a>to the FCC explaining that no parade of copyright horribles (<em>viz.</em> unchecked piracy) will flow from “unlocking the box.” We pointed out in our comments that the FCC’s proposal is fully attentive to the content protection issues that could arise from opening up cable programming streams to non-cable equipment manufacturers. The cable box, in other words, is not a copyright Pandora’s box; it can be opened carefully, in a way that both protects copyright holders and enables overdue innovation in the way that cable subscribers access content for which they’ve paid.</p>
<p>            Out of concern that the Copyright Office is developing a position in the FCC proceeding that is at odds with the Supreme Court’s clear guidance in <a href=""https://cyber.law.harvard.edu/metaschool/fisher/integrity/Links/Cases/sony.html""><em>Sony v. Universal </em></a>concerning the limited scope of the copyright monopoly, my academic colleagues and I submitted a <a href=""https://cyberlaw.stanford.edu/files/blogs/IP%20Professors%20Letter%20to%20Librarian%20of%20Congress%207.22.2016_3.pdf"">letter</a> today to the Librarian of Congress, who has oversight of the Copyright Office. In our letter, we expressed our view that “[i]nterpretations of copyright law that operate to expand copyright entitlements into copyright-adjacent fields of commerce run counter to Supreme Court precedent and the copyright system’s goal of increasing public access to knowledge and information.” We hope that the FCC and members of Congress who have taken an interest in the current rulemaking will see that the copyright issues being raised are either not properly within the scope of copyright or, to the extent that they are, have been adequately addressed in the FCC’s proposal. <em>Sony</em> makes it clear that copyright holders do not get to control the manufacture or distribution of video equipment with substantial non-infringing uses. The threat of piracy should be taken seriously, but it cannot vitiate <em>Sony</em>’s important copyright-limiting principle.</p>
<p>            By <a href=""https://www.law.cornell.edu/uscode/text/17/701"">statute</a>, the Copyright Office has authority to “[a]dvise Congress on national and international issues relating to copyright, other matters arising under this title, and related matters.” The Office thus plays a legitimate and important role in shaping copyright policy. To properly fulfill that role, Office staff must take into account the public’s interest in both the protection of copyrighted works <em>and</em> the development of affordable new technologies for accessing and disseminating those works. Copyright is not just for the benefit of copyright holders, and neither is the Copyright Office.     </p>
","Copyright and Fair Use, Intermediary Liability",2016-07-22 12:11,1046,Annemarie Bridy,News
14515,,Council of Europe,0,0,Strasbourg Court To Hear A Case About Liability For Hyperlinking,Defamation or Personality Rights,"<div data-blogger-escaped-style=""text-align: left;"" data-blogger-escaped-trbidi=""on"" dir=""ltr"" style=""color: rgb(0, 0, 0); font-family: ""Times New Roman""; font-size: medium; line-height: normal;"">
<div data-blogger-escaped-style=""text-align: justify;"" style=""text-align: justify;"">
<p style=""margin: 0px;"">Internet case-law of the ECtHR will soon be enriched. Magyar Jeti Zrt v Hungary is a new important pending case. It concerns liability for hyperlinks in the domestic defamation law and its compatibility with freedom of expression.</p>
<p style=""margin: 0px;""> </p>
<p style=""margin: 0px;"">The applicant is in the case is an operator of the Hungarian news portal 444.hu which is used by approximately 250,000 users per day. The applicant often utilises hyperlinks embedded in the published contents, which lead readers to relating materials published elsewhere. On 5 September 2013 a group of football supporters travelling to Romania stopped at an elementary school in Konyár, Hungary. The pupils of the school were predominantly of Roma origin. After getting off the bus, the football supporters made racist remarks, waved flags; and one of them allegedly urinated on the school building. Some minutes later the football supporters got back on the bus and left the village.</p>
<div> </div>
<div>Mr J.Gy., the head of the local Roma minority self-government, accompanied by a parent and one of the children attending the school, gave an interview to a Roma minority media outlet on the same day. During the interview, he referred to persons related to Jobbik, a right-wing political party in Hungary, which had been previously criticised for its anti-Roma and anti-Semitic stance. The video was uploaded to Youtube.com the same day. On 6 September 2013 the applicant published an article on the incident on the 444.hu website that referred to reports concerning the events in Konyár and included an embedded text hyperlink leading to the video available on Youtube.com. The text of the article itself did not mention the term Jobbik. On 13 September 2013 Jobbik initiated legal proceedings against several respondents, including the applicant, the head of the local Roma minority self-government making the allegedly defamatory comment, the Roma minority media outlet recording the video uploaded on Youtube and the operators of other Hungarian news portals, alleging that its right to reputation had been violated by the Youtube video.</div>
<div> </div>
<div>
<div>On 30 March 2014 the Debrecen High Court established the responsibility of six out of the eight respondents, including the applicant, in respect of the defamatory comments made in the video. Regarding the applicant, the court found that in making available the Youtube video by providing a hyperlink leading to it, it had disseminated the defamatory statements. On appeal, on 25 September 2014 the Debrecen Court of Appeal upheld the judgment. The applicant now compaints that this ruling is a disproportionate interference with its freedom of expression. </div>
</div>
</div>
</div>
<div data-blogger-escaped-style=""text-align: justify;"" style=""color: rgb(0, 0, 0); font-family: ""Times New Roman""; font-size: medium; line-height: normal; text-align: justify;"">
<p style=""margin: 0px;""> </p>
</div>
<div data-blogger-escaped-style=""text-align: justify;"" style=""color: rgb(0, 0, 0); font-family: ""Times New Roman""; font-size: medium; line-height: normal; text-align: justify;"">
<p style=""margin: 0px;"">It is without doubt that the decision of the Court will set important limits for the future of freedom of expression online. Therefore, on Monday, <i>European Information Society Institute (EISi)</i> filed <a href=""http://eisionline.org/index.php/en/projekty-m-2/sudy-a-obcianska-spolocnost-m/141-eisi-intervenes-in-magyar-jeti-case-to-support-online-freedom-of-expression"">its third party intervention</a> also co-authored by me. The submission explains the importance of hyperlinks for the functioning of the Internet and illustrates how imposing restrictions on their use can have strong adverse effects on our societies.</p>
</div>
<div data-blogger-escaped-style=""text-align: justify;"" style=""color: rgb(0, 0, 0); font-family: ""Times New Roman""; font-size: medium; line-height: normal; text-align: justify;"">
<p style=""margin: 0px;""> </p>
</div>
<div data-blogger-escaped-style=""text-align: justify;"" style=""color: rgb(0, 0, 0); font-family: ""Times New Roman""; font-size: medium; line-height: normal; text-align: justify;"">
<div>We urge the Court to take into consideration the special content-neutral nature of a hyperlink and of their importance for innovative journalism and decentralized non-editorial speech. In line with <em>Thoma v. Luxemburg</em>, hyper-linkers should not be subject to unnecessary obligations to distance themselves systematically and formally from the referred content. The hyperlinks are already understood by general public, as also evidenced in this brief, as opinion-neutral references. </div>
<div> </div>
<div>Any restriction on the dissemination of the information in a form of liability, also inevitably diminishes the value of initial authorship. A strict rule regarding liability for hyperlinking will inevitably lead to self-censorship and over-restriction of legitimate content which this court already outlawed as impermissible forms of collateral censorship. We urge the court to rely on its Grand Chamber ruling in <em>Jersild v. Denmark</em> by holding that “unless there are particularly strong reasons for doing so”, imposing civil liability for assisting in the dissemination of statements made by another person by means of hyperlinks is a breach Art. 10 of the Convention. The states should be bear a heavy burden to justify why a democratic society necessitates a rule that sanctions its own citizens, let alone its journalists, for merely referring to what other people say. </div>
<div> </div>
<div>As recognized by this court in <em>Editorial Board of Pravoye Delo and Shtekel v. Ukraine</em>, the states should even underlie a positive obligation to create an appropriate regulatory framework to ensure effective protection of journalists’ freedom of expression when the journalists are engaging with third party speech online. This obligation is in line with the explicit legislative approach of some of the states which created clear liability exemptions to prevent imposition of liability for referring to third party content in their own hyperlinks. Although European Union decided not to address this topic under the E-Commerce Directive, it left the possibility open to its Member States to decide whether or not to regulate hyperlinks in the context of commercial activities on internet.  Austria,  Liechtenstein,  Portugal  and Spain  have developed unambiguous liability exemptions for the provision of links to third party content. In other countries this is a standard outcome based on their national tort laws.  It is therefore usual to prevent any liability to be imposed on the person who sets a link as long as he/she has no actual knowledge that the information is unlawful,  and has no control over the content to which it refers.</div>
<div> </div>
<div>The ‘particularly strong reasons’ for holding a hyper-linker liable should depend on ‘all the circumstances of the (..) case, in particular the nature of the information contained in the shared material and the weighty reasons for the interference with the applicants’ freedom of expression’, but also his/her privileged position (e.g. being a journalist). The ECtHR has already accepted that criminal liability can be imposed for a specific type of hyperlinks in case the person concerned (1) acts with the intent, (2) is not a journalist, and (3) the information that he links affords lower protection than political expressions (<em>Neij and Sunde Kolmisoppi v. Sweden</em>). Such circumstances should in any case remain exceptional in their nature.</div>
<div> </div>
<div>Therefore, the rule accepted by the Hungarian court, imposing strict liability on the mere sharing of information, cannot be considered as a necessary interference with freedom of expression in a democratic society.</div>
<div> </div>
<div><em>(The brief was prepared by me, students of the Tilburg Law School (Bruno Bautista) and attorneys & affiliates of Law Firm TRINITI and University of Tartu (Karmen Turk and Maarja Pild), as part of an Internet Policy Clinic that I run at the Tilburg Institute for Law, Technology, and Society (TILT).)</em></div>
<div> </div>
<p><a href=""http://www.eisionline.org/files/Interventions/final-Intervention_Jeti.pdf""><span style=""color: rgb(0, 0, 238); text-decoration: underline;"">Magyar Jeti Zrt Intervention ECtHR (.pdf)</span></a></p></div>
<p> </p>
",Intermediary Liability,2016-08-05 5:36,759,Martin Husovec,News
14728,,International,1,1,Cross Border Content Removal Demands - You Decide,General,"<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""><span id=""docs-internal-guid-4dcb2af1-0801-6fd6-7fdb-5b9348d0fec2""><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">The Center for Internet and Society just wrapped up its </span><span style=""font-size: 14.6667px; font-family: Arial; color: rgb(17, 85, 204); background-color: transparent; text-decoration: underline; white-space: pre-wrap;""><a href=""https://cyberlaw.stanford.edu/page/law-borders-and-speech"">Law, Borders, and Speech Conference</a>.</span><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; white-space: pre-wrap;""> We had an amazing line-up of <a href=""https://cyberlaw.stanford.edu/page/law-borders-and-speech-speakers"">speakers</a> and a great set of <a href=""https://cyberlaw.stanford.edu/page/law-borders-and-speech-event-schedule"">topics</a> -- the event was a blast, and we are getting enthusiastic feedback from newly minted Internet jurisdiction nerds and old hands alike. </span></span></p>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </p>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""><span><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">The hypothetical exercises I wrote about real-life Internet platforms and cross-border content removal requests proved popular, so I'm sharing them more widely.  </span></span><span style=""background-color: transparent; font-family: Arial; font-size: 14.6667px; white-space: pre-wrap;"">These are based on real life, but they include significant simplifications and changed or invented facts for the purpose of the exercise. Don’t take them as true stories. Do feel free to use them in teaching or otherwise, with attribution.</span></p>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;text-align: center;""> </div>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;text-align: center;""> </div>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;text-align: center;""><span id=""docs-internal-guid-4dcb2af1-0801-6fd6-7fdb-5b9348d0fec2""><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; font-weight: 700; text-decoration: underline; white-space: pre-wrap;"">Internet Platforms Exercise</span></span></p>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;text-align: center;""><span id=""docs-internal-guid-4dcb2af1-0801-6fd6-7fdb-5b9348d0fec2""><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">Stanford Center for Internet and Society</span></span></p>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;text-align: center;""> </div>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""><span id=""docs-internal-guid-4dcb2af1-0801-6fd6-7fdb-5b9348d0fec2""><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">This exercise puts you in the shoes of online platforms confronted with difficult cross-border content removal demands. It uses examples based on real life, but with facts simplified for sake of discussion.</span></span></p>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""><span id=""docs-internal-guid-4dcb2af1-0801-6fd6-7fdb-5b9348d0fec2""><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">Please discuss and decide what action the company should take in response to the particular demand. That could include compliance, partial compliance, litigation, changing business models, changing product design, ceasing operations in a country, negotiating with the government or person seeking removal, asking NGOs or governments for help, or anything else that you think of. If you need to make assumptions about the facts of the case (e.g. whether the company has an office in a particular country, where its servers are located) please do so. </span></span></p>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""><span id=""docs-internal-guid-4dcb2af1-0801-6fd6-7fdb-5b9348d0fec2""><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; text-decoration: underline; white-space: pre-wrap;"">Hypo 1: Anne Frank and Wikipedia</span></span></p>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""><span id=""docs-internal-guid-4dcb2af1-0801-6fd6-7fdb-5b9348d0fec2""><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">Wikimedia receives a DMCA removal request from the US copyright holders for </span><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; text-decoration: underline; white-space: pre-wrap;"">The Diary of Anne Frank</span><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">, demanding that Wikipedia remove all links to, or hosted copies of, the original Dutch-language version of the diary. The diary is in the public domain under Dutch copyright law, but still protected by US copyright law. Wikimedia is legally established in the US, and its employees and servers are all here. It has separate Dutch and English-language pages about the diary, and allows users to navigate to either one.  Both the Dutch and English pages have links to a Wikimedia-hosted copy of the diary at the time the DMCA request arrives. What should it do in response to the request?*</span></span></p>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""><span id=""docs-internal-guid-4dcb2af1-0801-6fd6-7fdb-5b9348d0fec2""><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; text-decoration: underline; white-space: pre-wrap;"">Hypo 2: Reddit and Russia</span></span></p>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""><span id=""docs-internal-guid-4dcb2af1-0801-6fd6-7fdb-5b9348d0fec2""><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">In 2013, Russian regulator Roskomnadzor ordered Russian ISPs to block a page on reddit.com where Russian users discussed illegal drugs. Because Reddit encrypts traffic using HTTPS, the ISPs could only block the entire site -- not individual pages. Russia later agreed to lift the ban, and Reddit agreed to block traffic at its end by preventing users with Russian IP addresses from accessing pages that violate Russian law. This allowed the rest of Reddit to remain accessible in Russia.**</span></span></p>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""><span id=""docs-internal-guid-4dcb2af1-0801-6fd6-7fdb-5b9348d0fec2""><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">Suppose that Roskomnadzor notifies Reddit that another page violates Russian law.  This one offers psychological support for gay and transgender teenagers in Russia. Russian regulators say, and local counsel in Russia confirms, that the page violates Russia’s “gay propaganda” laws.  What should Reddit do now? </span></span></p>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </p>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""><span><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; white-space: pre-wrap;""> </span></span></p>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""><span id=""docs-internal-guid-4dcb2af1-0801-6fd6-7fdb-5b9348d0fec2""><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; text-decoration: underline; white-space: pre-wrap;"">Hypo 3: DuckDuckGo and the EU</span></span></p>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""><span id=""docs-internal-guid-4dcb2af1-0801-6fd6-7fdb-5b9348d0fec2""><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">DuckDuckGo is a search engine company based in Pennsylvania. It prides itself on protecting users’ privacy by not tracking them. </span></span></p>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""><span id=""docs-internal-guid-4dcb2af1-0801-6fd6-7fdb-5b9348d0fec2""><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">The company has no offices, employees, or servers outside the US, and it does not deposit cookies on users’ machines. It does sell advertising space in search results, including to advertisers in the EU. It allows ad campaigns to target users in particular countries or regions, presumably based on the user’s IP address. It also lets users create accounts in order to participate in discussion forums, including forums for open source developers who contribute code to the search engine. It supports informal in-person “Quack & Hack” meetings for these developers, including in the EU. The Strasbourg Quack & Hack group, for example, has 98 members. According to alexa.com, at least 23% of DuckDuckGo’s traffic comes from users in the EU.</span></span></p>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""><span id=""docs-internal-guid-4dcb2af1-0801-6fd6-7fdb-5b9348d0fec2""><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">The EU’s pending General Data Protection Regulation, which goes into effect in 2018, arguably applies to DuckDuckGo because of the accounts it maintains for EU users. French Counsel has advised the company that the law is unclear, but she thinks there is a 40% chance that regulators and courts would find jurisdiction to apply the law to the company.  If that happens, DuckDuckGo would face some expensive legal and technical compliance work, and also have to honor “Right to Be Forgotten” requests for search results.  French regulators maintain that such de-listings must apply globally, not just to results seen by European users. The search engine currently does not honor such requests, which means that European users can use DuckDuckGo to find results that Google has de-listed.***</span></span></p>
<div dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""> </div>
<p dir=""ltr"" style=""line-height:1.38;margin-top:0pt;margin-bottom:0pt;""><span id=""docs-internal-guid-4dcb2af1-0801-6fd6-7fdb-5b9348d0fec2""><span style=""font-size: 14.6667px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">Suppose that in October 2018, the CEO of a French shipping company threatens to sue DuckDuckGo if it does not de-list search results linking to allegations that he cheated on his taxes ten years ago. The French Data Protection Authority agrees that he has a right to de-list the results.  What should DuckDuckGo do now?</span></span></p>
<div> </div>
<div> </div>
<div> </div>
<div> </div>
<div> </div>
<div><span id=""docs-internal-guid-4dcb2af1-0802-ab6c-a289-1334d664fbed""><span style=""font-size: 13.3333px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">* These facts are simplified based on the real world example described </span><a href=""https://blog.wikimedia.org/2016/02/10/anne-frank-diary-removal/""><span style=""font-size: 13.3333px; font-family: Arial; color: rgb(17, 85, 204); background-color: transparent; text-decoration: underline; white-space: pre-wrap;"">here</span></a><span style=""font-size: 13.3333px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">. Among other differences, the public domain status of the diary in the Netherlands is disputed in real life.</span></span></div>
<div><span><span style=""font-size: 13.3333px; font-family: Arial; background-color: transparent; white-space: pre-wrap;"">** </span></span><span style=""background-color: transparent; font-size: 13.3333px; font-family: Arial; white-space: pre-wrap;"">Up to this point the hypo tracks reported </span><a href=""http://www.businessinsider.com/reddit-unbanned-russia-magic-mushrooms-germany-watchpeopledie-localised-censorship-2015-8?r=UK&IR=T"" style=""font-size: 13.008px;""><span style=""font-size: 13.3333px; font-family: Arial; color: rgb(17, 85, 204); background-color: transparent; text-decoration: underline; white-space: pre-wrap;"">facts</span></a><span style=""background-color: transparent; font-size: 13.3333px; font-family: Arial; white-space: pre-wrap;"">.</span></div>
<div><span style=""background-color: transparent; font-size: 13.3333px; font-family: Arial; white-space: pre-wrap;"">*** Facts</span><span style=""background-color: transparent; font-family: Arial; font-size: 13.3333px; white-space: pre-wrap;""> up to here are based on reporting by DuckDuckGo and other Internet sources - not always clearly reliable ones, so take these details with a particularly large grain of salt. Main exceptions: (1) in real life, DuckDuckGo partners with Bing and Yahoo for ads and results; (2) we made up the legal prediction about odds of French lawmakers finding jurisdiction over DDG.</span></div>
<div> </div>
<div> </div>
","Architecture and Public Policy, Copyright and Fair Use, Intermediary Liability, Privacy",2016-10-27 14:38,1188,Daphne Keller,News
14779,,United States,0,0,What the Second Circuit Just Got Wrong about the DMCA in EMI v. MP3Tunes,Copyright,"<p>            With the Second Circuit’s recent decision in <a href=""http://www.loeb.com/~/media/files/publications/2016/11/emiopinion.pdf""><em>EMI v. MP3Tunes</em></a>, the formerly small body of case law interpreting § 512(i) of the DMCA – the “repeat infringer” provision – continues to grow. Last year, for example, district courts held service providers ineligible for safe harbor for failing to comply with § 512(i) in two closely watched cases, <em>BMG Rights Management v. Cox Communications </em>(now on appeal, and about which I blogged <a href=""http://cyberlaw.stanford.edu/blog/2015/12/bmg-v-cox-high-cost-losing-safe-harbor"">here</a>) and <em>Capitol Records v. Escape Media Group </em>(involving the now-defunct file-sharing site Grooveshark).</p>
<p>            As the law in this area develops, it’s worth taking stock of how recent decisions on § 512(i) implicate the DMCA’s overall architecture and the balance of enforcement obligations it was intended to strike between right holders and ISPs seeking safe harbor. In particular, it’s important to look carefully at the interaction between the repeat infringer provision and the DMCA’s “no duty to monitor” rule in § 512(m). In order to respect the balance of obligations the safe harbors establish, courts cannot read § 512(i)’s obligation to terminate access for repeat infringers in a way that imposes de facto or de jure investigative obligations on ISPs, in violation of § 512(m), which provides that safe harbor cannot be conditioned on a provider’s “monitoring its service or affirmatively seeking facts indicating infringing activity.” That, however, is precisely what the court has done in the MP3Tunes case.</p>
<p>            By way of background, the MP3Tunes litigation has been active since 2007. The service was founded in 2005 and declared bankruptcy two years before trial. Although MP3Tunes and its sister service, sideload.com, are very much yesterday’s news, the Second Circuit’s decision in this case will have potentially far-reaching effects in the DMCA ecosystem. The services at issue were a cloud storage locker for music files, to which users could upload files ripped from their own CDs, and a website that allowed users to search the Internet for “free” music files and then, using a plug-in provided by the site, sideload (i.e., copy) the linked files into their MP3Tunes storage lockers. </p>
<p>            The Second Circuit’s decision vacated a grant of partial summary judgment for MP3Tunes on the repeat infringer issue. In the Second Circuit’s view, the district court erred with respect to § 512(i) in two ways. First, it defined what counts as a repeat infringer too narrowly, holding that a repeat infringer can only be one who knowingly uploads infringing content to the Internet for others to share (vs. just downloading it for personal use). Second, it erred in holding that MP3Tunes “reasonably implemented” its repeat infringer policy. The doctrinal noise the case creates vis-a-vis § 512(m)’s no-duty-to-monitor rule comes with the part of the court’s decision on implementation, so that will be the focus of my attention here.</p>
<p>            In past cases, a provider has generally been able to show reasonable implementation of a repeat infringer policy by offering proof that it both has a system in place for receiving notices of infringement from right holders and has actually terminated the accounts of some subscribers for engaging in what the provider determined to be blatant repeat infringement. Courts have been reluctant to read § 512(i) as imposing precise qualitative or quantitative requirements on providers with respect to repeat infringer policies, because judges have tended to interpret the vague language in § 512(i) as a sign of Congressional intent to give providers discretion to craft and implement individualized policies.</p>
<p>            In this case, MP3Tunes offered evidence that it terminated as repeat infringers 153 users who shared their passwords with other users. That, in the Second Circuit’s view, was not enough to warrant summary judgment for MP3Tunes on the question of reasonable implementation of a repeat infringer policy. The Court held that the plaintiffs created a triable issue of fact by demonstrating that MP3Tunes failed to make efforts to “connect known infringing activity of which it became aware through takedown notices to users who repeatedly created links to that infringing content in the sideload.com index or who copied files from those links.” Under the Second Circuit’s interpretation of § 512(i), the plaintiffs “could prevail by demonstrating that MP3tunes's failure to track users who created links to infringing content identified on takedown notices or who copied files from those links evidenced its willful blindness to the repeat infringing activity of its users.”</p>
<p>            The problem with the court’s reasoning here is that “tracking” large tranches of users over time to determine whether they serially copied files from links identified in notices looks very much like the kind of affirmative fact-seeking that § 512(m) shields providers from having to undertake. Under the court’s logic, a provider can reasonably be required under § 512(i) to do all of the following upon receiving a notice identifying an infringing link: (1) identify which user uploaded the link; (2) keep track of that user’s future activity with respect to that link (to see if he re-posted it after a takedown); (3) keep track of that user’s activity with respect to any links identified in subsequent notices (to see if he uploaded any of the links himself or copied any of the underlying files from links uploaded by others); (4) search system logs to identify all of the users who copied the file underlying the link in the notice; (5) keep track of whether any of those users uploaded links identified in subsequent notices or copied files underlying links identified in subsequent notices. In this scenario, the provider’s tracking requirement applies not only to users who upload infringing links, but also to the entire universe of users—possibly thousands per link—who copy files underlying infringing links. And that tracking requirement continues in an open-ended way to the extent that serial or repeat infringers can be identified only by tracking all of their link-uploading and file-copying activity over time.</p>
<p>            As I see it, this cascade of connecting and tracking, triggered anew each time an incoming notice identifies one or more links to infringing material, qualifies as monitoring and/or fact-seeking. The court held that these activities can’t be classified as monitoring because they involve functions routinely carried out by the provider (searches of user activity) to discover information already in the provider’s possession. I don’t see it that way. “Affirmatively seeking facts” must be read to include searching for facts already in existence, even if you don’t believe (as the court seemed not to) that “monitoring” can involve searches of existing data.</p>
<p>            The court’s holding that MP3Tunes could reasonably have been required to “make use” of information in its possession by tracking, on a rolling basis, not only who created links to infringing material but also who copied the underlying files violates § 512(m)'s no-duty-to-monitor rule. Whereas it seems reasonable to expect a provider to keep track of users who serially upload links to infringing material identified in notices, requiring the provider to also keep track of every user who makes use of those uploaded links to copy files is a bridge too far, given the limitations on fact-seeking in § 512(m). The jury therefore should not be given an opportunity on remand to disqualify MP3Tunes from safe harbor because it failed to investigate and track which users copied files from links identified in notices. A jury could legitimately find, however, without intruding on § 512(m), that MP3Tunes failed to reasonably implement its repeat infringer policy because there was evidence in the record both that it failed to keep track of users who uploaded links identified in notices and that its agents and executives themselves engaged with impunity in serial acts of infringement by copying infringing files.</p>
","Copyright and Fair Use, Intermediary Liability",2016-11-07 17:43,1046,Annemarie Bridy,News
14783,European Union,,0,0,Global Right to Be Forgotten Delisting: Why CNIL is Wrong,Right to Be Forgotten,"<p>The French Data Protection Agency, CNIL, is currently <a href=""https://www.theguardian.com/technology/2016/may/19/google-right-to-be-forgotten-fight-france-highest-court"">before a French court</a>, arguing that Google needs to do more to comply with “Right to Be Forgotten” or “Right to Be Delisted” (RTBD) laws. The EU’s highest court, the <a href=""https://europa.eu/european-union/about-eu/institutions-bodies/court-justice_en"">CJEU</a>, defined the search engine’s obligations in the 2014 <em><a href=""http://curia.europa.eu/juris/document/document_print.jsf?doclang=EN&docid=152065"">Google Spain v. Costeja</a></em> case, ruling that Google must comply with requests to remove links from the results it displays when people search for the requester by name. The Court did not say whether this remedy applied to search results outside of the EU. CNIL’s <a href=""https://www.cnil.fr/sites/default/files/atoms/files/d2016-054_penalty_google.pdf"">position</a> is that if Google’s search results violate Data Protection rights under French law, then Google must prevent users everywhere in the world from seeing them.</p>
<p>CNIL’s position has been widely criticized, including in a New York Times <a href=""http://www.nytimes.com/2016/04/25/opinion/europes-web-privacy-rules-bad-for-google-bad-for-everyone.html?_r=0"">opinion piece</a> that Bruce Brown and I wrote, for threatening speech and information rights in other countries. (I used to work on these issues at Google, and Bruce defends journalists for a living, so our position surprised no one.) As a matter of black letter jurisdiction law, some experts have also questioned CNIL’s extraterritorial authority under Article 4 of the EU’s <a href=""http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:31995L0046:en:HTML"">Data Protection Directive</a>. Much of the legal debate has centered on these jurisdiction questions, and on CNIL’s argument that French law governs Google’s worldwide index because it constitutes a single “processing” under Data Protection law.</p>
<p>In this blog post I will argue that several other express provisions of the Data Protection Directive support national, rather than global, application of French RTBD law. The French court should consider these in rejecting CNIL’s bid to regulate expression and information rights around the world.</p>
<p> </p>
<p><strong>1. Data Protection Directive Articles 12 and 14 require only partial, not complete, erasure.</strong></p>
<p>The current <em>CNIL v. Google</em> case is about the series of decisions that search engines, DPAs, or courts must make when assessing RTBD requests. According to CNIL, only one decision matters: whether the requester’s Data Protection rights trump the public’s interest in finding information though Google searches. Once that decision is made, CNIL maintains, the legal analysis ends. Google must remove that web page from search results for the requester’s name, and do so everywhere in the world, in order to provide ""effective and complete"" protection to data subjects.</p>
<p>But that is not where the CJEU ended its analysis. The CJEU assessed proportional interests at a second point, in order to tailor a remedy that balanced Mr. Costeja’s rights against those of other Internet users. Mr. Costeja and the Spanish DPA wanted Google to “prevent indexing of the information relating to him personally,” so that it would “not be known to internet users.” (Par. 20) In other words, they wanted the data completely erased from Google’s index. The CJEU responded that Google only needed to prevent <em>some</em> aspects of indexing, by removing data “from the list of results displayed following a search made on the basis of a person’s name[.]” (Rul. Par. 3) The Court let Google continue processing that same personal data – text about Mr. Costeja from a newspaper page – on its servers. It also let Google link users to the data, and show it to them in snippets of text from the page, when they searched for terms other than the plaintiff’s name. The Court applied the same ""effective and complete"" standard advanced by CNIL, and found that it mandated partial -- not total -- erasure.</p>
<p><span style=""font-size: 13.008px;"">The practical and policy reasons for this limited scope of erasure are clear. The Court says that search results create a new and unique Privacy harm by aggregating information from separate web pages to create a “more or less detailed profile” of an individual. (Par. 80) Its remedy, which only requires erasure of these “profile” results, is tailored to address this specific harm. As commentators including CNIL have pointed out, letting Google continue to process the same data and provide it in search results for other queries also strikes a balance between the plaintiff’s rights and those of other Internet users seeking information online.</span></p>
<p>The doctrinal, black letter law foundation for the Court’s limited erasure remedy is less clear. That foundation matters a lot for the resolution of the current CNIL case against Google. For example, the CJEU could have meant that search results for a person’s name are one instance of “processing,” subject to separate legal obligations from the processing that Google does for other search operations. In that case, CNIL’s “single processing” argument for applying the same legal analysis to every component of web search would fail. Or the Court could have meant that Google is a data controller as to search results for a person’s name, but not as to other indexed data. Both of those interpretations are possible, but the Court doesn’t talk about them.</p>
<p><span style=""font-size: 13.008px;"">What the court does say is that the limited-scope erasure is mandated by Data Protection Directive Articles 12 and 14. These provisions spell out what data controllers must do when a data subject asks them to stop processing her data. Article 12 requires “erasure or blocking,” and Article 14 requires controllers to honor “objections” to processing. </span><em style=""font-size: 13.008px;"">Google Spain</em><span style=""font-size: 13.008px;""> says these two Articles “are to be interpreted as meaning that… the operator of a search engine is obliged to remove from the list of results displayed following a search made on the basis of a person’s name links to web pages published by third parties and containing information relating to that person[.] (Rul. Par. 3)</span></p>
<p>A look at these two Articles shows why they support, and even mandate, the kind of tailored, proportionate remedy the CJEU provided – and why they do not support the CNIL’s global, all-or-nothing approach. Here is the language:</p>
<p style=""margin-left:1.0in;"">·       Article 12(b) gives data subjects “the right to obtain from the controller . . . <em>as appropriate </em>the rectification, erasure or blocking of data the processing of which <em>does not comply with the provisions of this Directive</em>[.]” The italicized language makes clear that the scope of erasure is flexible, and depends on a nuanced and proportional determination about what is “appropriate.” The CJEU’s ruling effectively tells us that complete erasure was not “appropriate,” and that Google could continue some aspects of its processing while still “comply[ing] with the provisions of this Directive[.]”</p>
<p style=""margin-left:1.0in;"">·       Article 14(a) gives data subjects “the right… in the cases referred to in Article 7 (e) and (f), to object at any time <em>on compelling legitimate grounds</em>… to the processing of data relating to him…. <em>Where there is a justified objection</em>, the processing instigated by the controller may no longer involve those data[.]” Here, too, the Directive tells controllers and courts to apply balance and proportionality in tailoring the scope of compliance with an objection. Where a controller processes data in multiple ways, it should honor objections only for some of them – the ones that support a “justified” objection on “compelling legitimate grounds.” In <em>Google Spain</em>, that meant Google should cease processing only for searches on Mr. Costeja’s name.</p>
<p>The CJEU balanced interests under Articles 12 and 14 to define a tailored and proportionate <em>technical</em> scope of erasure within Google’s search operations. The same approach should govern the <em>geographic</em> scope of erasure in the current CNIL case. The CJEU was not asked about this potential limitation, and did not undertake to answer it or balance the relevant rights and interests. These include the rights of Internet users around the world to seek and impart information under their own countries’ legal interpretations of universal human rights – interpretations that are as legitimate, and as entitled to respect, as the ones advanced by French or EU lawmakers. These also include sovereignty interests of other governments both within and outside of the EU – the interests traditionally recognized under the legal doctrine of <a href=""https://www.law.cornell.edu/wex/comity"">comity</a>. Articles 12 and 14 require, and the <em>Google Spain</em> judgment confirms, that courts must pause to consider the balance of rights and interests, and tailor the scope of erasure obligations accordingly.</p>
<p> </p>
<p><strong>2. Data Protection Directive Article 9 recognizes that the same processing may be protected by Free Expression laws in one country but not in another.</strong></p>
<p><span style=""font-size: 13.008px;"">The other problem with CNIL’s reasoning is simpler. I assume it has been addressed elsewhere in more detail. The Data Protection Directive, in Article 9, explicitly makes Free Expression protections a matter for Member State law. The practical result of this has been a </span><a href=""https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2471531"" style=""font-size: 13.008px;"">very wide array</a><span style=""font-size: 13.008px;""> of national laws – meaning that the same RTBD request may require compliance in one EU country, but not in another.</span></p>
<p><span style=""font-size: 13.008px;"">This diversity of laws is not a bug – it is a feature. The Data Protection Directive is designed to generate different outcomes in different parts of the EU when Free Expression is at issue. The point is not a race to the courthouse, with the fastest-moving DPAs or courts displacing Free Expression laws in other EU countries. Rather, the point is to accept divergent outcomes within the range of permissible national approaches to balancing Privacy and Free Expression rights. CNIL’s approach overthrows this system, encouraging forum shopping and displacing the authority reserved to other nations. The French court should reject it.</span></p>
<p> </p>
<p> </p>
","Architecture and Public Policy, Intermediary Liability, Privacy",2016-11-18 0:59,1188,Daphne Keller,News
14824,,United States,0,0,Dear Silicon Valley: Great satire can be fake news!,Other,"<p>Watch out! Fake news is coming to get you! Lock your doors and iPhones, guard your dogs and children, and hold on to your comb overs! But is fake news so bad, and isn't some, all, or most of it legally protected parody? </p>
<p>According to the New York Times, <a href=""http://www.nytimes.com/2016/11/28/opinion/fake-news-and-the-internet-shell-game.html?_r=0"">""fake news"" is ""pure fiction masquerading as truth.""</a> Many in your Valley have recently expressed concern about how such news not only affected the recent election, but also how to combat it via algorithm and other fancy methods. Mark Zuckerberg is but one in the Valley who has expressed concern.</p>
<p>The problem is that much parody and satire comes in the form of ""pure fiction masquerading as truth."" In fact, many would argue that the best satire is so good, so biting, because it could very well be true. During the election, satirical news and interviews prliferated like <a href=""http://www.qualityfilth.com/interviews/author-sophia-l-gordon/clintons-30000000-77-hacked-e-mails-1-of-4/"">""Clinton's 30,000,000.77 Deleted E-mails!""</a> And yet this particular imaginary August interview was close to the truth in imagining Mrs. Clinton using 10 cell phones -- real number 12, as later determined by the FBI in September -- to send e-mails!</p>
<p>Some have argued, however, that many in the newer generation don't get satire, and have trouble telling the difference between fake news and satire. A recent <a href=""http://www.wsj.com/articles/most-students-dont-know-when-news-is-fake-stanford-study-finds-1479752576"">Wall Street Journal article</a> makes this point. And yet the argument begs the question of why such students don't have the critical thinking skills to tell the difference between humor and news. Even if the article is factually accurate, the question also becomes whether Facebook and other sites need to cater to such students, or keep in mind that many adults enjoy absurd ""fiction masquerading as truth"" because it makes fun of how surreal reality can be. Important to keep in mind Einstein’s quote, “imagination is more important than knowledge,” cause sometimes our intuitive imaginations can know things about events or people our rational minds cannot fathom.</p>
<p>That's why parody is one of the explicitly fair use categories under the Copyright Act. While a finding of such use isn't a per se finding of fair use, it certainly pushes the scale in the defendant's favor. The same is true of the First Amendment. Parody, satire, and humor are tools that dark souls use to make fun of societal extremes so as to avoid real, physical, conflict that inevitably results without the pressure release of humor.</p>
<p>So great satire can be fake news!</p>
<p>This means don't throw the satirical baby out with the fake news bath water. Even assuming that such news is undesirable, an objective adult person standard, as opposed to a clueless teenager standard, should be used in determining if the fake news in question more closely resembles false advertising than parody. Even after reasonable reliance is shown, damage would need to be proved from the alleged deception. But mere offense at the humor, or political position taken in the false ad, wouldn’t suffice.</p>
<p>In so doing, we protect the healthy satire that keeps us laughing, thinking on our feet, and away from destructive binary – yes/no, on/off, bourgeois/proletariat – robot thinking.</p>
",Copyright and Fair Use,2016-11-30 20:24,1047,Ryan E. Long,News
14838,European Union,,0,0,CEIPI Opinion on a EU Proposal for a Neighboring Right for Press Publishers Online,Copyright,"<p>At <a href=""http://www.ceipi.edu/en/"">CEIPI</a>, I have co-authored with Christophe Geiger and Oleksandr Bulayenko a position paper discussing the proposed introduction in EU law of neighboring rights for press publishers for the digital uses of their publications. The proposal is included in the European Commission’s Draft Directive on copyright in the Digital Single Market of September 14, 2016. Below you find the summary of the paper:</p>
<div>Among its key features, the European Commission’s planned copyright reform proposes to introduce in EU copyright law neighbouring rights for press publishers.  This proposal is (i) contrary to the objective of creating a Digital Single Market, (ii) detrimental for authors’ interests, and (iii) does not solve any systemic issues of the EU copyright system for the reasons stated below.</div>
<ul><li>The Directive Proposal—and the documents accompanying it—fail to explain how an additional layer of 28 national rights might promote the Digital Single Market. Rather, the proposal poses further challenges related to the territoriality of rights and their fragmentation. In addition, as there is already no uniform approach to exceptions or limitations to 28 national authors’ rights, 28 additional national rights for publishers will suffer the same uncertainty, making the Digital Single Market harder to reach.</li>
<li>Granting rights to ever more actors will reduce the economic value of each right covering essentially the same economic use. While the Impact Assessment accompanying the Directive Proposal concludes that the “introduction of a related right covering digital uses of press publications is not expected to generate higher licence fees for online service providers”, it fails to assess the impact of the Directive Proposal on authors. As the “pie” does not get any bigger, the authors’ share will inevitably decrease. Ultimately, this might undermine the overall functioning of the copyright system, especially because it should primarily secure fair remunerations to creators (rather than only compensate the investment of rightholders), while at the same time providing access to users.</li>
<li>In this regard, the Impact Assessment fails to demonstrate a causal link between publishers’ revenues and investments and granting them neighbouring rights to press publications—and/or promoting mechanisms facilitating initial ownership of authors’ rights by publishers. In contrast, recent empirical evidence from national implementation of publishers’ neighbouring rights confirmed a negative impact on small publishers, while news aggregators might have a positive effect on online news sites. This might have negative repercussions on plurality of sources, users’ access to information—and therefore on democratization. Also, increasing barriers to innovation and desincentivizing new business models might be an additional effect of the reform.</li>
<li>The Directive Proposal does not limit the subject matter to publications presently protected by authors’ rights. It goes far beyond, restricting, for example, uses of works in the public domain. Lifting materials out of the public domain has unwanted consequences, impinging greatly on freedom of expression and democratization, while favouring centralization of information.</li>
<li>Any economic input into the value chain of creative activities does not merit the grant of a property right. Also, a grant of a neighbouring right to one economic actor cannot be a reason for granting such right to another one. Moreover, the Directive Proposal does not follow any meaningful logic of investment reward, since it proposes to grant rights to any publication, even those that do not involve any substantive investment. For example, publication of any trivial information on a “news website” will be sufficient for the grant of neighbouring rights.</li>
<li>Finally, in any event, if this proposal is ever going to be approved, the scope of protection—extending also to non-commercial uses—and the term of protection are overbroad.</li>
</ul><div> </div>
<div>The CEIPI Opinion is available <a href=""http://www.ceipi.edu/en/news/piece-of-news/?tx_ttnews%5Btt_news%5D=9416&cHash=6d5162a2ffb84d27e79a48f01e12d9e7"">here</a>.</div>
","Copyright and Fair Use, Intermediary Liability",2016-12-06 0:54,505,Giancarlo Frosio,News
14903,,United States,0,0,Using Transparency to Fight Takedown Trolls – A Model from the DMCA,Copyright,"<p>The Internet is full of trolls. So it’s no surprise that notice and takedown systems for online speech attract their fair share of them – people insisting that <a href=""http://arstechnica.com/science/2013/02/site-plagiarizes-blog-posts-then-files-dmca-takedown-on-originals/"">criticism of their scientific research</a>, <a href=""https://www.hrw.org/news/2014/12/15/censorship-ecuador-has-made-it-internet"">videos of police brutality</a>, and other legitimate online speech should be removed from Internet platforms.</p>
<p>In the US, the <a href=""https://www.law.cornell.edu/uscode/text/17/512"">Digital Millennium Copyright Act</a> (DMCA) sets up a notice and takedown system for copyright claims. It’s the only notice and takedown tool our law provides – so it’s used for trollish removal demands, alongside the many legitimate ones submitted by copyright holders. Unless Internet intermediaries like Twitter or Etsy or Google (where I used to work) do a perfect job of identifying which claims are BS, <a href=""http://cyberlaw.stanford.edu/blog/2015/10/empirical-evidence-over-removal-internet-companies-under-intermediary-liability-laws"">legal speech gets removed</a> from the Internet.  </p>
<p>How can we keep that from happening? The DMCA sets up some procedural rules that ought to help, but they fail a lot in practice. Internet users can “counternotice” if their online speech is wrongfully removed – but the process has <a href=""http://cyberlaw.stanford.edu/blog/2017/01/dmca-counter-notice-does-it-work-correct-erroneous-takedowns"">problems</a> and is rarely used. And the DMCA provides penalties for bad faith removal demands – but courts have set such <a href=""http://blog.ericgoldman.org/archives/2015/03/it-takes-a-default-judgment-to-win-a-17-usc-512f-case-automattic-v-steiner.htm"">difficult standards</a> to prove bad faith, few people pursue this remedy either.</p>
<p>In practice, the best tool against DMCA abuse may be the same thing we use for other kinds of hidden misbehavior: public transparency.  It turns out that letting the whole Internet know about content removals can work magic. For one thing, fear of exposure deters some trolls from bothering to try. For another, when bad takedown requests do succeed, transparency crowd-sources the work of finding and correcting them. <a href=""https://en.wikipedia.org/wiki/Linus's_Law"">With enough eyeballs, all bugs are shallow</a>.</p>
<p>The <a href=""https://www.lumendatabase.org"">Lumen Database</a> at Harvard’s Berkman Klein center makes one key part of DMCA transparency easy.  Companies can send Lumen copies of the removal requests they receive, and Lumen will archive them in a public, searchable repository.  This trove of data has enabled an <a href=""https://www.eff.org/document/amicus-brief-chilling-effects"">amazing amount of scholarship</a>, and helped us understand what works – and doesn’t – about the DMCA. Internet platforms can go one important step further by letting users who go looking for online information know when it has disappeared based on a removal request. Twitter does this with its “tweet withheld” <a href=""http://www.digitaltrends.com/social-media/twitter-policy-changes-for-copyright-infringement-claims/"">notices</a> in users’ feeds, for example; and Google does it with notices on its <a href=""http://veilus.com/wp-content/uploads/2016/06/google-removed-search-results.jpg"">search results</a> page.</p>
<p>Of course, Internet users can only spot bad removals if they know what content came down. Mere aggregate data – the kind included in companies’ own <a href=""https://www.accessnow.org/transparency-reporting-index/"">transparency reports</a> -- doesn’t work for that.  If a removal demand lists URLs of content that’s still online, determined users might use a publicized copy of the demand itself to find infringing content. (Though this would presumably be less efficient than more well-trodden paths to piracy.) Some copyright holders have <a href=""https://assets.documentcloud.org/documents/1088118/statement-for-the-record-of-sandra-aistars.pdf"">argued</a> that this risk outweighs the upsides of transparency and public review for DMCA removals.  </p>
<p>Among Internet civil society groups around the world, though, transparency is increasingly discussed as a solution to an array of problems – many going well beyond copyright issues.  At meetings like the <a href=""https://www.intgovforum.org/multilingual/content/igf-2016"">Internet Governance Forum</a>, it’s pretty much common currency that Internet companies should be more transparent about other legal removal demands they comply with around the world, as well as what content they remove under their own policies. And increasingly, civil liberties advocates are asking governments and rightsholders to support transparency as well.  In discussions around the world, I’ve heard suggestions that</p>
<ul><li>In countries where intermediaries are not sure if disclosing removal demands could get them in legal trouble, legal experts and lawmakers should make clear that such disclosures are welcome and protected by law. (Potentially this would include redacting certain personal information, which Lumen already does).</li>
<li>Transparency should be expected from governments or private actors who <em>seek</em> content removal, not just the Internet companies that process their requests.</li>
</ul><p>This kind of transparency has real potential to shine sunlight on over-reaching removals of all sorts. Experience and tools developed in response to the US experience with the DMCA could help combat trollish removals, and protect online speech, around the world. </p>
<p> </p>
","Architecture and Public Policy, Copyright and Fair Use, Intermediary Liability",2017-01-18 5:00,1188,Daphne Keller,News
14905,,United States,0,0,DMCA Counter-Notice: Does It Work to Correct Erroneous Takedowns?,Copyright,"<p><em>This blog post is excerpted from our filing in response to the U.S. Copyright Office's 2016 <a href=""https://www.federalregister.gov/documents/2015/12/31/2015-32973/section-512-study-notice-and-request-for-public-comment"">Notice and Request for Public Comment</a> on notice and takedown practice under the Digital Millennium Copyright Act (DMCA). The entire filing is available <a href=""https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2757197"">here</a>. </em></p>
<p><span style=""color: rgb(51, 51, 51); font-family: calluna-1, calluna-2, Georgia, serif; font-size: 16px; background-color: rgb(241, 241, 241);"">16. How effective is the counter-notification process for addressing false and mistaken assertions of infringement?</span></p>
<p>We have not seen studies or significant public data on this question, though there will be useful information in the study just published by Urban, et al.<a href=""#_ftn1"" name=""_ftnref1"" title="""" id=""_ftnref1""><sup>97</sup></a> Based on our own experience and discussion with other practitioners, we believe that it is rare for users to file counter-notices. Counter-notices certainly appear to be far less common than the improper removals that they are intended to counteract.</p>
<p>A handful of companies track counter-notices in their transparency reports. These companies don’t appear to aggregate the data over time and, in some cases, they track it using non-parallel categories so that comparison is difficult. For example:</p>
<ul><li style=""margin-left: 0.25in;"">Twitter’s transparency report includes counter-notices, though seemingly only for tweets, not for Vine or Periscope material. Twitter’s latest semiannual report says that 56,971 tweets were withheld pursuant to DMCA notice, and the company received counternotices for 65 or 0.11%, all of which led to the restoration of the targeted content.<a href=""#_ftn2"" name=""_ftnref2"" title="""" id=""_ftnref2""><sup>98</sup></a></li>
<li style=""margin-left: 0.25in;"">Tumblr’s June 2015 report states that of the 77,357 posts that were removed pursuant to takedown notices, 0.08% were restored using the counter-notice process.<a href=""#_ftn3"" name=""_ftnref3"" title="""" id=""_ftnref3""><sup>99</sup></a> Tumblr received additional counter-notices that it did not honor, though it is unclear whether those counter-notices were rejected based on substantive copyright problems or formal noncompliance with section 512(g).</li>
<li style=""margin-left: 0.25in;"">Github reports some counter-notices, but counts them in the same category with retracted DMCA notices, reporting 17 counter-notices or retractions out of 258 notices, which may each have identified numerous alleged infringements.<a href=""#_ftn4"" name=""_ftnref4"" title="""" id=""_ftnref4""><sup>100</sup></a></li>
<li style=""margin-left: 0.25in;"">Automattic reports, for its latest data set, that “less than 0.6% of the DMCA notices we received were later subject to a counter-notice; of those cases, we’re aware of further action being taken by the original DMCA complainant only once.”<a href=""#_ftn5"" name=""_ftnref5"" title="""" id=""_ftnref5""><sup>101</sup></a></li>
</ul><p>These tiny percentages are dwarfed by the portion of dubious DMCA removal requests that researchers have identified. (See studies reported in Appendix B [<em>ed note for blog: also <a href=""http://cyberlaw.stanford.edu/blog/2015/10/empirical-evidence-over-removal-internet-companies-under-intermediary-liability-laws"">here</a>]</em>.) Even if the studies are off by an order of magnitude in their estimates, the number of potentially mistaken or malicious notices still vastly exceeds the number of counter-notices.<a href=""#_ftn6"" name=""_ftnref6"" title="""" id=""_ftnref6""><sup>102</sup></a></p>
<p>Importantly, the companies issuing detailed transparency reports may be relatively unique among small intermediaries in their commitment to protecting users and offering them a chance to counter-notice. It is unclear whether the thousands of other companies that have registered DMCA agents with the Copyright Office assume similar costs and inconveniences to provide a viable counter-notice process.</p>
<p>The ineffectiveness of the DMCA counter-notice process may be attributable to a number of causes:</p>
<ul><li style=""margin-left: 0.25in;""><em>Intermediaries do not have significant incentive to bother notifying a user when her content has been removed based on a DMCA notice.</em> The section 512(g) counternotification process refers only to 512(c) hosting providers, not other OSPs (e.g., search engines), for starters. Even for hosts, the only reason to offer counter-notice is to avoid liability to a user for improperly removing that user’s lawful content. But few believe that hosts face any meaningful risk of such liability, regardless of section 512(g). “Wrongful removal” claims against intermediaries in US courts have consistently failed, based on contractual and other defenses.<a href=""#_ftn7"" name=""_ftnref7"" title="""" id=""_ftnref7""><sup>103</sup></a></li>
<li style=""margin-left: 0.25in;""><em>It is not clear how many users actually receive notice that their content has been removed.</em> Not all hosting services tie user-generated content to user email addresses or other contact information. For those that do, users may supply email addresses from temporary or old and unmonitored accounts. It is accordingly difficult to know how many users really find out when their posts have been removed.</li>
<li style=""margin-left: 0.25in;""><em>The counter-notice process is intimidating. </em>Consent to jurisdiction, which is a required element of a counter-notice under section 512(g)(3)(D), is a meaningful legal concession, and is particularly problematic for users who do not reside in the United States. In addition, the 512 section (g)(3)(C) statement under penalty of perjury, while analogous to the similar requirement for the notifier, is likely to be far more intimidating to individual users responding without benefit of counsel. And the cost of error for a user if she is mistaken about her copyright defenses is much higher than the cost of error for a copyright owner who is mistaken about her claims. </li>
</ul><p>Collectively, these factors constitute a meaningful deterrent to counter-notice. The point we make here is not that Congress lacked the intent or policy basis for establishing the detailed hurdles for counter-notifiers in section 512(g). The problem is that, because counter-notice has not been an effective corrective for wrongful notices, section 512(g) alone cannot adequately protect Internet users from having their legal speech removed. For that reason, the other procedural protections for users in section 512, such as form-of-notice requirements and declarations of good faith by copyright owners, play a more important role than Congress may have foreseen. Robust interpretations and enforcement of those protections by the courts and the Copyright Office are critical to maintain the DMCA’s carefully structured balance. A more detailed discussion of these other protections in is included above in response to Question 12.</p>
<p>In (weak) defense of section 512(g), the transparency and expectation of procedural fairness created by the counter-notice process may be acting as a deterrent for some bad faith removal requests. It is possible, however, that the value of counter-notice is far exceeded by the value of public transparency about particular removals, such as those posted through Lumen or noted by the OSP on the page from which content has been removed. This transparency allows the identification of erroneous DMCA notices to be crowd-sourced across interested individuals online. To our knowledge there are no public datasets that would allow us to test this hypothesis.</p>
<p> </p>
<div><br clear=""all"" /><hr align=""left"" size=""1"" width=""33%"" /><div id=""ftn1"">
<p><a href=""#_ftnref1"" name=""_ftn1"" title="""" id=""_ftn1""><sup>97</sup></a> See Jennifer Urban, et al., Notice and Takedown in Everyday Practice (2016), <a href=""https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2755628"">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2755628</a>.</p>
</div>
<div id=""ftn2"">
<p><a href=""#_ftnref2"" name=""_ftn2"" title="""" id=""_ftn2""><sup>98</sup></a>Twitter, Transparency Report, Copyright Notices (2015), <a href=""https://transparency.twitter.com/copyrightnotices/2015/jul-dec"">https://transparency.twitter.com/copyrightnotices/2015/jul-dec</a>.</p>
</div>
<div id=""ftn3"">
<p><a href=""#_ftnref3"" name=""_ftn3"" title="""" id=""_ftn3""><sup>99</sup></a> Tumblr, Copyright and Trademark Transparency Report (2015), <a href=""http://static.tumblr.com/zyubucd/0uWntp2iw/iptransparencyreport2015a_updatedfinal.pdf"">http://static.tumblr.com/zyubucd/0uWntp2iw/iptransparencyreport2015a_upd...</a>.</p>
</div>
<div id=""ftn4"">
<p><a href=""#_ftnref4"" name=""_ftn4"" title="""" id=""_ftn4""><sup>100</sup></a> GitHub, Transparency Report (2014), <a href=""https://github.com/blog/1987-github-s-2014-transparency-report"">https://github.com/blog/1987-github-s-2014-transparency-report</a>.</p>
</div>
<div id=""ftn5"">
<p><a href=""#_ftnref5"" name=""_ftn5"" title="""" id=""_ftn5""><sup>101</sup></a> Automattic, Intellectual Property (2015), <a href=""https://transparency.automattic.com/intellectual-property/intellectualproperty-2015-jul-1-dec-31/"">https://transparency.automattic.com/intellectual-property/intellectualpr...</a>.</p>
</div>
<div id=""ftn6"">
<p><a href=""#_ftnref6"" name=""_ftn6"" title="""" id=""_ftn6""><sup>102</sup></a> This calculation assumes that the rate of counter-notice for the data sets discussed in Appendix B is similar to the rates reported in the transparency data discussed above. We see no reason to expect otherwise.  </p>
</div>
<div id=""ftn7"">
<p><a href=""#_ftnref7"" name=""_ftn7"" title="""" id=""_ftn7""><sup>103</sup></a> See, e.g., Song Fi, Inc. v. Google, Inc., 2015 WL 3624335 (N.D. Cal. June 10, 2015); Lewis v. YouTube LLC, 2015 WL 9480614 (Cal. App. Ct. Dec. 28, 2015); Sikhs for Justice “SFJ,” Inc. v. Facebook, Inc., 2015 WL 7075696 (N.D. Cal. Nov. 13, 2015). </p>
</div>
</div>
<p> </p>
","Copyright and Fair Use, Intermediary Liability",2017-01-17 5:16,1188,Daphne Keller,News
14934,,United States,0,0,Remember That Time We Saved the Internet?,Copyright,"<p>My Twitter feed tells me that today is the fifth anniversary of the day the Internet “went dark” in protest of the Stop Online Piracy Act (SOPA) and the Protect Intellectual Property Act (PIPA). For anyone who needs a reminder, SOPA and PIPA were pieces of copyright legislation touted by their proponents as necessary to prevent online piracy and to protect U.S. jobs in the film, television, and music industries. They required a range of online intermediaries—ad networks, search engines, ISPs, and payment processors—to prevent users from accessing “foreign infringing sites.” Their most controversial provisions required ISPs, through the (mal)functioning of the Domain Name System (DNS), to block access to “foreign infringing sites” that allegedly traffic illegally in copyrighted content.</p>
<p>Back in 2012, online opposition to the two bills mounted quickly as word spread that they required ISPs to blacklist websites. In an open letter to Congress, Google co-founder Sergey Brin and other prominent Internet entrepreneurs asserted that the legislation would give the U.S. government “power to censor the web using techniques similar to those used by China . . . and Iran.” Contributing to and marshaling web-roots resistance, the operators of Wikipedia made the unprecedented decision to shut down in protest for one day—January 18, 2012. In addition to Wikipedia, more than 100,000 Internet companies, including Google, Mozilla, Reddit, and I Can Has Cheezburger (of LOLcats fame), joined the one-day protest. Their forms of protest varied, but their message to their users and fans was unitary: “Petition your elected representatives to oppose these bills.” And petition their representatives people did—in droves. Google reported that 4.5 million people in one day signed its petition opposing SOPA and PIPA. Even the White House came out against them.</p>
<p>My Twitter feed also tells me, or at least strongly implies, that I should celebrate this day as a victory for the Open Internet. I would find that exhortation more compelling if I hadn’t spent the last five years documenting the piecemeal implementation of SOPA and PIPA’s site-blocking and site-starving provisions through privately negotiated “best practices” in anti-piracy and anti-counterfeiting. Many of the intermediaries who would have been compelled to act by SOPA have since voluntarily agreed to do so under pressure from members of Congress and the Executive Branch. Under a series of ""voluntary agreements,"" which the EFF calls “<a href=""https://www.eff.org/issues/shadow-regulation"">shadow regulation</a>,” operators of major online advertising and payment networks have agreed to choke the supply of revenue to alleged pirate site operators in response to notices from copyright and trademark holders, without even the minimal judicial process that SOPA and PIPA would have required. If you’re interested in reading more about these agreements, I’ve written about them at length <a href=""https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2628827"">here</a> and <a href=""https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2494019"">here</a>.</p>
<p>Just last year, two registry operators for new generic Top Level Domains (gTLDs) in the DNS agreed to a domain-blocking protocol that designates the Motion Picture Association of America (MPAA) as a “trusted notifier” for purposes of identifying “pirate sites.” Under the agreement with the MPAA, participating registry operators can cancel or suspend entire second level domains in response to right holder complaints, without first undertaking anything that one would recognize as a fair alternative dispute resolution process. The MPAA responds to concerns about lack of fair process in this program by assuring those who inquire that the program is targeting only “the worst of the worst.” I believe they’re sincere when they say this. But their “trust us” logic flouts the most basic principles of fairness in a system of justice. Fairness isn’t about identifying complainants we think we can trust and then more or less automatically giving them the remedies they want against the parties they identify as bad guys. Fairness is about testing complaints in a neutral forum with a qualified adjudicator, clear substantive rules, clear evidentiary rules, and an opportunity to appeal. The forum needn’t be a public courtroom. Take, for example, the <a href=""http://www.copyrightinformation.org/the-copyright-alert-system/"">Copyright Alert System</a>, which was implemented post-SOPA to adjudicate P2P file-sharing claims arising from residential broadband use. For all of CAS’s <a href=""https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2145059"">shortcomings</a>, its architects made a real effort to ensure a fair and predictable alternative dispute resolution process for accused infringers. The system employed real arbitrators who (ostensibly) applied settled rules of copyright law. I’m not sure what the current status of that program is, because its overseers haven’t done any public reporting about it for years. But it had better bones by far than what the MPAA and its partner DNS registries rolled out last year.  </p>
<p>So, I will celebrate the anniversary of the defeat of SOPA and PIPA today, because I think they were bad bills that grew out of an evidence-free, industry-captured policymaking process. But I won’t get all carried away about how we saved the Internet back in 2012, because much of what SOPA and PIPA would have accomplished has since come about by less transparent means and with even fewer procedural protections for accused wrongdoers. Five years is a century in the life of the Internet. In 2017, the campaign for friction-free online content removal goes far beyond the MPAA and copyrights. Now, the targets are amorphously identified fake news, hate speech, and terrorist content, in addition to piracy and counterfeiting. The roster of powerful complainants is expanding. And the largest intermediaries (Facebook, Microsoft, YouTube, Twitter) are <a href=""http://fortune.com/2016/05/31/hate-speech-code/"">putting up less resistance</a> to categorical takedown demands than they did in the past. The Open Internet still needs saving, and the forces that threaten it now are both more complex and harder to contain than they were in 2012.</p>
","Copyright and Fair Use, Intermediary Liability",2017-01-18 16:23,1046,Annemarie Bridy,News
14962,,International,1,1,"Internet & Jurisdiction's January in Retrospect: fake news in the EU, “toxic” content in Vietnam, and other cases",General,"<div style=""color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">The January 2017 edition of Retrospect is </span><a data-saferedirecturl=""https://www.google.com/url?hl=en&q=http://www.internetjurisdiction.net/publications/retrospect%23eyJmcm9tIjoiMjAxNy0wMSIsInRvIjoiMjAxNy0wMSJ9&source=gmail&ust=1486590489085000&usg=AFQjCNGeOrEFvsQgLUzPvRxBmTio_xHFRQ"" href=""http://www.internetjurisdiction.net/publications/retrospect#eyJmcm9tIjoiMjAxNy0wMSIsInRvIjoiMjAxNy0wMSJ9"" style=""color: rgb(17, 85, 204);"" target=""_blank""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">now available</span></a><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">.</span></div>
<div style=""color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""> </div>
<div style=""line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""><span class=""im"" style=""color: rgb(80, 0, 80); font-family: arial, sans-serif; font-size: 12.8px;""><span style=""font-size: 14.6667px; font-family: Arial; font-weight: 700; font-variant-numeric: normal; white-space: pre-wrap;"">Retrospect</span><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;""> is the flagship, open-access publication of the Internet & Jurisdiction policy network, documenting policy developments, judicial decisions, international agreements, and other cases that reflect jurisdictional tensions on the cross-border internet. Retrospect offers policymakers and other stakeholders a unique tool to monitor emerging trends, stimulate discussions, and ensure that debates are grounded in empirical evidence.</span></span></div>
<div style=""line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""> </div>
<div style=""line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""><span class=""im"" style=""color: rgb(80, 0, 80); font-family: arial, sans-serif; font-size: 12.8px;""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">Each month, concise summaries of most influential cases from around the world are crowd-ranked by the I&J Observatory, a group of leading academic experts, and the top 20 cases are added to the I&J Retrospect Database. The database is the culmination of a diligent process of monitoring, documenting, and synthesizing policy developments that the I&J Secretariat has carried out since 2012. </span></span></div>
<div style=""line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""> </div>
<div style=""line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""><span class=""im"" style=""color: rgb(80, 0, 80); font-family: arial, sans-serif; font-size: 12.8px;""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">Filter your results by actor, issue, and more on the </span><a data-saferedirecturl=""https://www.google.com/url?hl=en&q=http://www.internetjurisdiction.net/publications/retrospect&source=gmail&ust=1486590489085000&usg=AFQjCNH_Bzzei14fHQkemIu4lwMws-wLDA"" href=""http://www.internetjurisdiction.net/publications/retrospect"" style=""color: rgb(17, 85, 204);"" target=""_blank""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; text-decoration: underline; white-space: pre-wrap;"">I&J Retrospect Database</span></a><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">.</span></span></div>
",Intermediary Liability,2017-02-08 11:34,1625,Luiz Fernando Marrey Moncau,News
15059,,United States,0,0,"A Response to Paul Vixie’s ""Notice, Takedown, Borders, and Scale”",Copyright,"<p><em>Late last month, I posted to SSRN a </em><a href=""https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2920805""><em>draft</em></a><em> of my forthcoming article, “Notice and Takedown in the Domain Name System: ICANN’s Ambivalent Drift into Online Content Regulation.” The article takes a close look at ICANN’s role in facilitating a new program of extrajudicial notice and takedown in the DNS for domain names associated with accused “pirate sites.” The program is a cooperative, private venture between Donuts, the registry operator for hundreds of new gTLDs in the DNS, and the Motion Picture Association of America (MPAA). Yesterday, Paul Vixie (Internet engineering legend, now CEO of Farsight Security) posted a </em><a href=""http://www.circleid.com/posts/20170301_notice_takedown_borders_and_scale/#add_comment""><em>critique</em></a><em> of the article on CircleID. In the spirit of having a conversation about what we clearly agree is an important issue for the future of Internet governance and the DNS, I offer this response to Vixie’s post.</em></p>
<p>It’s obvious that Paul Vixie and I differ on whether the implementation of the MPAA/Donuts trusted notifier program represents a success or a failure of the private governance processes associated with administration of the DNS. A central question in this debate is whether a registry operator is a competent authority to pass judgment on the legality of online content and to intervene technically, using its ICANN-delegated control over DNS functions, to disable access to content that it has judged to be illegal or simply ""abusive."" Another important question is whether ICANN should be encouraging or facilitating private content regulation by DNS intermediaries. These are certainly points on which reasonable people of good faith can disagree.</p>
<p>I want to respond to a few specific points in Vixie’s reading of my article that I believe are mistaken or misguided:</p>
<p>(1) Vixie claims that I produced no support for my assertion that “copyright holders appear to be laying the groundwork for a broad program of DNS-based enforcement, with the long-term goal of implementing a UDRP-like procedure for claims of piracy and counterfeiting.” Vixie presents this claim as a “subjective declamation” on my part, with no proffered factual basis. In fact, the sentence Vixie quotes is footnoted, and the accompanying footnote text reads as follows: <em>""See </em><a href=""https://meetings.icann.org/en/marrakech55/schedule/wed-dna-healthy-domains-initiative/transcript-dna-healthy-domains-initiative-09mar16-en.pdf"">Meeting Transcript</a>, MARRAKECH–Industry Best Practices–the DNA's Healthy Domains Initiative, at 13 ('We’re discussing and exploring the idea that there could be a clearinghouse that can include copyright, piracy, and counterfeiting, along with other potential online abusive behavior, and then perhaps developing a new dispute resolution model similar to UDRP.').""</p>
<p>Last week, the Public Interest Registry (PIR) abruptly <a href=""http://domainincite.com/21564-pir-slams-brakes-on-udrp-for-copyright"">pulled back</a> from a plan called the ""Systemic Copyright Infringement Alternative Dispute Resolution Policy” or SCDRP. At around the same time, the Domain Name Association <a href=""http://thedna.org/update-healthy-domain-initiative-recommendations/"">dropped</a> a proposal for copyright alternative dispute resolution from its “Healthy Domains” recommendations. I’m not sure what more or what else Vixie would hope to see in the way of proof that plans are being laid for a UDRP-like procedure for copyright infringement and counterfeiting.</p>
<p>(2) Vixie claims that by identifying the MPAA and its members as “corporate right holders,” I mean to cast an implicit aspersion on them (i.e., by pointing out that they are not “individual right holders”). This is simply untrue. I identify “corporate right holders” as such because they are the ones that have driven the initiative the article addresses, and they are the <em>only</em> right holders that are currently given “trusted” status under the MPAA/Donuts program. I believe the same exclusivity holds for other voluntary enforcement agreements that have been adopted by online intermediaries, including those with online advertising networks and payment processors. As far as I know, individual right holders do not have standing to bring complaints or request sanctions under those agreements.</p>
<p>(3) Vixie suggests that the trusted notifier program is actually intended to operate at scale: “Notice and takedown, at scale, without borders, requires mutual cooperation. And that's what the Trusted Notifier Program is meant to effect.” I’ll note that Donuts has repeatedly made the point that it does <em>not</em> want the program to operate at scale. For example, Donuts has said that it will not accept notices generated by robots, which are now the norm in the world of DMCA takedowns. Donuts has gone out of its way to point out how few takedowns it has executed under the agreement so far.</p>
<p>One of the concerns I raise in the article is what will happen, and what is likely to go wrong, if there are attempts to scale up enforcement in the DNS. To highlight the basis for my concerns, I point to a recent <a href=""https://www.regulations.gov/document?D=COLC-2015-0013-92473"">filing</a> by Google with the United States Copyright Office, which stated that 99.95% (!) of the links identified as infringing by “trusted” partners in its “Trusted Content Removal Program” for search were fabricated and had never appeared in Google’s search index. So much for trust. Vixie portrays takedown at scale in the DNS as something to cheer; I think it’s something to fear. And my fear is empirically grounded in past and current experience with overbroad and abusive takedowns. In the article, I point to some specific historical examples in addition to Google’s recent filing.</p>
<p>Vixie expresses the view that the Internet’s “fish-bowl culture” will somehow prevent misbehavior or overreach by notifiers. I don’t share his optimism, particularly given that neither Donuts nor the MPAA has taken on any binding public reporting obligation with respect to the operation of their trusted notifier agreement. Although Donuts has <a href=""http://www.donuts.domains/donuts-media/blog/the-trusted-notifier-program-summary-of-one-year-of-mpaa-referrals."">reported</a> on the number of referrals it received from MPAA and the number of times it took action on those referrals, it has not reported which specific domains were taken down. Nor has it stated that it will report its takedowns on a continuing, periodic basis.</p>
<p>(4) Vixie expresses discomfort at the prospect that I intended to imply or did imply “that ICANN might be actively trying to divert attention” from the fact that its contracts facilitate agreements like the MPAA/Donuts trusted notifier agreement. I don’t think it’s accurate to say that I implied any dishonesty on ICANN’s part. I do believe—and I explain why in the article—that ICANN’s actions on this front have not been consistent with its words. I don’t impute any nefarious intent with respect to that misalignment. ICANN is a complex and internally diverse organization with many moving parts.</p>
<p>What I actually wrote is that the Domain Name Association, of which Donuts is a member, misses the mark when it characterizes the trusted notifier program as a form of “self-governance” for registry operators. That’s because the obvious regulatory targets of the trusted notifier program are registrants, whose alleged bad behavior the program is aimed at sanctioning. It is true that Donuts came to its agreement with the MPAA voluntarily. The same cannot be said, however, for registrants who are ultimately subject to actions taken under that agreement. I stand by my conclusion that the trusted notifier program is not simply a form of voluntary self-governance by registries but is actually a form of DNS governance in which registries are as much governors of others as they are governors of themselves.</p>
<p> </p>
","Architecture and Public Policy, Copyright and Fair Use, Intermediary Liability",2017-03-03 6:39,1046,Annemarie Bridy,News
15061,,International,1,1,"Internet & Jurisdiction's February in Retrospect: Right to be de-indexed in Japan and France, Blocking Orders in Sweden and Russia, and more",General,"<div class=""field field-name-field-thumbnail field-type-image field-label-hidden"" style=""float: right; margin-top: 1.1em; margin-bottom: 0.6em; margin-left: 1.3em; color: rgb(51, 51, 51); font-family: ""Helvetica Neue"", ""Helvetica Neue"", Helvetica, Arial, sans-serif; font-size: 14px;"">
<div class=""field-items"">
<div class=""field-item even""><a href=""https://cyberlaw.stanford.edu/files/blogimages/I%26J%20stakeholders%20footer%20-%20no%20social.png"" style=""background: transparent; color: rgb(128, 0, 0); transition: all 0.3s; outline: none;""><img alt="""" height=""37"" src=""https://cyberlaw.stanford.edu/files/styles/medium/public/blogimages/I%26J%20stakeholders%20footer%20-%20no%20social.png?itok=Tyx7KlTN"" typeof=""foaf:Image"" width=""250"" /></a></div>
</div>
</div>
<div class=""field field-name-body field-type-text-with-summary field-label-hidden"" style=""color: rgb(51, 51, 51); font-family: ""Helvetica Neue"", ""Helvetica Neue"", Helvetica, Arial, sans-serif; font-size: 14px;"">
<div class=""field-items"">
<div class=""field-item even"" property=""content:encoded"">
<div style=""color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">The February 2017 edition of Retrospect is </span><a href=""http://www.internetjurisdiction.net/publications/retrospect#eyJmcm9tIjoiMjAxNy0wMiIsInRvIjoiMjAxNy0wMiJ9""><span style=""font-size: 14.6667px; background: transparent; color: rgb(17, 85, 204); transition: all 0.3s; outline: none; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">now available</span></a><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">.</span></div>
<div style=""color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""> </div>
<div style=""color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""><span style=""font-family: Arial; font-size: 14.6667px; white-space: pre-wrap;"">This edition brings news about the right to be de-indexed in Japan and France, information about blocking orders in Russia and Sweden, recent developments on voluntary agreements to remove content in Europe, and more.</span></div>
<div style=""color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""> </div>
<div style=""line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""><span class=""im"" style=""color: rgb(80, 0, 80); font-family: arial, sans-serif; font-size: 12.8px;""><span style=""font-size: 14.6667px; font-family: Arial; font-weight: 700; font-variant-numeric: normal; white-space: pre-wrap;"">Retrospect</span><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;""> is the flagship, open-access publication of the Internet & Jurisdiction policy network, documenting policy developments, judicial decisions, international agreements, and other cases that reflect jurisdictional tensions on the cross-border internet. Retrospect offers policymakers and other stakeholders a unique tool to monitor emerging trends, stimulate discussions, and ensure that debates are grounded in empirical evidence.</span></span></div>
<div style=""line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""> </div>
<div style=""line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""><span class=""im"" style=""color: rgb(80, 0, 80); font-family: arial, sans-serif; font-size: 12.8px;""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">Each month, concise summaries of most influential cases from around the world are crowd-ranked by the I&J Observatory, a group of leading academic experts, and the top 20 cases are added to the I&J Retrospect Database. The database is the culmination of a diligent process of monitoring, documenting, and synthesizing policy developments that the I&J Secretariat has carried out since 2012. </span></span></div>
<div style=""line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""> </div>
<div style=""line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;""><span class=""im"" style=""color: rgb(80, 0, 80); font-family: arial, sans-serif; font-size: 12.8px;""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">Filter your results by actor, issue, and more on the </span><a data-saferedirecturl=""https://www.google.com/url?hl=en&q=http://www.internetjurisdiction.net/publications/retrospect&source=gmail&ust=1486590489085000&usg=AFQjCNH_Bzzei14fHQkemIu4lwMws-wLDA"" href=""http://www.internetjurisdiction.net/publications/retrospect"" style=""font-size: 12.8px; background: transparent; color: rgb(17, 85, 204); transition: all 0.3s; outline: none;"" target=""_blank""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; text-decoration: underline; white-space: pre-wrap;"">I&J Retrospect Database</span></a><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">.</span></span></div>
</div>
</div>
</div>
<p> </p>
",Intermediary Liability,2017-03-06 16:14,1625,Luiz Fernando Marrey Moncau,News
15117,,United States,0,0,Amazon’s Kodi Box Ban and Copyright Liability for Device Distributors,Copyright,"<p>Amazon’s latest effort to mitigate IP infringement in its third-party seller program is a ban on the sale of streaming media devices (“Kodi boxes”) that promote piracy. In addition to banning sales of the devices, Amazon reserves the right to destroy any offending physical inventory in its warehouses. The new policy raises not-so-new questions about the ability of copyright holders to control the distribution of dual-use technologies that can (but needn’t necessarily) be used to infringe copyrights. </p>
<p>What, you may be wondering, is a Kodi box? According to <a href=""https://en.wikipedia.org/wiki/Kodi_(software)"">Wikipedia</a>,   </p>
<p style=""margin-left:.5in;"">Kodi (formerly XBMC) is a free and open-source media player software application developed by the XBMC Foundation, a non-profit technology consortium. Kodi is available for multiple operating systems and hardware platforms, with a software 10-foot user interface for use with televisions and remote controls. It allows users to play and view most streaming media, such as videos, music, podcasts, and videos from the internet, as well as all common digital media files from local and network storage media.</p>
<p style=""margin-left:.5in;"">It is a multi-platform home-theater PC (HTPC) application. Kodi is highly customizable: a variety of skins can change its appearance, and various plug-ins allow users to access streaming media content via online services such as Amazon Prime Instant Video, Crackle, Pandora Internet Radio, Rhapsody, Spotify, and YouTube. The later versions also have a personal video-recorder (PVR) graphical front end for receiving live television with electronic program guide (EPG) and high-definition digital video recorder (DVR) support.</p>
<p>In the UK, both copyright holders and the police have been cracking down hard on sellers of Kodi boxes, which are being widely used to pirate streams of live sporting events and just about everything else. As the <em>Birmingham Mail</em> recently <a href=""http://www.birminghammail.co.uk/news/midlands-news/law-using-kodi-legal-illegal-12491422"">reported</a>, “the boxes themselves are, effectively, legal. But realistically, the only reason you would ever want one is it if was bought either pre-loaded or altered in order to watch PPV content.”</p>
<p>On this side of the pond, right holders have a long history of leveraging copyright law and its secondary liability doctrines to try to control the distribution of dual-use technologies like Kodi boxes. The leading case in this area is of course <em>Sony v. Universal</em>, in which Universal sought to ban the distribution of VHS recorders in the early 1980s. In the early 2000s, the major record labels targeted distributors of peer-to-peer file-sharing software, successfully forcing services like Grokster and LimeWire out of business, even as the P2P file-sharing protocols underlying those services have remained legal.   </p>
<p>In <em>Sony</em>, the Supreme Court invoked the staple article of commerce doctrine from patent law and declined to impute to Sony culpable knowledge of VHS users’ infringements. The court reasoned that the machines were capable of substantial non-infringing uses, and Sony had no post-sale relationship to either the machines or their users that could give rise to any knowledge on Sony’s part of particular infringing uses. Accordingly, the Court denied the preliminary injunction Universal sought, and Sony continued to market and sell VHS players to US consumers.</p>
<p>In <em>MGM v. Grokster</em>, by contrast, the Court held that Grokster <em>could</em> be held liable for its users’ infringements, even though the P2P software Grokster distributed could be used for non-infringing purposes. Grokster was found liable because its employees actively encouraged users to infringe copyrights. This has come to be known as the inducement standard for secondary copyright infringement by device distributors.</p>
<p>Streaming media boxes, like their VHS and P2P ancestors, are dual-use articles of commerce. Amazon’s newly announced policy for regulating their sale appears to have been derived from <em>Grokster</em>’s inducement standard:</p>
<p style=""margin-left:.5in;"">Products offered for sale on Amazon should not <em>promote, suggest the facilitation of, or actively enable the infringement</em> of or unauthorized access to digital media or other protected content. Any streaming media player or other device that violates this policy is prohibited from sale on Amazon.</p>
<p style=""margin-left:.5in;"">It is your responsibility to source and sell products that do not <em>promote, promise the facilitation of, or actively enable the infringement </em>of or unauthorized access to digital media or other protected content. If you sell these products, we may immediately suspend or terminate your selling privileges and destroy inventory in our fulfillment centers without reimbursement. In addition, if we determine that your account has been used to engage in fraud or other illegal activity, remittances and payments may be withheld or forfeited.</p>
<p>The Amazon standard is technology protective insofar as it doesn’t ban the sale of Kodi boxes outright. That’s a good thing. I do worry a little, however, about the clarity of the language that defines the scope of prohibited activity. Specifically, the phrases “suggesting facilitation of infringement” and “actively enabling infringement” depart from the case law in ways that make their meaning hard to pin down. Distinguishing ""active"" from ""passive"" behavior can be especially tricky in copyright cases involving intermediaries and new technologies. I hope that Amazon has some clear internal guidance for the employees who will be implementing this new policy.</p>
","Copyright and Fair Use, Intermediary Liability",2017-03-31 16:20,1046,Annemarie Bridy,News
15121,,International,1,1,"Internet & Jurisdiction's March in Retrospect: Intermediary Liablity in Germany and Sweden, Requests to be De-Indexed in Europe, Fake News, and more",General,"<div class=""field field-name-body field-type-text-with-summary field-label-hidden"" style=""color: rgb(51, 51, 51); font-family: ""Helvetica Neue"", ""Helvetica Neue"", Helvetica, Arial, sans-serif; font-size: 14px;"">
<div class=""field-items"">
<div class=""field-item even"" property=""content:encoded"">
<div style=""margin-top: 0pt; margin-bottom: 0pt; color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38;""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">The March 2017 edition of Retrospect is </span><a href=""http://www.internetjurisdiction.net/publications/retrospect#eyJ0byI6IjIwMTctMDMifQ==""><span style=""font-size: 14.6667px; background: transparent; color: rgb(17, 85, 204); transition: all 0.3s; outline: none; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">now available</span></a><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">.</span></div>
<div style=""margin-top: 0pt; margin-bottom: 0pt; color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38;"">
<div class=""field field-name-field-thumbnail field-type-image field-label-hidden"" style=""float: right; margin-top: 1.1em; margin-bottom: 0.6em; margin-left: 1.3em; color: rgb(51, 51, 51); font-family: ""Helvetica Neue"", ""Helvetica Neue"", Helvetica, Arial, sans-serif; font-size: 14px;"">
<div class=""field-items"">
<div class=""field-item even""><a href=""https://cyberlaw.stanford.edu/files/blogimages/I%26J%20stakeholders%20footer%20-%20no%20social.png"" style=""background: transparent; color: rgb(128, 0, 0); transition: all 0.3s; outline: none;""><img alt="""" height=""37"" src=""https://cyberlaw.stanford.edu/files/styles/medium/public/blogimages/I%26J%20stakeholders%20footer%20-%20no%20social.png?itok=Tyx7KlTN"" typeof=""foaf:Image"" width=""250"" /></a></div>
</div>
</div>
</div>
<div style=""margin-top: 0pt; margin-bottom: 0pt; color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38;""> </div>
<div style=""margin-top: 0pt; margin-bottom: 0pt; color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38;""><span style=""font-family: Arial; font-size: 14.6667px; white-space: pre-wrap;"">This edition brings news about Intermediary Liability in Germany and Sweden, a decision on a request to be-indexed Europe, developments on how plataforms are being pressured to tackle ""fake"" content, and more.</span></div>
<div style=""margin-top: 0pt; margin-bottom: 0pt; color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38;""> </div>
<div style=""margin-top: 0pt; margin-bottom: 0pt; line-height: 1.38;""><span class=""im"" style=""color: rgb(80, 0, 80); font-family: arial, sans-serif; font-size: 12.8px;""><span style=""font-size: 14.6667px; font-family: Arial; font-weight: 700; font-variant-numeric: normal; white-space: pre-wrap;"">Retrospect</span><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;""> is the flagship, open-access publication of the Internet & Jurisdiction policy network, documenting policy developments, judicial decisions, international agreements, and other cases that reflect jurisdictional tensions on the cross-border internet. Retrospect offers policymakers and other stakeholders a unique tool to monitor emerging trends, stimulate discussions, and ensure that debates are grounded in empirical evidence.</span></span></div>
<div style=""margin-top: 0pt; margin-bottom: 0pt; line-height: 1.38;""> </div>
<div style=""margin-top: 0pt; margin-bottom: 0pt; line-height: 1.38;""><span class=""im"" style=""color: rgb(80, 0, 80); font-family: arial, sans-serif; font-size: 12.8px;""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">Each month, concise summaries of most influential cases from around the world are crowd-ranked by the I&J Observatory, a group of leading academic experts, and the top 20 cases are added to the I&J Retrospect Database. The database is the culmination of a diligent process of monitoring, documenting, and synthesizing policy developments that the I&J Secretariat has carried out since 2012. </span></span></div>
<div style=""margin-top: 0pt; margin-bottom: 0pt; line-height: 1.38;""> </div>
<div style=""margin-top: 0pt; margin-bottom: 0pt; line-height: 1.38;""><span class=""im"" style=""color: rgb(80, 0, 80); font-family: arial, sans-serif; font-size: 12.8px;""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">Filter your results by actor, issue, and more on the </span><a data-saferedirecturl=""https://www.google.com/url?hl=en&q=http://www.internetjurisdiction.net/publications/retrospect&source=gmail&ust=1486590489085000&usg=AFQjCNH_Bzzei14fHQkemIu4lwMws-wLDA"" href=""http://www.internetjurisdiction.net/publications/retrospect"" style=""color: rgb(17, 85, 204); font-size: 12.8px; background: transparent; transition: all 0.3s; outline: none;"" target=""_blank""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; text-decoration: underline; white-space: pre-wrap;"">I&J Retrospect Database</span></a><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">.</span></span></div>
<div> </div>
</div>
</div>
</div>
<p> </p>
",Intermediary Liability,2017-04-07 10:09,1625,Luiz Fernando Marrey Moncau,News
15122,,United States,0,0,Is Bad News for LiveJournal Bad News for the DMCA Safe Harbors? (Post 1 of 3),Copyright,"<p>The Ninth Circuit has decided <a href=""http://caselaw.findlaw.com/us-9th-circuit/1856011.html""><em>Mavrix Photographs v. LiveJournal</em></a>, and the outcome is in every respect bad news for LiveJournal. In some respects, it’s also bad for the safe harbors themselves, as I’ll explain below and in subsequent posts. The district court in the case granted summary judgment for LiveJournal on grounds that there were no material factual disputes concerning LiveJournal’s eligibility for safe harbor under Section 512(c) of the DMCA. Mavrix alleged that LiveJournal infringed copyrights in its watermarked photographs. Users submitted the photos to LiveJournal along with celebrity gossip news items, and the site's moderators posted them following a fairly intensive screening process (including screening for copyright infringement). There was no question in the case that LiveJournal complied with the DMCA’s notice and takedown requirements when it received notices from right holders. However, Mavrix did not send notices for any of the photos in suit. LiveJournal removed the photos when Mavrix filed its complaint.</p>
<!--break-->
<p>Depending on how you count, there were six issues on appeal, all related to LiveJournal’s safe-harbor eligibility: (1) whether LiveJournal’s unpaid moderators were its agents, so that any knowledge they may have had of specific infringements could be attributed to LiveJournal; (2) whether the allegedly infringing photos appeared on LiveJournal’s website “at the direction of users” (vs. on LiveJournal’s own initiative), which is a requirement for safe harbor under Section 512(c); (3) whether, in the absence of takedown notices, LiveJournal had actual or red flag knowledge that the photos were infringing; (4) whether LiveJournal had the right and ability to control the infringements, as evidenced by the required “something more” than the right to remove or block access to infringing material; (5) whether Mavrix financially benefited from infringements that it had the right and ability to control; and, finally, (6) whether the district court erred in denying Mavrix’s motion to compel production of the identity of the moderators who screened the posts at issue in the case.</p>
<p>This case is important to the growing body of DMCA case law for the large number of discrete issues it addresses relating to the application and scope of the safe harbors. I’ll focus on issue (2) in this post and on issues (3) and (4) in two subsequent posts. These three issues are the ones that I believe will be most relevant in future cases. I’ll say in passing that I think the court’s analysis of agency—issue (1)—is correct. As the court describes LiveJournal’s operations, the platform’s moderators play a significant enough role in its curation process, and LiveJournal’s relationship to its moderators is sufficiently “thick,” to justify further inquiry on that issue. With respect to the court’s vacatur of the district court’s denial of the motion to compel—issue (6)—I think the court has gotten that right, too. If <em>(but only if)</em> the moderators are found on remand to be LiveJournal’s agents, discovering what they subjectively knew about the alleged infringements will be necessary to determine LiveJournal’s knowledge or lack thereof. If the moderators who screened the posts containing Mavrix’s photos are LiveJournal’s agents, I don’t see how LiveJournal's knowledge could be determined without their testimony.</p>
<p align=""center""><u>Issue 2: Were the posts “at the direction"" of users?</u></p>
<p>The court begins its discussion of this issue with an incorrect description of the different activities covered by the different safe harbors. It then goes on to misapply its own precedent—<em>UMG Recordings v. Shelter Capital Partners</em>. This part of the opinion is highly problematic, and it’s a good candidate for rehearing <em>en banc</em> considering how it might reverberate in future cases. The court’s reasoning on this issue undermines the safe harbors for all sites that use moderators to screen and curate user-submitted content before posting it, including the world’s largest platforms—Facebook, Twitter, and YouTube. Such curation is precisely what Congress encouraged when it enacted Section 230 of the Communications Decency Act. In this era of rampant online harassment, “fake news,” and revenge porn, it seems especially misguided for a court to interpret the DMCA in a way that could discourage human moderation of user-submitted content.</p>
<p>According to the court, the section 512(a) safe harbor covers users’ <em>submission</em> of material to providers, and section 512(c) covers the providers’ subsequent <em>posting </em>of that material to their sites. There is no such submission-posting distinction in section 512. On the face of the statute and in the legislative history, it’s quite clear that section 512(a) is meant to cover user-initiated, end-to-end routing of information across a provider’s network. A residential broadband access provider is the paradigmatic section 512(a) provider. Section 512(c) covers hosting providers like LiveJournal that receive, store, and provide public access to stored user-generated content. To characterize LiveJournal as a hybrid 512(a)/512(c) provider misapplies the statute and introduces into the case law a wrongheaded distinction between submitting and posting material.</p>
<p>Putting aside the peculiar submission-posting dyad, the dispositive question concerning LiveJournal’s eligibility for the section 512(c) safe harbor is whether the site’s moderator-curated, user-submitted posts occur “at the direction of users,” taking into consideration the nature of moderators’ review and the fact that only about one-third of user submissions are ultimately posted. That question can be answered entirely within the ambit of section 512(c) and the existing case law interpreting it, including the Ninth Circuit’s own decision in <em>Shelter Capital</em>. There was simply no need for the court to invoke section 512(a) in this case.</p>
<p><em>Shelter Capital</em> held that a provider can undertake “accessibility-enhancing” activities that go beyond storage without surrendering the storage safe harbor in section 512(c). Included among these permissible, “storage-plus” activities are active behaviors like transcoding and displaying user-uploaded files. The nub of the “storage-plus” inquiry is when it is no longer fair to say in light of a provider’s post-upload actions that material appearing on the provider’s site appears there “at the direction of users” (versus on the initiative of the provider itself).</p>
<p>To my mind, this is a much simpler question to answer in LiveJournal’s case than the court makes it out to be. If a user submits material to a website with the intention that it be posted, and the material is ultimately posted, that posting should be held to have occurred “at the direction” of the user, regardless of what the provider did between the time the material was submitted and the time it was posted. The fact that a provider culls user-submitted material does not alter the fact that all users who submit material to the provider, including those whose material is ultimately posted, are in effect directing the provider to post their material. For a curated site, sometimes the provider heeds the user’s direction, and sometimes it doesn’t. But the existence of <em>discarded</em> user-submitted material does not undermine the proposition that <em>posted</em> user-submitted material was posted “at the direction” of the users who submitted it. It was therefore correct for the district court to conclude as a matter of law that LiveJournal was not disqualified from the storage safe harbor by virtue of its moderators’ review and curation of user-submitted posts. The Ninth Circuit was wrong to reverse on this issue and has created uncertainty where none existed before.</p>
<p>Concluding that the court erred on this point is not to say, however, that LiveJournal’s activities in relation to user-submitted material are irrelevant to the safe harbor analysis. On the contrary, what a provider does between the time a user submits material and the time that material is posted—assuming it’s posted—may give rise to knowledge of specific infringements that disqualifies the provider from safe harbor. The court’s analysis of actual and red flag knowledge under the DMCA will be the subject of my next post in this series.</p>
","Copyright and Fair Use, Intermediary Liability",2017-04-09 8:38,1046,Annemarie Bridy,News
15123,,United States,0,0,Is Bad News for LiveJournal Bad News for the DMCA Safe Harbors? (Post 2 of 3),Copyright,"<p>This is the second of three posts on the Ninth Circuit’s decision in <a href=""http://caselaw.findlaw.com/us-9th-circuit/1856011.html""><em>Mavrix v. LiveJournal</em></a>. The first <a href=""https://cyberlaw.stanford.edu/blog/2017/04/bad-news-livejournal-bad-news-dmca-safe-harbors-post-1-3"">post</a> considered (and found fault with) the court’s conclusion that LiveJournal’s moderation and curation of user-submitted posts created a triable issue of fact on the question of the site’s eligibility for the section 512(c) safe harbor for sites that store material “at the direction” of users. This post will consider the court’s analysis of issue (3) of the six issues I called out in the first post: whether, in the absence of takedown notices, LiveJournal had actual or red flag knowledge that the watermarked Mavrix photos were infringing.</p>
<!--break-->
<p align=""center""><u>Issue 3: Did LiveJournal have actionable knowledge of the infringing photos?</u></p>
<p>As a condition for eligibility, the safe harbors require service providers to remove material that they either actually know or should know from surrounding facts or circumstances (i.e., “red flags”) to be infringing. In <em>Viacom v. YouTube</em>, the Second Circuit interpreted red flag knowledge under the DMCA to mean a provider’s subjective awareness of facts or circumstances from which specific instances of infringement would be objectively obvious to a reasonable person. The red flag standard is a mixed subjective/objective one that requires courts to assess what a hypothetical reasonable person should be able to discern in light of the facts in front of her. The Ninth Circuit adopted <em>Viacom</em>’s formulation of the mixed standard in <em>UMG Recordings v. Shelter Capital </em>and <em>Columbia Records v. Fung</em>.</p>
<p>In order for red flag knowledge to arise, “the infringement must be immediately apparent to a non-expert.” That rule comes from the district court’s opinion in <em>UMG Recordings v. Veoh Networks—</em>later re-captioned as <em>Shelter Capital</em>, following Veoh’s bankruptcy. More recently, the Second Circuit in <em>Capitol Records v. Vimeo</em> held that red flag knowledge must be assessed from the perspective of an ordinary tech company employee/agent “not endowed with specialized knowledge or expertise concerning [a specific category or body of copyrighted works] or the laws of copyright.” I read the Second Circuit’s rule in <em>Vimeo</em> as a more detailed articulation of the rule from <em>Veoh</em> that the perspective from which red flag knowledge must be assessed is that of a non-expert in both factual and legal matters concerning copyright.</p>
<p>The Ninth Circuit’s analysis of the knowledge issue in this case begins with the observation that Mavrix’s failure to send DMCA takedown notices for the photos in suit deprived it of the most compelling evidence it could have produced that LiveJournal had actual knowledge of the alleged infringements. The district court cited the absence of DMCA notices and held that LiveJournal consequently lacked actual knowledge of the infringements as a matter of law. The Ninth Circuit’s opinion concludes that this was error, because actual knowledge can come from sources other than DMCA notices. The court remanded on this issue for deposition testimony from the moderators who processed the posts in suit, apparently assuming that those individuals will be found to be LiveJournal’s agents after full analysis of the agency issue. If the moderators turn out to be LiveJournal’s agents, and they had subjective knowledge that the specific photos in suit were infringing, then Mavrix’s failure to send DMCA notices is not fatal to its claim that LiveJournal didn't do what the DMCA requires. Given that LiveJournal's moderators were charged with screening for copyright infringement as part of their intake and review process for photos, it seems plausible to me that individual moderators could have had actual knowledge of infringement with respect to specific photos. Remand on the issue of actual knowledge therefore seems appropriate.</p>
<p>The red flag knowledge question is thornier than actual knowledge, as it always is. The inquiry involves an assessment of what would be obvious to a reasonable person, and reasonableness very often ends up being a jury question. Cases in which the plaintiff asserts that the defendant had red-flag knowledge of infringement are often unsuitable for disposition on summary judgment. I have argued <a href=""https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2710341"">elsewhere</a> that the red flag standard is a structural weakness in the DMCA framework because it injects a high degree of uncertainty into a legislative scheme that was designed to give copyright holders and online service providers clear, systematic guidance for safe harbor compliance. This case perfectly illustrates the problem, inasmuch as LiveJournal complied faithfully with the DMCA’s notice and takedown requirements but has nevertheless been exposed to expensive litigation and substantial, uncertain damages.</p>
<p>The potential red flags in this case were watermarks visible on the face of the uploaded photos. Some of the photos featured, in the words of the court, a ""generic"" watermark; others were marked with “Mavrixonline.com.” In the Ninth Circuit’s view, contra the district court, “[t]he existence of a watermark, and particularly a watermark with a company name, is relevant to the knowledge inquiry.” Applying the standard from <em>Veoh</em>/<em>Shelter Capital</em>, the question with red flag knowledge is not whether the watermarks are relevant to the knowledge inquiry but whether the presence of the watermarks on the photos should have made it ""immediately apparent to a non-expert"" that the photos were infringing. This strikes me as doubtful. The presence of a watermark on a photo can, but does not necessarily, convey that the person who placed the watermark did so for the purpose of asserting copyright in it. For example, in the market for stock photos, when an image advertised with a watermark is licensed, the licensor will often provide the licensee with a clean, unmarked version of the image file. In that context, the mark seems to be a tacit (though not explicit) assertion of copyright. In other circumstances, however, photos are posted with watermarks not as a tacit assertion of rights but as an indicator of origin, specifically which website was first to post the photo. This happens in the case of ""spy"" shots for new models of cars, which at least some photographers actually expect and want to be shared, albeit with the built-in attribution that comes with a watermark. Given the different messages that watermarks can convey and the absence in this case of a copyright symbol or the word ""copyright"" from the watermarks, it seems a reach to say that infringement would have been immediately apparent to a hypothetical non-expert moderator. It would have been easy enough for Mavrix to incorporate a copyright symbol or the word ""copyright"" into its watermarks. If it had done that, the message it sought to convey (i.e., that the images were protected by copyright and were not to be copied without permission) would have been more plausibly ""immediately apparent.""</p>
<p>By failing to apply the <em>Veoh/Shelter Capital</em> red flag standard more rigorously to the facts of this case, the Ninth Circuit has expanded the reach of red flag knowledge and thereby narrowed the scope of the safe harbors. Whether LiveJournal's individual moderators, assuming they were LiveJournal's agents, had actual knowledge that individual Marvrix photos were infringing is an appropriate question to put to a jury. It should not, however, be for the jury to decide red flag knowledge in this case, given the nonobviousness of the message that Marvrix's watermarks convey.</p>
<p> </p>
","Copyright and Fair Use, Intermediary Liability",2017-04-10 11:56,1046,Annemarie Bridy,News
15135,,United States,0,0,Is Bad News for LiveJournal Bad News for the DMCA Safe Harbors? (Post 3 of 3),Copyright,"<p>This is the last of three posts on the Ninth Circuit’s decision in <em><a href=""http://caselaw.findlaw.com/us-9th-circuit/1856011.html"">Mavrix v. LiveJournal</a></em>. The first <a href=""https://cyberlaw.stanford.edu/blog/2017/04/bad-news-livejournal-bad-news-dmca-safe-harbors-post-1-3"">post</a> considered the court’s conclusion that LiveJournal’s moderation and curation of user-submitted posts created a triable issue of fact on the question of the site’s eligibility for the section 512(c) safe harbor for sites that store material “at the direction” of users. The second <a href=""https://cyberlaw.stanford.edu/blog/2017/04/bad-news-livejournal-bad-news-dmca-safe-harbors-post-2-3"">post</a> examined the court’s analysis of LiveJournal’s potential knowledge of the alleged infringements in light of the fact that Mavrix didn’t send takedown notices for them. This final entry takes a look at what I identified in the first post as issue (4): whether LiveJournal had the right and ability to control the infringements, as evidenced by the required “something more” than the right to remove or block access to user-submitted infringing material.</p>
<!--break-->
<p align=""center""><u>Issue 4: Did LiveJournal do “something more” that demonstrates its control over its users’ infringements?</u></p>
<p>To be eligible for safe harbor, a provider can’t receive a direct financial benefit from infringing activity that it has the right and ability to control. This condition appears on its face to incorporate the common law test for vicarious copyright infringement into the safe harbor framework. In <em>Fonovisa v. Cherry Auction</em>, a pre-Internet premises liability case, the Ninth Circuit held that a swap meet operator had the right and ability to control its vendors’ infringements because its contract with vendors gave it the right to patrol the venue for infringing material and to expel vendors caught in the act of selling pirated sound recordings.</p>
<p>Adapting the premises cases to the online environment, and specifically to site operators that claim safe harbor under the DMCA, the Ninth and Second Circuits have both held that disqualification from the safe harbor must entail “something more” in the way of control by an accused site operator than the pre-Internet cases require. This higher standard is necessary when interpreting the control element in the context of the DMCA because the safe harbors are conditioned on providers’ engaging in the very behaviors (i.e., terminating access for infringers and getting rid of infringing material) that would give rise to liability under the physical premises precedents. It would make no sense, the courts have held (see <em>Viacom </em>and <em>Shelter Capital</em>), to disqualify a provider from safe harbor for being able to do—and doing—the very things it <em>has</em> to do to qualify for safe harbor in the first place. To give effect to Congressional intent that the safe harbors provide protection from all types of copyright liability—including vicarious—courts have read section 512(c)(2)’s control element to require “something more” on the provider’s part than the ability to terminate infringers and block access to infringing content.</p>
<p>In <em>Viacom</em>, which the Ninth Circuit cited approvingly in <em>Shelter Capital</em>, the Second Circuit noted that the requirement of “something more” could be satisfied through behaviors amounting to intentional inducement of infringement under the Supreme Court’s decision in <em>MGM v. Grokster</em>. The court went on to say, however, that the “something more” threshold could be met by something less than outright inducement. The focus of the inquiry must be whether the provider has exerted “substantial influence on the activities of its users.”</p>
<p>The district court in this case held that LiveJournal did not exercise enough control over users and their submissions to satisfy the “something more” standard. The Ninth Circuit disagreed, remanding for reconsideration in light of facts in the record concerning LiveJournal’s “extensive” moderation practices and its fairly elaborate rules governing user submissions. Some of those rules were directed specifically to copyright infringement, including a prohibition on copying from sources that had previously complained to LiveJournal about infringement. LiveJournal also automatically blocked user submissions containing material from a specific site from which it had received a cease and desist letter. The court directed the trial court to consider on remand “LiveJournal’s extensive review process, infringement list, and blocker tool.” In light of cases like <em>Viacom</em> and <em>Shelter Capital </em>and their discussions of what “something more” might look like, I think the Ninth Circuit was right to remand on this issue.</p>
<p>As I wrote in my first post, LiveJournal shouldn’t lose safe harbor in this case because it didn’t post content “at the direction of users.” It plainly did act at users’ direction, because all of the content it posted <em>came from users</em>. Under existing DMCA case law, however, LiveJournal could lose safe harbor because it had too heavy a hand in influencing what its users directed it to do. The question is whether that influence was “substantial.” LiveJournal does seem to have channeled the efforts and interests of its users to a degree that isn’t typical of platforms that have previously qualified for safe harbor. And its lines of authority were not entirely clear with respect to its relationship to its community moderators, as the case’s dispute over agency makes clear. For good or ill from a policy perspective, the safe harbors include a version of the rule from common law that links control over third parties with liability for their bad actions. The more control a provider exercises over the actions of its users and the content of their submissions, the greater the risk of liability. The outcome in this case reinforces that policy.</p>
","Copyright and Fair Use, Intermediary Liability",2017-04-12 8:13,1046,Annemarie Bridy,News
15200,European Union,,0,0,The “Right to Be Forgotten” and National Laws Under the GDPR,Right to Be Forgotten,"<p>The EU’s new General Data Protection Regulation (GDPR) will come into effect in the spring of 2018, bringing with it a newly codified version of the “Right to Be Forgotten” (RTBF).  Depending how the new law is interpreted, this right could prove broader than the “right to be de-listed” established in 2014’s <em>Google Spain</em> case.  It could put even more decisions about the balance between privacy and free expression in the hands of private Internet platforms like Google. National lawmakers have an opportunity to shape the platforms’ processes, and to ensure that both privacy and expression rights get a fairer hearing. This post reviews the issues. Another post, <a href=""https://cyberlaw.stanford.edu/blog/2017/05/gdpr-and-national-legislation-relevant-articles-private-platform-adjudication-%E2%80%9Cright-be"">here</a>, lists eight specific GDPR articles that affect RTBF de-listings and erasures. </p>
<p>The GDPR’s “erasure” provision says that data controllers can reject some RTBF claims if necessary to protect expression and information rights. (Art. 17.3) Individual EU Member States are responsible for fleshing out this exception, providing national laws to reconcile the GDPR with free expression and information rights. (Art. 85) They can also adopt legislation about the specific RTBF articles in order to protect both data subjects and “the rights and freedoms of others.” (Art. 23.1(i)) Any such adjustments in national law must be necessary and proportionate, in accordance with fundamental rights defined in the EU <a href=""http://www.europarl.europa.eu/charter/pdf/text_en.pdf"">Charter</a> and European <a href=""https://rm.coe.int/CoERMPublicCommonSearchServices/DisplayDCTMContent?documentId=0900001680063765"">Convention</a>.</p>
<p>RTBF laws primarily affect two fundamental rights: the data subject’s right to privacy, and other people’s rights to seek and impart information. National laws define the scope of information rights, and help determine which interest should prevail for any given RTBF request. Those laws can also protect procedural fairness when RTBF claims conflict with the interests of publishers and ordinary Internet users. Without adequate procedural protections, these Internet users will almost certainly find their online expression erased or de-listed in more cases than the GDPR’s drafters or national legislators intended.</p>
<p>National laws addressing this and other aspects of the GDPR are being drafted now. (If you read this by May 10, 2017, you can respond to the UK’s <a href=""https://www.gov.uk/government/consultations/general-data-protection-regulation-call-for-views"">Call for Views</a> on its legislation.) Lawmakers should take this opportunity to protect citizens’ information and expression rights under the private notice-and-takedown process for RTBF requests.</p>
<p>I explore the GDPR’s new RTBF rules in detail in my new <a href=""https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2914684"">article</a>, focusing on the nuts and bolts – the operational steps that private platforms like Google are supposed to carry out when “adjudicating” RTBF requests.  Like civil or criminal procedural rules in a court, these matter a lot. Must a claimant make a particular showing of fact, or provide particular information, before a platform must honor her RTBF request? Is the affected Internet user notified or consulted? Who can appeal the platform’s decision, and under what circumstances?  Procedural questions like these can determine the real-world outcome of RTBF requests when platforms, regulators, or courts balance privacy and information rights.</p>
<p><a href=""http://cyberlaw.stanford.edu/blog/2015/10/empirical-evidence-over-removal-internet-companies-under-intermediary-liability-laws"">Research</a> and common sense tell us that when platforms face legal trouble for failing to remove user expression, they are likely to remove too much. Claimants consistently ask platforms to remove more information than the law requires: studies <a href=""http://cyberlaw.stanford.edu/blog/2016/04/dmca-classic-dmca-turbo-major-new-empirical-research-notice-and-takedown-operations"">say</a> that 38% of copyright removal requests to Google Image Search raise invalid legal claims; <a href=""https://www.google.com/transparencyreport/removals/europeprivacy/"">Google</a> and <a href=""https://www.microsoft.com/about/csr/transparencyhub/crrr/"">Bing</a> both report that over 50% of RTBF requests do as well. But as the studies show, platforms often err on the side of caution, taking down lawful or lawfully processed information. Incentives to play it safe and simply comply with RTBF requests are strong under the GDPR, which permits penalties as high as 4% of annual global turnover or €20 million.  (Art. 83) National law should account for this dynamic, putting procedural checks in place to limit over-removal by private platforms. Civil society recommendations like the <a href=""manilaprinciples.org"">Manila Principles</a> offer a menu of options for doing just this. For example, the law can penalize people (or <a href=""http://www.forbes.com/sites/ericgoldman/2013/07/23/the-latest-insidious-tactic-to-scrub-online-consumer-reviews/#70cb4b6d7dde"">businesses</a>, <a href=""https://www.hrw.org/news/2014/12/15/censorship-ecuador-has-made-it-internet"">governments</a>, or <a href=""https://www.eff.org/deeplinks/2008/09/massive-takedown-anti-scientology-videos-youtube"">religious organizations</a>) if they abuse notice-and-takedown to target other people’s lawful expression. </p>
<p>The GDPR does not provide meaningful procedural barriers to over-removal. In many cases, it appears to strongly tilt the playing field in favor of honoring even dubious RTBF requests – like ones Google <a href=""https://www.google.com/transparencyreport/removals/europeprivacy/"">received</a> from priests trying to hide sexual abuse scandals, or financial professionals who wanted their fraud convictions forgotten.</p>
<p>Better and more balanced GDPR interpretations are possible, but realistic avenues to make those interpretations part of accepted law are rare: individuals whose rights are affected by RTBF removals will not have the opportunity to ask DPAs or courts to clarify the law, and the platforms will generally not have the incentive to do so. That makes proactive clarification by lawmakers or regulators important, to reduce platforms’ incentives to simply erase or de-list information upon request.</p>
<p>This post will not try to set forth specific legislative interventions under any country’s national law, but will identify key concerns arising from the GDPR’s new RTBF provisions. Each is explored in more detail in the <a href=""https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2914684"">article</a>.</p>
<p><u>Will Facebook and Other Social Media Platforms Have to Honor RTBF Requests?</u></p>
<p>This is a key question, with no clear answer in current law or in the GDPR (though interesting <a href=""https://inforrm.wordpress.com/2017/01/20/the-facebook-ireland-cases-intermediary-liability-and-defences-under-the-e-commerce-regulations-part-1-the-judgments-aidan-wills/"">litigation</a> on point is brewing Northern Ireland). Litigating this issue is a risky choice for platforms, because if a DPA or court decides the platform is a data controller for user generated content, the platform must take on extensive -- and expensive -- new legal obligations, in addition to RTBF compliance. For small or risk-averse platforms, simply complying with RTBF requests is far safer and easier.</p>
<p>Applying RTBF to platforms like Facebook, Dailymotion, or Twitter would be a big deal for Internet users’ expression and information rights. RTBF in its current form under <em>Google Spain</em> only covers search engines, and only requires “de-listing” search results – meaning that users will not see certain webpage titles, snippets, and links when they search for a data subject by name. Regulators have said that the RTBF is reconcilable with information and expression rights precisely <em>because</em> information is only de-listed, and not removed from the source page. But if social media or other hosts had to honor RTBF requests, much of the information they erased would not merely be harder to find – it would be truly gone. For ephemeral expression like tweets or Facebook posts, that might mean the author’s only copy is erased. The same could happen to cloud computing users or bloggers like artist Dennis Cooper, who <a href=""http://www.sciencealert.com/google-has-deleted-an-artist-s-blog-with-14-years-of-his-work"">lost 14 years of creative output</a> when Google abruptly terminated his Blogger account.</p>
<p>Expanding the list of private platforms that must accept and adjudicate RTBF requests would directly affect users’ expression and information rights. But it is hard to pinpoint quite which GDPR articles speak to this issue. Is it purely a question of who counts as a controller under the GDPR’s definitions (Art. 4)? Might it be, as I have argued <a href=""http://cyberlaw.stanford.edu/blog/2016/11/global-right-be-forgotten-delisting-why-cnil-wrong"">in other contexts</a>, a question about the scope of objection and erasure rights (Arts. 17 and 21)? Do national expression and information rights shape a platform’s “responsibilities, powers and capabilities” under the <em>Google Spain</em> ruling (para. 38)? These are difficult questions. The answers will, in a very real way, affect the expression and information rights that Member State legislatures are charged with protecting.</p>
<p><u>Will Ordinary Internet Users and Publishers Have Redress if Their Expression is Wrongfully Erased or De-Listed? </u></p>
<p><span style=""font-size: 13.008px;"">The Article 29 Working Party has said that search engines generally shouldn’t tell webmasters about de-listings, and the Spanish DPA recently </span><a href=""https://inforrm.wordpress.com/2017/03/21/communicating-responsibilities-the-spanish-dpa-targets-googles-notification-practices-when-delisting-personal-information-david-erdos/"" style=""font-size: 13.008px;"">fined</a><span style=""font-size: 13.008px;""> Google €150,000 for doing so.  The data protection logic here is understandable. When a data subject tells a controller to stop processing her data, it seems perverse for the controller to instead process it </span><em style=""font-size: 13.008px;"">more</em><span style=""font-size: 13.008px;""> by communicating with other people about it.</span></p>
<p>But excluding the publisher or speaker from the platforms’ behind-closed-doors legal decisions puts a very heavy thumb on the scales against her. It effectively means that one private individual (the person asserting a privacy right) can object to a platform’s RTBF decision and seek review, while the other private individual or publisher (asserting an expression right) cannot.  Other procedural details of the GDPR tilt the balance further. For example, a platform can reject a RTBF request that is “manifestly unfounded,” but only if the platform itself – which likely has little knowledge about or interest in the information posted by a user – assumes the burden of proof for this decision. (Art. 12.5)</p>
<p>This lopsided approach may be sensible for ordinary data erasure requests, outside the RTBF context. When a data subject asks a bank or online service to cancel her account, the power imbalance between the individual and the data controller may justify giving her some procedural advantages. But RTBF requests add important new rights and interests to the equation: those of other Internet users. Procedural rules should not always favor the data subject over other private individuals.</p>
<p>A similar imbalance occurs in the public process for reviewing platforms’ RTBF decisions. Data subjects   can “appeal” the platforms’ decisions to government institutions – DPAs – which are charged with helping them. Internet users whose expression is de-listed or erased generally have no regulators on their side. Even in courts, data subjects have clear standing to enforce their rights, while people whose expression has been erased or de-listed likely do not.</p>
<p>Tilting the scales so strongly in favor of one party would be harmless if private platforms decided every RTBF request correctly. Far too many public discussions about RTBF seem to turn on the idea that they will – that “Google is doing a good job.” I used to be on the inside of Google’s RTBF de-listing process, and I believe they are trying hard. But that’s not the same as always getting it right. And since DPA review only happens when a data subject wants <em>more</em> de-listing, there is no public correction mechanism for cases where Google actually should de-list <em>less</em>. Whatever we think of Google and Bing’s work in this area, we certainly should not expect similar efforts and expenditures from smaller and less wealthy platforms, if RTBF obligations are extended to them. Absent better procedural rules, we should expect over-removal.</p>
<p><u>Will <em>All</em> the GDPR Provisions About Personal Data Really Apply to Publicly Shared Information? </u></p>
<p><span style=""font-size: 13.008px;"">Internet platforms and data protection law have always been an odd fit.  For example, it is not clear what basis Google as a data controller has for processing “sensitive” data, such as celebrity pregnancy gossip, from indexed websites. (The CJEU will soon hear a case on this general question.) Rules governing data controllers often seem to be designed for databases and other kinds of “back-end” processing, not for the public exchange of information. But under </span><em style=""font-size: 13.008px;"">Google Spain</em><span style=""font-size: 13.008px;""> and in the GDPR, databases and public expression are governed by the same rules.</span></p>
<p>Under the GDPR, one odd result comes from provisions requiring controllers to tell data subjects “from which source the personal data [about them] originate” and “any available information as to their source[.]” (Arts.  14.2(f) and 15.1(g)) Applied to Google, this would seem to mean RTBF claimants can learn whatever the company knows about the webmaster whose page is targeted by the RTBF request. That could be anything from the webmaster’s communications with the company to the contents of her Gmail account. Similarly, if Twitter were deemed a controller for tweets, it seemingly would have to freely disclose the identity of anonymous speakers. Surely this was not the intention of the GDPR’s drafters. But it is hard to find grounds for other interpretations in the GDPR.</p>
<p>As another example, if the “accuracy of the personal data is contested by the data subject,” then the controller must restrict public access to the data “for a period enabling the controller to verify [its] accuracy.” (Art. 18.1(a)) If Twitter were a controller, for example, it might have to delete tweets on this basis – unless the platform itself could somehow prove that users’ tweets are truthful. This would seemingly displace existing defamation law, along with the notice-and-takedown rules under laws like the eCommerce Directive or the UK’s carefully calibrated 2013 <a href=""https://www.theregister.co.uk/2013/11/21/uk_defamation_law_reforms_take_effect_from_start_of_2014/"">Defamation Act</a>. Then again… maybe that’s <em>not</em> what the GDPR means. The “restriction” requirement has an unclear exception “for the protection of the rights of another natural or legal person,” which might excuse compliance when expression or information rights are on the line.  That’s the kind of thing that lawmakers can make clear – so users are not dependent on the platforms to adopt an interpretation that protects their rights.</p>
<p><u>Conclusion</u></p>
<p>The examples discussed here are just a starting point. My longer <a href=""https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2914684"">article</a> lays out more, and suggests specific legal fixes that lawmakers could adopt. For example, they could commit up front not to assess fines against platforms that, in good faith, reject RTBF requests. This could considerably ease pressures on small platforms to comply with improper requests. Options like this should be on the table as lawmakers weigh their powers and responsibilities to protect information and expression rights under the GDPR. </p>
","Architecture and Public Policy, Intermediary Liability, Privacy",2017-04-27 8:59,1188,Daphne Keller,News
15202,European Union,,0,0,Copyright Liability for Streaming Box Distributors: A Comparative EU-US Perspective,Copyright,"<p>“Loaded” Kodi set-top boxes are back in the copyright news again this week. (If you’re wondering what Kodi boxes are, and what they have to do with copyrights, here’s a <a href=""https://cyberlaw.stanford.edu/blog/2017/03/amazon%E2%80%99s-kodi-box-ban-and-copyright-liability-device-distributors"">backgrounder</a>.) The CJEU has decided <em><a href=""http://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A62015CN0527"">BREIN v. Wullems</a></em>, a case involving the rights of communication to the public and reproduction. The plaintiff, BREIN, is a Dutch trade association representing copyright holders including the film and recording industries. The defendant, Jack Wullems, built and sold a multimedia streaming device called the Filmspeler. Wullems loaded Filmspeler boxes with third-party add-ons to Kodi that enabled users to easily access websites streaming copyrighted programming without authorization from right holders. Wullems advertised the Filmspeler as providing free and easy access to copyrighted content.    </p>
<p>The primary question in the case was whether the sale of the Filmspeler was a “communication to the public” of the copyrighted works streamed illegally through the box. The court’s opinion opens with a description of the Filmspeler as “a device which acts as a medium between…a source of visual and/or sound data and...a television screen.” Some of that “data,” according to the court, was provided with authorization from copyright holders, and some wasn’t—making the Filmspeler a dual-use device.</p>
<p>To a reader of the CJEU’s opinion who is familiar with the US cases on copyright liability for device distributors, the description of the Filmspeler as a dual-use technology suggests that the appropriate doctrinal framework for legal analysis is that of secondary liability. The relevant US Supreme court cases are <em>Sony v. Universal</em> and <em>MGM v. Grokster</em>. In those cases, plaintiffs pursued claims of contributory and vicarious infringement against device distributors based on alleged acts of direct infringement by users.</p>
<p>That, however, is not how the CJEU approached the analysis of Wullems’s liability—a point of divergence between EU and US copyright law that makes for an interesting comparative analysis. (In a post on the case over at <a href=""http://ipkitten.blogspot.com/2017/04/filmspeler-right-of-communication-to.html"">IPKat</a>, Eleonora Rosati reminds readers that secondary liability has not been formally harmonized at the EU level and that not all EU Member States recognize it.) The CJEU approached the question of communication to the public as one of direct infringement, where the putatively infringing act was the sale of the Filmspeler to the public:</p>
<p style=""margin-left:.5in;"">Must Article 3(1) of Directive 2001/29 be interpreted as meaning that there is “a communication to the public” within the meaning of that provision, when someone sells a product (multimedia player) in which he has installed add-ons containing hyperlinks to websites on which copyright-protected works, such as films, series and live broadcasts are made directly accessible, without the authorisation of the right holders?</p>
<p>The court answered this question in the affirmative, explaining that “’communication to the public’ must be interpreted broadly” in light of the objectives of the EU InfoSoc Directive. In reaching its conclusion, the court pointed out that Wullems did more than merely provide consumers with equipment—“physical facilities for enabling or making a communication”—which would not be considered “communication” within the meaning of the Directive.</p>
<p style=""margin-left:.5in;"">Mr Wullems, with full knowledge of the consequences of his conduct, pre-installs onto the ‘filmspeler’ multimedia player that he markets add-ons that specifically enable purchasers to have access to protected works published—without the consent of the copyright holders of those works—on streaming websites and enable those purchasers to watch those works on their television screens…. That intervention enabling a direct link to be established between websites broadcasting counterfeit works and purchasers of the multimedia player, without which the purchasers would find it difficult to benefit from those protected works, is quite different from the mere provision of physical facilities.</p>
<p>The court went on to conclude that the communication in question was “to the public” as that requirement has been interpreted in previous CJEU case law.</p>
<p>Had this case been decided under US copyright law, <em>Sony</em> and <em>Grokster</em> would have guided the analysis. Under US law, the sale of a dual-use device cannot on its own give rise to liability, because, as the Supreme Court wrote in <em>Grokster</em>, <em>Sony</em> “absolves the equivocal conduct of selling an item with substantial lawful as well as unlawful uses, and limits liability to instances of more acute fault than the mere understanding that some of one’s products will be misused.” Clarifying what “more acute fault” could entail, the Supreme Court held in <em>Grokster</em> that “one who distributes a device with the object of promoting its use to infringe copyright, as shown by clear expression or other affirmative steps taken to foster infringement, is liable for the resulting acts of infringement by third parties.” With this rule, the Supreme Court imported patent law’s inducement theory of secondary liability into copyright law.</p>
<p>Under <em>Sony</em> and <em>Grokster</em>, the sale of the Filmspeler on its own would not give rise to liability. However, Wullems’s marketing efforts for the Filmspeler, which apparently highlighted access to infringing material as a selling point, would likely meet the <em>Grokster</em> standard for inducement to infringe. For there to be inducement liability, however, there must be an underlying direct infringement that the defendant’s conduct induced. The interesting question in this case is whose direct infringement Wullems can be said to have induced. The potential direct infringers in this case are the Filmspeler’s users and the operators of the websites to which the Filmspeler’s Kodi add-ons provided access. Arguably, the former are not infringers at all, and the latter were not induced by Wullems to infringe.</p>
<p><strong>Are Filmspeler users direct infringers?</strong> The CJEU held in this case that a user’s reception of an infringing program stream violates the right of reproduction under the InfoSoc Directive. It’s not clear to me, however, that applying US law on the right of reproduction would yield the same result. For a temporary, buffer copy of a work to implicate the right of reproduction under US law, the copy must satisfy both embodiment and duration requirements. (See <em>Cartoon Networks v. CSC Holdings.</em>) I’m not sure whether Kodi’s streaming architecture creates sufficiently persistent copies of streamed programs to satisfy the duration requirement. That’s a technical and factual question that the CJEU’s decision doesn’t provide enough detail to answer.</p>
<p><strong>Are the linked website operators direct infringers?</strong> The answer to this question under US law is almost surely yes. The unauthorized delivery of a copyrighted program stream infringes the right holder’s public performance right. (See<em> ABC v. Aereo</em>.) The problem here for BREIN under US law would be that Wullems didn’t really induce the site operators to infringe. They would be doing what they do with or without Wullems providing links to their sites through Kodi add-ons in the Filmspeler.</p>
<p>It could be, then, that inducement is the obvious <em>but wrong</em> secondary liability theory in this case—because the induced were most likely not infringers, and the infringers were most likely not induced. Good old-fashioned contributory infringement may be a better fit. If Wullems knew that copyrights in specific programs were being infringed by the site operators to which the Kodi add-ons linked—for example, if he advertised that specific copyrighted programs could be viewed using the Filmspeler—and if he materially assisted “pirate site” operators by building the Filmspeler to channel users to their sites, then he would be contributorily liable under US law for the site operators’ direct infringements.</p>
","Copyright and Fair Use, Intermediary Liability",2017-04-29 17:05,1046,Annemarie Bridy,News
15203,European Union,,0,0,The GDPR and National Legislation:  Relevant Articles for Private Platform Adjudication of “Right to Be Forgotten” Requests,Right to Be Forgotten,"<p align=""center""> </p>
<p><span style=""font-size: 13.008px;"">In a recent </span><a href=""http://cyberlaw.stanford.edu/blog/2017/04/%E2%80%9Cright-be-forgotten%E2%80%9D-and-national-laws-under-gdpr"" style=""font-size: 13.008px;"">blog post</a><span style=""font-size: 13.008px;"">, I discuss the role of EU Member State laws in defining and enforcing the “Right to Be Forgotten” (RTBF) under the EU’s new General Data Protection Regulation (GDPR). I talk about these GDPR provisions in more detail in my forthcoming </span><a href=""https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2914684"" style=""font-size: 13.008px;"">article</a><span style=""font-size: 13.008px;"">. Because in the future RTBF may be applied to hosting services like Facebook or Dailymotion, I discuss potential consequences for them as well as search engines.</span></p>
<p><span style=""font-size: 13.008px;"">This post lists key GDPR articles that are relevant for this kind of Member State legislation. It doesn’t attempt to analyze the scope of Member State authority, beyond noting where the GDPR states that some authority exists.</span></p>
<p><u>Article 85 – general protections for expression and information rights</u></p>
<p>Article 85 states that Member States “shall by law reconcile the right to the protection of personal data pursuant to this Regulation with the right to freedom of expression and information[.]” One way the laws can do so in the RTBF context is through substantive guidance: identifying factors that weigh for or against erasure and de-listing when platforms assess RTBF requests.  Another way is through procedural protections: identifying what legal checks and balances can protect legitimate online expression, in the face of platforms’ strong incentives to simply honor all RTBF requests, even legally groundless ones. As a practical matter, procedural constraints may be just as important as substantive ones in protecting Internet users’ rights under privately operated “notice-and-takedown” systems.</p>
<p><u>Article 23 – restrictions on specified GDPR articles</u></p>
<p>Article 23 gives Member States authority to “restrict by way of a legislative measure the scope of the obligations and rights” when “such a restriction respects the essence of the fundamental rights and freedoms and is a necessary and proportionate measure[.]” Authorized purposes for national laws of this sort include “the protection of the data subject or the rights and freedoms of others.” The expression and information rights of Internet users affected by RTBF requests are important “rights and freedoms of others” affected by the GDPR.  These rights are very directly affected by GDPR articles 17, 18, and 21, which will be the most important rules governing platforms’ decisions to erase or block public access to information.</p>
<p>            <u>Article 17 - right to erasure</u></p>
<p style=""margin-left:.5in;"">Article 17, along with Article 21, provides the basis for RTBF requirements. They are analogues of Articles 12 and 14 of the 1995 Data Protection Directive – the articles the CJEU applied in <em><a href=""http://curia.europa.eu/juris/liste.jsf?num=C-131/12"">Google Spain</a></em> and more recently in <em><a href=""http://curia.europa.eu/juris/liste.jsf?language=en&num=C-398/15"">Manni</a></em>. GDPR Article 17.3 specifies that controllers need not honor erasure requests that conflict with expression and information rights.  Important issues that may be governed by Article 17 include potential RTBF obligations for Internet platforms like Facebook; the scope of free expression exceptions; and procedural protections for online speakers wrongly targeted by “Right to Be Forgotten” requests. These are discussed in depth in my article.</p>
<p style=""margin-left:.5in;""><u>Article 21 – right to object</u></p>
<p style=""margin-left:.5in;"">The article 21 “objection” right is the other core basis for RTBF claims. Controllers must honor objections unless they have “compelling legitimate grounds for the processing which override the interests, rights and freedoms of the data subject[.]” As the CJEU recently emphasized regarding the current objection right, national legislation is intended to provide exceptions to balance out this right in particular cases. (Manni par. 47)</p>
<p style=""margin-left:.5in;""><u style=""font-size: 13.008px;"">Article 18 – right to restriction of processing</u></p>
<p style=""margin-left:.5in;"">Article 18 sets forth a newly detailed right of data subjects: the right to require data controllers to “restrict” or suspend processing of personal data. In the RTBF context this seems to let claimants take information offline before a platform actually assesses the merits of their claim. Data subjects may request this if they allege that data is inaccurate (Art. 18.1(a)) or otherwise not legitimately processed. (Art. 18.1(d)). However, controllers may reject these requests “for the protection of the rights of another natural or legal person.”  Lawmakers could avert considerable mischief by telling platforms that this exception covers RTBF requests to remove public online information – in effect, that in order to protect the rights of other Internet users, platforms should not  take information or links off the Internet before carefully assessing whether the RTBF claim against them is legitimate.</p>
<p><span style=""font-size: 13.008px;"">Some other GDPR provisions that States may modify under their Article 23 powers are relevant to RTBF claims in more subtle ways.</span></p>
<p>            <u>Article 12 – communications between controller and data subject</u></p>
<p style=""margin-left:.5in;"">Article 12 provides that where requests made under certain articles (including the erasure, restriction, and objection provisions in Arts 17, 18, and 21) are “manifestly unfounded or excessive,” a controller may “refuse to act on the request.” In this case, the controller shall “bear the burden of demonstrating the manifestly unfounded or excessive character of the request.” (Art. 12.5) Legal clarification about what requests may be deemed “manifestly unfounded or excessive” could help protect Internet users against over-reaching RTBF demands.</p>
<p style=""margin-left: 0.5in; font-size: 13.008px;""><u style=""font-size: 13.008px;"">Article</u><u style=""font-size: 13.008px;"">s 14 and 1</u><u style=""font-size: 13.008px;"">5</u></p>
<p style=""margin-left:.5in;"">These articles should not have much bearing on RTBF requests, and it is unlikely that their drafters had RTBF in mind. But they create a disturbing possibility for motivated parties to intimidate online speakers or infringe on those individuals’ data protection rights. These articles require controllers to tell data subjects “from which source the personal data [about them] originate” and “any available information as to their source[.]” (Arts.  14.2(f) and 15.1(g)) Applied to public information platforms, this would seem to mean disclosing personal information about online speakers, including anonymous ones. For example, the data indexed by Google originates with individual webmasters or authors. These people may be Google account-holders, in which case Google’s “available information” about them may be very extensive -- and private. Should Google have to disclose such information under Articles 14 and 15? Similarly, personal data contained in tweets or Facebook posts comes from users of those platforms – if the platforms were deemed controllers, these speakers’ information could seemingly also be subject to disclosure.</p>
<p><u>Article 83 – Fines assessed by Data Protection Agencies (DPAs)</u></p>
<p>The GDPR permits high administrative fines, but only where those fines will be “effective, proportionate and dissuasive.” At 83.8, it specifies that DPAs assessing fines “shall be subject to appropriate procedural safeguards in accordance with Union and Member State law, including effective judicial remedy and due process.” This could provide a foundation for Member States to insist on procedural safeguards that protect both data subjects’ privacy rights and other Internet users’ information and expression rights. </p>
<p> </p>
","Architecture and Public Policy, Intermediary Liability, Privacy",2017-05-01 14:57,1188,Daphne Keller,News
15213,,International,1,1,"Internet & Jurisdiction's April in Retrospect: Blocks in Turkey, Russia and Iran, Hate Speech Bill in Debate in Germany, and More.",General,"<div style=""margin-top: 0pt; margin-bottom: 0pt; color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38;""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">The April 2017 edition of Retrospect is </span><a href=""http://www.internetjurisdiction.net/publications/retrospect#eyJmcm9tIjoiMjAxNy0wNCIsInRvIjoiMjAxNy0wNCJ9"" style=""font-size: 12.8px; background: transparent; color: rgb(128, 0, 0); transition: all 0.3s; outline: none;""><span style=""font-size: 14.6667px; background: transparent; color: rgb(17, 85, 204); transition: all 0.3s; outline: none; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">now available</span></a><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">.</span></div>
<div style=""margin-top: 0pt; margin-bottom: 0pt; color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38;"">
<div class=""field field-name-field-thumbnail field-type-image field-label-hidden"" style=""float: right; margin-top: 1.1em; margin-bottom: 0.6em; margin-left: 1.3em; color: rgb(51, 51, 51); font-family: ""Helvetica Neue"", ""Helvetica Neue"", Helvetica, Arial, sans-serif; font-size: 14px;"">
<div class=""field-items"">
<div class=""field-item even""><a href=""https://cyberlaw.stanford.edu/files/blogimages/I%26J%20stakeholders%20footer%20-%20no%20social.png"" style=""background: transparent; color: rgb(128, 0, 0); transition: all 0.3s; outline: none;""><img alt="""" height=""37"" src=""https://cyberlaw.stanford.edu/files/styles/medium/public/blogimages/I%26J%20stakeholders%20footer%20-%20no%20social.png?itok=Tyx7KlTN"" typeof=""foaf:Image"" width=""250"" /></a></div>
</div>
</div>
</div>
<div style=""margin-top: 0pt; margin-bottom: 0pt; color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38;""> </div>
<div style=""margin-top: 0pt; margin-bottom: 0pt; color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38;""><span style=""font-family: Arial; font-size: 14.6667px; white-space: pre-wrap;"">This edition brings news about blocks in Turkey, Russia and Iran, developments of a legislative effort to tackle hate speech in Germany, protests agains the extraterritorial application of requests to be de-indexed in France, and more.</span></div>
<div style=""margin-top: 0pt; margin-bottom: 0pt; color: rgb(34, 34, 34); font-family: arial, sans-serif; font-size: 12.8px; line-height: 1.38;""> </div>
<div style=""color: rgb(51, 51, 51); font-family: ""Helvetica Neue"", ""Helvetica Neue"", Helvetica, Arial, sans-serif; font-size: 14px; margin-top: 0pt; margin-bottom: 0pt; line-height: 1.38;""><span class=""im"" style=""color: rgb(80, 0, 80); font-family: arial, sans-serif; font-size: 12.8px;""><span style=""font-size: 14.6667px; font-family: Arial; font-weight: 700; font-variant-numeric: normal; white-space: pre-wrap;"">Retrospect</span><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;""> is the flagship, open-access publication of the Internet & Jurisdiction policy network, documenting policy developments, judicial decisions, international agreements, and other cases that reflect jurisdictional tensions on the cross-border internet. Retrospect offers policymakers and other stakeholders a unique tool to monitor emerging trends, stimulate discussions, and ensure that debates are grounded in empirical evidence.</span></span></div>
<div style=""color: rgb(51, 51, 51); font-family: ""Helvetica Neue"", ""Helvetica Neue"", Helvetica, Arial, sans-serif; font-size: 14px; margin-top: 0pt; margin-bottom: 0pt; line-height: 1.38;""> </div>
<div style=""color: rgb(51, 51, 51); font-family: ""Helvetica Neue"", ""Helvetica Neue"", Helvetica, Arial, sans-serif; font-size: 14px; margin-top: 0pt; margin-bottom: 0pt; line-height: 1.38;""><span class=""im"" style=""color: rgb(80, 0, 80); font-family: arial, sans-serif; font-size: 12.8px;""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">Each month, concise summaries of most influential cases from around the world are crowd-ranked by the I&J Observatory, a group of leading academic experts, and the top 20 cases are added to the I&J Retrospect Database. The database is the culmination of a diligent process of monitoring, documenting, and synthesizing policy developments that the I&J Secretariat has carried out since 2012. </span></span></div>
<div style=""color: rgb(51, 51, 51); font-family: ""Helvetica Neue"", ""Helvetica Neue"", Helvetica, Arial, sans-serif; font-size: 14px; margin-top: 0pt; margin-bottom: 0pt; line-height: 1.38;""> </div>
<div style=""color: rgb(51, 51, 51); font-family: ""Helvetica Neue"", ""Helvetica Neue"", Helvetica, Arial, sans-serif; font-size: 14px; margin-top: 0pt; margin-bottom: 0pt; line-height: 1.38;""><span class=""im"" style=""color: rgb(80, 0, 80); font-family: arial, sans-serif; font-size: 12.8px;""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">Filter your results by actor, issue, and more on the </span><a data-saferedirecturl=""https://www.google.com/url?hl=en&q=http://www.internetjurisdiction.net/publications/retrospect&source=gmail&ust=1486590489085000&usg=AFQjCNH_Bzzei14fHQkemIu4lwMws-wLDA"" href=""http://www.internetjurisdiction.net/publications/retrospect"" style=""font-size: 12.8px; background: transparent; color: rgb(17, 85, 204); transition: all 0.3s; outline: none;"" target=""_blank""><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; text-decoration-line: underline; white-space: pre-wrap;"">I&J Retrospect Database</span></a><span style=""font-size: 14.6667px; font-family: Arial; font-variant-numeric: normal; white-space: pre-wrap;"">.</span></span></div>
<div style=""color: rgb(51, 51, 51); font-family: ""Helvetica Neue"", ""Helvetica Neue"", Helvetica, Arial, sans-serif; font-size: 14px;""> </div>
",Intermediary Liability,2017-05-08 12:15,1625,Luiz Fernando Marrey Moncau,News
15267,,United States,0,0,First Amendment’s Outward Creep Makes It Harder to Hold Platforms Accountable,Freedom of Expression,"<p>Today, the <em><a href=""https://www.stanfordlawreview.org/print/article/expanding-the-periphery-and-threatening-the-core/"">Stanford Law Review </a></em><a href=""https://www.stanfordlawreview.org/print/article/expanding-the-periphery-and-threatening-the-core/"">published</a> my very first single-authored publication, “Expanding the Periphery and Threatening the Core: The Ascendant Libertarian Speech Tradition.” This <a href=""https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2921745"">article</a> contributes to the legal scholarly literature about the rise in the mid-to-late twentieth century of increasingly diverse and dissonant First Amendment claims, especially by corporations, specifically showing that there is a theoretical component at work both justifying and generating this expansion. This descriptive element is coupled with a normative argument (more on that later); essentially, I explain that the doctrine’s outward creep is really, really harmful to the core principles of free expression theory.  </p>
<p>But this article also speaks directly to concerns of those working in the academic and policy fields of media, culture, and communication. As the first JD/PhD between Stanford Law School and Stanford’s Communication Department, the point of my scholarship and policy work is to speak to both worlds, to show how they are intertwined, and to argue that solutions to some of our most pressing social problems are best solved by leveraging tools from both disciplines. Let me explain how this article matters to the community of scholars and policymakers in media, culture, and communication.</p>
<p>At first cut, the article shows how, at the level of free expression theory, expanding the scope of the speech and press doctrines to encompass commercial speech and corporate political spending as speech (e.g. <em>Citizens United</em>) was undergirded by a new and heretofore unidentified speech theory, which I call the “libertarian tradition.” The libertarian tradition threatens to undermine free expression theory’s core commitments and purposes. Those are twofold. First, the republican tradition emphasizes free expression as a social good and underscores the “public” in our conception of public communication (think Alexander Meiklejohn). Second, the liberal tradition focuses on individual liberty, emphasizing our autonomy interests in expression (think John Stuart Mill). Though these two traditions are sometimes in tension, they can co-exist.  </p>
<p>But the libertarian tradition – which I show not only justifies the Supreme Court’s expansion of the speech and press doctrines to include corporate speech, but also is generative of its outward creep – perverts both longstanding traditions. It undermines the republican tradition by purporting to vindicate listeners’ rights in the free flow of information (i.e. they have a right to receive advertising, so we should strike down laws restricting that). Corporate benefit was supposed to be incidental. But by narrowly conceptualizing listeners as individuals whose interests are aligned with corporate speech interests, the Court ended up instrumentalizing listeners’ rights in the service of corporate speech rights. Ultimately, listeners’ rights as a justification for corporate speech has been abandoned entirely (as in the case of Internet service providers or ISPs claiming a speech interest in the transmission of data to argue that net neutrality is unconstitutional; no bother with listeners’ rights there). This perversion of listeners’ rights should concern anyone who has a stake in an audience-centered (as opposed to speaker-centered) theory of expression or is otherwise concerned with the public purposes of private speech. Additionally, the libertarian tradition undermines the liberal tradition by focusing on vindicating corporate speech rights, stripping away the hallmarks of individual autonomy. The result is a naked speech right against the state, which I call “thin autonomy.”</p>
<p>Understanding how the theory of speech and press expansionism operates matters for two reasons relevant to media, culture, and communication scholars. First, the fact that these types of arguments have become even more potent and unbridled today should be a cautionary tale to anyone who’s interested in the possibility of regulating speech-y or press-like entities, like Facebook or Twitter. (As I mentioned in the context of ISPs arguing against net neutrality, corporations more broadly have dropped the listeners’ rights justification, and courts are going along with it.) In this constitutional law landscape, it’s going to be *much* easier for these companies to make increasingly compelling First Amendment arguments – the output of our algorithm is protected speech, our search engine’s search results are protected First Amendment activity (yes, <a href=""http://volokh.com/wp-content/uploads/2012/05/SearchEngineFirstAmendment.pdf"">Eugene Volokh and Donald M. Falk</a> have already argued that one for Google), and so forth – thereby potentially evading publicly interested regulations.</p>
<p>Second, my paper offers a path to resist this trend. It has seemed necessary, nearly inevitable to civil libertarians that we must protect speech with which we disagree, perhaps <em>especially </em>if we disagree with it. Isn’t that evidence of how resilient our First Amendment is and how well our democracy is working? At some point, I argue, the answer is no. But it’s no precisely <em>because</em> we care about the core commitments of the theory of free expression, which limitless expansion will dilute beyond recognition.</p>
<p>So, for those folks doing great work trying to understand the responsibilities of huge private companies and platforms that dominate our public sphere, and who care about the integrity of listeners’ rights, this article is for you. My work shows how listeners’ rights have been diluted in the Court’s doctrine (something you might want to fix). My work should help you see the risks of certain arguments for regulating these companies (watch out for constitutional landmines) and suggests strategies for counterargument (preserving the integrity of free expression theory). These are the problems I’ll be tackling next, but they’re going to take an army of scholars – especially those willing to engage both communities of law and communication.</p>
","Architecture and Public Policy, Intermediary Liability",2017-05-23 23:11,428,Morgan Weiland,News